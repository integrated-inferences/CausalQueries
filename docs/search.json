[{"path":"/articles/1 getting-started.html","id":"make-a-model","dir":"Articles","previous_headings":"","what":"Make a model","title":"Getting Started","text":"Generating: make model need provide DAG statement make_model. instance \"X->Y\" \"X -> M -> Y <- X\" \"Z -> X -> Y <-> X\". Graphing: made model can inspect DAG:  Inspecting: model set parameters default distribution . Tailoring: features can edited using set_restrictions, set_priors set_parameters. example setting monotonicity restriction (see ?set_restrictions ): example setting monotonicity restriction (see ?set_restrictions ): example setting priors (see ?set_priors ): Simulation: Data can drawn model like :","code":"# examples of models xy_model <- make_model(\"X -> Y\") iv_model <- make_model(\"Z -> X -> Y <-> X\") plot(iv_model) xy_model |> grab(\"parameters_df\") |> kable() iv_model <-    iv_model |> set_restrictions(decreasing('Z', 'X')) iv_model <-    iv_model |> set_priors(distribution = \"jeffreys\") #> No specific parameters to alter values for specified. Altering all parameters. data <- make_data(iv_model, n = 4)   data |> kable()"},{"path":"/articles/1 getting-started.html","id":"model-updating","dir":"Articles","previous_headings":"","what":"Model updating","title":"Getting Started","text":"Updating: Update using update_model. can pass rstan arguments update_model. Inspecting: can access posterior distribution model parameters directly thus: row draw parameters.","code":"df <- fabricatr::fabricate(N = 100, X = rbinom(N, 1, .5), Y = rbinom(N, 1, .25 + X*.5))  xy_model <-    xy_model |>    update_model(df, refresh = 0) xy_model |> grab(\"posterior_distribution\") |>    head() |> kable()"},{"path":"/articles/1 getting-started.html","id":"query-model","dir":"Articles","previous_headings":"","what":"Query model","title":"Getting Started","text":"Querying: ask arbitrary causal queries model. Examples unconditional queries: Examples conditional queries: Queries can even conditional counterfactual quantities. probability positive effect given effect:","code":"xy_model |>    query_model(\"Y[X=1] > Y[X=0]\", using = c(\"priors\", \"posteriors\")) |>   kable() xy_model |>    query_model(\"Y[X=1] > Y[X=0]\", using = c(\"priors\", \"posteriors\"),               given = \"X==1 & Y == 1\") |>   kable() xy_model |>    query_model(\"Y[X=1] > Y[X=0]\", using = c(\"priors\", \"posteriors\"),               given = \"Y[X=1] != Y[X=0]\") |>   kable()"},{"path":"/articles/1-getting-started.html","id":"make-a-model","dir":"Articles","previous_headings":"","what":"Make a model","title":"Getting Started","text":"Generating: make model need provide DAG statement make_model. instance \"X->Y\" \"X -> M -> Y <- X\" \"Z -> X -> Y <-> X\". Graphing: made model can inspect DAG:  Inspecting: model set parameters default distribution . Tailoring: features can edited using set_restrictions, set_priors set_parameters. example setting monotonicity restriction (see ?set_restrictions ): example setting monotonicity restriction (see ?set_restrictions ): example setting priors (see ?set_priors ): Simulation: Data can drawn model like :","code":"# examples of models xy_model <- make_model(\"X -> Y\") iv_model <- make_model(\"Z -> X -> Y <-> X\") plot(iv_model) xy_model |> grab(\"parameters_df\") |> kable() iv_model <-    iv_model |> set_restrictions(decreasing('Z', 'X')) iv_model <-    iv_model |> set_priors(distribution = \"jeffreys\") #> No specific parameters to alter values for specified. Altering all parameters. data <- make_data(iv_model, n = 4)   data |> kable()"},{"path":"/articles/1-getting-started.html","id":"model-updating","dir":"Articles","previous_headings":"","what":"Model updating","title":"Getting Started","text":"Updating: Update using update_model. can pass rstan arguments update_model. Inspecting: can access posterior distribution model parameters directly thus: row draw parameters.","code":"df <- fabricatr::fabricate(N = 100, X = rbinom(N, 1, .5), Y = rbinom(N, 1, .25 + X*.5))  xy_model <-    xy_model |>    update_model(df, refresh = 0) xy_model |> grab(\"posterior_distribution\") |>    head() |> kable()"},{"path":"/articles/1-getting-started.html","id":"query-model","dir":"Articles","previous_headings":"","what":"Query model","title":"Getting Started","text":"Querying: ask arbitrary causal queries model. Examples unconditional queries: Examples conditional queries: Queries can even conditional counterfactual quantities. probability positive effect given effect:","code":"xy_model |>    query_model(\"Y[X=1] > Y[X=0]\", using = c(\"priors\", \"posteriors\")) |>   kable() xy_model |>    query_model(\"Y[X=1] > Y[X=0]\", using = c(\"priors\", \"posteriors\"),               given = \"X==1 & Y == 1\") |>   kable() xy_model |>    query_model(\"Y[X=1] > Y[X=0]\", using = c(\"priors\", \"posteriors\"),               given = \"Y[X=1] != Y[X=0]\") |>   kable()"},{"path":"/articles/2-front-door.html","id":"try-it","dir":"Articles","previous_headings":"","what":"Try it","title":"Through the front door","text":"Say X, M, Y perfectly correlated. average treatment effect identified?","code":""},{"path":"/articles/3-inspecting-posteriors.html","id":"accessing-the-posterior","dir":"Articles","previous_headings":"","what":"Accessing the posterior","title":"Inspecting posteriors","text":"update model using CausalQueries, CausalQueries generates updates stan model saves posterior distribution parameters model. basic usage : posterior parameters can accessed thus: querying model can request use posterior distribution using argument:","code":"data <- data.frame(X = rep(c(0:1), 10), Y = rep(c(0:1), 10))  model <- make_model(\"X -> Y\") |>    update_model(data) grab(model, \"posterior_distribution\") #> Summary statistics of model parameter posterior distributions: #> Dimensions: 4000 rows (draws) by 6 cols (parameters)     mean   sd #> X.0  0.50 0.10 #> X.1  0.50 0.10 #> Y.00 0.08 0.07 #> Y.10 0.04 0.04 #> Y.01 0.80 0.11 #> Y.11 0.08 0.07 model |>    query_model(     query = \"Y[X=1] > Y[X=0]\",     using = c(\"priors\", \"posteriors\")) |>   kable(digits = 2)"},{"path":"/articles/3-inspecting-posteriors.html","id":"summary-of-stan-performance","dir":"Articles","previous_headings":"","what":"Summary of stan performance","title":"Inspecting posteriors","text":"can access summary parameter values convergence information produced stan thus: summary provides information distribution parameters well convergence diagnostics, summarized Rhat column. printout first 6 rows show distribution model parameters; next 8 rows show distribution transformed parameters, causal types. last row shows unnormalized log density Stan’s unconstrained space , described Stan documentation intended diagnose sampling efficiency evaluate approximations. See stan documentation details.","code":"grab(model, \"stan_summary\") #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>              mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> X.0          0.50    0.00 0.10   0.29   0.43   0.50   0.57   0.70  2138    1 #> X.1          0.50    0.00 0.10   0.30   0.43   0.50   0.57   0.71  2138    1 #> Y.00         0.08    0.00 0.07   0.00   0.02   0.06   0.12   0.27  1833    1 #> Y.10         0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  4508    1 #> Y.01         0.80    0.00 0.11   0.54   0.74   0.82   0.88   0.95  4151    1 #> Y.11         0.08    0.00 0.07   0.00   0.02   0.06   0.11   0.26  4424    1 #> X0.Y00       0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  1833    1 #> X1.Y00       0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  1944    1 #> X0.Y10       0.02    0.00 0.02   0.00   0.01   0.01   0.03   0.08  4363    1 #> X1.Y10       0.02    0.00 0.02   0.00   0.01   0.01   0.03   0.08  4007    1 #> X0.Y01       0.40    0.00 0.10   0.21   0.33   0.40   0.46   0.60  2534    1 #> X1.Y01       0.40    0.00 0.10   0.21   0.33   0.40   0.47   0.61  2412    1 #> X0.Y11       0.04    0.00 0.04   0.00   0.01   0.03   0.05   0.13  4172    1 #> X1.Y11       0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  4016    1 #> lp__       -14.59    0.04 1.50 -18.32 -15.35 -14.29 -13.47 -12.66  1224    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Mar 25 15:28:07 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1)."},{"path":"/articles/3-inspecting-posteriors.html","id":"advanced-diagnostics","dir":"Articles","previous_headings":"","what":"Advanced diagnostics","title":"Inspecting posteriors","text":"interested advanced diagnostics performance can save access raw stan output. Note summary raw output shows labels used generic stan model: lambda vector parameters, corresponding parameters parameters dataframe (grab(model, \"parameters_df\")), , saved, vector types causal types (see grab(model, \"causal_types\")) w event probabilities (grab(model, \"event_probabilities\")). can use diagnostic packages bayesplot.","code":"model <- make_model(\"X -> Y\") |>    update_model(data, keep_fit = TRUE) model |> grab(\"stan_fit\") #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>              mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> lambdas[1]   0.50    0.00 0.11   0.29   0.43   0.50   0.58   0.71  2287 1.00 #> lambdas[2]   0.50    0.00 0.11   0.29   0.42   0.50   0.57   0.71  2287 1.00 #> lambdas[3]   0.08    0.00 0.08   0.00   0.02   0.06   0.11   0.28  2092 1.00 #> lambdas[4]   0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  4183 1.00 #> lambdas[5]   0.80    0.00 0.11   0.54   0.74   0.82   0.88   0.96  3761 1.00 #> lambdas[6]   0.08    0.00 0.07   0.00   0.02   0.06   0.11   0.28  3998 1.00 #> types[1]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  2096 1.00 #> types[2]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  2099 1.00 #> types[3]     0.02    0.00 0.02   0.00   0.01   0.01   0.03   0.08  3841 1.00 #> types[4]     0.02    0.00 0.02   0.00   0.01   0.01   0.03   0.08  4090 1.00 #> types[5]     0.40    0.00 0.10   0.21   0.33   0.40   0.47   0.61  2638 1.00 #> types[6]     0.40    0.00 0.10   0.20   0.33   0.40   0.47   0.61  2609 1.00 #> types[7]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  3670 1.00 #> types[8]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  3839 1.00 #> lp__       -14.71    0.05 1.64 -18.74 -15.55 -14.38 -13.49 -12.64  1212 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Mon Mar 25 15:28:09 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). model |> grab(\"stan_fit\") |>   bayesplot::mcmc_pairs(pars = c(\"lambdas[3]\", \"lambdas[4]\", \"lambdas[5]\", \"lambdas[6]\")) np <- model |> grab(\"stan_fit\") |> bayesplot::nuts_params() head(np) |> kable() model |> grab(\"stan_fit\") |>   bayesplot::mcmc_trace(pars = \"lambdas[5]\", np = np)  #> No divergences to plot."},{"path":"/articles/front-door.html","id":"try-it","dir":"Articles","previous_headings":"","what":"Try it","title":"Through the front door","text":"Say X, M, Y perfectly correlated. average treatment effect identified?","code":""},{"path":"/articles/getting-started.html","id":"make-a-model","dir":"Articles","previous_headings":"","what":"Make a model","title":"1 Getting Started","text":"Generating: make model need provide DAG statement make_model. instance \"X->Y\" \"X -> M -> Y <- X\" \"Z -> X -> Y <-> X\". Graphing: made model can inspect DAG:  Inspecting: model set parameters default distribution . Tailoring: features can edited using set_restrictions, set_priors set_parameters. example setting monotonicity restriction (see ?set_restrictions ): example setting monotonicity restriction (see ?set_restrictions ): example setting priors (see ?set_priors ): Simulation: Data can drawn model like :","code":"# examples of models xy_model <- make_model(\"X -> Y\") iv_model <- make_model(\"Z -> X -> Y <-> X\") plot(iv_model) xy_model |> grab(\"parameters_df\") |> kable() iv_model <-    iv_model |> set_restrictions(decreasing('Z', 'X')) iv_model <-    iv_model |> set_priors(distribution = \"jeffreys\") #> No specific parameters to alter values for specified. Altering all parameters. data <- make_data(iv_model, n = 4)   data |> kable()"},{"path":"/articles/getting-started.html","id":"model-updating","dir":"Articles","previous_headings":"","what":"Model updating","title":"1 Getting Started","text":"Updating: Update using update_model. can pass rstan arguments update_model. Inspecting: can access posterior distribution model parameters directly thus: row draw parameters.","code":"df <- fabricatr::fabricate(N = 100, X = rbinom(N, 1, .5), Y = rbinom(N, 1, .25 + X*.5))  xy_model <-    xy_model |>    update_model(df, refresh = 0) xy_model |> grab(\"posterior_distribution\") |>    head() |> kable()"},{"path":"/articles/getting-started.html","id":"query-model","dir":"Articles","previous_headings":"","what":"Query model","title":"1 Getting Started","text":"Querying: ask arbitrary causal queries model. Examples unconditional queries: Examples conditional queries: Queries can even conditional counterfactual quantities. probability positive effect given effect:","code":"xy_model |>    query_model(\"Y[X=1] > Y[X=0]\", using = c(\"priors\", \"posteriors\")) |>   kable() xy_model |>    query_model(\"Y[X=1] > Y[X=0]\", using = c(\"priors\", \"posteriors\"),               given = \"X==1 & Y == 1\") |>   kable() xy_model |>    query_model(\"Y[X=1] > Y[X=0]\", using = c(\"priors\", \"posteriors\"),               given = \"Y[X=1] != Y[X=0]\") |>   kable()"},{"path":"/articles/inspecting-posteriors.html","id":"accessing-the-posterior","dir":"Articles","previous_headings":"","what":"Accessing the posterior","title":"Inspecting posteriors","text":"update model using CausalQueries, CausalQueries generates updates stan model saves posterior distribution parameters model. basic usage : posterior parameters can accessed thus: querying model can request use posterior distribution using argument:","code":"data <- data.frame(X = rep(c(0:1), 10), Y = rep(c(0:1), 10))  model <- make_model(\"X -> Y\") |>    update_model(data) grab(model, \"posterior_distribution\") #> Summary statistics of model parameter posterior distributions: #> Draws: 4000 #> rows are parameters #>      mean   sd #> X.0  0.50 0.10 #> X.1  0.50 0.10 #> Y.00 0.08 0.07 #> Y.10 0.04 0.04 #> Y.01 0.80 0.11 #> Y.11 0.08 0.07 model |>    query_model(     query = \"Y[X=1] > Y[X=0]\",     using = c(\"priors\", \"posteriors\")) |>   kable(digits = 2)"},{"path":"/articles/inspecting-posteriors.html","id":"summary-of-stan-performance","dir":"Articles","previous_headings":"","what":"Summary of stan performance","title":"Inspecting posteriors","text":"can access summary parameter values convergence information produced stan thus: summary provides information distribution parameters well convergence diagnostics, summarized Rhat column. printout first 6 rows show distribution model parameters; next 8 rows show distribution transformed parameters, causal types. last row shows unnormalized log density Stan’s unconstrained space , described Stan documentation intended diagnose sampling efficiency evaluate approximations. See stan documentation details.","code":"grab(model, \"stan_summary\") #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>              mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> X.0          0.50    0.00 0.10   0.30   0.43   0.50   0.57   0.70  1954    1 #> X.1          0.50    0.00 0.10   0.30   0.43   0.50   0.57   0.70  1954    1 #> Y.00         0.08    0.00 0.07   0.00   0.03   0.06   0.12   0.28  1917    1 #> Y.10         0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  4003    1 #> Y.01         0.80    0.00 0.11   0.52   0.73   0.81   0.88   0.95  3952    1 #> Y.11         0.08    0.00 0.07   0.00   0.02   0.06   0.11   0.28  4293    1 #> X0.Y00       0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  1930    1 #> X1.Y00       0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  1911    1 #> X0.Y10       0.02    0.00 0.02   0.00   0.01   0.01   0.03   0.07  3998    1 #> X1.Y10       0.02    0.00 0.02   0.00   0.01   0.01   0.03   0.08  3710    1 #> X0.Y01       0.40    0.00 0.10   0.21   0.32   0.40   0.46   0.59  2639    1 #> X1.Y01       0.40    0.00 0.10   0.21   0.33   0.40   0.47   0.59  2382    1 #> X0.Y11       0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  3842    1 #> X1.Y11       0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  4209    1 #> lp__       -14.60    0.04 1.55 -18.53 -15.38 -14.23 -13.48 -12.66  1196    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Mar 25 14:53:46 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1)."},{"path":"/articles/inspecting-posteriors.html","id":"advanced-diagnostics","dir":"Articles","previous_headings":"","what":"Advanced diagnostics","title":"Inspecting posteriors","text":"interested advanced diagnostics performance can save access raw stan output. Note summary raw output shows labels used generic stan model: lambda vector parameters, corresponding parameters parameters dataframe (grab(model, \"parameters_df\")), , saved, vector types causal types (see grab(model, \"causal_types\")) w event probabilities (grab(model, \"event_probabilities\")). can use diagnostic packages bayesplot.","code":"model <- make_model(\"X -> Y\") |>    update_model(data, keep_fit = TRUE) model |> grab(\"stan_fit\") #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>              mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> lambdas[1]   0.50    0.00 0.11   0.30   0.42   0.50   0.58   0.71  1923    1 #> lambdas[2]   0.50    0.00 0.11   0.29   0.42   0.50   0.58   0.70  1923    1 #> lambdas[3]   0.08    0.00 0.07   0.00   0.02   0.06   0.11   0.27  1634    1 #> lambdas[4]   0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  4226    1 #> lambdas[5]   0.80    0.00 0.11   0.54   0.73   0.82   0.88   0.95  4238    1 #> lambdas[6]   0.08    0.00 0.08   0.00   0.02   0.06   0.12   0.29  4573    1 #> types[1]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  1668    1 #> types[2]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  1823    1 #> types[3]     0.02    0.00 0.02   0.00   0.01   0.01   0.03   0.07  3539    1 #> types[4]     0.02    0.00 0.02   0.00   0.01   0.01   0.03   0.08  4250    1 #> types[5]     0.40    0.00 0.10   0.21   0.33   0.40   0.47   0.60  2312    1 #> types[6]     0.40    0.00 0.10   0.21   0.33   0.39   0.47   0.60  2378    1 #> types[7]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  4166    1 #> types[8]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  4452    1 #> lp__       -14.71    0.06 1.69 -18.84 -15.48 -14.34 -13.51 -12.69   813    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Mar 25 14:53:48 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). model |> grab(\"stan_fit\") |>   bayesplot::mcmc_pairs(pars = c(\"lambdas[3]\", \"lambdas[4]\", \"lambdas[5]\", \"lambdas[6]\")) np <- model |> grab(\"stan_fit\") |> bayesplot::nuts_params() head(np) |> kable() model |> grab(\"stan_fit\") |>   bayesplot::mcmc_trace(pars = \"lambdas[5]\", np = np)  #> No divergences to plot."},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Clara Bicalho. Contributor. Jasper Cooper. Contributor. Macartan Humphreys. Author. Till Tietz. Author, maintainer. Alan Jacobs. Author. Merlin Heidemanns. Contributor. Lily Medina. Author. Julio Solis. Contributor. Georgiy Syunyaev. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Humphreys M, Tietz T, Jacobs , Medina L, Syunyaev G (2024). CausalQueries: Make, Update, Query Binary Causal Models. R package version 1.0.2.","code":"@Manual{,   title = {CausalQueries: Make, Update, and Query Binary Causal Models},   author = {Macartan Humphreys and Till Tietz and Alan Jacobs and Lily Medina and Georgiy Syunyaev},   year = {2024},   note = {R package version 1.0.2}, }"},{"path":"/index.html","id":"causalqueries","dir":"","previous_headings":"","what":"Make, Update, and Query Binary Causal Models","title":"Make, Update, and Query Binary Causal Models","text":"https://integrated-inferences.github.io/CausalQueries/ CausalQueries package lets declare binary causal models, update beliefs causal types given data calculate arbitrary estimands. Model definition makes use dagitty functionality. Updating implemented stan. See vignettes guide getting started. See guide using CausalQueries along many examples causal models","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Make, Update, and Query Binary Causal Models","text":"install latest stable release CausalQueries: install latest development release :","code":"install.packages(\"CausalQueries\") install.packages(\"devtools\") devtools::install_github(\"integrated-inferences/CausalQueries\")"},{"path":"/index.html","id":"causal-models","dir":"","previous_headings":"","what":"Causal models","title":"Make, Update, and Query Binary Causal Models","text":"Causal models defined : directed acyclic graph (DAG), provides set variables, causal ordering , set assumptions regarding conditional independence. arrow B change never induces change B. Functional forms. Functional forms describe causal relationships nodes. often make strong assumptions specify functional form; fortunately however variables categorical need functional forms usual sense. DAG implies set “causal types.” Units can classed together causal type respond way variables. instance, type might set units X=1 Y=1 X=1. set causal types grows rapidly number nodes number nodes pointing given node. setting imposing functional forms placing restrictions causal types: restrictions reduce complexity require substantive assumptions. example restriction might “Y monotonic X.” Priors. standard case, DAG plus restrictions imply set parameters combine form causal types. parameters want learn . learn first provide priors parameters. priors specified causal model complete (“probabilistic causal model”) ready inference. Setting priors done using set_priors function many examples can seen typing ? set_priors.R. wrinkle: possible nodes related ways captured DAG. cases dotted curves sometimes placed nodes graph. possible specify possible unobservable confounding causal model. implications parameter space.","code":""},{"path":"/index.html","id":"inference","dir":"","previous_headings":"","what":"Inference","title":"Make, Update, and Query Binary Causal Models","text":"goal form beliefs parameters also substantive estimands: causal model hand data available nodes, possible make use generic stan model generates posteriors parameter vector. Given updated (prior) beliefs parameters possible calculate causal estimands inference causal model. example “probability X cause Y given X=1, Y=1 Z=1.”","code":""},{"path":"/index.html","id":"credits-etc","dir":"","previous_headings":"","what":"Credits etc","title":"Make, Update, and Query Binary Causal Models","text":"approach used CausalQueries developed Humphreys Jacobs 2023 drawing work probabilistic causal models described Pearl’s Causality (Pearl, 2009). thank Ben Goodrich provided generous insights using stan project. thank Alan M Jacobs key work developing framework underlying package. thanks Jasper Cooper contributions generating generic function create Stan code, Clara Bicalho helped figure syntax causal statements, Julio S. Solís Arce made many key contributions figuring simplify specification priors, Merlin Heidemanns figured rstantools integration made myriad code improvements.","code":""},{"path":"/reference/add_dots.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper to fill in missing do operators in causal expression — add_dots","title":"Helper to fill in missing do operators in causal expression — add_dots","text":"Helper fill missing operators causal expression","code":""},{"path":"/reference/add_dots.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper to fill in missing do operators in causal expression — add_dots","text":"","code":"add_dots(q, model)"},{"path":"/reference/add_dots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper to fill in missing do operators in causal expression — add_dots","text":"q character string. Causal query least one parent node missing operator. model causal_model. model object generated make_model.","code":""},{"path":"/reference/add_dots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper to fill in missing do operators in causal expression — add_dots","text":"causal query expression parents nodes set   either 0, 1 wildcard '.'.","code":""},{"path":"/reference/add_dots.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helper to fill in missing do operators in causal expression — add_dots","text":"","code":"# \\donttest{ model <- make_model('X -> Y <- M') CausalQueries:::add_dots('Y[X=1]', model) #> [1] \"Y[X=1, M = . ]\" CausalQueries:::add_dots('Y[]', model) #> [1] \"Y[M = . , X = . ]\" # }"},{"path":"/reference/add_wildcard.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds a wildcard for every missing parent — add_wildcard","title":"Adds a wildcard for every missing parent — add_wildcard","text":"Adds wildcard every missing parent","code":""},{"path":"/reference/add_wildcard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds a wildcard for every missing parent — add_wildcard","text":"","code":"add_wildcard(node, statement, parents, missing_parents)"},{"path":"/reference/add_wildcard.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds a wildcard for every missing parent — add_wildcard","text":"node character string. quoted name node. statement character string. quoted causal statement. parents vector characters. node's parents missing_parents vector characters.  node's missing parents","code":""},{"path":"/reference/add_wildcard.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adds a wildcard for every missing parent — add_wildcard","text":"causal query expression parents nodes set  either 0, 1 wildcard '.'","code":""},{"path":"/reference/CausalQueries-package.html","id":null,"dir":"Reference","previous_headings":"","what":"'CausalQueries' — CausalQueries-package","title":"'CausalQueries' — CausalQueries-package","text":"'CausalQueries' package lets generate binary causal models, update models given data calculate arbitrary causal queries. Model definition makes use dagitty syntax. Updating implemented 'stan'.","code":""},{"path":"/reference/CausalQueries_internal_inherit_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Create parameter documentation to inherit — CausalQueries_internal_inherit_params","title":"Create parameter documentation to inherit — CausalQueries_internal_inherit_params","text":"Create parameter documentation inherit","code":""},{"path":"/reference/CausalQueries_internal_inherit_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create parameter documentation to inherit — CausalQueries_internal_inherit_params","text":"","code":"CausalQueries_internal_inherit_params(   model,   query,   join_by,   parameters,   P,   A,   data,   data_events,   node,   statement,   using,   n_draws )"},{"path":"/reference/CausalQueries_internal_inherit_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create parameter documentation to inherit — CausalQueries_internal_inherit_params","text":"model causal_model. model object generated make_model. query character string. expression defining nodal types interrogate realise_outcomes. expression form \"Y[X=1]\" asks value Y X set 1 join_by logical operator. Used connect causal statements: ('&') ('|'). Defaults '|'. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn model$parameters_df. P data.frame. Parameter matrix. required may provided avoid repeated computation simulations. data.frame. Ambiguity matrix. required may provided avoid repeated computation simulations. data data.frame.  Data nodes can take three values: 0, 1, NA. long form generated make_events data_events data.frame. must compatible nodes model. default columns event, strategy count. node character string. quoted name node. statement character string. quoted causal statement. using character string. Indicates whether use `priors`, `posteriors` `parameters`. n_draws integer. prior distribution provided, generate prior distribution n_draws number draws.","code":""},{"path":"/reference/CausalQueries_internal_inherit_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create parameter documentation to inherit — CausalQueries_internal_inherit_params","text":"function return anything. used   inherit roxygen documentation","code":""},{"path":"/reference/causal_type_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Names for causal types — causal_type_names","title":"Names for causal types — causal_type_names","text":"Names causal types","code":""},{"path":"/reference/causal_type_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Names for causal types — causal_type_names","text":"","code":"causal_type_names(causal_types)"},{"path":"/reference/causal_type_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Names for causal types — causal_type_names","text":"causal_types data.frame whose rows containing 0-1 digits conform causal types.","code":""},{"path":"/reference/causal_type_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Names for causal types — causal_type_names","text":"data.frame whose rows contain character values   conform causal type model.","code":""},{"path":"/reference/causal_type_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Names for causal types — causal_type_names","text":"","code":"# \\donttest{ model <- make_model('X -> Y') possible_types <- grab(model, \"nodal_types\") df <- data.frame(expand.grid(possible_types, stringsAsFactors = FALSE)) CausalQueries:::causal_type_names(df) #>    X   Y #> 1 X0 Y00 #> 2 X1 Y00 #> 3 X0 Y10 #> 4 X1 Y10 #> 5 X0 Y01 #> 6 X1 Y01 #> 7 X0 Y11 #> 8 X1 Y11 # }"},{"path":"/reference/check_args.html","id":null,"dir":"Reference","previous_headings":"","what":"helper to check arguments — check_args","title":"helper to check arguments — check_args","text":"helper check arguments","code":""},{"path":"/reference/check_args.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"helper to check arguments — check_args","text":"","code":"check_args(model, using, given, queries, case_level, fun)"},{"path":"/reference/check_args.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"helper to check arguments — check_args","text":"model passed parent function using passed parent function given passed parent function queries passed parent function fun string specifying name parent function","code":""},{"path":"/reference/check_args.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"helper to check arguments — check_args","text":"list altered arguments","code":""},{"path":"/reference/check_query.html","id":null,"dir":"Reference","previous_headings":"","what":"Warn about improper query specification and apply fixes — check_query","title":"Warn about improper query specification and apply fixes — check_query","text":"Warn improper query specification apply fixes","code":""},{"path":"/reference/check_query.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Warn about improper query specification and apply fixes — check_query","text":"","code":"check_query(query)"},{"path":"/reference/check_query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Warn about improper query specification and apply fixes — check_query","text":"query string specifying query","code":""},{"path":"/reference/check_query.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Warn about improper query specification and apply fixes — check_query","text":"fixed query string","code":""},{"path":"/reference/check_string_input.html","id":null,"dir":"Reference","previous_headings":"","what":"Check string_input — check_string_input","title":"Check string_input — check_string_input","text":"Check string_input","code":""},{"path":"/reference/check_string_input.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check string_input — check_string_input","text":"","code":"check_string_input(param_list = list(), call_name = NULL)"},{"path":"/reference/check_string_input.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check string_input — check_string_input","text":"param_list List parameters call_name Name call.","code":""},{"path":"/reference/check_string_input.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check string_input — check_string_input","text":"appropriate, returns error message.","code":""},{"path":"/reference/clean_condition.html","id":null,"dir":"Reference","previous_headings":"","what":"Clean condition — clean_condition","title":"Clean condition — clean_condition","text":"Takes string specifying condition returns properly spaced string.","code":""},{"path":"/reference/clean_condition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clean condition — clean_condition","text":"","code":"clean_condition(condition)"},{"path":"/reference/clean_condition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clean condition — clean_condition","text":"condition character string. Condition refers unique position (possible outcome) nodal type.","code":""},{"path":"/reference/clean_condition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clean condition — clean_condition","text":"properly spaced string.","code":""},{"path":"/reference/clean_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Check parameters sum to 1 in param_set; normalize if needed; add\r\nnames if needed — clean_params","title":"Check parameters sum to 1 in param_set; normalize if needed; add\r\nnames if needed — clean_params","text":"Check parameters sum 1 param_set; normalize needed; add names needed","code":""},{"path":"/reference/clean_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check parameters sum to 1 in param_set; normalize if needed; add\r\nnames if needed — clean_params","text":"","code":"clean_params(parameters_df, warning = TRUE)"},{"path":"/reference/clean_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check parameters sum to 1 in param_set; normalize if needed; add\r\nnames if needed — clean_params","text":"parameters_df data.frame. object first generated make_model. warning Logical. Whether print warning () console. Defaults TRUE","code":""},{"path":"/reference/clean_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check parameters sum to 1 in param_set; normalize if needed; add\r\nnames if needed — clean_params","text":"parameters data.frame  names parameters   sum 1.","code":""},{"path":"/reference/clean_params.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check parameters sum to 1 in param_set; normalize if needed; add\r\nnames if needed — clean_params","text":"","code":"# \\donttest{ model <- make_model('X->Y') model$parameters_df$param_value <- 1:6 CausalQueries:::clean_params(model$parameters_df, warning = TRUE) #> Parameters in set X do not sum to 1. Using normalized parameters #> Parameters in set Y do not sum to 1. Using normalized parameters #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>   param_names node gen param_set nodal_type given param_value priors #> 1         X.0    X   1         X          0         0.3333333      1 #> 2         X.1    X   1         X          1         0.6666667      1 #> 3        Y.00    Y   2         Y         00         0.1666667      1 #> 4        Y.10    Y   2         Y         10         0.2222222      1 #> 5        Y.01    Y   2         Y         01         0.2777778      1 #> 6        Y.11    Y   2         Y         11         0.3333333      1 # }"},{"path":"/reference/clean_param_vector.html","id":null,"dir":"Reference","previous_headings":"","what":"Clean parameter vector — clean_param_vector","title":"Clean parameter vector — clean_param_vector","text":"Clean parameter vector","code":""},{"path":"/reference/clean_param_vector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clean parameter vector — clean_param_vector","text":"","code":"clean_param_vector(model, parameters)"},{"path":"/reference/clean_param_vector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clean parameter vector — clean_param_vector","text":"model causal_model. model object generated make_model. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn model$parameters_df.","code":""},{"path":"/reference/clean_param_vector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clean parameter vector — clean_param_vector","text":"vector named parameters summing 1.","code":""},{"path":"/reference/collapse_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Make compact data with data strategies — collapse_data","title":"Make compact data with data strategies — collapse_data","text":"Take `data.frame` return compact `data.frame` event types strategies.","code":""},{"path":"/reference/collapse_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make compact data with data strategies — collapse_data","text":"","code":"collapse_data(   data,   model,   drop_NA = TRUE,   drop_family = FALSE,   summary = FALSE )"},{"path":"/reference/collapse_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make compact data with data strategies — collapse_data","text":"data data.frame.  Data nodes can take three values: 0, 1, NA. long form generated make_events model causal_model. model object generated make_model. drop_NA Logical. Whether exclude strategy families contain observed data. Exceptionally data provided, minimal data data first node returned. Defaults `TRUE` drop_family Logical. Whether remove column strategy output. Defaults `FALSE`. summary Logical. Whether return summary data. See details. Defaults `FALSE`.","code":""},{"path":"/reference/collapse_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make compact data with data strategies — collapse_data","text":"vector data events summary = TRUE `collapse_data` returns list containing   following components: data_events compact data.frame event types strategies. observed_events vector character strings specifying events      observed data unobserved_events vector character strings specifying      events observed data","code":""},{"path":"/reference/collapse_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make compact data with data strategies — collapse_data","text":"","code":"# \\donttest{  model <- make_model('X -> Y')  df <- data.frame(X = c(0,1,NA), Y = c(0,0,1))  df %>% collapse_data(model) #>   event strategy count #> 1  X0Y0       XY     1 #> 2  X1Y0       XY     1 #> 3  X0Y1       XY     0 #> 4  X1Y1       XY     0 #> 5    Y0        Y     0 #> 6    Y1        Y     1   collapse_data(df, model, drop_NA = FALSE) #>   event strategy count #> 1  X0Y0       XY     1 #> 2  X1Y0       XY     1 #> 3  X0Y1       XY     0 #> 4  X1Y1       XY     0 #> 5    Y0        Y     0 #> 6    Y1        Y     1 #> 7    X0        X     0 #> 8    X1        X     0  collapse_data(df, model, drop_family = TRUE) #>   event count #> 1  X0Y0     1 #> 2  X1Y0     1 #> 3  X0Y1     0 #> 4  X1Y1     0 #> 5    Y0     0 #> 6    Y1     1  collapse_data(df, model, summary = TRUE) #> $data_events #>   event strategy count #> 1  X0Y0       XY     1 #> 2  X1Y0       XY     1 #> 3  X0Y1       XY     0 #> 4  X1Y1       XY     0 #> 5    Y0        Y     0 #> 6    Y1        Y     1 #>  #> $observed_events #> [1] \"X0Y0\" \"X1Y0\" \"Y1\"   #>  #> $unobserved_events #> [1] \"X0Y1\" \"X1Y1\" \"Y0\"   #>   data <- make_data(model, n = 0) collapse_data(data, model) #>   event strategy count #> 1  X0Y0       XY     0 #> 2  X1Y0       XY     0 #> 3  X0Y1       XY     0 #> 4  X1Y1       XY     0  model <- make_model('X -> Y') %>% set_restrictions('X[]==1') df <- make_data(model, n = 10) df[1,1] <- '' collapse_data(df, model) #>   event strategy count #> 1  X0Y0       XY     4 #> 2  X0Y1       XY     5 #> 3    Y0        Y     1 #> 4    Y1        Y     0 data <- data.frame(X= 0:1) collapse_data(data, model) #> X1 data is inconsistent with model and ignored #>   event strategy count #> 1    X0        X     1  # }"},{"path":"/reference/collapse_nodal_types.html","id":null,"dir":"Reference","previous_headings":"","what":"collapse nodal types — collapse_nodal_types","title":"collapse nodal types — collapse_nodal_types","text":"collapse nodal types","code":""},{"path":"/reference/collapse_nodal_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"collapse nodal types — collapse_nodal_types","text":"","code":"collapse_nodal_types(nodal_types, include_node_names = FALSE)"},{"path":"/reference/collapse_nodal_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"collapse nodal types — collapse_nodal_types","text":"nodal_types list nodal types. include_node_names Logical, TRUE returns names X0, X1; otherwise returns 0, 1","code":""},{"path":"/reference/collapse_nodal_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"collapse nodal types — collapse_nodal_types","text":"list containing nodes nodal types vector form.","code":""},{"path":"/reference/collapse_nodal_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"collapse nodal types — collapse_nodal_types","text":"","code":"model <- make_model('X -> K -> Y') (nodal_types <- grab(model, \"nodal_types\", collapse = FALSE)) #> Nodal types:  #> $X #> c(0, 1) #>  #> NULL #>  #> $K #> c(0, 1, 0, 1)  c(0, 0, 1, 1) #>  #> NULL #>  #> $Y #> c(0, 1, 0, 1)  c(0, 0, 1, 1) #>  #> NULL #>  #>  #> Number of types by node #> X K Y  #> 1 2 2  CausalQueries:::collapse_nodal_types(nodal_types ) #> Nodal types:  #> $X #> 0  1 #>  #> NULL #>  #> $K #> 00  10  01  11 #>  #> NULL #>  #> $Y #> 00  10  01  11 #>  #> NULL #>  #>  #> Number of types by node #> X K Y  #> 2 4 4"},{"path":"/reference/complements.html","id":null,"dir":"Reference","previous_headings":"","what":"Make statement for complements — complements","title":"Make statement for complements — complements","text":"Generate statement X1, X1 complement production Y","code":""},{"path":"/reference/complements.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make statement for complements — complements","text":"","code":"complements(X1, X2, Y)"},{"path":"/reference/complements.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make statement for complements — complements","text":"X1 character. quoted name input node 1. X2 character. quoted name input node 2. Y character. quoted name outcome node.","code":""},{"path":"/reference/complements.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make statement for complements — complements","text":"character statement class statement","code":""},{"path":[]},{"path":"/reference/complements.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make statement for complements — complements","text":"","code":"# \\donttest{ complements('A', 'B', 'W') #>  #> Statement:  #> ((W[A =1, B = 1]) - (W[A = 0, B = 1])) > ((W[A =1, B = 0]) - (W[A = 0, B = 0])) # }"},{"path":"/reference/construct_commands_alter_at.html","id":null,"dir":"Reference","previous_headings":"","what":"make_par_values — construct_commands_alter_at","title":"make_par_values — construct_commands_alter_at","text":"helper generate filter commands specifying rows parameters_df altered given alter_at statement","code":""},{"path":"/reference/construct_commands_alter_at.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_par_values — construct_commands_alter_at","text":"","code":"construct_commands_alter_at(alter_at)"},{"path":"/reference/construct_commands_alter_at.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_par_values — construct_commands_alter_at","text":"alter_at string specifying filtering operations applied parameters_df, yielding logical vector indicating parameters values altered.","code":""},{"path":"/reference/construct_commands_alter_at.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"make_par_values — construct_commands_alter_at","text":"string specifying filter command","code":""},{"path":"/reference/construct_commands_other_args.html","id":null,"dir":"Reference","previous_headings":"","what":"make_par_values — construct_commands_other_args","title":"make_par_values — construct_commands_other_args","text":"helper generate filter commands specifying rows parameters_df altered given combinations nodes, nodal_types, param_sets, givens statements","code":""},{"path":"/reference/construct_commands_other_args.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_par_values — construct_commands_other_args","text":"","code":"construct_commands_other_args(   node,   nodal_type,   param_set,   given,   statement,   model,   join_by )"},{"path":"/reference/construct_commands_other_args.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_par_values — construct_commands_other_args","text":"node string indicating nodes altered nodal_type string. Label nodal type indicating nodal types values altered param_set string indicating  name set parameters altered given string indicates node parameter altered depends statement causal query determines nodal types values altered model model created make_model join_by string specifying logical operator joining expanded types statement contains wildcards. Can take values '&' (logical ) '|' (logical ).","code":""},{"path":"/reference/construct_commands_other_args.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"make_par_values — construct_commands_other_args","text":"string specifying filter command","code":""},{"path":"/reference/construct_commands_param_names.html","id":null,"dir":"Reference","previous_headings":"","what":"make_par_values — construct_commands_param_names","title":"make_par_values — construct_commands_param_names","text":"helper generate filter commands specifying rows parameters_df altered given vector parameter names","code":""},{"path":"/reference/construct_commands_param_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_par_values — construct_commands_param_names","text":"","code":"construct_commands_param_names(param_names, model_param_names)"},{"path":"/reference/construct_commands_param_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_par_values — construct_commands_param_names","text":"param_names vector strings. name specific parameter form , example, 'X.1', 'Y.01' model_param_names vector strings. Parameter names found model.","code":""},{"path":"/reference/construct_commands_param_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"make_par_values — construct_commands_param_names","text":"string specifying filter command","code":""},{"path":"/reference/data_to_data.html","id":null,"dir":"Reference","previous_headings":"","what":"helper to generate a matrix mapping from names of M to names of A — data_to_data","title":"helper to generate a matrix mapping from names of M to names of A — data_to_data","text":"helper generate matrix mapping names M names ","code":""},{"path":"/reference/data_to_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"helper to generate a matrix mapping from names of M to names of A — data_to_data","text":"","code":"data_to_data(M, A)"},{"path":"/reference/data_to_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"helper to generate a matrix mapping from names of M to names of A — data_to_data","text":"M matrix matrix","code":""},{"path":"/reference/data_to_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"helper to generate a matrix mapping from names of M to names of A — data_to_data","text":"matrix","code":""},{"path":"/reference/data_type_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Data type names — data_type_names","title":"Data type names — data_type_names","text":"Provides names data types","code":""},{"path":"/reference/data_type_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data type names — data_type_names","text":"","code":"data_type_names(model, data)"},{"path":"/reference/data_type_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data type names — data_type_names","text":"model causal_model. model object generated make_model. data data.frame.  Data nodes can take three values: 0, 1, NA. long form generated make_events","code":""},{"path":"/reference/data_type_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data type names — data_type_names","text":"vector strings data types","code":""},{"path":"/reference/data_type_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data type names — data_type_names","text":"","code":"model <- make_model('X -> Y') data <- make_data(model, n = 2) data_type_names(model, data) #> [1] \"X0Y1\" \"X1Y1\""},{"path":"/reference/decreasing.html","id":null,"dir":"Reference","previous_headings":"","what":"Make monotonicity statement (negative) — decreasing","title":"Make monotonicity statement (negative) — decreasing","text":"Generate statement Y monotonic (decreasing) X","code":""},{"path":"/reference/decreasing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make monotonicity statement (negative) — decreasing","text":"","code":"decreasing(X, Y)"},{"path":"/reference/decreasing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make monotonicity statement (negative) — decreasing","text":"X character. quoted name input node Y character. quoted name outcome node","code":""},{"path":"/reference/decreasing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make monotonicity statement (negative) — decreasing","text":"character statement class statement","code":""},{"path":[]},{"path":"/reference/decreasing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make monotonicity statement (negative) — decreasing","text":"","code":"# \\donttest{ decreasing('A', 'B') #>  #> Statement:  #> (B[A=1] < B[A=0]) # }"},{"path":"/reference/default_stan_control.html","id":null,"dir":"Reference","previous_headings":"","what":"default_stan_control — default_stan_control","title":"default_stan_control — default_stan_control","text":"default_stan_control","code":""},{"path":"/reference/default_stan_control.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"default_stan_control — default_stan_control","text":"","code":"default_stan_control(adapt_delta = NULL, max_treedepth = 15L)"},{"path":"/reference/default_stan_control.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"default_stan_control — default_stan_control","text":"adapt_delta double 0 1. determines adapt_delta max_treedepth positive integer. determines maximum_tree_depth","code":""},{"path":"/reference/default_stan_control.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"default_stan_control — default_stan_control","text":"list containing arguments passed stan","code":""},{"path":"/reference/default_stan_control.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"default_stan_control — default_stan_control","text":"Sets controls default unless otherwise specified.","code":""},{"path":"/reference/democracy_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Development and Democratization: Data for replication of analysis in\r\n*Integrated Inferences* — democracy_data","title":"Development and Democratization: Data for replication of analysis in\r\n*Integrated Inferences* — democracy_data","text":"dataset containing information inequality, democracy, mobilization, international pressure. Made devtools::use_data(democracy_data, CausalQueries)","code":""},{"path":"/reference/democracy_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Development and Democratization: Data for replication of analysis in\r\n*Integrated Inferences* — democracy_data","text":"","code":"democracy_data"},{"path":"/reference/democracy_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Development and Democratization: Data for replication of analysis in\r\n*Integrated Inferences* — democracy_data","text":"data frame 84 rows 5 nodes: Case Case D Democracy Inequality P International Pressure M Mobilization","code":""},{"path":"/reference/democracy_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Development and Democratization: Data for replication of analysis in\r\n*Integrated Inferences* — democracy_data","text":"https://www.cambridge.org/core/journals/american-political-science-review/article/inequality--regime-change-democratic-transitions---stability--democratic-rule/C39AAF4CF274445555FF41F7CC896AE3#fndtn-supplementary-materials/","code":""},{"path":"/reference/draw_causal_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw a single causal type given a parameter vector — draw_causal_type","title":"Draw a single causal type given a parameter vector — draw_causal_type","text":"Output parameter dataframe recording parameters (case level priors) case level causal type.","code":""},{"path":"/reference/draw_causal_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw a single causal type given a parameter vector — draw_causal_type","text":"","code":"draw_causal_type(model, ...)"},{"path":"/reference/draw_causal_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw a single causal type given a parameter vector — draw_causal_type","text":"model causal_model. model object generated make_model. ... Arguments passed  `set_parameters`","code":""},{"path":"/reference/draw_causal_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw a single causal type given a parameter vector — draw_causal_type","text":"","code":"# Simple draw using model's parameter vector make_model(\"X -> M -> Y\") %>% draw_causal_type(.) #> # A tibble: 10 × 9 #>    param_names node    gen param_set nodal_type given param_value priors #>    <chr>       <chr> <int> <chr>     <chr>      <chr>       <dbl>  <dbl> #>  1 X.0         X         1 X         0          \"\"           0.5       1 #>  2 X.1         X         1 X         1          \"\"           0.5       1 #>  3 M.00        M         2 M         00         \"\"           0.25      1 #>  4 M.10        M         2 M         10         \"\"           0.25      1 #>  5 M.01        M         2 M         01         \"\"           0.25      1 #>  6 M.11        M         2 M         11         \"\"           0.25      1 #>  7 Y.00        Y         3 Y         00         \"\"           0.25      1 #>  8 Y.10        Y         3 Y         10         \"\"           0.25      1 #>  9 Y.01        Y         3 Y         01         \"\"           0.25      1 #> 10 Y.11        Y         3 Y         11         \"\"           0.25      1 #> # ℹ 1 more variable: causal_type <int>  # Draw parameters from priors and draw type from parameters make_model(\"X -> M -> Y\") %>% draw_causal_type(., param_type = \"prior_draw\") #> # A tibble: 10 × 9 #>    param_names node    gen param_set nodal_type given param_value priors #>    <chr>       <chr> <int> <chr>     <chr>      <chr>       <dbl>  <dbl> #>  1 X.0         X         1 X         0          \"\"       0.144         1 #>  2 X.1         X         1 X         1          \"\"       0.856         1 #>  3 M.00        M         2 M         00         \"\"       0.439         1 #>  4 M.10        M         2 M         10         \"\"       0.132         1 #>  5 M.01        M         2 M         01         \"\"       0.383         1 #>  6 M.11        M         2 M         11         \"\"       0.0465        1 #>  7 Y.00        Y         3 Y         00         \"\"       0.0224        1 #>  8 Y.10        Y         3 Y         10         \"\"       0.178         1 #>  9 Y.01        Y         3 Y         01         \"\"       0.000677      1 #> 10 Y.11        Y         3 Y         11         \"\"       0.799         1 #> # ℹ 1 more variable: causal_type <int>  # Draw type given specified parameters make_model(\"X -> M -> Y\") %>% draw_causal_type(., parameters = 1:10) #> # A tibble: 10 × 9 #>    param_names node    gen param_set nodal_type given param_value priors #>    <chr>       <chr> <int> <chr>     <chr>      <chr>       <dbl>  <dbl> #>  1 X.0         X         1 X         0          \"\"          0.333      1 #>  2 X.1         X         1 X         1          \"\"          0.667      1 #>  3 M.00        M         2 M         00         \"\"          0.167      1 #>  4 M.10        M         2 M         10         \"\"          0.222      1 #>  5 M.01        M         2 M         01         \"\"          0.278      1 #>  6 M.11        M         2 M         11         \"\"          0.333      1 #>  7 Y.00        Y         3 Y         00         \"\"          0.206      1 #>  8 Y.10        Y         3 Y         10         \"\"          0.235      1 #>  9 Y.01        Y         3 Y         01         \"\"          0.265      1 #> 10 Y.11        Y         3 Y         11         \"\"          0.294      1 #> # ℹ 1 more variable: causal_type <int>  # Define a causal type and reveal data model <- make_model(\"X -> Y; X <-> Y\") type <- model %>% draw_causal_type() make_data(model, parameters = type$causal_type) #>   X Y #> 1 1 0"},{"path":"/reference/drop_empty_families.html","id":null,"dir":"Reference","previous_headings":"","what":"Drop empty families — drop_empty_families","title":"Drop empty families — drop_empty_families","text":"Drop empty families","code":""},{"path":"/reference/drop_empty_families.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Drop empty families — drop_empty_families","text":"","code":"drop_empty_families(data_events)"},{"path":"/reference/drop_empty_families.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Drop empty families — drop_empty_families","text":"data_events data.frame. must compatible nodes model. default columns event, strategy count.","code":""},{"path":"/reference/drop_empty_families.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Drop empty families — drop_empty_families","text":"Returns data events strategies (excluding  strategy families   contain observed data)","code":""},{"path":"/reference/drop_empty_families.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Drop empty families — drop_empty_families","text":"","code":"# \\donttest{ data_events <- data.frame(event = c('X0Y0', 'Y0'),                           strategy = c('XY', 'Y'),                           count = 1:0) CausalQueries:::drop_empty_families(data_events) #>   event strategy count #> 1  X0Y0       XY     1 # }"},{"path":"/reference/expand_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand compact data object to data frame — expand_data","title":"Expand compact data object to data frame — expand_data","text":"Expand compact data object data frame","code":""},{"path":"/reference/expand_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand compact data object to data frame — expand_data","text":"","code":"expand_data(data_events = NULL, model)"},{"path":"/reference/expand_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand compact data object to data frame — expand_data","text":"data_events data.frame. must compatible nodes model. default columns event, strategy count. model causal_model. model object generated make_model.","code":""},{"path":"/reference/expand_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand compact data object to data frame — expand_data","text":"data.frame rows data observation","code":""},{"path":"/reference/expand_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand compact data object to data frame — expand_data","text":"","code":"# \\donttest{ model <- make_model('X->M->Y') make_events(model, n = 5) %>%   expand_data(model) #>   X M Y #> 1 0 0 0 #> 2 0 1 1 #> 3 1 0 0 #> 4 1 1 1 #> 5 1 1 1 make_events(model, n = 0) %>%   expand_data(model) #>    X  M  Y #> 1 NA NA NA  # }"},{"path":"/reference/expand_nodal_expression.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper to expand nodal expression — expand_nodal_expression","title":"Helper to expand nodal expression — expand_nodal_expression","text":"Helper expand nodal expression","code":""},{"path":"/reference/expand_nodal_expression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper to expand nodal expression — expand_nodal_expression","text":"","code":"expand_nodal_expression(model, query, node, join_by = \"|\")"},{"path":"/reference/expand_nodal_expression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper to expand nodal expression — expand_nodal_expression","text":"model causal_model. model object generated make_model. query character string. expression defining nodal types interrogate realise_outcomes. expression form \"Y[X=1]\" asks value Y X set 1 node character string. quoted name node. join_by logical operator. Used connect causal statements: ('&') ('|'). Defaults '|'.","code":""},{"path":"/reference/expand_nodal_expression.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper to expand nodal expression — expand_nodal_expression","text":"nodal expression missing parents","code":""},{"path":"/reference/expand_wildcard.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand wildcard — expand_wildcard","title":"Expand wildcard — expand_wildcard","text":"Expand statement containing wildcard","code":""},{"path":"/reference/expand_wildcard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand wildcard — expand_wildcard","text":"","code":"expand_wildcard(to_expand, join_by = \"|\", verbose = TRUE)"},{"path":"/reference/expand_wildcard.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand wildcard — expand_wildcard","text":"to_expand character vector length 1L. join_by logical operator. Used connect causal statements: ('&') ('|'). Defaults '|'. verbose Logical. Whether print expanded query console.","code":""},{"path":"/reference/expand_wildcard.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand wildcard — expand_wildcard","text":"character string expanded expression.   Wildcard '.' replaced 0 1.","code":""},{"path":"/reference/expand_wildcard.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand wildcard — expand_wildcard","text":"","code":"# Position of parentheses matters for type of expansion # In the \"global expansion\" versions of the entire statement are joined expand_wildcard('(Y[X=1, M=.] > Y[X=1, M=.])') #> Error in expand_wildcard(\"(Y[X=1, M=.] > Y[X=1, M=.])\"): could not find function \"expand_wildcard\" # In the \"local expansion\" versions of indicated parts are joined expand_wildcard('(Y[X=1, M=.]) > (Y[X=1, M=.])') #> Error in expand_wildcard(\"(Y[X=1, M=.]) > (Y[X=1, M=.])\"): could not find function \"expand_wildcard\"  # If parentheses are missing global expansion used. expand_wildcard('Y[X=1, M=.] > Y[X=1, M=.]') #> Error in expand_wildcard(\"Y[X=1, M=.] > Y[X=1, M=.]\"): could not find function \"expand_wildcard\"  # Expressions not requiring expansion are allowed expand_wildcard('(Y[X=1])') #> Error in expand_wildcard(\"(Y[X=1])\"): could not find function \"expand_wildcard\""},{"path":"/reference/find_rounding_threshold.html","id":null,"dir":"Reference","previous_headings":"","what":"helper to find rounding thresholds for print methods — find_rounding_threshold","title":"helper to find rounding thresholds for print methods — find_rounding_threshold","text":"helper find rounding thresholds print methods","code":""},{"path":"/reference/find_rounding_threshold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"helper to find rounding thresholds for print methods — find_rounding_threshold","text":"","code":"find_rounding_threshold(x)"},{"path":"/reference/get_all_data_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Get all data types — get_all_data_types","title":"Get all data types — get_all_data_types","text":"Creates dataframe data types (including NA types) possible model.","code":""},{"path":"/reference/get_all_data_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get all data types — get_all_data_types","text":"","code":"get_all_data_types(   model,   complete_data = FALSE,   possible_data = FALSE,   given = NULL )"},{"path":"/reference/get_all_data_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get all data types — get_all_data_types","text":"model causal_model. model object generated make_model. complete_data Logical. `TRUE` returns complete data types (NAs). Defaults `FALSE`. possible_data Logical. `TRUE` returns complete data types (NAs) *possible* given model restrictions. Note principle intervention make observationally impossible data types arise. Defaults `FALSE`. given character.  quoted statement evaluates logical. Data conditional specific values.","code":""},{"path":"/reference/get_all_data_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get all data types — get_all_data_types","text":"data.frame data types (including NA types)   possible model.","code":""},{"path":"/reference/get_all_data_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get all data types — get_all_data_types","text":"","code":"# \\donttest{ make_model('X -> Y') |> get_all_data_types() #>      event  X  Y #> X0Y0  X0Y0  0  0 #> X1Y0  X1Y0  1  0 #> X0Y1  X0Y1  0  1 #> X1Y1  X1Y1  1  1 #> Y0      Y0 NA  0 #> Y1      Y1 NA  1 #> X0      X0  0 NA #> X1      X1  1 NA #> None  None NA NA model <- make_model('X -> Y') %>%   set_restrictions(labels = list(Y = '00'), keep = TRUE)   get_all_data_types(model) #>      event  X  Y #> X0Y0  X0Y0  0  0 #> X1Y0  X1Y0  1  0 #> X0Y1  X0Y1  0  1 #> X1Y1  X1Y1  1  1 #> Y0      Y0 NA  0 #> Y1      Y1 NA  1 #> X0      X0  0 NA #> X1      X1  1 NA #> None  None NA NA   get_all_data_types(model, complete_data = TRUE) #>      event X Y #> X0Y0  X0Y0 0 0 #> X1Y0  X1Y0 1 0 #> X0Y1  X0Y1 0 1 #> X1Y1  X1Y1 1 1   get_all_data_types(model, possible_data = TRUE) #>      event X Y #> X0Y0  X0Y0 0 0 #> X1Y0  X1Y0 1 0   get_all_data_types(model, given  = 'X==1') #>      event X  Y #> X1Y0  X1Y0 1  0 #> X1Y1  X1Y1 1  1 #> X1      X1 1 NA   get_all_data_types(model, given  = 'X==1 & Y==1') #>      event X Y #> X1Y1  X1Y1 1 1 # }"},{"path":"/reference/get_ambiguities_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Get ambiguities matrix — get_ambiguities_matrix","title":"Get ambiguities matrix — get_ambiguities_matrix","text":"Return ambiguities matrix exists; otherwise calculate assuming confounding.ambiguities matrix maps causal types data types.","code":""},{"path":"/reference/get_ambiguities_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get ambiguities matrix — get_ambiguities_matrix","text":"","code":"get_ambiguities_matrix(model)"},{"path":"/reference/get_ambiguities_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get ambiguities matrix — get_ambiguities_matrix","text":"model causal_model. model object generated make_model.","code":""},{"path":"/reference/get_ambiguities_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get ambiguities matrix — get_ambiguities_matrix","text":"data.frame. Causal types (rows) corresponding possible data realizations (columns).","code":""},{"path":"/reference/get_ambiguities_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get ambiguities matrix — get_ambiguities_matrix","text":"","code":"model <- make_model('X -> Y') get_ambiguities_matrix(model = model) #> Error in get_ambiguities_matrix(model = model): could not find function \"get_ambiguities_matrix\""},{"path":"/reference/get_causal_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Get causal types — get_causal_types","title":"Get causal types — get_causal_types","text":"Return data frame types produced combinations possible data produced DAG.","code":""},{"path":"/reference/get_causal_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get causal types — get_causal_types","text":"","code":"get_causal_types(model)"},{"path":"/reference/get_causal_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get causal types — get_causal_types","text":"model causal_model. model object generated make_model.","code":""},{"path":"/reference/get_causal_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get causal types — get_causal_types","text":"data.frame indicating causal types model","code":""},{"path":"/reference/get_causal_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get causal types — get_causal_types","text":"","code":"get_causal_types(make_model('X -> Y')) #> Error in get_causal_types(make_model(\"X -> Y\")): could not find function \"get_causal_types\""},{"path":"/reference/get_data_families.html","id":null,"dir":"Reference","previous_headings":"","what":"get_data_families — get_data_families","title":"get_data_families — get_data_families","text":"Get possible data types","code":""},{"path":"/reference/get_data_families.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get_data_families — get_data_families","text":"","code":"get_data_families(   model,   drop_impossible = TRUE,   drop_all_NA = TRUE,   mapping_only = FALSE )"},{"path":"/reference/get_data_families.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get_data_families — get_data_families","text":"model causal_model. model object generated make_model. drop_impossible Logical. Whether drop data impossible given model restrictions. Defaults `TRUE`. drop_all_NA Logical. Whether drop row `NA`s. Defaults `TRUE` mapping_only Logical. Whether return data mapping matrix . Defaults `FALSE`.","code":""},{"path":"/reference/get_data_families.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"get_data_families — get_data_families","text":"Returns indices ambiguity matrix","code":""},{"path":"/reference/get_data_families.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"get_data_families — get_data_families","text":"","code":"# \\donttest{ CausalQueries:::get_data_families(model = make_model('X->Y')) #>      event strategy X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0  X0Y0       XY    1    0    0    0 #> X1Y0  X1Y0       XY    0    1    0    0 #> X0Y1  X0Y1       XY    0    0    1    0 #> X1Y1  X1Y1       XY    0    0    0    1 #> Y0      Y0        Y    1    1    0    0 #> Y1      Y1        Y    0    0    1    1 #> X0      X0        X    1    0    1    0 #> X1      X1        X    0    1    0    1 CausalQueries:::get_data_families(model = make_model('X->Y'),                                   mapping_only = TRUE) #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 #> Y0      1    1    0    0 #> Y1      0    0    1    1 #> X0      1    0    1    0 #> X1      0    1    0    1 CausalQueries:::get_data_families(model = make_model('X-> M -> Y')) #>         event strategy X0M0Y0 X1M0Y0 X0M1Y0 X1M1Y0 X0M0Y1 X1M0Y1 X0M1Y1 X1M1Y1 #> X0M0Y0 X0M0Y0      XMY      1      0      0      0      0      0      0      0 #> X1M0Y0 X1M0Y0      XMY      0      1      0      0      0      0      0      0 #> X0M1Y0 X0M1Y0      XMY      0      0      1      0      0      0      0      0 #> X1M1Y0 X1M1Y0      XMY      0      0      0      1      0      0      0      0 #> X0M0Y1 X0M0Y1      XMY      0      0      0      0      1      0      0      0 #> X1M0Y1 X1M0Y1      XMY      0      0      0      0      0      1      0      0 #> X0M1Y1 X0M1Y1      XMY      0      0      0      0      0      0      1      0 #> X1M1Y1 X1M1Y1      XMY      0      0      0      0      0      0      0      1 #> M0Y0     M0Y0       MY      1      1      0      0      0      0      0      0 #> M1Y0     M1Y0       MY      0      0      1      1      0      0      0      0 #> M0Y1     M0Y1       MY      0      0      0      0      1      1      0      0 #> M1Y1     M1Y1       MY      0      0      0      0      0      0      1      1 #> X0Y0     X0Y0       XY      1      0      1      0      0      0      0      0 #> X1Y0     X1Y0       XY      0      1      0      1      0      0      0      0 #> X0Y1     X0Y1       XY      0      0      0      0      1      0      1      0 #> X1Y1     X1Y1       XY      0      0      0      0      0      1      0      1 #> X0M0     X0M0       XM      1      0      0      0      1      0      0      0 #> X1M0     X1M0       XM      0      1      0      0      0      1      0      0 #> X0M1     X0M1       XM      0      0      1      0      0      0      1      0 #> X1M1     X1M1       XM      0      0      0      1      0      0      0      1 #> Y0         Y0        Y      1      1      1      1      0      0      0      0 #> Y1         Y1        Y      0      0      0      0      1      1      1      1 #> M0         M0        M      1      1      0      0      1      1      0      0 #> M1         M1        M      0      0      1      1      0      0      1      1 #> X0         X0        X      1      0      1      0      1      0      1      0 #> X1         X1        X      0      1      0      1      0      1      0      1  # }"},{"path":"/reference/get_estimands.html","id":null,"dir":"Reference","previous_headings":"","what":"helper to get estimands — get_estimands","title":"helper to get estimands — get_estimands","text":"helper get estimands","code":""},{"path":"/reference/get_estimands.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"helper to get estimands — get_estimands","text":"","code":"get_estimands(jobs, given_types, query_types, type_distributions)"},{"path":"/reference/get_estimands.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"helper to get estimands — get_estimands","text":"jobs DataFrame argument combinations given_types output queries_to_types query_types output queries_to_types type_distributions output get_type_distributions","code":""},{"path":"/reference/get_estimands.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"helper to get estimands — get_estimands","text":"list estimands","code":""},{"path":"/reference/get_event_probabilities.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw event probabilities — get_event_probabilities","title":"Draw event probabilities — get_event_probabilities","text":"`get_event_probabilities` draws event probability vector `w` given single realization parameters","code":""},{"path":"/reference/get_event_probabilities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw event probabilities — get_event_probabilities","text":"","code":"get_event_probabilities(   model,   parameters = NULL,   A = NULL,   P = NULL,   given = NULL )"},{"path":"/reference/get_event_probabilities.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw event probabilities — get_event_probabilities","text":"model causal_model. model object generated make_model. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn model$parameters_df. data.frame. Ambiguity matrix. required may provided avoid repeated computation simulations. P data.frame. Parameter matrix. required may provided avoid repeated computation simulations. given string specifying known values nodes, e.g. \"X==1 & Y==1\"","code":""},{"path":"/reference/get_event_probabilities.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw event probabilities — get_event_probabilities","text":"array event probabilities","code":""},{"path":"/reference/get_event_probabilities.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw event probabilities — get_event_probabilities","text":"","code":"# \\donttest{ model <- make_model('X -> Y') get_event_probabilities(model = model) #>      event_probs #> X0Y0        0.25 #> X1Y0        0.25 #> X0Y1        0.25 #> X1Y1        0.25 get_event_probabilities(model = model, given = \"X==1\") #>      event_probs #> X0Y0         0.0 #> X1Y0         0.5 #> X0Y1         0.0 #> X1Y1         0.5 get_event_probabilities(model = model, parameters = rep(1, 6)) #>      event_probs #> X0Y0        0.25 #> X1Y0        0.25 #> X0Y1        0.25 #> X1Y1        0.25 get_event_probabilities(model = model, parameters = 1:6) #>      event_probs #> X0Y0   0.1481481 #> X1Y0   0.2592593 #> X0Y1   0.1851852 #> X1Y1   0.4074074 # }"},{"path":"/reference/get_nodal_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Get list of types for nodes in a DAG — get_nodal_types","title":"Get list of types for nodes in a DAG — get_nodal_types","text":"type labels hard interpret large models, type list includes attribute help interpret . See  attr(types, interpret)","code":""},{"path":"/reference/get_nodal_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get list of types for nodes in a DAG — get_nodal_types","text":"","code":"get_nodal_types(model, collapse = TRUE)"},{"path":"/reference/get_nodal_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get list of types for nodes in a DAG — get_nodal_types","text":"model causal_model. model object generated make_model. collapse Logical. `TRUE`, shows unique nodal types node. `FALSE`, shows node matrix nodal types rows parent types columns, applicable. Defaults `TRUE`.","code":""},{"path":"/reference/get_nodal_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get list of types for nodes in a DAG — get_nodal_types","text":"named list nodal types parent DAG","code":""},{"path":"/reference/get_nodal_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get list of types for nodes in a DAG — get_nodal_types","text":"","code":"# \\donttest{ model <- make_model('X -> K -> Y') get_nodal_types(model) #> Error in get_nodal_types(model): could not find function \"get_nodal_types\"  model <- make_model('X -> K -> Y') %>%    set_restrictions(statement = 'K[X=1]>K[X=0]') %>%    set_confound(list(K = 'Y[K=1]>Y[K=0]')) get_nodal_types(model) #> Error in get_nodal_types(model): could not find function \"get_nodal_types\" # }"},{"path":"/reference/get_parameter_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Get parameter matrix — get_parameter_matrix","title":"Get parameter matrix — get_parameter_matrix","text":"Return parameter matrix exists; otherwise calculate assuming confounding. parameter matrix  maps parameters causal types. models without confounding parameters correspond nodal types.","code":""},{"path":"/reference/get_parameter_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get parameter matrix — get_parameter_matrix","text":"","code":"get_parameter_matrix(model)"},{"path":"/reference/get_parameter_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get parameter matrix — get_parameter_matrix","text":"model model created make_model()","code":""},{"path":"/reference/get_parameter_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get parameter matrix — get_parameter_matrix","text":"data.frame, parameter matrix, mapping   parameters causal types","code":""},{"path":"/reference/get_parameter_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get parameter matrix — get_parameter_matrix","text":"","code":"model <- make_model('X -> Y') get_parameter_matrix(model) #> Error in get_parameter_matrix(model): could not find function \"get_parameter_matrix\""},{"path":"/reference/get_parameter_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Get parameter names — get_parameter_names","title":"Get parameter names — get_parameter_names","text":"Parameter names taken P matrix model P  matrix provided","code":""},{"path":"/reference/get_parameter_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get parameter names — get_parameter_names","text":"","code":"get_parameter_names(model, include_paramset = TRUE)"},{"path":"/reference/get_parameter_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get parameter names — get_parameter_names","text":"model causal_model. model object generated make_model. include_paramset Logical. Whether include param set prefix part name.","code":""},{"path":"/reference/get_parameter_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get parameter names — get_parameter_names","text":"character vector names parameters model","code":""},{"path":"/reference/get_parameter_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get parameter names — get_parameter_names","text":"","code":"get_parameter_names(make_model('X->Y')) #> Error in get_parameter_names(make_model(\"X->Y\")): could not find function \"get_parameter_names\""},{"path":"/reference/get_param_dist.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a distribution of model parameters — get_param_dist","title":"Get a distribution of model parameters — get_param_dist","text":"Using parameters, priors, posteriors","code":""},{"path":"/reference/get_param_dist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a distribution of model parameters — get_param_dist","text":"","code":"get_param_dist(model, using, n_draws = 4000)"},{"path":"/reference/get_param_dist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a distribution of model parameters — get_param_dist","text":"model causal_model. model object generated make_model. using character string. Indicates whether use `priors`, `posteriors` `parameters`. n_draws integer. prior distribution provided, generate prior distribution n_draws number draws.","code":""},{"path":"/reference/get_param_dist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a distribution of model parameters — get_param_dist","text":"matrix distribution parameters model","code":""},{"path":"/reference/get_param_dist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get a distribution of model parameters — get_param_dist","text":"","code":"get_param_dist(model = make_model('X->Y'), using = 'priors', n_draws = 4) #> Error in get_param_dist(model = make_model(\"X->Y\"), using = \"priors\",     n_draws = 4): could not find function \"get_param_dist\" get_param_dist(model = make_model('X->Y'), using = 'parameters') #> Error in get_param_dist(model = make_model(\"X->Y\"), using = \"parameters\"): could not find function \"get_param_dist\""},{"path":"/reference/get_parents.html","id":null,"dir":"Reference","previous_headings":"","what":"Get list of parents of all nodes in a model — get_parents","title":"Get list of parents of all nodes in a model — get_parents","text":"Get list parents nodes model","code":""},{"path":"/reference/get_parents.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get list of parents of all nodes in a model — get_parents","text":"","code":"get_parents(model)"},{"path":"/reference/get_parents.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get list of parents of all nodes in a model — get_parents","text":"model causal_model. model object generated make_model.","code":""},{"path":"/reference/get_parents.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get list of parents of all nodes in a model — get_parents","text":"list parents DAG","code":""},{"path":"/reference/get_parents.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get list of parents of all nodes in a model — get_parents","text":"","code":"model <- make_model('X -> K -> Y') get_parents(model) #> Error in get_parents(model): could not find function \"get_parents\""},{"path":"/reference/get_parmap.html","id":null,"dir":"Reference","previous_headings":"","what":"Get parmap: a matrix mapping from parameters to data types — get_parmap","title":"Get parmap: a matrix mapping from parameters to data types — get_parmap","text":"Gets parmap model, generates available.","code":""},{"path":"/reference/get_parmap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get parmap: a matrix mapping from parameters to data types — get_parmap","text":"","code":"get_parmap(model, A = NULL, P = NULL)"},{"path":"/reference/get_parmap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get parmap: a matrix mapping from parameters to data types — get_parmap","text":"model causal_model. model object generated make_model. data.frame. Ambiguity matrix. required may provided avoid repeated computation simulations. P data.frame. Parameter matrix. required may provided avoid repeated computation simulations.","code":""},{"path":"/reference/get_parmap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get parmap: a matrix mapping from parameters to data types — get_parmap","text":"matrix","code":""},{"path":"/reference/get_parmap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get parmap: a matrix mapping from parameters to data types — get_parmap","text":"","code":"get_parmap(model = make_model('X->Y')) #> Error in get_parmap(model = make_model(\"X->Y\")): could not find function \"get_parmap\""},{"path":"/reference/get_posterior_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the posterior distribution from a model — get_posterior_distribution","title":"Get the posterior distribution from a model — get_posterior_distribution","text":"Access posterior distribution model one added via `update_model`.","code":""},{"path":"/reference/get_posterior_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the posterior distribution from a model — get_posterior_distribution","text":"","code":"get_posterior_distribution(model)"},{"path":"/reference/get_posterior_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the posterior distribution from a model — get_posterior_distribution","text":"model causal_model. model object generated make_model.","code":""},{"path":"/reference/get_posterior_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the posterior distribution from a model — get_posterior_distribution","text":"`data.frame` parameters draws","code":""},{"path":"/reference/get_posterior_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the posterior distribution from a model — get_posterior_distribution","text":"","code":"make_model('X -> Y') |>   update_model()  |>   get_posterior_distribution() #> Error in get_posterior_distribution(update_model(make_model(\"X -> Y\"))): could not find function \"get_posterior_distribution\""},{"path":"/reference/get_prior_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a prior distribution from model — get_prior_distribution","title":"Get a prior distribution from model — get_prior_distribution","text":"Access prior distribution model one added via `set_prior_distribution`. Otherwise call  `make_prior_distribution` generate return `n_draws x n_param`  prior distribution.","code":""},{"path":"/reference/get_prior_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a prior distribution from model — get_prior_distribution","text":"","code":"get_prior_distribution(model, n_draws = 4000)"},{"path":"/reference/get_prior_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a prior distribution from model — get_prior_distribution","text":"model causal_model. model object generated make_model. n_draws scalar. Number draws.","code":""},{"path":"/reference/get_prior_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a prior distribution from model — get_prior_distribution","text":"`data.frame` dimension `n_param`x `n_draws` possible   lambda draws","code":""},{"path":[]},{"path":"/reference/get_prior_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get a prior distribution from model — get_prior_distribution","text":"","code":"make_model('X -> Y') %>%   set_prior_distribution(n_draws = 5) %>%   get_prior_distribution() #> Error in get_prior_distribution(.): could not find function \"get_prior_distribution\" make_model('X -> Y') %>%   get_prior_distribution(3) #> Error in get_prior_distribution(., 3): could not find function \"get_prior_distribution\""},{"path":"/reference/get_query_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Look up query types — get_query_types","title":"Look up query types — get_query_types","text":"Find nodal causal types satisfied query.","code":""},{"path":"/reference/get_query_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Look up query types — get_query_types","text":"","code":"get_query_types(model, query, map = \"causal_type\", join_by = \"|\")"},{"path":"/reference/get_query_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Look up query types — get_query_types","text":"model causal_model. model object generated make_model. query character string. expression defining nodal types interrogate realise_outcomes. expression form \"Y[X=1]\" asks value Y X set 1 map Types query. Either nodal_type causal_type. Default causal_type. join_by logical operator. Used connect causal statements: ('&') ('|'). Defaults '|'.","code":""},{"path":"/reference/get_query_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Look up query types — get_query_types","text":"list containing following elements types named vector logical values indicating whether   nodal_type causal_type satisfy `query` query character string specified user expanded_query character string expanded query.   differs `query` contains wildcard '.' evaluated_nodes Value nodes take given query node character string node whose   nodal types queried type_list List causal types satisfied query","code":""},{"path":"/reference/get_query_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Look up query types — get_query_types","text":"","code":"model <- make_model('X -> M -> Y; X->Y') query <- '(Y[X=0] > Y[X=1])' # \\donttest{ get_query_types(model, query, map=\"nodal_type\") #>  #> Nodal types adding weight to query #>  #>  query :  (Y[X=0,M=0]>Y[X=1,M=0] | Y[X=0,M=1]>Y[X=1,M=1])  #>  #>  1000   0010 #>  1010   0110 #>  1110   1001 #>  1011    #>  #>  #>  Number of nodal types that add weight to query = 7 #>  Total number of nodal types related to Y = 16 get_query_types(model, query, map=\"causal_type\") #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  (Y[X=0]>Y[X=1])  #>  #> X0.M00.Y1000  X1.M00.Y1000 #> X0.M01.Y1000  X1.M01.Y1000 #> X0.M01.Y1100  X1.M01.Y1100 #> X0.M10.Y0010  X1.M10.Y0010 #> X0.M11.Y0010  X1.M11.Y0010 #> X0.M00.Y1010  X1.M00.Y1010 #> X0.M10.Y1010  X1.M10.Y1010 #> X0.M01.Y1010  X1.M01.Y1010 #> X0.M11.Y1010  X1.M11.Y1010 #> X0.M11.Y0110  X1.M11.Y0110 #> X0.M01.Y1110  X1.M01.Y1110 #> X0.M11.Y1110  X1.M11.Y1110 #> X0.M00.Y1001  X1.M00.Y1001 #> X0.M10.Y0011  X1.M10.Y0011 #> X0.M00.Y1011  X1.M00.Y1011 #> X0.M10.Y1011  X1.M10.Y1011 #>  #>  #>  Number of causal types that meet condition(s) =  32 #>  Total number of causal types in model =  128 get_query_types(model, query) #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  (Y[X=0]>Y[X=1])  #>  #> X0.M00.Y1000  X1.M00.Y1000 #> X0.M01.Y1000  X1.M01.Y1000 #> X0.M01.Y1100  X1.M01.Y1100 #> X0.M10.Y0010  X1.M10.Y0010 #> X0.M11.Y0010  X1.M11.Y0010 #> X0.M00.Y1010  X1.M00.Y1010 #> X0.M10.Y1010  X1.M10.Y1010 #> X0.M01.Y1010  X1.M01.Y1010 #> X0.M11.Y1010  X1.M11.Y1010 #> X0.M11.Y0110  X1.M11.Y0110 #> X0.M01.Y1110  X1.M01.Y1110 #> X0.M11.Y1110  X1.M11.Y1110 #> X0.M00.Y1001  X1.M00.Y1001 #> X0.M10.Y0011  X1.M10.Y0011 #> X0.M00.Y1011  X1.M00.Y1011 #> X0.M10.Y1011  X1.M10.Y1011 #>  #>  #>  Number of causal types that meet condition(s) =  32 #>  Total number of causal types in model =  128  # Examples with map = \"nodal_type\"  query <- '(Y[X=0, M = .] > Y[X=1, M = 0])' get_query_types(model, query, map=\"nodal_type\") #>  #> Nodal types adding weight to query #>  #>  query :  (Y[X=0,M=0]>Y[X=1,M=0] | Y[X=0,M=1]>Y[X=1,M=0])  #>  #>  1000   0010 #>  1010   1001 #>  0011   1011 #>  #>  #>  Number of nodal types that add weight to query = 6 #>  Total number of nodal types related to Y = 16  query <- '(Y[] == 1)' get_query_types(model, query, map=\"nodal_type\") #>  #> Nodal types adding weight to query #>  #>  query :  (Y[X=0,M=0]==1 | Y[X=1,M=0]==1 | Y[X=0,M=1]==1 | Y[X=1,M=1]==1)  #>  #>  1000   0100 #>  1100   0010 #>  1010   0110 #>  1110   0001 #>  1001   0101 #>  1101   0011 #>  1011   0111 #>  1111    #>  #>  #>  Number of nodal types that add weight to query = 15 #>  Total number of nodal types related to Y = 16 get_query_types(model, query, map=\"nodal_type\", join_by = '&') #>  #> Nodal types adding weight to query #>  #>  query :  (Y[X=0,M=0]==1 & Y[X=1,M=0]==1 & Y[X=0,M=1]==1 & Y[X=1,M=1]==1)  #>  #>  1111    #>  #>  #>  Number of nodal types that add weight to query = 1 #>  Total number of nodal types related to Y = 16  # Root nodes specified with [] get_query_types(model, '(X[] == 1)', map=\"nodal_type\") #>  #> Nodal types adding weight to query #>  #>  query :  (X[]==1)  #>  #>  1    #>  #>  #>  Number of nodal types that add weight to query = 1 #>  Total number of nodal types related to X = 2  query <- '(M[X=1] == M[X=0])' get_query_types(model, query, map=\"nodal_type\") #>  #> Nodal types adding weight to query #>  #>  query :  (M[X=1]==M[X=0])  #>  #>  00   11 #>  #>  #>  Number of nodal types that add weight to query = 2 #>  Total number of nodal types related to M = 4  # Nested do operations get_query_types(  model = make_model('A -> B -> C -> D'),  query = '(D[C=C[B=B[A=1]], A=0] > D[C=C[B=B[A=0]], A=0])') #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  (D[C=C[B=B[A=1]],A=0]>D[C=C[B=B[A=0]],A=0])  #>  #> A0.B01.C10.D10  A1.B01.C10.D10 #> A0.B10.C01.D10  A1.B10.C01.D10 #> A0.B10.C10.D01  A1.B10.C10.D01 #> A0.B01.C01.D01  A1.B01.C01.D01 #>  #>  #>  Number of causal types that meet condition(s) =  8 #>  Total number of causal types in model =  128  # Helpers model <- make_model('M->Y; X->Y') query <- complements('X', 'M', 'Y') get_query_types(model, query, map=\"nodal_type\") #>  #> Nodal types adding weight to query #>  #>  query :  ((Y[X=1,M=1])-(Y[X=0,M=1]))>((Y[X=1,M=0])-(Y[X=0,M=0]))  #>  #>  1000   0001 #>  1001   1101 #>  1011    #>  #>  #>  Number of nodal types that add weight to query = 5 #>  Total number of nodal types related to Y = 16  # Examples with map = \"causal_type\"  model <- make_model('X -> M -> Y; X->Y') query <- 'Y[M=M[X=0], X=1]==1' get_query_types(model, query, map= \"causal_type\") #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  Y[M=M[X=0],X=1]==1  #>  #> X0.M00.Y0100  X1.M00.Y0100 #> X0.M01.Y0100  X1.M01.Y0100 #> X0.M00.Y1100  X1.M00.Y1100 #> X0.M01.Y1100  X1.M01.Y1100 #> X0.M00.Y0110  X1.M00.Y0110 #> X0.M01.Y0110  X1.M01.Y0110 #> X0.M00.Y1110  X1.M00.Y1110 #> X0.M01.Y1110  X1.M01.Y1110 #> X0.M10.Y0001  X1.M10.Y0001 #> X0.M11.Y0001  X1.M11.Y0001 #> X0.M10.Y1001  X1.M10.Y1001 #> X0.M11.Y1001  X1.M11.Y1001 #> X0.M00.Y0101  X1.M00.Y0101 #> X0.M10.Y0101  X1.M10.Y0101 #> X0.M01.Y0101  X1.M01.Y0101 #> X0.M11.Y0101  X1.M11.Y0101 #> X0.M00.Y1101  X1.M00.Y1101 #> X0.M10.Y1101  X1.M10.Y1101 #> X0.M01.Y1101  X1.M01.Y1101 #> X0.M11.Y1101  X1.M11.Y1101 #> X0.M10.Y0011  X1.M10.Y0011 #> X0.M11.Y0011  X1.M11.Y0011 #> X0.M10.Y1011  X1.M10.Y1011 #> X0.M11.Y1011  X1.M11.Y1011 #> X0.M00.Y0111  X1.M00.Y0111 #> X0.M10.Y0111  X1.M10.Y0111 #> X0.M01.Y0111  X1.M01.Y0111 #> X0.M11.Y0111  X1.M11.Y0111 #> X0.M00.Y1111  X1.M00.Y1111 #> X0.M10.Y1111  X1.M10.Y1111 #> X0.M01.Y1111  X1.M01.Y1111 #> X0.M11.Y1111  X1.M11.Y1111 #>  #>  #>  Number of causal types that meet condition(s) =  64 #>  Total number of causal types in model =  128  query <- '(Y[X = 1, M = 1] >  Y[X = 0, M = 1]) &           (Y[X = 1, M = 0] >  Y[X = 0, M = 0])' get_query_types(model, query, \"causal_type\") #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  (Y[X=1,M=1]>Y[X=0,M=1])& #> (Y[X=1,M=0]>Y[X=0,M=0])  #>  #> X0.M00.Y0101  X1.M00.Y0101 #> X0.M10.Y0101  X1.M10.Y0101 #> X0.M01.Y0101  X1.M01.Y0101 #> X0.M11.Y0101  X1.M11.Y0101 #>  #>  #>  Number of causal types that meet condition(s) =  8 #>  Total number of causal types in model =  128  query <- 'Y[X=1] == Y[X=0]' get_query_types(model, query, \"causal_type\") #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  Y[X=1]==Y[X=0]  #>  #> X0.M00.Y0000  X1.M00.Y0000 #> X0.M10.Y0000  X1.M10.Y0000 #> X0.M01.Y0000  X1.M01.Y0000 #> X0.M11.Y0000  X1.M11.Y0000 #> X0.M10.Y1000  X1.M10.Y1000 #> X0.M11.Y1000  X1.M11.Y1000 #> X0.M01.Y0100  X1.M01.Y0100 #> X0.M11.Y0100  X1.M11.Y0100 #> X0.M00.Y1100  X1.M00.Y1100 #> X0.M11.Y1100  X1.M11.Y1100 #> X0.M00.Y0010  X1.M00.Y0010 #> X0.M01.Y0010  X1.M01.Y0010 #> X0.M10.Y0110  X1.M10.Y0110 #> X0.M01.Y0110  X1.M01.Y0110 #> X0.M00.Y1110  X1.M00.Y1110 #> X0.M10.Y1110  X1.M10.Y1110 #> X0.M00.Y0001  X1.M00.Y0001 #> X0.M10.Y0001  X1.M10.Y0001 #> X0.M10.Y1001  X1.M10.Y1001 #> X0.M01.Y1001  X1.M01.Y1001 #> X0.M00.Y1101  X1.M00.Y1101 #> X0.M01.Y1101  X1.M01.Y1101 #> X0.M00.Y0011  X1.M00.Y0011 #> X0.M11.Y0011  X1.M11.Y0011 #> X0.M01.Y1011  X1.M01.Y1011 #> X0.M11.Y1011  X1.M11.Y1011 #> X0.M10.Y0111  X1.M10.Y0111 #> X0.M11.Y0111  X1.M11.Y0111 #> X0.M00.Y1111  X1.M00.Y1111 #> X0.M10.Y1111  X1.M10.Y1111 #> X0.M01.Y1111  X1.M01.Y1111 #> X0.M11.Y1111  X1.M11.Y1111 #>  #>  #>  Number of causal types that meet condition(s) =  64 #>  Total number of causal types in model =  128  query <- '(X == 1) & (M==1) & (Y ==1) & (Y[X=0] ==1)' get_query_types(model, query, \"causal_type\") #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  (X==1)&(M==1)&(Y==1)&(Y[X=0]==1)  #>  #> X1.M01.Y1001  X1.M01.Y1101 #> X1.M11.Y0011  X1.M01.Y1011 #> X1.M11.Y1011  X1.M11.Y0111 #> X1.M01.Y1111  X1.M11.Y1111 #>  #>  #>  Number of causal types that meet condition(s) =  8 #>  Total number of causal types in model =  128  query <- '(Y[X = .]==1)' get_query_types(model, query, \"causal_type\") #> Generated expanded expression: #> (Y[X=0]==1 | Y[X=1]==1) #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  (Y[X=0]==1|Y[X=1]==1)  #>  #> X0.M00.Y1000  X1.M00.Y1000 #> X0.M01.Y1000  X1.M01.Y1000 #> X0.M00.Y0100  X1.M00.Y0100 #> X0.M10.Y0100  X1.M10.Y0100 #> X0.M00.Y1100  X1.M00.Y1100 #> X0.M10.Y1100  X1.M10.Y1100 #> X0.M01.Y1100  X1.M01.Y1100 #> X0.M10.Y0010  X1.M10.Y0010 #> X0.M11.Y0010  X1.M11.Y0010 #> X0.M00.Y1010  X1.M00.Y1010 #> X0.M10.Y1010  X1.M10.Y1010 #> X0.M01.Y1010  X1.M01.Y1010 #> X0.M11.Y1010  X1.M11.Y1010 #> X0.M00.Y0110  X1.M00.Y0110 #> X0.M10.Y0110  X1.M10.Y0110 #> X0.M11.Y0110  X1.M11.Y0110 #> X0.M00.Y1110  X1.M00.Y1110 #> X0.M10.Y1110  X1.M10.Y1110 #> X0.M01.Y1110  X1.M01.Y1110 #> X0.M11.Y1110  X1.M11.Y1110 #> X0.M01.Y0001  X1.M01.Y0001 #> X0.M11.Y0001  X1.M11.Y0001 #> X0.M00.Y1001  X1.M00.Y1001 #> X0.M01.Y1001  X1.M01.Y1001 #> X0.M11.Y1001  X1.M11.Y1001 #> X0.M00.Y0101  X1.M00.Y0101 #> X0.M10.Y0101  X1.M10.Y0101 #> X0.M01.Y0101  X1.M01.Y0101 #> X0.M11.Y0101  X1.M11.Y0101 #> X0.M00.Y1101  X1.M00.Y1101 #> X0.M10.Y1101  X1.M10.Y1101 #> X0.M01.Y1101  X1.M01.Y1101 #> X0.M11.Y1101  X1.M11.Y1101 #> X0.M10.Y0011  X1.M10.Y0011 #> X0.M01.Y0011  X1.M01.Y0011 #> X0.M11.Y0011  X1.M11.Y0011 #> X0.M00.Y1011  X1.M00.Y1011 #> X0.M10.Y1011  X1.M10.Y1011 #> X0.M01.Y1011  X1.M01.Y1011 #> X0.M11.Y1011  X1.M11.Y1011 #> X0.M00.Y0111  X1.M00.Y0111 #> X0.M10.Y0111  X1.M10.Y0111 #> X0.M01.Y0111  X1.M01.Y0111 #> X0.M11.Y0111  X1.M11.Y0111 #> X0.M00.Y1111  X1.M00.Y1111 #> X0.M10.Y1111  X1.M10.Y1111 #> X0.M01.Y1111  X1.M01.Y1111 #> X0.M11.Y1111  X1.M11.Y1111 #>  #>  #>  Number of causal types that meet condition(s) =  96 #>  Total number of causal types in model =  128 # }"},{"path":"/reference/get_type_distributions.html","id":null,"dir":"Reference","previous_headings":"","what":"helper to get type distributions — get_type_distributions","title":"helper to get type distributions — get_type_distributions","text":"helper get type distributions","code":""},{"path":"/reference/get_type_distributions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"helper to get type distributions — get_type_distributions","text":"","code":"get_type_distributions(jobs, model, n_draws, parameters = NULL)"},{"path":"/reference/get_type_distributions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"helper to get type distributions — get_type_distributions","text":"jobs DataFrame argument combinations model list models n_draws integer specifying number draws prior distribution parameters optional list parameter vectors","code":""},{"path":"/reference/get_type_distributions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"helper to get type distributions — get_type_distributions","text":"jobs DataFrame nested column type distributions","code":""},{"path":"/reference/get_type_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Get type names — get_type_names","title":"Get type names — get_type_names","text":"Get type names","code":""},{"path":"/reference/get_type_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get type names — get_type_names","text":"","code":"get_type_names(nodal_types)"},{"path":"/reference/get_type_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get type names — get_type_names","text":"nodal_types Nodal types model. See get_nodal_types.","code":""},{"path":"/reference/get_type_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get type names — get_type_names","text":"vector containing causal type names","code":""},{"path":"/reference/get_type_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get type names — get_type_names","text":"","code":"model <- make_model('A->Y<-B') CausalQueries:::get_type_names(model$nodal_types) #>  [1] \"A.0\"    \"A.1\"    \"B.0\"    \"B.1\"    \"Y.0000\" \"Y.1000\" \"Y.0100\" \"Y.1100\" #>  [9] \"Y.0010\" \"Y.1010\" \"Y.0110\" \"Y.1110\" \"Y.0001\" \"Y.1001\" \"Y.0101\" \"Y.1101\" #> [17] \"Y.0011\" \"Y.1011\" \"Y.0111\" \"Y.1111\""},{"path":"/reference/get_type_prob.html","id":null,"dir":"Reference","previous_headings":"","what":"Get type probabilities — get_type_prob","title":"Get type probabilities — get_type_prob","text":"Gets probability vector causal types given single realization parameters, possibly drawn model priors.","code":""},{"path":"/reference/get_type_prob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get type probabilities — get_type_prob","text":"","code":"get_type_prob(model, P = NULL, parameters = NULL)"},{"path":"/reference/get_type_prob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get type probabilities — get_type_prob","text":"model causal_model. model object generated make_model. P data.frame. Parameter matrix. required may provided avoid repeated computation simulations. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn model$parameters_df.","code":""},{"path":"/reference/get_type_prob.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get type probabilities — get_type_prob","text":"vector probabilities vector causal types","code":""},{"path":"/reference/get_type_prob.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get type probabilities — get_type_prob","text":"default, parameters drawn `using` argument (either priors, posteriors, model$parameters)","code":""},{"path":"/reference/get_type_prob.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get type probabilities — get_type_prob","text":"","code":"get_type_prob(model = make_model('X->Y')) #> Error in get_type_prob(model = make_model(\"X->Y\")): could not find function \"get_type_prob\" get_type_prob(model = make_model('X->Y'), parameters = 1:6) #> Error in get_type_prob(model = make_model(\"X->Y\"), parameters = 1:6): could not find function \"get_type_prob\""},{"path":"/reference/get_type_prob_c.html","id":null,"dir":"Reference","previous_headings":"","what":"generates one draw from type probability distribution for each type in P — get_type_prob_c","title":"generates one draw from type probability distribution for each type in P — get_type_prob_c","text":"generates one draw type probability distribution type P","code":""},{"path":"/reference/get_type_prob_c.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"generates one draw from type probability distribution for each type in P — get_type_prob_c","text":"","code":"get_type_prob_c(P, parameters)"},{"path":"/reference/get_type_prob_c.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"generates one draw from type probability distribution for each type in P — get_type_prob_c","text":"P parameter_matrix parameters causal types parameters, priors posteriors","code":""},{"path":"/reference/get_type_prob_c.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"generates one draw from type probability distribution for each type in P — get_type_prob_c","text":"draw type distribution type P","code":""},{"path":"/reference/get_type_prob_multiple.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw matrix of type probabilities, before or after estimation — get_type_prob_multiple","title":"Draw matrix of type probabilities, before or after estimation — get_type_prob_multiple","text":"Draw matrix type probabilities, estimation","code":""},{"path":"/reference/get_type_prob_multiple.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw matrix of type probabilities, before or after estimation — get_type_prob_multiple","text":"","code":"get_type_prob_multiple(   model,   using = \"priors\",   parameters = NULL,   n_draws = 4000,   param_dist = NULL,   P = NULL )"},{"path":"/reference/get_type_prob_multiple.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw matrix of type probabilities, before or after estimation — get_type_prob_multiple","text":"model causal_model. model object generated make_model. using character. indicates whether use `priors`, `posteriors` `parameters`. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn model$parameters_df. n_draws integer. prior distribution provided, generate prior distribution n_draws number draws. param_dist matrix.  Distribution parameters. Optional speed. P data.frame. Parameter matrix. required may provided avoid repeated computation simulations.","code":""},{"path":"/reference/get_type_prob_multiple.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw matrix of type probabilities, before or after estimation — get_type_prob_multiple","text":"matrix type probabilities.","code":""},{"path":"/reference/get_type_prob_multiple.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw matrix of type probabilities, before or after estimation — get_type_prob_multiple","text":"","code":"model <- make_model('X -> Y') get_type_prob_multiple(model, using = 'priors', n_draws = 3) #> Error in get_type_prob_multiple(model, using = \"priors\", n_draws = 3): could not find function \"get_type_prob_multiple\" get_type_prob_multiple(model, using = 'parameters', n_draws = 3) #> Error in get_type_prob_multiple(model, using = \"parameters\", n_draws = 3): could not find function \"get_type_prob_multiple\""},{"path":"/reference/get_type_prob_multiple_c.html","id":null,"dir":"Reference","previous_headings":"","what":"generates n draws from type probability distribution for each type in P — get_type_prob_multiple_c","title":"generates n draws from type probability distribution for each type in P — get_type_prob_multiple_c","text":"generates n draws type probability distribution type P","code":""},{"path":"/reference/get_type_prob_multiple_c.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"generates n draws from type probability distribution for each type in P — get_type_prob_multiple_c","text":"","code":"get_type_prob_multiple_c(params, P)"},{"path":"/reference/get_type_prob_multiple_c.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"generates n draws from type probability distribution for each type in P — get_type_prob_multiple_c","text":"params parameters, priors posteriors P parameter_matrix parameters causal types","code":""},{"path":"/reference/get_type_prob_multiple_c.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"generates n draws from type probability distribution for each type in P — get_type_prob_multiple_c","text":"draws type distribution type P","code":""},{"path":"/reference/grab.html","id":null,"dir":"Reference","previous_headings":"","what":"Grab — grab","title":"Grab — grab","text":"Returns specified elements causal_model. Users can use grab extract model's components objects implied model structure including nodal types, causal types, parameter priors, parameter posteriors, type priors, type posteriors, relevant elements. See argument object ","code":""},{"path":"/reference/grab.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Grab — grab","text":"","code":"grab(model, object = NULL, ...)"},{"path":"/reference/grab.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Grab — grab","text":"model causal_model. model object generated make_model. object character string specifying component retrieve. Available options : \"causal_statement\" character. Statement describing causal relations using dagitty syntax, \"dag\" data frame columns ‘parent’ ‘children’ indicating nodes relate , \"nodes\" list containing nodes model, \"parents\" table listing nodes, whether root nodes , number names parents , \"parameters_df\" data frame containing parameter information, \"causal_types\" data frame listing causal types nodal types produce , \"nodal_types\" list nodal types model, \"data_types\" list data  types consistent model; options see \"?get_all_data_types\", \"event_probabilities\"  vector data (event) probabilities given parameter vector; options see \"?get_event_probabilities\", \"ambiguities_matrix\" matrix mapping causal types data types, \"parameters\" vector 'true' parameters, \"parameter_names\"  vector names parameters, \"parameter_mapping\"  matrix mapping parameters data types, \"parameter_matrix\" matrix mapping parameters causal types, \"prior_hyperparameters\"  vector alpha values used parameterize Dirichlet prior distributions, \"prior_distribution\"  data frame parameter prior distribution, \"posterior_distribution\"  data frame parameter posterior distribution, \"posterior_event_probabilities\" sample data (event) probabilities posterior, \"stan_objects\"  stan_objects list Stan outputs can include stanfit object, data used, distributions causal types event probabilities. \"stan_fit\" stanfit object generated Stan, \"stan_summary\" summary stanfit object generated Stan, \"type_prior\" matrix type probabilities using priors, \"type_posterior\" matrix type probabilities using posteriors, ... arguments passed helper \"get_*\" functions.","code":""},{"path":"/reference/grab.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Grab — grab","text":"Objects causal_model specified.","code":""},{"path":"/reference/grab.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Grab — grab","text":"","code":"# \\donttest{ model <-   make_model('X -> Y') |>    update_model(    keep_event_probabilities = TRUE,    keep_fit = TRUE,    refresh = 0 ) #> No data provided  grab(model, object = \"causal_statement\") #>  #> Statement:  #> X -> Y grab(model, object = \"dag\") #>  #> Dag:  #>   parent children #> 1      X        Y grab(model, object = \"nodes\") #>  #> Nodes:  #> X, Y grab(model, object = \"parents\") #>   node  root parents parent_nodes #> 1    X  TRUE       0              #> 2    Y FALSE       1            X grab(model, object = \"parameters_df\") #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>   param_names node gen param_set nodal_type given param_value priors #> 1         X.0    X   1         X          0              0.50      1 #> 2         X.1    X   1         X          1              0.50      1 #> 3        Y.00    Y   2         Y         00              0.25      1 #> 4        Y.10    Y   2         Y         10              0.25      1 #> 5        Y.01    Y   2         Y         01              0.25      1 #> 6        Y.11    Y   2         Y         11              0.25      1 grab(model, object = \"causal_types\") #>  #> Causal Types:  #> cartesian product of nodal types #>  #>        X  Y #> X0.Y00 0 00 #> X1.Y00 1 00 #> X0.Y10 0 10 #> X1.Y10 1 10 #> X0.Y01 0 01 #> X1.Y01 1 01 #> X0.Y11 0 11 #> X1.Y11 1 11 grab(model, object = \"nodal_types\") #> Nodal types:  #> $X #> 0  1 #>  #>   node position display interpretation #> 1    X       NA      X0          X = 0 #> 2    X       NA      X1          X = 1 #>  #> $Y #> 00  10  01  11 #>  #>   node position display interpretation #> 1    Y        1   Y[*]*      Y | X = 0 #> 2    Y        2   Y*[*]      Y | X = 1 #>  #>  #> Number of types by node #> X Y  #> 2 4  grab(model, object = \"data_types\") #>      event  X  Y #> X0Y0  X0Y0  0  0 #> X1Y0  X1Y0  1  0 #> X0Y1  X0Y1  0  1 #> X1Y1  X1Y1  1  1 #> Y0      Y0 NA  0 #> Y1      Y1 NA  1 #> X0      X0  0 NA #> X1      X1  1 NA #> None  None NA NA grab(model, object = \"event_probabilities\") #>      event_probs #> X0Y0        0.25 #> X1Y0        0.25 #> X0Y1        0.25 #> X1Y1        0.25 grab(model, object = \"ambiguities_matrix\") #>       X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y00    1    0    0    0 #> X1Y00    0    1    0    0 #> X0Y10    0    0    1    0 #> X1Y10    0    1    0    0 #> X0Y01    1    0    0    0 #> X1Y01    0    0    0    1 #> X0Y11    0    0    1    0 #> X1Y11    0    0    0    1 grab(model, object = \"parameters\") #> Model parameters with associated probabilities:  #>  #> X.0 X.1 Y.00 Y.10 Y.01 Y.11 #> 0.5 0.5 0.25 0.25 0.25 0.25 grab(model, object = \"parameter_names\") #> [1] \"X.0\"  \"X.1\"  \"Y.00\" \"Y.10\" \"Y.01\" \"Y.11\" grab(model, object = \"parameter_mapping\") #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X.0     1    0    1    0 #> X.1     0    1    0    1 #> Y.00    1    1    0    0 #> Y.10    0    1    1    0 #> Y.01    1    0    0    1 #> Y.11    0    0    1    1 #> attr(,\"map\") #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 grab(model, object = \"parameter_matrix\") #>  #> Rows are parameters, grouped in parameter sets #>  #> Columns are causal types #>  #> Cell entries indicate whether a parameter probability isused #> in the calculation of causal type probability #>  #>      X0.Y00 X1.Y00 X0.Y10 X1.Y10 X0.Y01 X1.Y01 X0.Y11 X1.Y11 #> X.0       1      0      1      0      1      0      1      0 #> X.1       0      1      0      1      0      1      0      1 #> Y.00      1      1      0      0      0      0      0      0 #> Y.10      0      0      1      1      0      0      0      0 #> Y.01      0      0      0      0      1      1      0      0 #> Y.11      0      0      0      0      0      0      1      1 #>  #>   #>  param_set  (P) #>   grab(model, object = \"prior_hyperparameters\") #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #>    1    1    1    1    1    1  grab(model, object = \"prior_distribution\") #> Prior distribution added to model #> Summary statistics of model parameter prior distributions: #> Dimensions: 4000 rows (draws) by 6 cols (parameters)     mean   sd #> X.0  0.51 0.29 #> X.1  0.49 0.29 #> Y.00 0.25 0.20 #> Y.10 0.25 0.19 #> Y.01 0.25 0.20 #> Y.11 0.25 0.19 grab(model, object = \"posterior_distribution\") #> Summary statistics of model parameter posterior distributions: #> Dimensions: 4000 rows (draws) by 6 cols (parameters)     mean   sd #> X.0  0.50 0.29 #> X.1  0.50 0.29 #> Y.00 0.25 0.20 #> Y.10 0.25 0.20 #> Y.01 0.25 0.20 #> Y.11 0.25 0.20 grab(model, object = \"posterior_event_probabilities\") #>  #> Posterior draws of event probabilities (transformed parameters) #>  #> Dimensions: 4000 rows (draws) by 4 cols (data types)      mean    sd #> X0Y0 0.250 0.197 #> X1Y0 0.254 0.199 #> X0Y1 0.245 0.192 #> X1Y1 0.250 0.195 grab(model, object = \"stan_objects\") #> $data #> NULL #>  #> $stanfit #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>             mean se_mean   sd   2.5%   25%   50%   75% 97.5% n_eff Rhat #> lambdas[1]  0.50    0.01 0.29   0.02  0.24  0.50  0.75  0.98  2775    1 #> lambdas[2]  0.50    0.01 0.29   0.02  0.25  0.50  0.76  0.98  2775    1 #> lambdas[3]  0.25    0.00 0.20   0.01  0.09  0.21  0.37  0.72  1748    1 #> lambdas[4]  0.25    0.00 0.20   0.01  0.09  0.20  0.37  0.71  4574    1 #> lambdas[5]  0.25    0.00 0.20   0.01  0.09  0.20  0.36  0.73  4614    1 #> lambdas[6]  0.25    0.00 0.20   0.01  0.09  0.20  0.38  0.71  4043    1 #> w[1]        0.25    0.00 0.20   0.01  0.09  0.21  0.38  0.71  3130    1 #> w[2]        0.25    0.00 0.20   0.01  0.09  0.21  0.38  0.72  2767    1 #> w[3]        0.25    0.00 0.19   0.01  0.09  0.20  0.36  0.70  2894    1 #> w[4]        0.25    0.00 0.19   0.01  0.09  0.21  0.37  0.72  2581    1 #> types[1]    0.13    0.00 0.14   0.00  0.03  0.08  0.19  0.50  2152    1 #> types[2]    0.13    0.00 0.13   0.00  0.03  0.08  0.18  0.50  1949    1 #> types[3]    0.12    0.00 0.13   0.00  0.02  0.08  0.17  0.47  3403    1 #> types[4]    0.13    0.00 0.14   0.00  0.02  0.08  0.19  0.49  3566    1 #> types[5]    0.12    0.00 0.13   0.00  0.03  0.08  0.18  0.49  3682    1 #> types[6]    0.13    0.00 0.14   0.00  0.03  0.08  0.18  0.51  3455    1 #> types[7]    0.13    0.00 0.14   0.00  0.02  0.08  0.18  0.50  3242    1 #> types[8]    0.12    0.00 0.13   0.00  0.03  0.08  0.17  0.48  3074    1 #> lp__       -7.59    0.05 1.72 -11.86 -8.43 -7.17 -6.34 -5.43  1148    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Mar 25 15:25:35 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #>  #> $type_distribution #> Posterior draws of causal types (transformed parameters) #> Dimensions: 4000 rows (draws) by 8 cols (types)        mean    sd #> X0.Y00 0.127 0.135 #> X1.Y00 0.126 0.134 #> X0.Y10 0.120 0.129 #> X1.Y10 0.128 0.138 #> X0.Y01 0.123 0.132 #> X1.Y01 0.126 0.136 #> X0.Y11 0.126 0.136 #> X1.Y11 0.125 0.134 #>  #> $event_probabilities #>  #> Posterior draws of event probabilities (transformed parameters) #>  #> Dimensions: 4000 rows (draws) by 4 cols (data types)      mean    sd #> X0Y0 0.250 0.197 #> X1Y0 0.254 0.199 #> X0Y1 0.245 0.192 #> X1Y1 0.250 0.195 #>  #> $stan_summary #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>             mean se_mean   sd   2.5%   25%   50%   75% 97.5% n_eff Rhat #> X.0         0.50    0.01 0.29   0.02  0.24  0.50  0.75  0.98  2775    1 #> X.1         0.50    0.01 0.29   0.02  0.25  0.50  0.76  0.98  2775    1 #> Y.00        0.25    0.00 0.20   0.01  0.09  0.21  0.37  0.72  1748    1 #> Y.10        0.25    0.00 0.20   0.01  0.09  0.20  0.37  0.71  4574    1 #> Y.01        0.25    0.00 0.20   0.01  0.09  0.20  0.36  0.73  4614    1 #> Y.11        0.25    0.00 0.20   0.01  0.09  0.20  0.38  0.71  4043    1 #> X0Y0        0.25    0.00 0.20   0.01  0.09  0.21  0.38  0.71  3130    1 #> X1Y0        0.25    0.00 0.20   0.01  0.09  0.21  0.38  0.72  2767    1 #> X0Y1        0.25    0.00 0.19   0.01  0.09  0.20  0.36  0.70  2894    1 #> X1Y1        0.25    0.00 0.19   0.01  0.09  0.21  0.37  0.72  2581    1 #> X0.Y00      0.13    0.00 0.14   0.00  0.03  0.08  0.19  0.50  2152    1 #> X1.Y00      0.13    0.00 0.13   0.00  0.03  0.08  0.18  0.50  1949    1 #> X0.Y10      0.12    0.00 0.13   0.00  0.02  0.08  0.17  0.47  3403    1 #> X1.Y10      0.13    0.00 0.14   0.00  0.02  0.08  0.19  0.49  3566    1 #> X0.Y01      0.12    0.00 0.13   0.00  0.03  0.08  0.18  0.49  3682    1 #> X1.Y01      0.13    0.00 0.14   0.00  0.03  0.08  0.18  0.51  3455    1 #> X0.Y11      0.13    0.00 0.14   0.00  0.02  0.08  0.18  0.50  3242    1 #> X1.Y11      0.12    0.00 0.13   0.00  0.03  0.08  0.17  0.48  3074    1 #> lp__       -7.59    0.05 1.72 -11.86 -8.43 -7.17 -6.34 -5.43  1148    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Mar 25 15:25:35 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #>  #> attr(,\"class\") #> [1] \"stan_objects\" \"list\"         grab(model, object = \"stan_fit\") #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>             mean se_mean   sd   2.5%   25%   50%   75% 97.5% n_eff Rhat #> lambdas[1]  0.50    0.01 0.29   0.02  0.24  0.50  0.75  0.98  2775    1 #> lambdas[2]  0.50    0.01 0.29   0.02  0.25  0.50  0.76  0.98  2775    1 #> lambdas[3]  0.25    0.00 0.20   0.01  0.09  0.21  0.37  0.72  1748    1 #> lambdas[4]  0.25    0.00 0.20   0.01  0.09  0.20  0.37  0.71  4574    1 #> lambdas[5]  0.25    0.00 0.20   0.01  0.09  0.20  0.36  0.73  4614    1 #> lambdas[6]  0.25    0.00 0.20   0.01  0.09  0.20  0.38  0.71  4043    1 #> w[1]        0.25    0.00 0.20   0.01  0.09  0.21  0.38  0.71  3130    1 #> w[2]        0.25    0.00 0.20   0.01  0.09  0.21  0.38  0.72  2767    1 #> w[3]        0.25    0.00 0.19   0.01  0.09  0.20  0.36  0.70  2894    1 #> w[4]        0.25    0.00 0.19   0.01  0.09  0.21  0.37  0.72  2581    1 #> types[1]    0.13    0.00 0.14   0.00  0.03  0.08  0.19  0.50  2152    1 #> types[2]    0.13    0.00 0.13   0.00  0.03  0.08  0.18  0.50  1949    1 #> types[3]    0.12    0.00 0.13   0.00  0.02  0.08  0.17  0.47  3403    1 #> types[4]    0.13    0.00 0.14   0.00  0.02  0.08  0.19  0.49  3566    1 #> types[5]    0.12    0.00 0.13   0.00  0.03  0.08  0.18  0.49  3682    1 #> types[6]    0.13    0.00 0.14   0.00  0.03  0.08  0.18  0.51  3455    1 #> types[7]    0.13    0.00 0.14   0.00  0.02  0.08  0.18  0.50  3242    1 #> types[8]    0.12    0.00 0.13   0.00  0.03  0.08  0.17  0.48  3074    1 #> lp__       -7.59    0.05 1.72 -11.86 -8.43 -7.17 -6.34 -5.43  1148    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Mar 25 15:25:35 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). grab(model, object = \"stan_summary\") #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>             mean se_mean   sd   2.5%   25%   50%   75% 97.5% n_eff Rhat #> X.0         0.50    0.01 0.29   0.02  0.24  0.50  0.75  0.98  2775    1 #> X.1         0.50    0.01 0.29   0.02  0.25  0.50  0.76  0.98  2775    1 #> Y.00        0.25    0.00 0.20   0.01  0.09  0.21  0.37  0.72  1748    1 #> Y.10        0.25    0.00 0.20   0.01  0.09  0.20  0.37  0.71  4574    1 #> Y.01        0.25    0.00 0.20   0.01  0.09  0.20  0.36  0.73  4614    1 #> Y.11        0.25    0.00 0.20   0.01  0.09  0.20  0.38  0.71  4043    1 #> X0Y0        0.25    0.00 0.20   0.01  0.09  0.21  0.38  0.71  3130    1 #> X1Y0        0.25    0.00 0.20   0.01  0.09  0.21  0.38  0.72  2767    1 #> X0Y1        0.25    0.00 0.19   0.01  0.09  0.20  0.36  0.70  2894    1 #> X1Y1        0.25    0.00 0.19   0.01  0.09  0.21  0.37  0.72  2581    1 #> X0.Y00      0.13    0.00 0.14   0.00  0.03  0.08  0.19  0.50  2152    1 #> X1.Y00      0.13    0.00 0.13   0.00  0.03  0.08  0.18  0.50  1949    1 #> X0.Y10      0.12    0.00 0.13   0.00  0.02  0.08  0.17  0.47  3403    1 #> X1.Y10      0.13    0.00 0.14   0.00  0.02  0.08  0.19  0.49  3566    1 #> X0.Y01      0.12    0.00 0.13   0.00  0.03  0.08  0.18  0.49  3682    1 #> X1.Y01      0.13    0.00 0.14   0.00  0.03  0.08  0.18  0.51  3455    1 #> X0.Y11      0.13    0.00 0.14   0.00  0.02  0.08  0.18  0.50  3242    1 #> X1.Y11      0.12    0.00 0.13   0.00  0.03  0.08  0.17  0.48  3074    1 #> lp__       -7.59    0.05 1.72 -11.86 -8.43 -7.17 -6.34 -5.43  1148    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Mar 25 15:25:35 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). grab(model, object = \"type_prior\") #> Prior distribution added to model #> Summary statistics of causal type prior distributions: #> Dimensions: 4000 rows (draws) by 8 cols (types) #> rows are causal types #>        V1   V2   V3   V4   V5   V6   V7   V8   V9  V10  V11  V12  V13  V14  V15 #> mean 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.13 0.12 0.12 #> sd   0.09 0.08 0.12 0.13 0.18 0.15 0.10 0.17 0.13 0.11 0.12 0.11 0.07 0.14 0.15 #>       V16  V17  V18  V19  V20  V21  V22  V23  V24  V25  V26  V27  V28  V29  V30 #> mean 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.13 0.12 #> sd   0.10 0.12 0.12 0.17 0.15 0.09 0.16 0.12 0.16 0.15 0.05 0.04 0.07 0.09 0.22 #>       V31  V32  V33  V34  V35  V36  V37  V38  V39  V40  V41  V42  V43  V44  V45 #> mean 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.13 0.12 0.12 0.12 0.13 0.13 0.13 #> sd   0.15 0.11 0.10 0.12 0.15 0.09 0.22 0.08 0.16 0.11 0.16 0.25 0.14 0.20 0.11 #>       V46  V47  V48  V49  V50  V51  V52  V53  V54  V55  V56  V57  V58  V59  V60 #> mean 0.13 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.13 0.12 #> sd   0.20 0.15 0.18 0.12 0.15 0.10 0.15 0.05 0.19 0.09 0.29 0.09 0.11 0.16 0.15 #>       V61  V62  V63  V64  V65  V66  V67  V68  V69  V70  V71  V72  V73  V74  V75 #> mean 0.13 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.13 0.13 0.12 #> sd   0.16 0.07 0.05 0.23 0.17 0.12 0.23 0.10 0.14 0.15 0.15 0.12 0.12 0.24 0.16 #>       V76  V77  V78  V79  V80  V81  V82  V83  V84  V85  V86  V87  V88  V89  V90 #> mean 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.13 #> sd   0.06 0.15 0.10 0.08 0.16 0.13 0.11 0.17 0.20 0.13 0.04 0.11 0.29 0.18 0.19 #>       V91  V92  V93  V94  V95  V96  V97  V98  V99 V100 V101 V102 V103 V104 V105 #> mean 0.12 0.13 0.13 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.13 0.12 #> sd   0.14 0.04 0.11 0.16 0.17 0.13 0.08 0.17 0.18 0.21 0.14 0.09 0.09 0.13 0.13 #>      V106 V107 V108 V109 V110 V111 V112 V113 V114 V115 V116 V117 V118 V119 V120 #> mean 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.13 0.12 0.12 0.12 #> sd   0.16 0.18 0.09 0.12 0.09 0.16 0.07 0.09 0.08 0.14 0.14 0.20 0.21 0.15 0.12 #>      V121 V122 V123 V124 V125 V126 V127 V128 V129 V130 V131 V132 V133 V134 V135 #> mean 0.12 0.13 0.12 0.12 0.13 0.13 0.13 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.12 #> sd   0.10 0.09 0.18 0.04 0.15 0.10 0.16 0.16 0.09 0.10 0.21 0.08 0.19 0.08 0.11 #>      V136 V137 V138 V139 V140 V141 V142 V143 V144 V145 V146 V147 V148 V149 V150 #> mean 0.12 0.13 0.12 0.13 0.12 0.13 0.13 0.13 0.12 0.12 0.13 0.12 0.12 0.13 0.13 #> sd   0.16 0.19 0.09 0.10 0.18 0.11 0.16 0.14 0.16 0.12 0.09 0.08 0.14 0.11 0.09 #>      V151 V152 V153 V154 V155 V156 V157 V158 V159 V160 V161 V162 V163 V164 V165 #> mean 0.12 0.13 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 #> sd   0.11 0.22 0.10 0.12 0.13 0.12 0.14 0.16 0.13 0.07 0.19 0.13 0.09 0.20 0.17 #>      V166 V167 V168 V169 V170 V171 V172 V173 V174 V175 V176 V177 V178 V179 V180 #> mean 0.12 0.13 0.13 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.13 0.12 0.12 0.13 #> sd   0.16 0.15 0.12 0.08 0.18 0.17 0.05 0.15 0.10 0.13 0.12 0.13 0.12 0.13 0.08 #>      V181 V182 V183 V184 V185 V186 V187 V188 V189 V190 V191 V192 V193 V194 V195 #> mean 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.12 #> sd   0.10 0.06 0.10 0.14 0.14 0.07 0.13 0.13 0.15 0.13 0.12 0.15 0.23 0.09 0.11 #>      V196 V197 V198 V199 V200 V201 V202 V203 V204 V205 V206 V207 V208 V209 V210 #> mean 0.13 0.12 0.12 0.13 0.13 0.12 0.12 0.13 0.12 0.12 0.12 0.13 0.12 0.12 0.12 #> sd   0.16 0.05 0.08 0.18 0.13 0.14 0.20 0.21 0.13 0.11 0.20 0.12 0.09 0.09 0.08 #>      V211 V212 V213 V214 V215 V216 V217 V218 V219 V220 V221 V222 V223 V224 V225 #> mean 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.13 0.13 0.12 0.12 #> sd   0.15 0.18 0.16 0.02 0.11 0.21 0.18 0.23 0.18 0.11 0.09 0.11 0.05 0.13 0.27 #>      V226 V227 V228 V229 V230 V231 V232 V233 V234 V235 V236 V237 V238 V239 V240 #> mean 0.12 0.12 0.12 0.13 0.12 0.13 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.12 #> sd   0.15 0.07 0.05 0.11 0.13 0.08 0.18 0.19 0.16 0.13 0.13 0.18 0.12 0.21 0.12 #>      V241 V242 V243 V244 V245 V246 V247 V248 V249 V250 V251 V252 V253 V254 V255 #> mean 0.12 0.13 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.12 #> sd   0.10 0.14 0.21 0.08 0.17 0.16 0.24 0.16 0.13 0.18 0.14 0.19 0.19 0.13 0.12 #>      V256 V257 V258 V259 V260 V261 V262 V263 V264 V265 V266 V267 V268 V269 V270 #> mean 0.12 0.12 0.13 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 #> sd   0.09 0.05 0.17 0.17 0.15 0.09 0.09 0.17 0.12 0.20 0.12 0.12 0.14 0.15 0.11 #>      V271 V272 V273 V274 V275 V276 V277 V278 V279 V280 V281 V282 V283 V284 V285 #> mean 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.13 0.13 0.12 0.12 0.12 0.12 0.13 #> sd   0.22 0.09 0.11 0.21 0.04 0.09 0.14 0.12 0.14 0.14 0.09 0.14 0.12 0.07 0.08 #>      V286 V287 V288 V289 V290 V291 V292 V293 V294 V295 V296 V297 V298 V299 V300 #> mean 0.13 0.12 0.12 0.12 0.13 0.12 0.12 0.13 0.13 0.13 0.13 0.13 0.12 0.12 0.12 #> sd   0.16 0.11 0.19 0.12 0.09 0.06 0.14 0.18 0.14 0.19 0.11 0.08 0.04 0.10 0.10 #>      V301 V302 V303 V304 V305 V306 V307 V308 V309 V310 V311 V312 V313 V314 V315 #> mean 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.13 0.12 0.12 0.12 #> sd   0.21 0.08 0.14 0.12 0.16 0.11 0.09 0.14 0.16 0.18 0.17 0.13 0.15 0.26 0.07 #>      V316 V317 V318 V319 V320 V321 V322 V323 V324 V325 V326 V327 V328 V329 V330 #> mean 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.13 0.12 #> sd   0.11 0.15 0.10 0.19 0.24 0.07 0.10 0.22 0.13 0.16 0.07 0.08 0.15 0.08 0.12 #>      V331 V332 V333 V334 V335 V336 V337 V338 V339 V340 V341 V342 V343 V344 V345 #> mean 0.13 0.12 0.12 0.13 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.13 0.12 #> sd   0.16 0.19 0.14 0.15 0.20 0.13 0.16 0.15 0.09 0.10 0.12 0.14 0.10 0.10 0.12 #>      V346 V347 V348 V349 V350 V351 V352 V353 V354 V355 V356 V357 V358 V359 V360 #> mean 0.13 0.12 0.13 0.12 0.13 0.13 0.12 0.13 0.12 0.12 0.12 0.13 0.12 0.12 0.12 #> sd   0.15 0.14 0.17 0.08 0.10 0.17 0.12 0.15 0.18 0.14 0.19 0.09 0.10 0.07 0.16 #>      V361 V362 V363 V364 V365 V366 V367 V368 V369 V370 V371 V372 V373 V374 V375 #> mean 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.13 0.12 0.12 0.12 0.12 #> sd   0.08 0.16 0.11 0.12 0.17 0.08 0.05 0.12 0.29 0.08 0.13 0.12 0.18 0.19 0.16 #>      V376 V377 V378 V379 V380 V381 V382 V383 V384 V385 V386 V387 V388 V389 V390 #> mean 0.13 0.12 0.12 0.12 0.13 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.13 #> sd   0.09 0.21 0.08 0.13 0.06 0.18 0.13 0.17 0.09 0.08 0.15 0.24 0.08 0.11 0.17 #>      V391 V392 V393 V394 V395 V396 V397 V398 V399 V400 V401 V402 V403 V404 V405 #> mean 0.12 0.12 0.13 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.13 #> sd   0.16 0.19 0.14 0.05 0.14 0.07 0.20 0.16 0.17 0.10 0.10 0.14 0.13 0.08 0.17 #>      V406 V407 V408 V409 V410 V411 V412 V413 V414 V415 V416 V417 V418 V419 V420 #> mean 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.13 0.13 #> sd   0.15 0.06 0.16 0.15 0.10 0.17 0.13 0.06 0.13 0.17 0.19 0.15 0.12 0.16 0.10 #>      V421 V422 V423 V424 V425 V426 V427 V428 V429 V430 V431 V432 V433 V434 V435 #> mean 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.13 0.12 0.13 0.12 #> sd   0.11 0.06 0.16 0.09 0.07 0.13 0.10 0.14 0.22 0.13 0.09 0.08 0.16 0.14 0.17 #>      V436 V437 V438 V439 V440 V441 V442 V443 V444 V445 V446 V447 V448 V449 V450 #> mean 0.12 0.13 0.13 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.12 #> sd   0.10 0.18 0.17 0.16 0.16 0.14 0.17 0.19 0.11 0.12 0.06 0.10 0.18 0.16 0.10 #>      V451 V452 V453 V454 V455 V456 V457 V458 V459 V460 V461 V462 V463 V464 V465 #> mean 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.13 0.13 0.12 0.12 0.12 0.13 0.12 0.12 #> sd   0.09 0.20 0.12 0.15 0.13 0.09 0.12 0.15 0.12 0.12 0.15 0.08 0.13 0.13 0.28 #>      V466 V467 V468 V469 V470 V471 V472 V473 V474 V475 V476 V477 V478 V479 V480 #> mean 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.13 #> sd   0.11 0.19 0.14 0.11 0.20 0.09 0.17 0.12 0.13 0.16 0.09 0.18 0.17 0.07 0.20 #>      V481 V482 V483 V484 V485 V486 V487 V488 V489 V490 V491 V492 V493 V494 V495 #> mean 0.12 0.12 0.12 0.12 0.12 0.13 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 #> sd   0.11 0.16 0.17 0.13 0.11 0.07 0.25 0.06 0.21 0.09 0.16 0.16 0.23 0.16 0.07 #>      V496 V497 V498 V499 V500 V501 V502 V503 V504 V505 V506 V507 V508 V509 V510 #> mean 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.12 #> sd   0.10 0.07 0.21 0.16 0.14 0.13 0.11 0.12 0.09 0.17 0.10 0.07 0.10 0.12 0.18 #>      V511 V512 V513 V514 V515 V516 V517 V518 V519 V520 V521 V522 V523 V524 V525 #> mean 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.12 #> sd   0.27 0.13 0.12 0.16 0.08 0.18 0.11 0.07 0.11 0.14 0.11 0.11 0.07 0.15 0.27 #>      V526 V527 V528 V529 V530 V531 V532 V533 V534 V535 V536 V537 V538 V539 V540 #> mean 0.13 0.12 0.12 0.12 0.13 0.13 0.13 0.13 0.12 0.12 0.12 0.12 0.12 0.13 0.12 #> sd   0.07 0.14 0.20 0.13 0.21 0.18 0.15 0.14 0.20 0.05 0.11 0.12 0.19 0.22 0.13 #>      V541 V542 V543 V544 V545 V546 V547 V548 V549 V550 V551 V552 V553 V554 V555 #> mean 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.12 #> sd   0.07 0.05 0.22 0.18 0.10 0.17 0.15 0.13 0.15 0.06 0.09 0.16 0.14 0.07 0.23 #>      V556 V557 V558 V559 V560 V561 V562 V563 V564 V565 V566 V567 V568 V569 V570 #> mean 0.12 0.12 0.13 0.13 0.13 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 #> sd   0.13 0.10 0.14 0.16 0.06 0.19 0.11 0.16 0.19 0.11 0.13 0.11 0.08 0.11 0.16 #>      V571 V572 V573 V574 V575 V576 V577 V578 V579 V580 V581 V582 V583 V584 V585 #> mean 0.12 0.12 0.12 0.12 0.13 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.13 0.13 0.12 #> sd   0.15 0.08 0.16 0.13 0.11 0.16 0.17 0.10 0.16 0.06 0.06 0.19 0.12 0.14 0.09 #>      V586 V587 V588 V589 V590 V591 V592 V593 V594 V595 V596 V597 V598 V599 V600 #> mean 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 #> sd   0.17 0.19 0.07 0.18 0.12 0.18 0.08 0.13 0.21 0.13 0.07 0.12 0.10 0.13 0.10 #>      V601 V602 V603 V604 V605 V606 V607 V608 V609 V610 V611 V612 V613 V614 V615 #> mean 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 #> sd   0.08 0.12 0.13 0.08 0.11 0.10 0.18 0.22 0.08 0.14 0.13 0.15 0.09 0.15 0.20 #>      V616 V617 V618 V619 V620 V621 V622 V623 V624 V625 V626 V627 V628 V629 V630 #> mean 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.12 #> sd   0.17 0.11 0.12 0.10 0.10 0.15 0.08 0.18 0.06 0.05 0.18 0.13 0.20 0.10 0.24 #>      V631 V632 V633 V634 V635 V636 V637 V638 V639 V640 V641 V642 V643 V644 V645 #> mean 0.12 0.12 0.13 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 #> sd   0.18 0.17 0.07 0.12 0.08 0.12 0.18 0.15 0.10 0.13 0.13 0.08 0.09 0.10 0.21 #>      V646 V647 V648 V649 V650 V651 V652 V653 V654 V655 V656 V657 V658 V659 V660 #> mean 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.12 #> sd   0.13 0.20 0.06 0.13 0.13 0.12 0.13 0.07 0.15 0.12 0.16 0.07 0.11 0.13 0.12 #>      V661 V662 V663 V664 V665 V666 V667 V668 V669 V670 V671 V672 V673 V674 V675 #> mean 0.12 0.13 0.12 0.13 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.13 #> sd   0.08 0.10 0.09 0.21 0.28 0.11 0.16 0.13 0.20 0.17 0.07 0.14 0.13 0.15 0.12 #>      V676 V677 V678 V679 V680 V681 V682 V683 V684 V685 V686 V687 V688 V689 V690 #> mean 0.13 0.12 0.12 0.13 0.12 0.12 0.12 0.13 0.13 0.12 0.12 0.12 0.12 0.12 0.13 #> sd   0.21 0.13 0.17 0.17 0.09 0.18 0.04 0.15 0.11 0.17 0.11 0.10 0.14 0.10 0.07 #>      V691 V692 V693 V694 V695 V696 V697 V698 V699 V700 V701 V702 V703 V704 V705 #> mean 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.13 0.12 0.12 0.13 0.12 0.12 #> sd   0.09 0.15 0.23 0.27 0.11 0.15 0.08 0.22 0.06 0.13 0.09 0.13 0.11 0.03 0.09 #>      V706 V707 V708 V709 V710 V711 V712 V713 V714 V715 V716 V717 V718 V719 V720 #> mean 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.13 0.12 0.12 0.12 0.12 #> sd   0.12 0.18 0.14 0.24 0.05 0.11 0.11 0.13 0.14 0.20 0.27 0.13 0.11 0.17 0.15 #>      V721 V722 V723 V724 V725 V726 V727 V728 V729 V730 V731 V732 V733 V734 V735 #> mean 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.13 0.12 0.12 0.12 0.12 #> sd   0.11 0.20 0.09 0.06 0.16 0.13 0.22 0.13 0.28 0.08 0.16 0.19 0.17 0.05 0.11 #>      V736 V737 V738 V739 V740 V741 V742 V743 V744 V745 V746 V747 V748 V749 V750 #> mean 0.13 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.13 0.12 0.12 #> sd   0.16 0.05 0.14 0.14 0.09 0.11 0.13 0.16 0.19 0.22 0.27 0.10 0.21 0.17 0.14 #>      V751 V752 V753 V754 V755 V756 V757 V758 V759 V760 V761 V762 V763 V764 V765 #> mean 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.13 0.12 0.13 0.12 0.13 #> sd   0.15 0.14 0.14 0.10 0.13 0.15 0.08 0.12 0.13 0.09 0.07 0.14 0.10 0.14 0.14 #>      V766 V767 V768 V769 V770 V771 V772 V773 V774 V775 V776 V777 V778 V779 V780 #> mean 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.13 0.13 0.12 0.12 0.12 0.13 #> sd   0.07 0.18 0.15 0.06 0.17 0.06 0.20 0.15 0.12 0.12 0.16 0.13 0.10 0.13 0.15 #>      V781 V782 V783 V784 V785 V786 V787 V788 V789 V790 V791 V792 V793 V794 V795 #> mean 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.13 0.12 #> sd   0.16 0.13 0.18 0.17 0.17 0.16 0.16 0.08 0.19 0.19 0.13 0.15 0.13 0.14 0.27 #>      V796 V797 V798 V799 V800 V801 V802 V803 V804 V805 V806 V807 V808 V809 V810 #> mean 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 #> sd   0.12 0.15 0.18 0.16 0.18 0.13 0.09 0.14 0.06 0.18 0.11 0.19 0.12 0.07 0.06 #>      V811 V812 V813 V814 V815 V816 V817 V818 V819 V820 V821 V822 V823 V824 V825 #> mean 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.12 #> sd   0.16 0.10 0.20 0.11 0.17 0.13 0.11 0.15 0.11 0.10 0.15 0.14 0.17 0.13 0.15 #>      V826 V827 V828 V829 V830 V831 V832 V833 V834 V835 V836 V837 V838 V839 V840 #> mean 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.13 0.12 0.12 #> sd   0.13 0.17 0.21 0.10 0.11 0.13 0.11 0.17 0.12 0.15 0.23 0.14 0.13 0.10 0.17 #>      V841 V842 V843 V844 V845 V846 V847 V848 V849 V850 V851 V852 V853 V854 V855 #> mean 0.12 0.13 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.13 0.12 0.12 #> sd   0.17 0.14 0.10 0.16 0.06 0.16 0.11 0.23 0.14 0.10 0.20 0.26 0.10 0.12 0.10 #>      V856 V857 V858 V859 V860 V861 V862 V863 V864 V865 V866 V867 V868 V869 V870 #> mean 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.13 0.12 0.12 #> sd   0.15 0.13 0.14 0.20 0.11 0.18 0.16 0.19 0.22 0.16 0.11 0.17 0.09 0.15 0.09 #>      V871 V872 V873 V874 V875 V876 V877 V878 V879 V880 V881 V882 V883 V884 V885 #> mean 0.12 0.13 0.13 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.13 0.12 0.12 0.13 0.12 #> sd   0.16 0.04 0.11 0.05 0.07 0.17 0.11 0.11 0.10 0.10 0.07 0.08 0.28 0.18 0.16 #>      V886 V887 V888 V889 V890 V891 V892 V893 V894 V895 V896 V897 V898 V899 V900 #> mean 0.13 0.12 0.13 0.12 0.12 0.12 0.13 0.12 0.13 0.12 0.13 0.12 0.12 0.13 0.13 #> sd   0.14 0.12 0.10 0.13 0.09 0.12 0.08 0.12 0.20 0.10 0.11 0.11 0.22 0.19 0.15 #>      V901 V902 V903 V904 V905 V906 V907 V908 V909 V910 V911 V912 V913 V914 V915 #> mean 0.12 0.13 0.12 0.13 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 #> sd   0.15 0.16 0.19 0.14 0.06 0.24 0.08 0.10 0.12 0.10 0.13 0.15 0.06 0.10 0.10 #>      V916 V917 V918 V919 V920 V921 V922 V923 V924 V925 V926 V927 V928 V929 V930 #> mean 0.12 0.13 0.13 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.13 0.12 0.12 #> sd   0.13 0.10 0.13 0.07 0.08 0.14 0.09 0.07 0.09 0.08 0.18 0.16 0.14 0.18 0.13 #>      V931 V932 V933 V934 V935 V936 V937 V938 V939 V940 V941 V942 V943 V944 V945 #> mean 0.12 0.12 0.13 0.12 0.12 0.13 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.13 0.12 #> sd   0.20 0.17 0.08 0.17 0.23 0.14 0.13 0.14 0.13 0.16 0.08 0.10 0.11 0.10 0.06 #>      V946 V947 V948 V949 V950 V951 V952 V953 V954 V955 V956 V957 V958 V959 V960 #> mean 0.12 0.13 0.13 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.12 0.12 #> sd   0.17 0.21 0.09 0.13 0.14 0.06 0.11 0.19 0.09 0.11 0.20 0.15 0.11 0.12 0.09 #>      V961 V962 V963 V964 V965 V966 V967 V968 V969 V970 V971 V972 V973 V974 V975 #> mean 0.13 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.13 #> sd   0.18 0.14 0.10 0.13 0.17 0.05 0.12 0.12 0.25 0.10 0.17 0.12 0.14 0.10 0.21 #>      V976 V977 V978 V979 V980 V981 V982 V983 V984 V985 V986 V987 V988 V989 V990 #> mean 0.12 0.13 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.13 0.13 0.12 0.12 0.12 #> sd   0.14 0.17 0.15 0.15 0.11 0.20 0.11 0.12 0.06 0.14 0.19 0.10 0.09 0.18 0.12 #>      V991 V992 V993 V994 V995 V996 V997 V998 V999 V1000 V1001 V1002 V1003 V1004 #> mean 0.12 0.12 0.13 0.12 0.12 0.12 0.12 0.12 0.13  0.12  0.13  0.12  0.12  0.12 #> sd   0.13 0.20 0.07 0.09 0.12 0.07 0.13 0.09 0.10  0.11  0.14  0.18  0.13  0.12 #>      V1005 V1006 V1007 V1008 V1009 V1010 V1011 V1012 V1013 V1014 V1015 V1016 #> mean  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12 #> sd    0.08  0.12  0.08  0.19  0.14  0.14  0.09  0.16  0.22  0.09  0.20  0.15 #>      V1017 V1018 V1019 V1020 V1021 V1022 V1023 V1024 V1025 V1026 V1027 V1028 #> mean  0.12  0.12  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.13 #> sd    0.14  0.13  0.13  0.09  0.18  0.17  0.16  0.11  0.14  0.11  0.12  0.17 #>      V1029 V1030 V1031 V1032 V1033 V1034 V1035 V1036 V1037 V1038 V1039 V1040 #> mean  0.12  0.13  0.12  0.13  0.13  0.13  0.12  0.13  0.12  0.12  0.12  0.12 #> sd    0.12  0.10  0.10  0.11  0.21  0.08  0.19  0.16  0.14  0.09  0.11  0.19 #>      V1041 V1042 V1043 V1044 V1045 V1046 V1047 V1048 V1049 V1050 V1051 V1052 #> mean  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.06  0.13  0.16  0.21  0.09  0.14  0.09  0.17  0.17  0.18  0.15  0.08 #>      V1053 V1054 V1055 V1056 V1057 V1058 V1059 V1060 V1061 V1062 V1063 V1064 #> mean  0.13  0.12  0.13  0.12  0.12  0.12  0.12  0.13  0.13  0.13  0.12  0.12 #> sd    0.11  0.14  0.08  0.05  0.06  0.17  0.17  0.11  0.09  0.13  0.13  0.16 #>      V1065 V1066 V1067 V1068 V1069 V1070 V1071 V1072 V1073 V1074 V1075 V1076 #> mean  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.13  0.12  0.12  0.12 #> sd    0.09  0.15  0.17  0.15  0.18  0.13  0.16  0.08  0.05  0.11  0.12  0.09 #>      V1077 V1078 V1079 V1080 V1081 V1082 V1083 V1084 V1085 V1086 V1087 V1088 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12 #> sd    0.11  0.17  0.08  0.13  0.19  0.12  0.08  0.13  0.11  0.17  0.19  0.14 #>      V1089 V1090 V1091 V1092 V1093 V1094 V1095 V1096 V1097 V1098 V1099 V1100 #> mean  0.13  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.12  0.12 #> sd    0.14  0.17  0.13  0.11  0.09  0.16  0.17  0.17  0.21  0.14  0.15  0.06 #>      V1101 V1102 V1103 V1104 V1105 V1106 V1107 V1108 V1109 V1110 V1111 V1112 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.13  0.12  0.13  0.12 #> sd    0.13  0.10  0.08  0.15  0.09  0.14  0.15  0.13  0.14  0.17  0.12  0.15 #>      V1113 V1114 V1115 V1116 V1117 V1118 V1119 V1120 V1121 V1122 V1123 V1124 #> mean  0.13  0.13  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.12  0.12  0.13 #> sd    0.13  0.16  0.21  0.18  0.16  0.19  0.16  0.13  0.12  0.14  0.11  0.12 #>      V1125 V1126 V1127 V1128 V1129 V1130 V1131 V1132 V1133 V1134 V1135 V1136 #> mean  0.12  0.12  0.13  0.13  0.12  0.12  0.13  0.13  0.12  0.12  0.13  0.12 #> sd    0.10  0.09  0.19  0.10  0.10  0.12  0.17  0.10  0.11  0.16  0.17  0.09 #>      V1137 V1138 V1139 V1140 V1141 V1142 V1143 V1144 V1145 V1146 V1147 V1148 #> mean  0.13  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.13  0.12 #> sd    0.19  0.18  0.13  0.11  0.09  0.18  0.06  0.09  0.19  0.10  0.19  0.14 #>      V1149 V1150 V1151 V1152 V1153 V1154 V1155 V1156 V1157 V1158 V1159 V1160 #> mean  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12 #> sd    0.14  0.09  0.13  0.15  0.07  0.24  0.23  0.05  0.21  0.10  0.20  0.20 #>      V1161 V1162 V1163 V1164 V1165 V1166 V1167 V1168 V1169 V1170 V1171 V1172 #> mean  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.13  0.12  0.13  0.12  0.12 #> sd    0.11  0.14  0.07  0.17  0.15  0.15  0.14  0.16  0.13  0.14  0.18  0.17 #>      V1173 V1174 V1175 V1176 V1177 V1178 V1179 V1180 V1181 V1182 V1183 V1184 #> mean  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.13 #> sd    0.09  0.13  0.12  0.17  0.07  0.19  0.11  0.14  0.13  0.08  0.07  0.20 #>      V1185 V1186 V1187 V1188 V1189 V1190 V1191 V1192 V1193 V1194 V1195 V1196 #> mean  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12 #> sd    0.11  0.12  0.18  0.14  0.14  0.14  0.21  0.10  0.09  0.18  0.15  0.20 #>      V1197 V1198 V1199 V1200 V1201 V1202 V1203 V1204 V1205 V1206 V1207 V1208 #> mean  0.12  0.12  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12 #> sd    0.16  0.16  0.09  0.18  0.11  0.15  0.16  0.12  0.15  0.19  0.08  0.12 #>      V1209 V1210 V1211 V1212 V1213 V1214 V1215 V1216 V1217 V1218 V1219 V1220 #> mean  0.12  0.12  0.13  0.12  0.13  0.12  0.13  0.12  0.12  0.12  0.12  0.13 #> sd    0.14  0.12  0.15  0.14  0.18  0.08  0.19  0.13  0.16  0.15  0.12  0.15 #>      V1221 V1222 V1223 V1224 V1225 V1226 V1227 V1228 V1229 V1230 V1231 V1232 #> mean  0.13  0.12  0.12  0.13  0.13  0.12  0.12  0.13  0.12  0.13  0.13  0.12 #> sd    0.10  0.09  0.16  0.17  0.23  0.13  0.21  0.12  0.18  0.13  0.13  0.17 #>      V1233 V1234 V1235 V1236 V1237 V1238 V1239 V1240 V1241 V1242 V1243 V1244 #> mean  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12 #> sd    0.15  0.16  0.16  0.13  0.18  0.11  0.04  0.16  0.10  0.11  0.17  0.08 #>      V1245 V1246 V1247 V1248 V1249 V1250 V1251 V1252 V1253 V1254 V1255 V1256 #> mean  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.13 #> sd    0.13  0.19  0.06  0.19  0.12  0.20  0.16  0.17  0.18  0.13  0.13  0.25 #>      V1257 V1258 V1259 V1260 V1261 V1262 V1263 V1264 V1265 V1266 V1267 V1268 #> mean  0.13  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.12 #> sd    0.06  0.11  0.06  0.12  0.20  0.16  0.18  0.10  0.14  0.13  0.08  0.18 #>      V1269 V1270 V1271 V1272 V1273 V1274 V1275 V1276 V1277 V1278 V1279 V1280 #> mean  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.12  0.12  0.13  0.12  0.12 #> sd    0.13  0.12  0.12  0.17  0.10  0.14  0.05  0.12  0.16  0.19  0.11  0.12 #>      V1281 V1282 V1283 V1284 V1285 V1286 V1287 V1288 V1289 V1290 V1291 V1292 #> mean  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.12  0.12 #> sd    0.15  0.08  0.13  0.16  0.12  0.10  0.18  0.15  0.21  0.12  0.12  0.19 #>      V1293 V1294 V1295 V1296 V1297 V1298 V1299 V1300 V1301 V1302 V1303 V1304 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13 #> sd    0.14  0.13  0.11  0.14  0.10  0.08  0.16  0.17  0.11  0.15  0.22  0.15 #>      V1305 V1306 V1307 V1308 V1309 V1310 V1311 V1312 V1313 V1314 V1315 V1316 #> mean  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.13  0.12  0.14  0.13  0.29  0.17  0.12  0.07  0.12  0.11  0.21  0.10 #>      V1317 V1318 V1319 V1320 V1321 V1322 V1323 V1324 V1325 V1326 V1327 V1328 #> mean  0.12  0.13  0.12  0.12  0.12  0.12  0.13  0.12  0.13  0.13  0.12  0.13 #> sd    0.05  0.11  0.15  0.08  0.09  0.12  0.18  0.09  0.10  0.16  0.22  0.16 #>      V1329 V1330 V1331 V1332 V1333 V1334 V1335 V1336 V1337 V1338 V1339 V1340 #> mean  0.12  0.13  0.12  0.12  0.13  0.13  0.12  0.12  0.12  0.12  0.13  0.12 #> sd    0.17  0.08  0.09  0.10  0.06  0.07  0.14  0.07  0.13  0.21  0.15  0.15 #>      V1341 V1342 V1343 V1344 V1345 V1346 V1347 V1348 V1349 V1350 V1351 V1352 #> mean  0.13  0.13  0.13  0.12  0.12  0.13  0.12  0.12  0.13  0.13  0.12  0.12 #> sd    0.10  0.19  0.09  0.09  0.07  0.20  0.09  0.08  0.18  0.10  0.11  0.10 #>      V1353 V1354 V1355 V1356 V1357 V1358 V1359 V1360 V1361 V1362 V1363 V1364 #> mean  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.13  0.12  0.12  0.13  0.12 #> sd    0.11  0.18  0.10  0.10  0.24  0.19  0.14  0.09  0.23  0.07  0.05  0.09 #>      V1365 V1366 V1367 V1368 V1369 V1370 V1371 V1372 V1373 V1374 V1375 V1376 #> mean  0.13  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.13  0.12  0.12 #> sd    0.07  0.15  0.06  0.13  0.14  0.11  0.19  0.19  0.19  0.24  0.14  0.18 #>      V1377 V1378 V1379 V1380 V1381 V1382 V1383 V1384 V1385 V1386 V1387 V1388 #> mean  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.13  0.12  0.13 #> sd    0.26  0.16  0.18  0.08  0.16  0.09  0.17  0.13  0.18  0.03  0.13  0.12 #>      V1389 V1390 V1391 V1392 V1393 V1394 V1395 V1396 V1397 V1398 V1399 V1400 #> mean  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.12  0.12  0.13  0.13 #> sd    0.11  0.12  0.06  0.11  0.18  0.11  0.17  0.13  0.10  0.08  0.11  0.11 #>      V1401 V1402 V1403 V1404 V1405 V1406 V1407 V1408 V1409 V1410 V1411 V1412 #> mean  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.13  0.07  0.09  0.10  0.13  0.12  0.16  0.07  0.15  0.16  0.15  0.06 #>      V1413 V1414 V1415 V1416 V1417 V1418 V1419 V1420 V1421 V1422 V1423 V1424 #> mean  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12 #> sd    0.13  0.18  0.17  0.22  0.12  0.12  0.16  0.10  0.16  0.05  0.16  0.12 #>      V1425 V1426 V1427 V1428 V1429 V1430 V1431 V1432 V1433 V1434 V1435 V1436 #> mean  0.13  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.20  0.19  0.25  0.15  0.14  0.18  0.15  0.08  0.11  0.13  0.09  0.20 #>      V1437 V1438 V1439 V1440 V1441 V1442 V1443 V1444 V1445 V1446 V1447 V1448 #> mean  0.12  0.12  0.13  0.13  0.12  0.13  0.12  0.12  0.12  0.13  0.13  0.12 #> sd    0.23  0.26  0.10  0.16  0.12  0.18  0.10  0.11  0.11  0.10  0.16  0.06 #>      V1449 V1450 V1451 V1452 V1453 V1454 V1455 V1456 V1457 V1458 V1459 V1460 #> mean  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.13  0.13  0.12  0.13  0.13 #> sd    0.23  0.14  0.17  0.16  0.17  0.19  0.13  0.09  0.11  0.12  0.14  0.13 #>      V1461 V1462 V1463 V1464 V1465 V1466 V1467 V1468 V1469 V1470 V1471 V1472 #> mean  0.12  0.12  0.12  0.13  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.06  0.11  0.13  0.13  0.11  0.15  0.04  0.12  0.14  0.08  0.06  0.07 #>      V1473 V1474 V1475 V1476 V1477 V1478 V1479 V1480 V1481 V1482 V1483 V1484 #> mean  0.12  0.13  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.12 #> sd    0.08  0.17  0.19  0.22  0.16  0.18  0.17  0.10  0.11  0.14  0.12  0.15 #>      V1485 V1486 V1487 V1488 V1489 V1490 V1491 V1492 V1493 V1494 V1495 V1496 #> mean  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.13  0.12  0.13 #> sd    0.11  0.11  0.17  0.21  0.14  0.17  0.12  0.14  0.06  0.11  0.15  0.10 #>      V1497 V1498 V1499 V1500 V1501 V1502 V1503 V1504 V1505 V1506 V1507 V1508 #> mean  0.13  0.13  0.12  0.12  0.13  0.13  0.12  0.12  0.12  0.13  0.12  0.12 #> sd    0.16  0.12  0.16  0.03  0.11  0.13  0.10  0.08  0.08  0.13  0.09  0.12 #>      V1509 V1510 V1511 V1512 V1513 V1514 V1515 V1516 V1517 V1518 V1519 V1520 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.13  0.12 #> sd    0.20  0.15  0.15  0.09  0.13  0.17  0.19  0.14  0.14  0.11  0.13  0.09 #>      V1521 V1522 V1523 V1524 V1525 V1526 V1527 V1528 V1529 V1530 V1531 V1532 #> mean  0.13  0.13  0.13  0.12  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.12 #> sd    0.14  0.14  0.15  0.21  0.10  0.09  0.15  0.05  0.20  0.14  0.18  0.08 #>      V1533 V1534 V1535 V1536 V1537 V1538 V1539 V1540 V1541 V1542 V1543 V1544 #> mean  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12 #> sd    0.09  0.14  0.14  0.19  0.19  0.14  0.15  0.22  0.11  0.11  0.11  0.04 #>      V1545 V1546 V1547 V1548 V1549 V1550 V1551 V1552 V1553 V1554 V1555 V1556 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.13  0.12  0.12  0.12 #> sd    0.12  0.16  0.09  0.12  0.14  0.12  0.07  0.14  0.15  0.23  0.19  0.13 #>      V1557 V1558 V1559 V1560 V1561 V1562 V1563 V1564 V1565 V1566 V1567 V1568 #> mean  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.13  0.13  0.12  0.13 #> sd    0.17  0.12  0.21  0.11  0.20  0.12  0.12  0.09  0.16  0.13  0.09  0.14 #>      V1569 V1570 V1571 V1572 V1573 V1574 V1575 V1576 V1577 V1578 V1579 V1580 #> mean  0.12  0.12  0.12  0.12  0.13  0.12  0.13  0.13  0.13  0.12  0.12  0.12 #> sd    0.13  0.16  0.25  0.09  0.10  0.16  0.06  0.11  0.14  0.05  0.25  0.14 #>      V1581 V1582 V1583 V1584 V1585 V1586 V1587 V1588 V1589 V1590 V1591 V1592 #> mean  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12 #> sd    0.17  0.24  0.09  0.14  0.09  0.30  0.19  0.12  0.08  0.17  0.10  0.09 #>      V1593 V1594 V1595 V1596 V1597 V1598 V1599 V1600 V1601 V1602 V1603 V1604 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.13  0.12 #> sd    0.09  0.14  0.15  0.12  0.10  0.19  0.11  0.16  0.13  0.12  0.06  0.17 #>      V1605 V1606 V1607 V1608 V1609 V1610 V1611 V1612 V1613 V1614 V1615 V1616 #> mean  0.12  0.13  0.13  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.13 #> sd    0.16  0.17  0.16  0.28  0.17  0.14  0.15  0.14  0.12  0.10  0.19  0.11 #>      V1617 V1618 V1619 V1620 V1621 V1622 V1623 V1624 V1625 V1626 V1627 V1628 #> mean  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.13  0.12  0.12 #> sd    0.21  0.09  0.05  0.07  0.15  0.12  0.13  0.12  0.07  0.17  0.11  0.13 #>      V1629 V1630 V1631 V1632 V1633 V1634 V1635 V1636 V1637 V1638 V1639 V1640 #> mean  0.13  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.16  0.16  0.03  0.13  0.17  0.12  0.09  0.10  0.19  0.21  0.20  0.20 #>      V1641 V1642 V1643 V1644 V1645 V1646 V1647 V1648 V1649 V1650 V1651 V1652 #> mean  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.13  0.12  0.13  0.13  0.13 #> sd    0.20  0.13  0.11  0.15  0.21  0.14  0.14  0.16  0.20  0.05  0.21  0.09 #>      V1653 V1654 V1655 V1656 V1657 V1658 V1659 V1660 V1661 V1662 V1663 V1664 #> mean  0.13  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.13  0.13  0.12 #> sd    0.16  0.17  0.17  0.07  0.15  0.15  0.18  0.24  0.17  0.11  0.24  0.11 #>      V1665 V1666 V1667 V1668 V1669 V1670 V1671 V1672 V1673 V1674 V1675 V1676 #> mean  0.13  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.10  0.13  0.09  0.10  0.16  0.15  0.14  0.08  0.11  0.18  0.10  0.16 #>      V1677 V1678 V1679 V1680 V1681 V1682 V1683 V1684 V1685 V1686 V1687 V1688 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.12 #> sd    0.19  0.17  0.17  0.16  0.08  0.20  0.13  0.12  0.15  0.09  0.10  0.17 #>      V1689 V1690 V1691 V1692 V1693 V1694 V1695 V1696 V1697 V1698 V1699 V1700 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.13  0.13  0.12 #> sd    0.08  0.11  0.14  0.15  0.18  0.08  0.11  0.09  0.14  0.15  0.18  0.05 #>      V1701 V1702 V1703 V1704 V1705 V1706 V1707 V1708 V1709 V1710 V1711 V1712 #> mean  0.12  0.13  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.13 #> sd    0.13  0.11  0.17  0.09  0.11  0.09  0.15  0.16  0.06  0.15  0.14  0.16 #>      V1713 V1714 V1715 V1716 V1717 V1718 V1719 V1720 V1721 V1722 V1723 V1724 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12 #> sd    0.18  0.07  0.10  0.11  0.12  0.16  0.12  0.19  0.14  0.23  0.19  0.10 #>      V1725 V1726 V1727 V1728 V1729 V1730 V1731 V1732 V1733 V1734 V1735 V1736 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12 #> sd    0.15  0.16  0.17  0.08  0.24  0.19  0.16  0.15  0.13  0.11  0.08  0.20 #>      V1737 V1738 V1739 V1740 V1741 V1742 V1743 V1744 V1745 V1746 V1747 V1748 #> mean  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12 #> sd    0.11  0.16  0.15  0.15  0.15  0.15  0.17  0.08  0.13  0.19  0.10  0.09 #>      V1749 V1750 V1751 V1752 V1753 V1754 V1755 V1756 V1757 V1758 V1759 V1760 #> mean  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.12 #> sd    0.13  0.12  0.04  0.13  0.08  0.12  0.06  0.17  0.12  0.10  0.13  0.09 #>      V1761 V1762 V1763 V1764 V1765 V1766 V1767 V1768 V1769 V1770 V1771 V1772 #> mean  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.12 #> sd    0.07  0.13  0.18  0.11  0.25  0.08  0.08  0.27  0.13  0.10  0.14  0.12 #>      V1773 V1774 V1775 V1776 V1777 V1778 V1779 V1780 V1781 V1782 V1783 V1784 #> mean  0.13  0.13  0.12  0.13  0.12  0.13  0.13  0.12  0.12  0.12  0.12  0.12 #> sd    0.11  0.10  0.15  0.17  0.24  0.08  0.07  0.17  0.13  0.11  0.16  0.19 #>      V1785 V1786 V1787 V1788 V1789 V1790 V1791 V1792 V1793 V1794 V1795 V1796 #> mean  0.12  0.13  0.13  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12 #> sd    0.11  0.12  0.14  0.17  0.10  0.05  0.12  0.21  0.15  0.20  0.25  0.17 #>      V1797 V1798 V1799 V1800 V1801 V1802 V1803 V1804 V1805 V1806 V1807 V1808 #> mean  0.12  0.13  0.13  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.13  0.12 #> sd    0.06  0.06  0.10  0.23  0.11  0.15  0.16  0.16  0.11  0.14  0.09  0.13 #>      V1809 V1810 V1811 V1812 V1813 V1814 V1815 V1816 V1817 V1818 V1819 V1820 #> mean  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12 #> sd    0.06  0.16  0.10  0.15  0.09  0.13  0.09  0.21  0.08  0.17  0.12  0.14 #>      V1821 V1822 V1823 V1824 V1825 V1826 V1827 V1828 V1829 V1830 V1831 V1832 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.12  0.12  0.12 #> sd    0.17  0.21  0.06  0.11  0.13  0.10  0.11  0.08  0.11  0.14  0.12  0.13 #>      V1833 V1834 V1835 V1836 V1837 V1838 V1839 V1840 V1841 V1842 V1843 V1844 #> mean  0.13  0.12  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12 #> sd    0.13  0.25  0.07  0.06  0.13  0.23  0.11  0.14  0.14  0.09  0.13  0.15 #>      V1845 V1846 V1847 V1848 V1849 V1850 V1851 V1852 V1853 V1854 V1855 V1856 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.19  0.12  0.04  0.04  0.12  0.13  0.12  0.24  0.13  0.12  0.16  0.11 #>      V1857 V1858 V1859 V1860 V1861 V1862 V1863 V1864 V1865 V1866 V1867 V1868 #> mean  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.13  0.12  0.12 #> sd    0.18  0.22  0.19  0.18  0.17  0.17  0.25  0.16  0.18  0.09  0.15  0.07 #>      V1869 V1870 V1871 V1872 V1873 V1874 V1875 V1876 V1877 V1878 V1879 V1880 #> mean  0.12  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.16  0.13  0.08  0.18  0.17  0.05  0.13  0.15  0.19  0.02  0.17  0.11 #>      V1881 V1882 V1883 V1884 V1885 V1886 V1887 V1888 V1889 V1890 V1891 V1892 #> mean  0.12  0.12  0.13  0.12  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.12 #> sd    0.09  0.15  0.13  0.27  0.14  0.10  0.17  0.17  0.23  0.17  0.21  0.10 #>      V1893 V1894 V1895 V1896 V1897 V1898 V1899 V1900 V1901 V1902 V1903 V1904 #> mean  0.13  0.12  0.13  0.13  0.12  0.12  0.13  0.13  0.13  0.13  0.13  0.13 #> sd    0.13  0.13  0.07  0.22  0.09  0.11  0.16  0.11  0.08  0.17  0.13  0.08 #>      V1905 V1906 V1907 V1908 V1909 V1910 V1911 V1912 V1913 V1914 V1915 V1916 #> mean  0.12  0.13  0.12  0.12  0.12  0.13  0.13  0.12  0.13  0.12  0.12  0.13 #> sd    0.10  0.07  0.13  0.11  0.10  0.17  0.04  0.11  0.06  0.17  0.18  0.14 #>      V1917 V1918 V1919 V1920 V1921 V1922 V1923 V1924 V1925 V1926 V1927 V1928 #> mean  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.13 #> sd    0.11  0.14  0.06  0.15  0.17  0.08  0.05  0.12  0.14  0.08  0.15  0.15 #>      V1929 V1930 V1931 V1932 V1933 V1934 V1935 V1936 V1937 V1938 V1939 V1940 #> mean  0.13  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.13  0.12 #> sd    0.07  0.14  0.12  0.07  0.10  0.14  0.15  0.17  0.15  0.20  0.13  0.13 #>      V1941 V1942 V1943 V1944 V1945 V1946 V1947 V1948 V1949 V1950 V1951 V1952 #> mean  0.12  0.13  0.13  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.10  0.15  0.10  0.20  0.17  0.21  0.12  0.19  0.14  0.14  0.07  0.12 #>      V1953 V1954 V1955 V1956 V1957 V1958 V1959 V1960 V1961 V1962 V1963 V1964 #> mean  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.12  0.12  0.13  0.12  0.12 #> sd    0.14  0.19  0.10  0.07  0.13  0.15  0.16  0.08  0.14  0.12  0.12  0.20 #>      V1965 V1966 V1967 V1968 V1969 V1970 V1971 V1972 V1973 V1974 V1975 V1976 #> mean  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.13  0.12  0.12  0.13  0.13 #> sd    0.15  0.09  0.15  0.10  0.11  0.22  0.14  0.21  0.10  0.22  0.14  0.09 #>      V1977 V1978 V1979 V1980 V1981 V1982 V1983 V1984 V1985 V1986 V1987 V1988 #> mean  0.13  0.13  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.13 #> sd    0.13  0.21  0.10  0.10  0.17  0.12  0.10  0.07  0.13  0.17  0.13  0.12 #>      V1989 V1990 V1991 V1992 V1993 V1994 V1995 V1996 V1997 V1998 V1999 V2000 #> mean  0.13  0.13  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.12  0.12  0.12 #> sd    0.13  0.11  0.11  0.18  0.18  0.06  0.13  0.09  0.14  0.16  0.17  0.07 #>      V2001 V2002 V2003 V2004 V2005 V2006 V2007 V2008 V2009 V2010 V2011 V2012 #> mean  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.18  0.08  0.17  0.16  0.16  0.10  0.12  0.13  0.25  0.16  0.13  0.17 #>      V2013 V2014 V2015 V2016 V2017 V2018 V2019 V2020 V2021 V2022 V2023 V2024 #> mean  0.12  0.12  0.13  0.12  0.13  0.12  0.12  0.13  0.12  0.12  0.13  0.13 #> sd    0.19  0.14  0.17  0.10  0.15  0.12  0.12  0.01  0.13  0.16  0.13  0.18 #>      V2025 V2026 V2027 V2028 V2029 V2030 V2031 V2032 V2033 V2034 V2035 V2036 #> mean  0.12  0.13  0.13  0.13  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12 #> sd    0.09  0.15  0.12  0.13  0.16  0.15  0.10  0.09  0.11  0.15  0.09  0.15 #>      V2037 V2038 V2039 V2040 V2041 V2042 V2043 V2044 V2045 V2046 V2047 V2048 #> mean  0.12  0.13  0.13  0.13  0.13  0.12  0.12  0.13  0.12  0.13  0.13  0.12 #> sd    0.09  0.14  0.24  0.18  0.21  0.11  0.15  0.12  0.13  0.20  0.12  0.17 #>      V2049 V2050 V2051 V2052 V2053 V2054 V2055 V2056 V2057 V2058 V2059 V2060 #> mean  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.13  0.12  0.12  0.12 #> sd    0.15  0.16  0.10  0.16  0.07  0.12  0.10  0.12  0.10  0.13  0.22  0.11 #>      V2061 V2062 V2063 V2064 V2065 V2066 V2067 V2068 V2069 V2070 V2071 V2072 #> mean  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.07  0.10  0.16  0.18  0.06  0.09  0.10  0.08  0.28  0.13  0.13  0.13 #>      V2073 V2074 V2075 V2076 V2077 V2078 V2079 V2080 V2081 V2082 V2083 V2084 #> mean  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.13  0.13  0.13  0.12  0.13 #> sd    0.09  0.09  0.13  0.15  0.17  0.12  0.08  0.13  0.12  0.10  0.19  0.16 #>      V2085 V2086 V2087 V2088 V2089 V2090 V2091 V2092 V2093 V2094 V2095 V2096 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12 #> sd    0.11  0.10  0.08  0.14  0.14  0.12  0.06  0.17  0.15  0.28  0.12  0.13 #>      V2097 V2098 V2099 V2100 V2101 V2102 V2103 V2104 V2105 V2106 V2107 V2108 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.13  0.12  0.12  0.12 #> sd    0.11  0.12  0.17  0.10  0.14  0.21  0.16  0.16  0.09  0.15  0.09  0.08 #>      V2109 V2110 V2111 V2112 V2113 V2114 V2115 V2116 V2117 V2118 V2119 V2120 #> mean  0.12  0.12  0.13  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.12 #> sd    0.14  0.15  0.14  0.12  0.11  0.19  0.08  0.09  0.17  0.08  0.11  0.16 #>      V2121 V2122 V2123 V2124 V2125 V2126 V2127 V2128 V2129 V2130 V2131 V2132 #> mean  0.13  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.12 #> sd    0.14  0.15  0.16  0.11  0.14  0.18  0.08  0.09  0.13  0.16  0.19  0.12 #>      V2133 V2134 V2135 V2136 V2137 V2138 V2139 V2140 V2141 V2142 V2143 V2144 #> mean  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.12  0.15  0.14  0.19  0.18  0.17  0.09  0.26  0.17  0.09  0.11  0.11 #>      V2145 V2146 V2147 V2148 V2149 V2150 V2151 V2152 V2153 V2154 V2155 V2156 #> mean  0.12  0.12  0.12  0.13  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.12 #> sd    0.18  0.16  0.05  0.14  0.08  0.09  0.10  0.11  0.14  0.18  0.21  0.10 #>      V2157 V2158 V2159 V2160 V2161 V2162 V2163 V2164 V2165 V2166 V2167 V2168 #> mean  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.13  0.12 #> sd    0.11  0.14  0.14  0.10  0.18  0.19  0.18  0.17  0.11  0.17  0.13  0.12 #>      V2169 V2170 V2171 V2172 V2173 V2174 V2175 V2176 V2177 V2178 V2179 V2180 #> mean  0.12  0.12  0.12  0.13  0.12  0.13  0.13  0.13  0.12  0.12  0.12  0.12 #> sd    0.17  0.16  0.15  0.26  0.13  0.10  0.12  0.12  0.19  0.15  0.13  0.18 #>      V2181 V2182 V2183 V2184 V2185 V2186 V2187 V2188 V2189 V2190 V2191 V2192 #> mean  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12 #> sd    0.13  0.18  0.16  0.14  0.19  0.09  0.15  0.19  0.14  0.09  0.17  0.10 #>      V2193 V2194 V2195 V2196 V2197 V2198 V2199 V2200 V2201 V2202 V2203 V2204 #> mean  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12 #> sd    0.16  0.11  0.21  0.12  0.08  0.11  0.11  0.10  0.07  0.17  0.08  0.09 #>      V2205 V2206 V2207 V2208 V2209 V2210 V2211 V2212 V2213 V2214 V2215 V2216 #> mean  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.13  0.12  0.13  0.12  0.12 #> sd    0.10  0.09  0.16  0.16  0.21  0.13  0.15  0.20  0.08  0.09  0.13  0.15 #>      V2217 V2218 V2219 V2220 V2221 V2222 V2223 V2224 V2225 V2226 V2227 V2228 #> mean  0.12  0.12  0.12  0.13  0.12  0.13  0.12  0.13  0.13  0.12  0.12  0.12 #> sd    0.03  0.15  0.14  0.21  0.23  0.14  0.10  0.10  0.12  0.07  0.13  0.05 #>      V2229 V2230 V2231 V2232 V2233 V2234 V2235 V2236 V2237 V2238 V2239 V2240 #> mean  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.13  0.13  0.13  0.12  0.12 #> sd    0.27  0.10  0.14  0.19  0.19  0.11  0.17  0.12  0.11  0.11  0.18  0.11 #>      V2241 V2242 V2243 V2244 V2245 V2246 V2247 V2248 V2249 V2250 V2251 V2252 #> mean  0.13  0.12  0.13  0.12  0.12  0.12  0.13  0.13  0.12  0.12  0.13  0.13 #> sd    0.14  0.14  0.13  0.12  0.08  0.09  0.18  0.15  0.18  0.13  0.15  0.10 #>      V2253 V2254 V2255 V2256 V2257 V2258 V2259 V2260 V2261 V2262 V2263 V2264 #> mean  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.12  0.12 #> sd    0.24  0.14  0.15  0.18  0.07  0.15  0.12  0.07  0.07  0.09  0.09  0.15 #>      V2265 V2266 V2267 V2268 V2269 V2270 V2271 V2272 V2273 V2274 V2275 V2276 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12 #> sd    0.17  0.08  0.08  0.09  0.06  0.12  0.24  0.08  0.06  0.09  0.18  0.11 #>      V2277 V2278 V2279 V2280 V2281 V2282 V2283 V2284 V2285 V2286 V2287 V2288 #> mean  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12 #> sd    0.07  0.20  0.15  0.19  0.07  0.12  0.27  0.10  0.11  0.16  0.15  0.13 #>      V2289 V2290 V2291 V2292 V2293 V2294 V2295 V2296 V2297 V2298 V2299 V2300 #> mean  0.13  0.13  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.13 #> sd    0.09  0.12  0.14  0.16  0.14  0.15  0.20  0.13  0.08  0.10  0.12  0.27 #>      V2301 V2302 V2303 V2304 V2305 V2306 V2307 V2308 V2309 V2310 V2311 V2312 #> mean  0.12  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.08  0.10  0.11  0.10  0.07  0.15  0.19  0.13  0.08  0.12  0.17  0.09 #>      V2313 V2314 V2315 V2316 V2317 V2318 V2319 V2320 V2321 V2322 V2323 V2324 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.13  0.12  0.12 #> sd    0.14  0.16  0.11  0.17  0.10  0.16  0.20  0.18  0.19  0.10  0.12  0.14 #>      V2325 V2326 V2327 V2328 V2329 V2330 V2331 V2332 V2333 V2334 V2335 V2336 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.13 #> sd    0.09  0.12  0.04  0.13  0.14  0.09  0.14  0.14  0.09  0.14  0.07  0.21 #>      V2337 V2338 V2339 V2340 V2341 V2342 V2343 V2344 V2345 V2346 V2347 V2348 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12 #> sd    0.14  0.08  0.17  0.20  0.14  0.09  0.05  0.28  0.19  0.10  0.09  0.18 #>      V2349 V2350 V2351 V2352 V2353 V2354 V2355 V2356 V2357 V2358 V2359 V2360 #> mean  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12 #> sd    0.18  0.15  0.07  0.16  0.13  0.10  0.18  0.21  0.13  0.16  0.13  0.13 #>      V2361 V2362 V2363 V2364 V2365 V2366 V2367 V2368 V2369 V2370 V2371 V2372 #> mean  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.13  0.12  0.13  0.12  0.12 #> sd    0.20  0.11  0.09  0.19  0.11  0.19  0.23  0.09  0.05  0.19  0.15  0.18 #>      V2373 V2374 V2375 V2376 V2377 V2378 V2379 V2380 V2381 V2382 V2383 V2384 #> mean  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.13 #> sd    0.12  0.05  0.14  0.02  0.15  0.13  0.16  0.13  0.08  0.15  0.19  0.18 #>      V2385 V2386 V2387 V2388 V2389 V2390 V2391 V2392 V2393 V2394 V2395 V2396 #> mean  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.13  0.12 #> sd    0.11  0.16  0.19  0.12  0.09  0.11  0.11  0.09  0.14  0.08  0.12  0.15 #>      V2397 V2398 V2399 V2400 V2401 V2402 V2403 V2404 V2405 V2406 V2407 V2408 #> mean  0.12  0.13  0.12  0.12  0.12  0.12  0.13  0.13  0.13  0.12  0.13  0.12 #> sd    0.24  0.15  0.14  0.20  0.10  0.10  0.08  0.08  0.10  0.06  0.08  0.20 #>      V2409 V2410 V2411 V2412 V2413 V2414 V2415 V2416 V2417 V2418 V2419 V2420 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.13 #> sd    0.11  0.05  0.08  0.14  0.06  0.13  0.08  0.13  0.11  0.15  0.15  0.11 #>      V2421 V2422 V2423 V2424 V2425 V2426 V2427 V2428 V2429 V2430 V2431 V2432 #> mean  0.13  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13 #> sd    0.11  0.15  0.06  0.14  0.10  0.16  0.07  0.18  0.07  0.18  0.12  0.18 #>      V2433 V2434 V2435 V2436 V2437 V2438 V2439 V2440 V2441 V2442 V2443 V2444 #> mean  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.12  0.13 #> sd    0.12  0.33  0.09  0.14  0.08  0.16  0.08  0.14  0.13  0.12  0.13  0.17 #>      V2445 V2446 V2447 V2448 V2449 V2450 V2451 V2452 V2453 V2454 V2455 V2456 #> mean  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.13  0.12  0.12  0.12 #> sd    0.23  0.13  0.09  0.12  0.11  0.10  0.20  0.15  0.15  0.14  0.20  0.13 #>      V2457 V2458 V2459 V2460 V2461 V2462 V2463 V2464 V2465 V2466 V2467 V2468 #> mean  0.13  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.22  0.26  0.14  0.22  0.15  0.11  0.16  0.11  0.13  0.11  0.19  0.12 #>      V2469 V2470 V2471 V2472 V2473 V2474 V2475 V2476 V2477 V2478 V2479 V2480 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.12 #> sd    0.19  0.15  0.11  0.15  0.13  0.17  0.12  0.06  0.08  0.22  0.11  0.03 #>      V2481 V2482 V2483 V2484 V2485 V2486 V2487 V2488 V2489 V2490 V2491 V2492 #> mean  0.12  0.13  0.13  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.14  0.13  0.05  0.17  0.12  0.19  0.15  0.09  0.10  0.08  0.13  0.11 #>      V2493 V2494 V2495 V2496 V2497 V2498 V2499 V2500 V2501 V2502 V2503 V2504 #> mean  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13 #> sd    0.07  0.14  0.11  0.12  0.16  0.18  0.07  0.12  0.16  0.09  0.14  0.17 #>      V2505 V2506 V2507 V2508 V2509 V2510 V2511 V2512 V2513 V2514 V2515 V2516 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12 #> sd    0.14  0.10  0.08  0.16  0.15  0.16  0.11  0.13  0.17  0.12  0.22  0.04 #>      V2517 V2518 V2519 V2520 V2521 V2522 V2523 V2524 V2525 V2526 V2527 V2528 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.12  0.22  0.17  0.14  0.10  0.09  0.20  0.21  0.18  0.17  0.10  0.09 #>      V2529 V2530 V2531 V2532 V2533 V2534 V2535 V2536 V2537 V2538 V2539 V2540 #> mean  0.13  0.12  0.12  0.12  0.13  0.12  0.13  0.13  0.13  0.13  0.12  0.12 #> sd    0.09  0.15  0.09  0.19  0.11  0.18  0.07  0.12  0.13  0.17  0.14  0.15 #>      V2541 V2542 V2543 V2544 V2545 V2546 V2547 V2548 V2549 V2550 V2551 V2552 #> mean  0.13  0.12  0.12  0.12  0.13  0.12  0.13  0.12  0.12  0.12  0.13  0.12 #> sd    0.13  0.09  0.09  0.12  0.14  0.13  0.19  0.14  0.15  0.17  0.15  0.15 #>      V2553 V2554 V2555 V2556 V2557 V2558 V2559 V2560 V2561 V2562 V2563 V2564 #> mean  0.12  0.12  0.13  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.10  0.08  0.07  0.09  0.06  0.18  0.20  0.14  0.07  0.16  0.18  0.13 #>      V2565 V2566 V2567 V2568 V2569 V2570 V2571 V2572 V2573 V2574 V2575 V2576 #> mean  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.12  0.13 #> sd    0.06  0.20  0.19  0.11  0.04  0.13  0.19  0.17  0.18  0.22  0.14  0.16 #>      V2577 V2578 V2579 V2580 V2581 V2582 V2583 V2584 V2585 V2586 V2587 V2588 #> mean  0.13  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.13 #> sd    0.12  0.16  0.14  0.22  0.09  0.11  0.05  0.12  0.09  0.10  0.14  0.16 #>      V2589 V2590 V2591 V2592 V2593 V2594 V2595 V2596 V2597 V2598 V2599 V2600 #> mean  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12 #> sd    0.14  0.14  0.20  0.09  0.15  0.15  0.10  0.16  0.03  0.15  0.10  0.14 #>      V2601 V2602 V2603 V2604 V2605 V2606 V2607 V2608 V2609 V2610 V2611 V2612 #> mean  0.12  0.13  0.12  0.12  0.12  0.13  0.12  0.13  0.12  0.13  0.12  0.12 #> sd    0.14  0.11  0.16  0.08  0.10  0.12  0.12  0.18  0.13  0.32  0.22  0.16 #>      V2613 V2614 V2615 V2616 V2617 V2618 V2619 V2620 V2621 V2622 V2623 V2624 #> mean  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.12  0.13  0.24  0.14  0.17  0.13  0.24  0.11  0.16  0.05  0.10  0.12 #>      V2625 V2626 V2627 V2628 V2629 V2630 V2631 V2632 V2633 V2634 V2635 V2636 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.13  0.13  0.12  0.12 #> sd    0.22  0.11  0.14  0.15  0.10  0.17  0.11  0.17  0.09  0.11  0.11  0.04 #>      V2637 V2638 V2639 V2640 V2641 V2642 V2643 V2644 V2645 V2646 V2647 V2648 #> mean  0.13  0.12  0.12  0.13  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.17  0.14  0.06  0.15  0.10  0.14  0.18  0.17  0.11  0.10  0.16  0.14 #>      V2649 V2650 V2651 V2652 V2653 V2654 V2655 V2656 V2657 V2658 V2659 V2660 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12 #> sd    0.08  0.10  0.13  0.18  0.14  0.17  0.17  0.14  0.15  0.19  0.06  0.13 #>      V2661 V2662 V2663 V2664 V2665 V2666 V2667 V2668 V2669 V2670 V2671 V2672 #> mean  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.13  0.13  0.12 #> sd    0.08  0.12  0.13  0.13  0.08  0.14  0.09  0.20  0.13  0.07  0.20  0.08 #>      V2673 V2674 V2675 V2676 V2677 V2678 V2679 V2680 V2681 V2682 V2683 V2684 #> mean  0.12  0.12  0.13  0.12  0.13  0.12  0.12  0.12  0.12  0.13  0.12  0.12 #> sd    0.07  0.10  0.24  0.29  0.10  0.10  0.13  0.12  0.13  0.14  0.13  0.16 #>      V2685 V2686 V2687 V2688 V2689 V2690 V2691 V2692 V2693 V2694 V2695 V2696 #> mean  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.12 #> sd    0.09  0.26  0.10  0.07  0.11  0.07  0.13  0.15  0.15  0.10  0.14  0.19 #>      V2697 V2698 V2699 V2700 V2701 V2702 V2703 V2704 V2705 V2706 V2707 V2708 #> mean  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.12  0.12  0.12 #> sd    0.16  0.08  0.18  0.16  0.18  0.12  0.22  0.11  0.15  0.16  0.09  0.07 #>      V2709 V2710 V2711 V2712 V2713 V2714 V2715 V2716 V2717 V2718 V2719 V2720 #> mean  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.12 #> sd    0.03  0.12  0.11  0.11  0.14  0.09  0.12  0.10  0.11  0.14  0.09  0.21 #>      V2721 V2722 V2723 V2724 V2725 V2726 V2727 V2728 V2729 V2730 V2731 V2732 #> mean  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.05  0.18  0.16  0.17  0.22  0.02  0.08  0.12  0.25  0.15  0.11  0.09 #>      V2733 V2734 V2735 V2736 V2737 V2738 V2739 V2740 V2741 V2742 V2743 V2744 #> mean  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.12 #> sd    0.15  0.09  0.08  0.09  0.14  0.12  0.15  0.15  0.10  0.16  0.07  0.18 #>      V2745 V2746 V2747 V2748 V2749 V2750 V2751 V2752 V2753 V2754 V2755 V2756 #> mean  0.12  0.12  0.12  0.13  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.10  0.17  0.10  0.18  0.06  0.06  0.18  0.22  0.13  0.13  0.13  0.09 #>      V2757 V2758 V2759 V2760 V2761 V2762 V2763 V2764 V2765 V2766 V2767 V2768 #> mean  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.12  0.12  0.12  0.13  0.13 #> sd    0.21  0.10  0.06  0.15  0.11  0.15  0.15  0.24  0.19  0.10  0.12  0.17 #>      V2769 V2770 V2771 V2772 V2773 V2774 V2775 V2776 V2777 V2778 V2779 V2780 #> mean  0.13  0.12  0.13  0.12  0.13  0.12  0.12  0.12  0.13  0.13  0.13  0.13 #> sd    0.12  0.09  0.06  0.21  0.11  0.13  0.11  0.10  0.13  0.17  0.07  0.11 #>      V2781 V2782 V2783 V2784 V2785 V2786 V2787 V2788 V2789 V2790 V2791 V2792 #> mean  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.12  0.12 #> sd    0.13  0.17  0.14  0.15  0.13  0.15  0.27  0.19  0.15  0.11  0.07  0.20 #>      V2793 V2794 V2795 V2796 V2797 V2798 V2799 V2800 V2801 V2802 V2803 V2804 #> mean  0.12  0.13  0.13  0.12  0.13  0.13  0.12  0.13  0.12  0.12  0.12  0.13 #> sd    0.06  0.15  0.16  0.12  0.05  0.20  0.04  0.14  0.10  0.09  0.08  0.18 #>      V2805 V2806 V2807 V2808 V2809 V2810 V2811 V2812 V2813 V2814 V2815 V2816 #> mean  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.12 #> sd    0.15  0.22  0.14  0.17  0.21  0.14  0.15  0.09  0.13  0.18  0.07  0.16 #>      V2817 V2818 V2819 V2820 V2821 V2822 V2823 V2824 V2825 V2826 V2827 V2828 #> mean  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.15  0.12  0.25  0.08  0.13  0.16  0.15  0.23  0.12  0.10  0.14  0.18 #>      V2829 V2830 V2831 V2832 V2833 V2834 V2835 V2836 V2837 V2838 V2839 V2840 #> mean  0.13  0.12  0.12  0.13  0.13  0.13  0.12  0.12  0.12  0.12  0.13  0.12 #> sd    0.10  0.07  0.13  0.09  0.12  0.08  0.15  0.08  0.11  0.10  0.16  0.11 #>      V2841 V2842 V2843 V2844 V2845 V2846 V2847 V2848 V2849 V2850 V2851 V2852 #> mean  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.12 #> sd    0.16  0.14  0.12  0.15  0.18  0.06  0.16  0.12  0.12  0.09  0.12  0.08 #>      V2853 V2854 V2855 V2856 V2857 V2858 V2859 V2860 V2861 V2862 V2863 V2864 #> mean  0.13  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.12 #> sd    0.14  0.08  0.17  0.09  0.12  0.20  0.14  0.09  0.18  0.18  0.14  0.10 #>      V2865 V2866 V2867 V2868 V2869 V2870 V2871 V2872 V2873 V2874 V2875 V2876 #> mean  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.13 #> sd    0.13  0.13  0.21  0.15  0.11  0.19  0.20  0.18  0.16  0.19  0.24  0.16 #>      V2877 V2878 V2879 V2880 V2881 V2882 V2883 V2884 V2885 V2886 V2887 V2888 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.13  0.13 #> sd    0.20  0.13  0.12  0.12  0.17  0.12  0.12  0.11  0.21  0.17  0.15  0.21 #>      V2889 V2890 V2891 V2892 V2893 V2894 V2895 V2896 V2897 V2898 V2899 V2900 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13 #> sd    0.13  0.09  0.09  0.10  0.13  0.12  0.16  0.20  0.21  0.13  0.11  0.13 #>      V2901 V2902 V2903 V2904 V2905 V2906 V2907 V2908 V2909 V2910 V2911 V2912 #> mean  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.12  0.13  0.13  0.13  0.12 #> sd    0.15  0.11  0.14  0.14  0.24  0.11  0.10  0.16  0.11  0.12  0.11  0.08 #>      V2913 V2914 V2915 V2916 V2917 V2918 V2919 V2920 V2921 V2922 V2923 V2924 #> mean  0.13  0.12  0.12  0.12  0.13  0.13  0.12  0.12  0.13  0.12  0.12  0.13 #> sd    0.22  0.10  0.11  0.15  0.11  0.17  0.09  0.07  0.13  0.11  0.14  0.14 #>      V2925 V2926 V2927 V2928 V2929 V2930 V2931 V2932 V2933 V2934 V2935 V2936 #> mean  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.13 #> sd    0.14  0.14  0.15  0.15  0.18  0.14  0.11  0.12  0.06  0.21  0.19  0.12 #>      V2937 V2938 V2939 V2940 V2941 V2942 V2943 V2944 V2945 V2946 V2947 V2948 #> mean  0.12  0.12  0.12  0.12  0.13  0.13  0.13  0.13  0.12  0.13  0.12  0.12 #> sd    0.05  0.15  0.17  0.10  0.15  0.08  0.09  0.22  0.05  0.10  0.06  0.21 #>      V2949 V2950 V2951 V2952 V2953 V2954 V2955 V2956 V2957 V2958 V2959 V2960 #> mean  0.13  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.16  0.17  0.06  0.08  0.18  0.15  0.08  0.10  0.11  0.10  0.14  0.16 #>      V2961 V2962 V2963 V2964 V2965 V2966 V2967 V2968 V2969 V2970 V2971 V2972 #> mean  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.20  0.16  0.13  0.10  0.14  0.12  0.13  0.11  0.19  0.08  0.20  0.14 #>      V2973 V2974 V2975 V2976 V2977 V2978 V2979 V2980 V2981 V2982 V2983 V2984 #> mean  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.12  0.12  0.12 #> sd    0.12  0.12  0.12  0.09  0.18  0.15  0.11  0.12  0.12  0.14  0.15  0.13 #>      V2985 V2986 V2987 V2988 V2989 V2990 V2991 V2992 V2993 V2994 V2995 V2996 #> mean  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13 #> sd    0.12  0.24  0.15  0.17  0.15  0.19  0.13  0.16  0.14  0.13  0.14  0.10 #>      V2997 V2998 V2999 V3000 V3001 V3002 V3003 V3004 V3005 V3006 V3007 V3008 #> mean  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13 #> sd    0.19  0.09  0.17  0.09  0.16  0.14  0.11  0.13  0.24  0.11  0.14  0.08 #>      V3009 V3010 V3011 V3012 V3013 V3014 V3015 V3016 V3017 V3018 V3019 V3020 #> mean  0.12  0.12  0.12  0.13  0.12  0.13  0.12  0.13  0.12  0.12  0.13  0.13 #> sd    0.16  0.20  0.16  0.14  0.14  0.08  0.14  0.12  0.11  0.14  0.05  0.18 #>      V3021 V3022 V3023 V3024 V3025 V3026 V3027 V3028 V3029 V3030 V3031 V3032 #> mean  0.12  0.12  0.13  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12 #> sd    0.22  0.13  0.20  0.14  0.06  0.13  0.06  0.12  0.11  0.17  0.18  0.05 #>      V3033 V3034 V3035 V3036 V3037 V3038 V3039 V3040 V3041 V3042 V3043 V3044 #> mean  0.13  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.13 #> sd    0.06  0.15  0.08  0.11  0.13  0.17  0.13  0.18  0.16  0.16  0.17  0.14 #>      V3045 V3046 V3047 V3048 V3049 V3050 V3051 V3052 V3053 V3054 V3055 V3056 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12 #> sd    0.20  0.15  0.08  0.13  0.17  0.09  0.10  0.13  0.13  0.15  0.13  0.07 #>      V3057 V3058 V3059 V3060 V3061 V3062 V3063 V3064 V3065 V3066 V3067 V3068 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.07  0.16  0.09  0.11  0.17  0.14  0.11  0.06  0.16  0.03  0.08  0.11 #>      V3069 V3070 V3071 V3072 V3073 V3074 V3075 V3076 V3077 V3078 V3079 V3080 #> mean  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.13 #> sd    0.18  0.10  0.11  0.11  0.10  0.16  0.12  0.16  0.17  0.15  0.11  0.16 #>      V3081 V3082 V3083 V3084 V3085 V3086 V3087 V3088 V3089 V3090 V3091 V3092 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.13 #> sd    0.12  0.15  0.20  0.08  0.14  0.10  0.15  0.08  0.08  0.20  0.13  0.11 #>      V3093 V3094 V3095 V3096 V3097 V3098 V3099 V3100 V3101 V3102 V3103 V3104 #> mean  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.15  0.22  0.20  0.21  0.10  0.12  0.13  0.12  0.17  0.24  0.13  0.09 #>      V3105 V3106 V3107 V3108 V3109 V3110 V3111 V3112 V3113 V3114 V3115 V3116 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.13  0.12  0.13  0.12 #> sd    0.13  0.10  0.09  0.21  0.15  0.18  0.13  0.12  0.17  0.18  0.10  0.09 #>      V3117 V3118 V3119 V3120 V3121 V3122 V3123 V3124 V3125 V3126 V3127 V3128 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.12  0.12  0.12 #> sd    0.19  0.21  0.10  0.16  0.18  0.11  0.24  0.17  0.14  0.10  0.16  0.13 #>      V3129 V3130 V3131 V3132 V3133 V3134 V3135 V3136 V3137 V3138 V3139 V3140 #> mean  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.12  0.12 #> sd    0.18  0.19  0.25  0.26  0.10  0.20  0.11  0.17  0.12  0.21  0.12  0.14 #>      V3141 V3142 V3143 V3144 V3145 V3146 V3147 V3148 V3149 V3150 V3151 V3152 #> mean  0.13  0.13  0.12  0.13  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.07  0.10  0.24  0.19  0.13  0.14  0.11  0.09  0.12  0.12  0.12  0.10 #>      V3153 V3154 V3155 V3156 V3157 V3158 V3159 V3160 V3161 V3162 V3163 V3164 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.12 #> sd    0.16  0.09  0.15  0.15  0.18  0.14  0.17  0.20  0.11  0.24  0.15  0.17 #>      V3165 V3166 V3167 V3168 V3169 V3170 V3171 V3172 V3173 V3174 V3175 V3176 #> mean  0.12  0.13  0.12  0.13  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.12 #> sd    0.13  0.15  0.17  0.05  0.07  0.13  0.19  0.23  0.12  0.13  0.15  0.13 #>      V3177 V3178 V3179 V3180 V3181 V3182 V3183 V3184 V3185 V3186 V3187 V3188 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.12  0.12 #> sd    0.16  0.10  0.08  0.13  0.10  0.12  0.15  0.08  0.07  0.16  0.14  0.20 #>      V3189 V3190 V3191 V3192 V3193 V3194 V3195 V3196 V3197 V3198 V3199 V3200 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.13 #> sd    0.16  0.13  0.08  0.20  0.14  0.17  0.16  0.12  0.10  0.10  0.09  0.15 #>      V3201 V3202 V3203 V3204 V3205 V3206 V3207 V3208 V3209 V3210 V3211 V3212 #> mean  0.12  0.13  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12 #> sd    0.15  0.15  0.15  0.14  0.09  0.21  0.11  0.11  0.08  0.08  0.14  0.07 #>      V3213 V3214 V3215 V3216 V3217 V3218 V3219 V3220 V3221 V3222 V3223 V3224 #> mean  0.12  0.13  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.13  0.12 #> sd    0.09  0.13  0.14  0.19  0.09  0.15  0.16  0.19  0.12  0.10  0.12  0.13 #>      V3225 V3226 V3227 V3228 V3229 V3230 V3231 V3232 V3233 V3234 V3235 V3236 #> mean  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.26  0.20  0.10  0.23  0.14  0.09  0.22  0.16  0.15  0.13  0.15  0.14 #>      V3237 V3238 V3239 V3240 V3241 V3242 V3243 V3244 V3245 V3246 V3247 V3248 #> mean  0.12  0.12  0.12  0.13  0.12  0.13  0.13  0.12  0.12  0.12  0.13  0.13 #> sd    0.10  0.06  0.14  0.20  0.24  0.10  0.11  0.10  0.10  0.17  0.13  0.09 #>      V3249 V3250 V3251 V3252 V3253 V3254 V3255 V3256 V3257 V3258 V3259 V3260 #> mean  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12 #> sd    0.19  0.21  0.14  0.15  0.25  0.16  0.10  0.16  0.10  0.05  0.07  0.14 #>      V3261 V3262 V3263 V3264 V3265 V3266 V3267 V3268 V3269 V3270 V3271 V3272 #> mean  0.13  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.13  0.12  0.12 #> sd    0.14  0.17  0.15  0.19  0.17  0.12  0.15  0.13  0.15  0.13  0.11  0.17 #>      V3273 V3274 V3275 V3276 V3277 V3278 V3279 V3280 V3281 V3282 V3283 V3284 #> mean  0.12  0.12  0.13  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.05  0.14  0.11  0.14  0.14  0.18  0.10  0.13  0.14  0.13  0.13  0.11 #>      V3285 V3286 V3287 V3288 V3289 V3290 V3291 V3292 V3293 V3294 V3295 V3296 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.13 #> sd    0.13  0.15  0.16  0.18  0.09  0.13  0.13  0.18  0.11  0.17  0.14  0.10 #>      V3297 V3298 V3299 V3300 V3301 V3302 V3303 V3304 V3305 V3306 V3307 V3308 #> mean  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.12 #> sd    0.21  0.10  0.15  0.18  0.10  0.14  0.15  0.11  0.17  0.08  0.20  0.17 #>      V3309 V3310 V3311 V3312 V3313 V3314 V3315 V3316 V3317 V3318 V3319 V3320 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13 #> sd    0.13  0.10  0.08  0.14  0.14  0.13  0.18  0.17  0.11  0.12  0.15  0.09 #>      V3321 V3322 V3323 V3324 V3325 V3326 V3327 V3328 V3329 V3330 V3331 V3332 #> mean  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.19  0.14  0.11  0.10  0.15  0.21  0.24  0.09  0.16  0.16  0.11  0.07 #>      V3333 V3334 V3335 V3336 V3337 V3338 V3339 V3340 V3341 V3342 V3343 V3344 #> mean  0.12  0.12  0.13  0.12  0.13  0.12  0.12  0.13  0.12  0.12  0.13  0.12 #> sd    0.08  0.15  0.16  0.15  0.12  0.10  0.08  0.12  0.10  0.12  0.17  0.28 #>      V3345 V3346 V3347 V3348 V3349 V3350 V3351 V3352 V3353 V3354 V3355 V3356 #> mean  0.12  0.12  0.12  0.13  0.13  0.13  0.13  0.12  0.13  0.12  0.13  0.12 #> sd    0.09  0.15  0.18  0.14  0.16  0.03  0.16  0.15  0.17  0.20  0.13  0.16 #>      V3357 V3358 V3359 V3360 V3361 V3362 V3363 V3364 V3365 V3366 V3367 V3368 #> mean  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.13  0.12 #> sd    0.15  0.20  0.09  0.09  0.17  0.10  0.12  0.16  0.19  0.18  0.11  0.11 #>      V3369 V3370 V3371 V3372 V3373 V3374 V3375 V3376 V3377 V3378 V3379 V3380 #> mean  0.12  0.12  0.13  0.12  0.13  0.13  0.12  0.12  0.13  0.12  0.13  0.12 #> sd    0.18  0.08  0.14  0.16  0.13  0.09  0.09  0.15  0.12  0.14  0.16  0.13 #>      V3381 V3382 V3383 V3384 V3385 V3386 V3387 V3388 V3389 V3390 V3391 V3392 #> mean  0.12  0.13  0.12  0.13  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.12 #> sd    0.09  0.18  0.18  0.14  0.14  0.20  0.15  0.16  0.12  0.19  0.10  0.18 #>      V3393 V3394 V3395 V3396 V3397 V3398 V3399 V3400 V3401 V3402 V3403 V3404 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.13  0.12 #> sd    0.13  0.12  0.21  0.16  0.15  0.14  0.11  0.13  0.17  0.19  0.16  0.11 #>      V3405 V3406 V3407 V3408 V3409 V3410 V3411 V3412 V3413 V3414 V3415 V3416 #> mean  0.13  0.12  0.12  0.13  0.12  0.12  0.13  0.13  0.12  0.12  0.13  0.12 #> sd    0.06  0.13  0.11  0.18  0.19  0.16  0.10  0.10  0.08  0.12  0.16  0.22 #>      V3417 V3418 V3419 V3420 V3421 V3422 V3423 V3424 V3425 V3426 V3427 V3428 #> mean  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.12 #> sd    0.09  0.15  0.09  0.21  0.20  0.12  0.19  0.19  0.17  0.16  0.07  0.15 #>      V3429 V3430 V3431 V3432 V3433 V3434 V3435 V3436 V3437 V3438 V3439 V3440 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12 #> sd    0.10  0.14  0.10  0.17  0.09  0.14  0.16  0.15  0.14  0.07  0.13  0.10 #>      V3441 V3442 V3443 V3444 V3445 V3446 V3447 V3448 V3449 V3450 V3451 V3452 #> mean  0.12  0.12  0.12  0.13  0.13  0.12  0.12  0.12  0.13  0.12  0.13  0.12 #> sd    0.08  0.14  0.09  0.11  0.08  0.12  0.05  0.24  0.20  0.11  0.15  0.08 #>      V3453 V3454 V3455 V3456 V3457 V3458 V3459 V3460 V3461 V3462 V3463 V3464 #> mean  0.13  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.13 #> sd    0.09  0.13  0.21  0.13  0.13  0.10  0.16  0.22  0.14  0.16  0.13  0.13 #>      V3465 V3466 V3467 V3468 V3469 V3470 V3471 V3472 V3473 V3474 V3475 V3476 #> mean  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13 #> sd    0.25  0.15  0.12  0.08  0.14  0.12  0.24  0.17  0.10  0.10  0.15  0.08 #>      V3477 V3478 V3479 V3480 V3481 V3482 V3483 V3484 V3485 V3486 V3487 V3488 #> mean  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.10  0.25  0.14  0.10  0.10  0.09  0.08  0.17  0.15  0.10  0.11  0.15 #>      V3489 V3490 V3491 V3492 V3493 V3494 V3495 V3496 V3497 V3498 V3499 V3500 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.12  0.07  0.11  0.12  0.11  0.10  0.20  0.11  0.10  0.13  0.14  0.12 #>      V3501 V3502 V3503 V3504 V3505 V3506 V3507 V3508 V3509 V3510 V3511 V3512 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.08  0.14  0.08  0.12  0.10  0.20  0.09  0.15  0.10  0.11  0.20  0.14 #>      V3513 V3514 V3515 V3516 V3517 V3518 V3519 V3520 V3521 V3522 V3523 V3524 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.13  0.12 #> sd    0.13  0.11  0.14  0.11  0.11  0.20  0.08  0.07  0.12  0.02  0.19  0.14 #>      V3525 V3526 V3527 V3528 V3529 V3530 V3531 V3532 V3533 V3534 V3535 V3536 #> mean  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.13 #> sd    0.11  0.08  0.13  0.10  0.15  0.14  0.10  0.18  0.17  0.10  0.14  0.16 #>      V3537 V3538 V3539 V3540 V3541 V3542 V3543 V3544 V3545 V3546 V3547 V3548 #> mean  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.13  0.12  0.12 #> sd    0.21  0.20  0.16  0.09  0.18  0.20  0.22  0.18  0.12  0.08  0.13  0.11 #>      V3549 V3550 V3551 V3552 V3553 V3554 V3555 V3556 V3557 V3558 V3559 V3560 #> mean  0.12  0.13  0.12  0.12  0.13  0.12  0.12  0.12  0.13  0.12  0.13  0.12 #> sd    0.16  0.20  0.08  0.16  0.08  0.09  0.15  0.19  0.20  0.14  0.16  0.28 #>      V3561 V3562 V3563 V3564 V3565 V3566 V3567 V3568 V3569 V3570 V3571 V3572 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12 #> sd    0.15  0.08  0.13  0.04  0.16  0.16  0.23  0.18  0.14  0.14  0.05  0.22 #>      V3573 V3574 V3575 V3576 V3577 V3578 V3579 V3580 V3581 V3582 V3583 V3584 #> mean  0.13  0.13  0.13  0.12  0.13  0.13  0.13  0.12  0.12  0.12  0.12  0.13 #> sd    0.12  0.12  0.19  0.16  0.13  0.16  0.16  0.07  0.19  0.09  0.16  0.11 #>      V3585 V3586 V3587 V3588 V3589 V3590 V3591 V3592 V3593 V3594 V3595 V3596 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.13  0.13 #> sd    0.12  0.14  0.06  0.07  0.14  0.19  0.21  0.12  0.22  0.16  0.25  0.05 #>      V3597 V3598 V3599 V3600 V3601 V3602 V3603 V3604 V3605 V3606 V3607 V3608 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.13 #> sd    0.08  0.11  0.12  0.09  0.16  0.11  0.12  0.10  0.17  0.13  0.07  0.12 #>      V3609 V3610 V3611 V3612 V3613 V3614 V3615 V3616 V3617 V3618 V3619 V3620 #> mean  0.12  0.13  0.12  0.13  0.13  0.12  0.13  0.12  0.12  0.12  0.12  0.13 #> sd    0.13  0.05  0.16  0.18  0.17  0.09  0.08  0.17  0.09  0.11  0.12  0.16 #>      V3621 V3622 V3623 V3624 V3625 V3626 V3627 V3628 V3629 V3630 V3631 V3632 #> mean  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.13  0.13  0.12  0.12  0.12 #> sd    0.15  0.07  0.16  0.12  0.19  0.16  0.14  0.17  0.13  0.11  0.09  0.16 #>      V3633 V3634 V3635 V3636 V3637 V3638 V3639 V3640 V3641 V3642 V3643 V3644 #> mean  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.12 #> sd    0.25  0.21  0.13  0.13  0.13  0.21  0.21  0.09  0.16  0.15  0.10  0.09 #>      V3645 V3646 V3647 V3648 V3649 V3650 V3651 V3652 V3653 V3654 V3655 V3656 #> mean  0.13  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12 #> sd    0.10  0.10  0.16  0.25  0.12  0.11  0.12  0.09  0.19  0.17  0.12  0.09 #>      V3657 V3658 V3659 V3660 V3661 V3662 V3663 V3664 V3665 V3666 V3667 V3668 #> mean  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.13  0.16  0.04  0.12  0.14  0.12  0.18  0.19  0.20  0.09  0.10  0.17 #>      V3669 V3670 V3671 V3672 V3673 V3674 V3675 V3676 V3677 V3678 V3679 V3680 #> mean  0.12  0.12  0.12  0.13  0.13  0.13  0.12  0.12  0.13  0.13  0.12  0.12 #> sd    0.10  0.21  0.12  0.15  0.12  0.12  0.12  0.20  0.10  0.09  0.17  0.16 #>      V3681 V3682 V3683 V3684 V3685 V3686 V3687 V3688 V3689 V3690 V3691 V3692 #> mean  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12 #> sd    0.19  0.15  0.14  0.11  0.13  0.15  0.08  0.09  0.13  0.05  0.18  0.12 #>      V3693 V3694 V3695 V3696 V3697 V3698 V3699 V3700 V3701 V3702 V3703 V3704 #> mean  0.12  0.13  0.12  0.12  0.13  0.13  0.13  0.12  0.12  0.12  0.12  0.12 #> sd    0.15  0.16  0.10  0.10  0.17  0.17  0.12  0.12  0.13  0.15  0.06  0.19 #>      V3705 V3706 V3707 V3708 V3709 V3710 V3711 V3712 V3713 V3714 V3715 V3716 #> mean  0.12  0.13  0.13  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.13 #> sd    0.19  0.09  0.15  0.06  0.16  0.11  0.24  0.17  0.12  0.17  0.13  0.21 #>      V3717 V3718 V3719 V3720 V3721 V3722 V3723 V3724 V3725 V3726 V3727 V3728 #> mean  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12 #> sd    0.15  0.16  0.19  0.15  0.13  0.09  0.11  0.11  0.11  0.14  0.09  0.14 #>      V3729 V3730 V3731 V3732 V3733 V3734 V3735 V3736 V3737 V3738 V3739 V3740 #> mean  0.12  0.12  0.13  0.12  0.13  0.13  0.12  0.12  0.13  0.12  0.12  0.12 #> sd    0.12  0.12  0.07  0.08  0.15  0.15  0.16  0.13  0.09  0.17  0.13  0.07 #>      V3741 V3742 V3743 V3744 V3745 V3746 V3747 V3748 V3749 V3750 V3751 V3752 #> mean  0.12  0.13  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.15  0.15  0.14  0.12  0.10  0.13  0.11  0.14  0.19  0.10  0.10  0.18 #>      V3753 V3754 V3755 V3756 V3757 V3758 V3759 V3760 V3761 V3762 V3763 V3764 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12 #> sd    0.21  0.15  0.18  0.19  0.15  0.11  0.12  0.12  0.10  0.10  0.12  0.15 #>      V3765 V3766 V3767 V3768 V3769 V3770 V3771 V3772 V3773 V3774 V3775 V3776 #> mean  0.12  0.12  0.12  0.12  0.13  0.12  0.13  0.12  0.12  0.12  0.12  0.12 #> sd    0.21  0.07  0.17  0.15  0.06  0.25  0.15  0.17  0.13  0.06  0.15  0.06 #>      V3777 V3778 V3779 V3780 V3781 V3782 V3783 V3784 V3785 V3786 V3787 V3788 #> mean  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.13  0.12  0.13  0.12  0.12 #> sd    0.22  0.14  0.14  0.12  0.06  0.12  0.13  0.20  0.11  0.09  0.12  0.13 #>      V3789 V3790 V3791 V3792 V3793 V3794 V3795 V3796 V3797 V3798 V3799 V3800 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.12 #> sd    0.11  0.15  0.13  0.16  0.13  0.13  0.09  0.18  0.17  0.12  0.12  0.09 #>      V3801 V3802 V3803 V3804 V3805 V3806 V3807 V3808 V3809 V3810 V3811 V3812 #> mean  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.12  0.13  0.12  0.12 #> sd    0.12  0.09  0.17  0.18  0.06  0.20  0.11  0.09  0.14  0.22  0.17  0.18 #>      V3813 V3814 V3815 V3816 V3817 V3818 V3819 V3820 V3821 V3822 V3823 V3824 #> mean  0.13  0.12  0.13  0.13  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12 #> sd    0.13  0.07  0.13  0.15  0.20  0.08  0.13  0.19  0.12  0.20  0.08  0.18 #>      V3825 V3826 V3827 V3828 V3829 V3830 V3831 V3832 V3833 V3834 V3835 V3836 #> mean  0.12  0.13  0.13  0.13  0.13  0.12  0.12  0.12  0.12  0.13  0.12  0.12 #> sd    0.10  0.17  0.13  0.10  0.15  0.09  0.10  0.13  0.13  0.17  0.13  0.16 #>      V3837 V3838 V3839 V3840 V3841 V3842 V3843 V3844 V3845 V3846 V3847 V3848 #> mean  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12 #> sd    0.06  0.13  0.13  0.10  0.13  0.11  0.19  0.14  0.14  0.06  0.07  0.10 #>      V3849 V3850 V3851 V3852 V3853 V3854 V3855 V3856 V3857 V3858 V3859 V3860 #> mean  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.13 #> sd    0.07  0.19  0.12  0.13  0.17  0.18  0.26  0.14  0.11  0.19  0.14  0.09 #>      V3861 V3862 V3863 V3864 V3865 V3866 V3867 V3868 V3869 V3870 V3871 V3872 #> mean  0.13  0.12  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.13  0.13 #> sd    0.13  0.09  0.07  0.17  0.06  0.08  0.12  0.24  0.28  0.15  0.09  0.17 #>      V3873 V3874 V3875 V3876 V3877 V3878 V3879 V3880 V3881 V3882 V3883 V3884 #> mean  0.12  0.13  0.12  0.13  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.13 #> sd    0.13  0.15  0.23  0.16  0.18  0.10  0.13  0.13  0.13  0.11  0.08  0.12 #>      V3885 V3886 V3887 V3888 V3889 V3890 V3891 V3892 V3893 V3894 V3895 V3896 #> mean  0.13  0.12  0.13  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12 #> sd    0.12  0.07  0.03  0.17  0.07  0.17  0.17  0.11  0.09  0.09  0.11  0.10 #>      V3897 V3898 V3899 V3900 V3901 V3902 V3903 V3904 V3905 V3906 V3907 V3908 #> mean  0.12  0.13  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.13 #> sd    0.19  0.17  0.21  0.20  0.10  0.21  0.18  0.19  0.10  0.17  0.11  0.08 #>      V3909 V3910 V3911 V3912 V3913 V3914 V3915 V3916 V3917 V3918 V3919 V3920 #> mean  0.12  0.13  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.13  0.12  0.12 #> sd    0.17  0.02  0.12  0.10  0.21  0.20  0.13  0.07  0.09  0.09  0.13  0.11 #>      V3921 V3922 V3923 V3924 V3925 V3926 V3927 V3928 V3929 V3930 V3931 V3932 #> mean  0.12  0.13  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12 #> sd    0.12  0.09  0.08  0.16  0.11  0.08  0.19  0.15  0.07  0.16  0.13  0.21 #>      V3933 V3934 V3935 V3936 V3937 V3938 V3939 V3940 V3941 V3942 V3943 V3944 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.13  0.12  0.12  0.13 #> sd    0.03  0.11  0.14  0.10  0.08  0.14  0.11  0.11  0.14  0.17  0.19  0.14 #>      V3945 V3946 V3947 V3948 V3949 V3950 V3951 V3952 V3953 V3954 V3955 V3956 #> mean  0.13  0.13  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.12 #> sd    0.17  0.13  0.08  0.12  0.25  0.15  0.06  0.12  0.18  0.19  0.08  0.16 #>      V3957 V3958 V3959 V3960 V3961 V3962 V3963 V3964 V3965 V3966 V3967 V3968 #> mean  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  0.12  0.12 #> sd    0.16  0.11  0.24  0.06  0.13  0.13  0.13  0.08  0.17  0.21  0.18  0.11 #>      V3969 V3970 V3971 V3972 V3973 V3974 V3975 V3976 V3977 V3978 V3979 V3980 #> mean  0.13  0.12  0.12  0.13  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12 #> sd    0.12  0.17  0.19  0.14  0.19  0.13  0.10  0.15  0.10  0.02  0.09  0.15 #>      V3981 V3982 V3983 V3984 V3985 V3986 V3987 V3988 V3989 V3990 V3991 V3992 #> mean  0.12  0.12  0.13  0.12  0.12  0.12  0.12  0.13  0.12  0.12  0.12  0.12 #> sd    0.16  0.14  0.15  0.14  0.16  0.17  0.14  0.13  0.18  0.06  0.12  0.08 #>      V3993 V3994 V3995 V3996 V3997 V3998 V3999 V4000 #> mean  0.12  0.12  0.12  0.12  0.12  0.13  0.13  0.13 #> sd    0.06  0.20  0.11  0.11  0.12  0.10  0.09  0.07 grab(model, object = \"type_posterior\") #> Posterior draws of causal types (transformed parameters) #> Dimensions: 4000 rows (draws) by 8 cols (types)        mean    sd #> X0.Y00 0.127 0.135 #> X1.Y00 0.126 0.134 #> X0.Y10 0.120 0.129 #> X1.Y10 0.128 0.138 #> X0.Y01 0.123 0.132 #> X1.Y01 0.126 0.136 #> X0.Y11 0.126 0.136 #> X1.Y11 0.125 0.134 # Example of arguments passed on to helpers grab(model, object = \"event_probabilities\", parameters = c(.6, .4, .1, .1, .7, .1)) #>      event_probs #> X0Y0        0.48 #> X1Y0        0.08 #> X0Y1        0.12 #> X1Y1        0.32  # }"},{"path":"/reference/gsub_many.html","id":null,"dir":"Reference","previous_headings":"","what":"Recursive substitution — gsub_many","title":"Recursive substitution — gsub_many","text":"Applies gsub() multiple patterns multiple replacements 1:1 mapping.","code":""},{"path":"/reference/gsub_many.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recursive substitution — gsub_many","text":"","code":"gsub_many(x, pattern_vector, replacement_vector, ...)"},{"path":"/reference/gsub_many.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recursive substitution — gsub_many","text":"x character vector. pattern_vector character vector. replacement_vector character vector. ... Options passed onto gsub() call.","code":""},{"path":"/reference/gsub_many.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Recursive substitution — gsub_many","text":"Returns multiple expression substituted elements","code":""},{"path":"/reference/increasing.html","id":null,"dir":"Reference","previous_headings":"","what":"Make monotonicity statement (positive) — increasing","title":"Make monotonicity statement (positive) — increasing","text":"Generate statement Y monotonic (increasing) X","code":""},{"path":"/reference/increasing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make monotonicity statement (positive) — increasing","text":"","code":"increasing(X, Y)"},{"path":"/reference/increasing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make monotonicity statement (positive) — increasing","text":"X character. quoted name input node Y character. quoted name outcome node","code":""},{"path":"/reference/increasing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make monotonicity statement (positive) — increasing","text":"character statement class statement","code":""},{"path":[]},{"path":"/reference/increasing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make monotonicity statement (positive) — increasing","text":"","code":"# \\donttest{ increasing('A', 'B') #>  #> Statement:  #> (B[A=1] > B[A=0]) # }"},{"path":"/reference/institutions_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Institutions and growth: Data for replication of analysis in\r\n*Integrated Inferences* — institutions_data","title":"Institutions and growth: Data for replication of analysis in\r\n*Integrated Inferences* — institutions_data","text":" dataset containing dichotomized versions variables Rodrik, Subramanian, Trebbi (2004).","code":""},{"path":"/reference/institutions_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Institutions and growth: Data for replication of analysis in\r\n*Integrated Inferences* — institutions_data","text":"","code":"institutions_data"},{"path":"/reference/institutions_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Institutions and growth: Data for replication of analysis in\r\n*Integrated Inferences* — institutions_data","text":"data frame 79 rows 5 columns: Y Income (GDP PPP 1995), dichotomized R Institutions, (based  Kaufmann, Kraay, Zoido-Lobaton (2002)) dichotomized D Distance equator (degrees), dichotomized M Settler mortality (Acemoglu, Johnson, Robinson), dichotomized country Country","code":""},{"path":"/reference/institutions_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Institutions and growth: Data for replication of analysis in\r\n*Integrated Inferences* — institutions_data","text":"https://drodrik.scholar.harvard.edu/publications/institutions-rule-primacy-institutions--geography--integration","code":""},{"path":"/reference/interacts.html","id":null,"dir":"Reference","previous_headings":"","what":"Make statement for any interaction — interacts","title":"Make statement for any interaction — interacts","text":"Generate statement X1, X1 interact production Y","code":""},{"path":"/reference/interacts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make statement for any interaction — interacts","text":"","code":"interacts(X1, X2, Y)"},{"path":"/reference/interacts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make statement for any interaction — interacts","text":"X1 character. quoted name input node 1. X2 character. quoted name input node 2. Y character. quoted name outcome node.","code":""},{"path":"/reference/interacts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make statement for any interaction — interacts","text":"character statement class statement","code":""},{"path":[]},{"path":"/reference/interacts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make statement for any interaction — interacts","text":"","code":"# \\donttest{ interacts('A', 'B', 'W') #>  #> Statement:  #> ((W[A =1, B = 1]) - (W[A = 0, B = 1])) != ((W[A =1, B = 0]) - (W[A = 0, B = 0])) get_query_types(model = make_model('X-> Y <- W'),          query = interacts('X', 'W', 'Y'), map = \"causal_type\") #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  ((Y[X=1,W=1])-(Y[X=0,W=1]))!=((Y[X=1,W=0])-(Y[X=0,W=0]))  #>  #> W0.X0.Y1000  W1.X0.Y1000 #> W0.X1.Y1000  W1.X1.Y1000 #> W0.X0.Y0100  W1.X0.Y0100 #> W0.X1.Y0100  W1.X1.Y0100 #> W0.X0.Y0010  W1.X0.Y0010 #> W0.X1.Y0010  W1.X1.Y0010 #> W0.X0.Y0110  W1.X0.Y0110 #> W0.X1.Y0110  W1.X1.Y0110 #> W0.X0.Y1110  W1.X0.Y1110 #> W0.X1.Y1110  W1.X1.Y1110 #> W0.X0.Y0001  W1.X0.Y0001 #> W0.X1.Y0001  W1.X1.Y0001 #> W0.X0.Y1001  W1.X0.Y1001 #> W0.X1.Y1001  W1.X1.Y1001 #> W0.X0.Y1101  W1.X0.Y1101 #> W0.X1.Y1101  W1.X1.Y1101 #> W0.X0.Y1011  W1.X0.Y1011 #> W0.X1.Y1011  W1.X1.Y1011 #> W0.X0.Y0111  W1.X0.Y0111 #> W0.X1.Y0111  W1.X1.Y0111 #>  #>  #>  Number of causal types that meet condition(s) =  40 #>  Total number of causal types in model =  64 # }"},{"path":"/reference/interpret_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Interpret or find position in nodal type — interpret_type","title":"Interpret or find position in nodal type — interpret_type","text":"Interprets position one digits (specified position) nodal type. Alternatively returns nodal type digit positions correspond one given condition.","code":""},{"path":"/reference/interpret_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interpret or find position in nodal type — interpret_type","text":"","code":"interpret_type(model, condition = NULL, position = NULL)"},{"path":"/reference/interpret_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interpret or find position in nodal type — interpret_type","text":"model causal_model. model object generated make_model. condition vector characters. Strings specifying child node, followed '|' (given) values parent nodes model. position named list integers. name name child node model, value vector digit positions node's nodal type interpreted. See `Details`.","code":""},{"path":"/reference/interpret_type.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interpret or find position in nodal type — interpret_type","text":"named list interpretation positions   digits nodal type","code":""},{"path":"/reference/interpret_type.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Interpret or find position in nodal type — interpret_type","text":"node child node X k parents nodal type   represented X followed 2^k digits. Argument position   allows user interpret meaning one digit positions   nodal type. example position = list(X = 1:3) return   interpretation first three digits causal types X.   Argument condition allows users query digit position   nodal type providing instead values parent nodes given   child. example, condition = 'X | Z=0 & R=1' returns digit   position corresponds values X takes Z = 0 R = 1.","code":""},{"path":"/reference/interpret_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interpret or find position in nodal type — interpret_type","text":"","code":"model <- make_model('R -> X; Z -> X; X -> Y') #Example using digit position interpret_type(model, position = list(X = c(3,4), Y = 1)) #> $X #>   node position display    interpretation #> 1    X        3 X**[*]* X | R = 0 & Z = 1 #> 2    X        4 X***[*] X | R = 1 & Z = 1 #>  #> $Y #>   node position display interpretation #> 1    Y        1   Y[*]*      Y | X = 0 #>  #Example using condition interpret_type(model, condition = c('X | Z=0 & R=1', 'X | Z=0 & R=0')) #> $X #>   node position display    interpretation #> 1    X        1 X[*]*** X | R = 0 & Z = 0 #> 2    X        2 X*[*]** X | R = 1 & Z = 0 #>  #Return interpretation of all digit positions of all nodes interpret_type(model) #> $R #>   node position display interpretation #> 1    R       NA      R0          R = 0 #> 2    R       NA      R1          R = 1 #>  #> $Z #>   node position display interpretation #> 1    Z       NA      Z0          Z = 0 #> 2    Z       NA      Z1          Z = 1 #>  #> $X #>   node position display    interpretation #> 1    X        1 X[*]*** X | R = 0 & Z = 0 #> 2    X        2 X*[*]** X | R = 1 & Z = 0 #> 3    X        3 X**[*]* X | R = 0 & Z = 1 #> 4    X        4 X***[*] X | R = 1 & Z = 1 #>  #> $Y #>   node position display interpretation #> 1    Y        1   Y[*]*      Y | X = 0 #> 2    Y        2   Y*[*]      Y | X = 1 #>"},{"path":"/reference/is_a_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Check whether argument is a model — is_a_model","title":"Check whether argument is a model — is_a_model","text":"Check whether argument model","code":""},{"path":"/reference/is_a_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check whether argument is a model — is_a_model","text":"","code":"is_a_model(model)"},{"path":"/reference/is_a_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check whether argument is a model — is_a_model","text":"model causal_model. model object generated make_model.","code":""},{"path":"/reference/is_a_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check whether argument is a model — is_a_model","text":"error message argument model.","code":""},{"path":"/reference/lipids_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Lipids: Data for Chickering and Pearl replication — lipids_data","title":"Lipids: Data for Chickering and Pearl replication — lipids_data","text":"compact dataset containing information encouragement, (Z, cholestyramine prescription), treatment (X, usage), outcome (Y, cholesterol). David Maxwell Chickering Judea Pearl: \"Clinician’s Tool Analyzing Non-compliance\", AAAI-96 Proceedings. Chickering Pearl turn draw data Efron, Bradley, David Feldman. \"Compliance explanatory variable clinical trials.\" Journal American Statistical Association 86.413 (1991): 9-17.","code":""},{"path":"/reference/lipids_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lipids: Data for Chickering and Pearl replication — lipids_data","text":"","code":"lipids_data"},{"path":"/reference/lipids_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Lipids: Data for Chickering and Pearl replication — lipids_data","text":"data frame 8 rows 3 columns: event data type strategy nodes data available count Number units data type","code":""},{"path":"/reference/lipids_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Lipids: Data for Chickering and Pearl replication — lipids_data","text":"https://cdn.aaai.org/AAAI/1996/AAAI96-188.pdf","code":""},{"path":"/reference/list_non_parents.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns a list with the nodes that are not directly pointing into a node — list_non_parents","title":"Returns a list with the nodes that are not directly pointing into a node — list_non_parents","text":"Returns list nodes directly pointing node","code":""},{"path":"/reference/list_non_parents.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns a list with the nodes that are not directly pointing into a node — list_non_parents","text":"","code":"list_non_parents(model, node)"},{"path":"/reference/list_non_parents.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns a list with the nodes that are not directly pointing into a node — list_non_parents","text":"model causal_model. model object generated make_model. node character string. quoted name node.","code":""},{"path":"/reference/list_non_parents.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns a list with the nodes that are not directly pointing into a node — list_non_parents","text":"Returns list nodes directly  pointing node","code":""},{"path":"/reference/make_ambiguities_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Make ambiguities matrix — make_ambiguities_matrix","title":"Make ambiguities matrix — make_ambiguities_matrix","text":"Make ambiguities matrix. ambiguities matrix maps causal types data types.","code":""},{"path":"/reference/make_ambiguities_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make ambiguities matrix — make_ambiguities_matrix","text":"","code":"make_ambiguities_matrix(model)"},{"path":"/reference/make_ambiguities_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make ambiguities matrix — make_ambiguities_matrix","text":"model causal_model. model object generated make_model.","code":""},{"path":"/reference/make_ambiguities_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make ambiguities matrix — make_ambiguities_matrix","text":"data.frame. Types (rows) corresponding possible   data realizations (columns).","code":""},{"path":"/reference/make_ambiguities_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make ambiguities matrix — make_ambiguities_matrix","text":"","code":"model <- make_model('X -> Y') CausalQueries:::make_ambiguities_matrix(model = model) #>       X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y00    1    0    0    0 #> X1Y00    0    1    0    0 #> X0Y10    0    0    1    0 #> X1Y10    0    1    0    0 #> X0Y01    1    0    0    0 #> X1Y01    0    0    0    1 #> X0Y11    0    0    1    0 #> X1Y11    0    0    0    1"},{"path":"/reference/make_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Make data — make_data","title":"Make data — make_data","text":"Make data","code":""},{"path":"/reference/make_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make data — make_data","text":"","code":"make_data(   model,   n = NULL,   parameters = NULL,   param_type = NULL,   nodes = NULL,   n_steps = NULL,   probs = NULL,   subsets = TRUE,   complete_data = NULL,   given = NULL,   verbose = TRUE,   ... )"},{"path":"/reference/make_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make data — make_data","text":"model causal_model. model object generated make_model. n Non negative integer. Number observations. provided inferred  largest n_step. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn model$parameters_df. param_type character. String specifying type parameters make (\"flat\", \"prior_mean\", \"posterior_mean\", \"prior_draw\", \"posterior_draw\", \"define\"). param_type set define use arguments passed make_priors; otherwise flat sets equal probabilities nodal type parameter set; prior_mean, prior_draw, posterior_mean, posterior_draw take parameters means draws prior posterior. nodes list. nodes observed step. NULL nodes observed. n_steps list. Number observations observed step probs list. Observation probabilities step subsets list. Strata within observations observed step. TRUE , otherwise expression evaluates logical condition. complete_data data.frame. Dataset complete observations. Optional. given string specifying known values nodes, e.g. \"X==1 & Y==1\" verbose Logical. TRUE prints step schedule. ... additional arguments can passed link{make_parameters}","code":""},{"path":"/reference/make_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make data — make_data","text":"data.frame simulated data.","code":""},{"path":"/reference/make_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make data — make_data","text":"Note default behavior take account whether node already observed determining whether select . One can however specifically request observation nodes previously observed.","code":""},{"path":"/reference/make_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make data — make_data","text":"","code":"# Simple draws model <- make_model(\"X -> M -> Y\") make_data(model) #>   X M Y #> 1 0 1 0 make_data(model, n = 3, nodes = c(\"X\",\"Y\")) #> # A tibble: 1 × 5 #>   node_names nodes     n_steps probs subsets #>   <chr>      <list>      <dbl> <dbl> <lgl>   #> 1 X, Y       <chr [2]>       3     1 TRUE    #>   X  M Y #> 1 0 NA 0 #> 2 0 NA 1 #> 3 1 NA 0 make_data(model, n = 3, param_type = \"prior_draw\") #>   X M Y #> 1 0 0 0 #> 2 1 1 1 #> 3 1 1 1 make_data(model, n = 10, param_type = \"define\", parameters =  0:9) #>    X M Y #> 1  1 0 0 #> 2  1 0 1 #> 3  1 0 1 #> 4  1 1 0 #> 5  1 1 0 #> 6  1 1 0 #> 7  1 1 1 #> 8  1 1 1 #> 9  1 1 1 #> 10 1 1 1  # Data Strategies # A strategy in which X, Y are observed for sure and M is observed # with 50% probability for X=1, Y=0 cases  model <- make_model(\"X -> M -> Y\") make_data(   model,   n = 8,   nodes = list(c(\"X\", \"Y\"), \"M\"),   probs = list(1, .5),   subsets = list(TRUE, \"X==1 & Y==0\")) #> # A tibble: 2 × 5 #>   node_names nodes     n_steps probs subsets     #>   <chr>      <list>    <lgl>   <dbl> <chr>       #> 1 X, Y       <chr [2]> NA        1   TRUE        #> 2 M          <chr [1]> NA        0.5 X==1 & Y==0 #> Empty subset #>   X  M Y #> 1 0 NA 1 #> 2 0 NA 0 #> 3 0 NA 0 #> 4 0 NA 1 #> 5 0 NA 1 #> 6 1 NA 1 #> 7 1 NA 1 #> 8 1 NA 1  # n not provided but inferred from largest n_step (not from sum of n_steps) make_data(   model,   nodes = list(c(\"X\", \"Y\"), \"M\"),   n_steps = list(5, 2)) #> # A tibble: 2 × 5 #>   node_names nodes     n_steps probs subsets #>   <chr>      <list>      <dbl> <dbl> <lgl>   #> 1 X, Y       <chr [2]>       5     1 TRUE    #> 2 M          <chr [1]>       2     1 TRUE    #>   X  M Y #> 1 0 NA 0 #> 2 0 NA 1 #> 3 1  0 0 #> 4 1 NA 0 #> 5 1  1 1  # Wide then deep   make_data(   model,   n = 8,   nodes = list(c(\"X\", \"Y\"), \"M\"),   subsets = list(TRUE, \"!is.na(X) & !is.na(Y)\"),   n_steps = list(6, 2)) #> # A tibble: 2 × 5 #>   node_names nodes     n_steps probs subsets               #>   <chr>      <list>      <dbl> <dbl> <chr>                 #> 1 X, Y       <chr [2]>       6     1 TRUE                  #> 2 M          <chr [1]>       2     1 !is.na(X) & !is.na(Y) #>    X  M  Y #> 1 NA NA NA #> 2  0 NA  1 #> 3  1 NA  0 #> 4 NA NA NA #> 5  1  0  1 #> 6  1  1  0 #> 7  1 NA  1 #> 8  1 NA  1   make_data(   model,   n = 8,   nodes = list(c(\"X\", \"Y\"), c(\"X\", \"M\")),   subsets = list(TRUE, \"is.na(X)\"),   n_steps = list(3, 2)) #> # A tibble: 2 × 5 #>   node_names nodes     n_steps probs subsets  #>   <chr>      <list>      <dbl> <dbl> <chr>    #> 1 X, Y       <chr [2]>       3     1 TRUE     #> 2 X, M       <chr [2]>       2     1 is.na(X) #>    X  M  Y #> 1  0 NA  0 #> 2 NA NA NA #> 3 NA NA NA #> 4  1  0 NA #> 5 NA NA NA #> 6  1 NA  0 #> 7  1  1 NA #> 8  1 NA  1  # Example with probabilities at each step  make_data(   model,   n = 8,   nodes = list(c(\"X\", \"Y\"), c(\"X\", \"M\")),   subsets = list(TRUE, \"is.na(X)\"),   probs = list(.5, .2)) #> # A tibble: 2 × 5 #>   node_names nodes     n_steps probs subsets  #>   <chr>      <list>    <lgl>   <dbl> <chr>    #> 1 X, Y       <chr [2]> NA        0.5 TRUE     #> 2 X, M       <chr [2]> NA        0.2 is.na(X) #>    X  M  Y #> 1  0 NA  0 #> 2  0  0 NA #> 3  0 NA  0 #> 4  0 NA  0 #> 5 NA NA NA #> 6  1 NA  0 #> 7 NA NA NA #> 8 NA NA NA  # Example with given data make_data(model, given = \"X==1 & Y==1\", n = 5) #>   X M Y #> 1 1 0 1 #> 2 1 0 1 #> 3 1 1 1 #> 4 1 1 1 #> 5 1 1 1"},{"path":"/reference/make_data_single.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate full dataset — make_data_single","title":"Generate full dataset — make_data_single","text":"Generate full dataset","code":""},{"path":"/reference/make_data_single.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate full dataset — make_data_single","text":"","code":"make_data_single(   model,   n = 1,   parameters = NULL,   param_type = NULL,   given = NULL,   w = NULL,   P = NULL,   A = NULL )"},{"path":"/reference/make_data_single.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate full dataset — make_data_single","text":"model causal_model. model object generated make_model. n integer. Number observations. parameters numeric vector. Values parameters may specified. default, parameters drawn priors. param_type character. String specifying type parameters make (\"flat\", \"prior_mean\", \"posterior_mean\", \"prior_draw\", \"posterior_draw\", \"define). param_type set define use arguments passed make_priors; otherwise flat sets equal probabilities nodal type parameter set; prior_mean, prior_draw, posterior_mean, posterior_draw take parameters means draws prior posterior. given string specifying known values nodes, e.g. \"X==1 & Y==1\" w Vector event probabilities can provided directly. useful speed repeated data draws. P matrix. Parameter matrix can used generate w w provided matrix. Ambiguity matrix can used generate w w provided","code":""},{"path":"/reference/make_data_single.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate full dataset — make_data_single","text":"data.frame simulated data.","code":""},{"path":"/reference/make_data_single.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate full dataset — make_data_single","text":"","code":"model <- make_model(\"X -> Y\")  # Simplest behavior uses by default the parameter vector contained in model CausalQueries:::make_data_single(model, n = 5) #>   X Y #> 1 0 0 #> 2 0 0 #> 3 0 1 #> 4 1 0 #> 5 1 1  CausalQueries:::make_data_single(model, n = 5, param_type = \"prior_draw\") #>   X Y #> 1 0 0 #> 2 0 0 #> 3 1 0 #> 4 1 1 #> 5 1 1  # Simulate multiple datasets. This is fastest if # event probabilities (w) are  provided w <- get_event_probabilities(model) replicate(5, CausalQueries:::make_data_single(model, n = 5, w = w)) #>   [,1]      [,2]      [,3]      [,4]      [,5]      #> X numeric,5 numeric,5 numeric,5 numeric,5 numeric,5 #> Y numeric,5 numeric,5 numeric,5 numeric,5 numeric,5"},{"path":"/reference/make_events.html","id":null,"dir":"Reference","previous_headings":"","what":"Make data in compact form — make_events","title":"Make data in compact form — make_events","text":"Draw n events given event probabilities. Draws full data . incomplete data see make_data.","code":""},{"path":"/reference/make_events.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make data in compact form — make_events","text":"","code":"make_events(   model,   n = 1,   w = NULL,   P = NULL,   A = NULL,   parameters = NULL,   param_type = NULL,   include_strategy = FALSE,   ... )"},{"path":"/reference/make_events.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make data in compact form — make_events","text":"model causal_model. model object generated make_model. n integer. Number observations. w numeric matrix. `n_parameters x 1` matrix event probabilities named rows. P data.frame. Parameter matrix. required may provided avoid repeated computation simulations. data.frame. Ambiguity matrix. required may provided avoid repeated computation simulations. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn model$parameters_df. param_type character. String specifying type parameters make 'flat', 'prior_mean', 'posterior_mean', 'prior_draw', 'posterior_draw', 'define. param_type set define use arguments passed make_priors; otherwise flat sets equal probabilities nodal type parameter set; prior_mean, prior_draw, posterior_mean, posterior_draw take parameters means draws prior posterior. include_strategy Logical. Whether include 'strategy' vector. Defaults FALSE. Strategy vector vary full data expected functions. ... Arguments passed make_priors param_type == define","code":""},{"path":"/reference/make_events.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make data in compact form — make_events","text":"data.frame events","code":""},{"path":"/reference/make_events.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make data in compact form — make_events","text":"","code":"# \\donttest{ model <- make_model('X -> Y') make_events(model = model) #>   event count #> 1  X0Y0     0 #> 2  X1Y0     1 #> 3  X0Y1     0 #> 4  X1Y1     0 make_events(model = model, param_type = 'prior_draw') #>   event count #> 1  X0Y0     0 #> 2  X1Y0     0 #> 3  X0Y1     0 #> 4  X1Y1     1 make_events(model = model, include_strategy = TRUE) #>   event strategy count #> 1  X0Y0       XY     0 #> 2  X1Y0       XY     0 #> 3  X0Y1       XY     1 #> 4  X1Y1       XY     0 # }"},{"path":"/reference/make_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a model — make_model","title":"Make a model — make_model","text":"make_model uses dagitty syntax functionality specify nodes edges graph. Implied causal types calculated default priors provided assumption confounding. Models can updated specification parameter matrix, P, providing restrictions causal types, /providing informative priors parameters. default setting causal model flat (uniform) priors parameters putting equal weight parameter within parameter set. can adjust set_priors set_parameters","code":""},{"path":"/reference/make_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a model — make_model","text":"","code":"make_model(statement, add_causal_types = TRUE, nodal_types = NULL)"},{"path":"/reference/make_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make a model — make_model","text":"statement character. Statement describing causal relations using dagitty syntax. directed relations permitted. instance \"X -> Y\"  \"X1 -> Y <- X2; X1 -> X2\". add_causal_types Logical. Whether create attach causal types model. Defaults `TRUE`. nodal_types List nodal types associated model nodes","code":""},{"path":"/reference/make_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make a model — make_model","text":"object class causal_model. object class \"causal_model\" list containing least following components: statement character vector statement defines model dag data.frame columns `parent``children`   indicating nodes relate . nodes named list nodes model parents_df data.frame listing nodes, whether   root nodes , number parents nodal_types Optional: named list nodal types   model. List ordered according causal ordering   nodes. NULL nodal types generated. FALSE, parameters data   frame generated. parameters_df data.frame descriptive information   parameters model causal_types data.frame listing causal types   nodal types produce ","code":""},{"path":[]},{"path":"/reference/make_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make a model — make_model","text":"","code":"make_model(statement = \"X -> Y\") #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>  modelXKY <- make_model(\"X -> K -> Y; X -> Y\")  # Example where cyclicaly dag attempted if (FALSE) {  modelXKX <- make_model(\"X -> K -> X\") }  # Examples with confounding model <- make_model(\"X->Y; X <-> Y\") model$P #>  #> Rows are parameters, grouped in parameter sets #>  #> Columns are causal types #>  #> Cell entries indicate whether a parameter probability isused #> in the calculation of causal type probability #>  #>          X0.Y00 X1.Y00 X0.Y10 X1.Y10 X0.Y01 X1.Y01 X0.Y11 X1.Y11 #> X.0           1      0      1      0      1      0      1      0 #> X.1           0      1      0      1      0      1      0      1 #> Y.00_X.0      1      0      0      0      0      0      0      0 #> Y.10_X.0      0      0      1      0      0      0      0      0 #> Y.01_X.0      0      0      0      0      1      0      0      0 #> Y.11_X.0      0      0      0      0      0      0      1      0 #> Y.00_X.1      0      1      0      0      0      0      0      0 #> Y.10_X.1      0      0      0      1      0      0      0      0 #> Y.01_X.1      0      0      0      0      0      1      0      0 #> Y.11_X.1      0      0      0      0      0      0      0      1 #>  #>   #>  param_set  (P) #>  X  Y.X.0  Y.X.1 model <- make_model(\"Y2 <- X -> Y1; X <-> Y1; X <-> Y2\") dim(model$P) #> [1] 18 32 model$P #>  #> Rows are parameters, grouped in parameter sets #>  #> Columns are causal types #>  #> Cell entries indicate whether a parameter probability isused #> in the calculation of causal type probability #>  #>           X0.Y100.Y200 X1.Y100.Y200 X0.Y110.Y200 X1.Y110.Y200 X0.Y101.Y200 #> X.0                  1            0            1            0            1 #> X.1                  0            1            0            1            0 #> Y1.00_X.0            1            0            0            0            0 #> Y1.10_X.0            0            0            1            0            0 #> Y1.01_X.0            0            0            0            0            1 #> Y1.11_X.0            0            0            0            0            0 #> Y1.00_X.1            0            1            0            0            0 #> Y1.10_X.1            0            0            0            1            0 #> Y1.01_X.1            0            0            0            0            0 #> Y1.11_X.1            0            0            0            0            0 #> Y2.00_X.0            1            0            1            0            1 #> Y2.10_X.0            0            0            0            0            0 #> Y2.01_X.0            0            0            0            0            0 #> Y2.11_X.0            0            0            0            0            0 #> Y2.00_X.1            0            1            0            1            0 #> Y2.10_X.1            0            0            0            0            0 #> Y2.01_X.1            0            0            0            0            0 #> Y2.11_X.1            0            0            0            0            0 #>           X1.Y101.Y200 X0.Y111.Y200 X1.Y111.Y200 X0.Y100.Y210 X1.Y100.Y210 #> X.0                  0            1            0            1            0 #> X.1                  1            0            1            0            1 #> Y1.00_X.0            0            0            0            1            0 #> Y1.10_X.0            0            0            0            0            0 #> Y1.01_X.0            0            0            0            0            0 #> Y1.11_X.0            0            1            0            0            0 #> Y1.00_X.1            0            0            0            0            1 #> Y1.10_X.1            0            0            0            0            0 #> Y1.01_X.1            1            0            0            0            0 #> Y1.11_X.1            0            0            1            0            0 #> Y2.00_X.0            0            1            0            0            0 #> Y2.10_X.0            0            0            0            1            0 #> Y2.01_X.0            0            0            0            0            0 #> Y2.11_X.0            0            0            0            0            0 #> Y2.00_X.1            1            0            1            0            0 #> Y2.10_X.1            0            0            0            0            1 #> Y2.01_X.1            0            0            0            0            0 #> Y2.11_X.1            0            0            0            0            0 #>           X0.Y110.Y210 X1.Y110.Y210 X0.Y101.Y210 X1.Y101.Y210 X0.Y111.Y210 #> X.0                  1            0            1            0            1 #> X.1                  0            1            0            1            0 #> Y1.00_X.0            0            0            0            0            0 #> Y1.10_X.0            1            0            0            0            0 #> Y1.01_X.0            0            0            1            0            0 #> Y1.11_X.0            0            0            0            0            1 #> Y1.00_X.1            0            0            0            0            0 #> Y1.10_X.1            0            1            0            0            0 #> Y1.01_X.1            0            0            0            1            0 #> Y1.11_X.1            0            0            0            0            0 #> Y2.00_X.0            0            0            0            0            0 #> Y2.10_X.0            1            0            1            0            1 #> Y2.01_X.0            0            0            0            0            0 #> Y2.11_X.0            0            0            0            0            0 #> Y2.00_X.1            0            0            0            0            0 #> Y2.10_X.1            0            1            0            1            0 #> Y2.01_X.1            0            0            0            0            0 #> Y2.11_X.1            0            0            0            0            0 #>           X1.Y111.Y210 X0.Y100.Y201 X1.Y100.Y201 X0.Y110.Y201 X1.Y110.Y201 #> X.0                  0            1            0            1            0 #> X.1                  1            0            1            0            1 #> Y1.00_X.0            0            1            0            0            0 #> Y1.10_X.0            0            0            0            1            0 #> Y1.01_X.0            0            0            0            0            0 #> Y1.11_X.0            0            0            0            0            0 #> Y1.00_X.1            0            0            1            0            0 #> Y1.10_X.1            0            0            0            0            1 #> Y1.01_X.1            0            0            0            0            0 #> Y1.11_X.1            1            0            0            0            0 #> Y2.00_X.0            0            0            0            0            0 #> Y2.10_X.0            0            0            0            0            0 #> Y2.01_X.0            0            1            0            1            0 #> Y2.11_X.0            0            0            0            0            0 #> Y2.00_X.1            0            0            0            0            0 #> Y2.10_X.1            1            0            0            0            0 #> Y2.01_X.1            0            0            1            0            1 #> Y2.11_X.1            0            0            0            0            0 #>           X0.Y101.Y201 X1.Y101.Y201 X0.Y111.Y201 X1.Y111.Y201 X0.Y100.Y211 #> X.0                  1            0            1            0            1 #> X.1                  0            1            0            1            0 #> Y1.00_X.0            0            0            0            0            1 #> Y1.10_X.0            0            0            0            0            0 #> Y1.01_X.0            1            0            0            0            0 #> Y1.11_X.0            0            0            1            0            0 #> Y1.00_X.1            0            0            0            0            0 #> Y1.10_X.1            0            0            0            0            0 #> Y1.01_X.1            0            1            0            0            0 #> Y1.11_X.1            0            0            0            1            0 #> Y2.00_X.0            0            0            0            0            0 #> Y2.10_X.0            0            0            0            0            0 #> Y2.01_X.0            1            0            1            0            0 #> Y2.11_X.0            0            0            0            0            1 #> Y2.00_X.1            0            0            0            0            0 #> Y2.10_X.1            0            0            0            0            0 #> Y2.01_X.1            0            1            0            1            0 #> Y2.11_X.1            0            0            0            0            0 #>           X1.Y100.Y211 X0.Y110.Y211 X1.Y110.Y211 X0.Y101.Y211 X1.Y101.Y211 #> X.0                  0            1            0            1            0 #> X.1                  1            0            1            0            1 #> Y1.00_X.0            0            0            0            0            0 #> Y1.10_X.0            0            1            0            0            0 #> Y1.01_X.0            0            0            0            1            0 #> Y1.11_X.0            0            0            0            0            0 #> Y1.00_X.1            1            0            0            0            0 #> Y1.10_X.1            0            0            1            0            0 #> Y1.01_X.1            0            0            0            0            1 #> Y1.11_X.1            0            0            0            0            0 #> Y2.00_X.0            0            0            0            0            0 #> Y2.10_X.0            0            0            0            0            0 #> Y2.01_X.0            0            0            0            0            0 #> Y2.11_X.0            0            1            0            1            0 #> Y2.00_X.1            0            0            0            0            0 #> Y2.10_X.1            0            0            0            0            0 #> Y2.01_X.1            0            0            0            0            0 #> Y2.11_X.1            1            0            1            0            1 #>           X0.Y111.Y211 X1.Y111.Y211 #> X.0                  1            0 #> X.1                  0            1 #> Y1.00_X.0            0            0 #> Y1.10_X.0            0            0 #> Y1.01_X.0            0            0 #> Y1.11_X.0            1            0 #> Y1.00_X.1            0            0 #> Y1.10_X.1            0            0 #> Y1.01_X.1            0            0 #> Y1.11_X.1            0            1 #> Y2.00_X.0            0            0 #> Y2.10_X.0            0            0 #> Y2.01_X.0            0            0 #> Y2.11_X.0            1            0 #> Y2.00_X.1            0            0 #> Y2.10_X.1            0            0 #> Y2.01_X.1            0            0 #> Y2.11_X.1            0            1 #>  #>   #>  param_set  (P) #>  X  Y1.X.0  Y1.X.1  Y2.X.0  Y2.X.1 model <- make_model(\"X1 -> Y <- X2; X1 <-> Y; X2 <-> Y\") dim(model$P) #> [1] 68 64 model$parameters_df #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>  #>  first 10 rows:  #>         param_names node gen   param_set nodal_type      given param_value #> 1              X1.0   X1   1          X1          0                 0.5000 #> 2              X1.1   X1   1          X1          1                 0.5000 #> 3              X2.0   X2   2          X2          0                 0.5000 #> 4              X2.1   X2   2          X2          1                 0.5000 #> 5  Y.0000_X1.0_X2.0    Y   3 Y.X1.0.X2.0       0000 X1.0, X2.0      0.0625 #> 6  Y.1000_X1.0_X2.0    Y   3 Y.X1.0.X2.0       1000 X1.0, X2.0      0.0625 #> 7  Y.0100_X1.0_X2.0    Y   3 Y.X1.0.X2.0       0100 X1.0, X2.0      0.0625 #> 8  Y.1100_X1.0_X2.0    Y   3 Y.X1.0.X2.0       1100 X1.0, X2.0      0.0625 #> 9  Y.0010_X1.0_X2.0    Y   3 Y.X1.0.X2.0       0010 X1.0, X2.0      0.0625 #> 10 Y.1010_X1.0_X2.0    Y   3 Y.X1.0.X2.0       1010 X1.0, X2.0      0.0625 #>    priors #> 1       1 #> 2       1 #> 3       1 #> 4       1 #> 5       1 #> 6       1 #> 7       1 #> 8       1 #> 9       1 #> 10      1  # A single node graph is also possible model <- make_model(\"X\")  # Unconnected nodes not allowed if (FALSE) {  model <- make_model(\"X <-> Y\") }  nodal_types <-   list(     A = c(\"0\",\"1\"),     B = c(\"0\",\"1\"),     C = c(\"0\",\"1\"),     D = c(\"0\",\"1\"),     E = c(\"0\",\"1\"),     Y = c(       \"00000000000000000000000000000000\",       \"01010101010101010101010101010101\",       \"00110011001100110011001100110011\",       \"00001111000011110000111100001111\",       \"00000000111111110000000011111111\",       \"00000000000000001111111111111111\",       \"11111111111111111111111111111111\" ))  make_model(\"A -> Y; B ->Y; C->Y; D->Y; E->Y\",           nodal_types = nodal_types)$parameters_df #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>  #>  first 10 rows:  #>    param_names node gen param_set nodal_type given param_value priors #> 1          A.0    A   1         A          0               0.5      1 #> 2          A.1    A   1         A          1               0.5      1 #> 3          B.0    B   2         B          0               0.5      1 #> 4          B.1    B   2         B          1               0.5      1 #> 5          C.0    C   3         C          0               0.5      1 #> 6          C.1    C   3         C          1               0.5      1 #> 7          D.0    D   4         D          0               0.5      1 #> 8          D.1    D   4         D          1               0.5      1 #> 9          E.0    E   5         E          0               0.5      1 #> 10         E.1    E   5         E          1               0.5      1  nodal_types = list(Y = c(\"01\", \"10\"), Z = c(\"0\", \"1\")) make_model(\"Z -> Y\", nodal_types = nodal_types)$parameters_df #> Ordering of provided nodal types is being altered to match generation #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>   param_names node gen param_set nodal_type given param_value priors #> 1         Z.0    Z   1         Z          0               0.5      1 #> 2         Z.1    Z   1         Z          1               0.5      1 #> 3        Y.01    Y   2         Y         01               0.5      1 #> 4        Y.10    Y   2         Y         10               0.5      1 make_model(\"Z -> Y\", nodal_types = FALSE)$parents_df #> Model not properly defined: nodal_types should be NULL or specified for all nodes in model:  Z, Y #>   node  root parents parent_nodes #> 1    Z  TRUE       0              #> 2    Y FALSE       1            Z"},{"path":"/reference/make_nodal_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Make nodal types — make_nodal_types","title":"Make nodal types — make_nodal_types","text":"Make nodal types","code":""},{"path":"/reference/make_nodal_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make nodal types — make_nodal_types","text":"","code":"make_nodal_types(model, include_node_names = FALSE)"},{"path":"/reference/make_nodal_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make nodal types — make_nodal_types","text":"model causal_model. model object generated make_model. include_node_names Logical. `TRUE` returns names form X0, X1; otherwise returns 0, 1. Defaults `FALSE`","code":""},{"path":"/reference/make_nodal_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make nodal types — make_nodal_types","text":"named list containing nodal types node","code":""},{"path":"/reference/make_nodal_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make nodal types — make_nodal_types","text":"","code":"# \\donttest{ model <- make_model('X -> K -> Y') CausalQueries:::make_nodal_types(model) #> Nodal types:  #> $X #> 0:1 #>  #> NULL #>  #> $K #> c(0, 1, 0, 1)  c(0, 0, 1, 1) #>  #> NULL #>  #> $Y #> c(0, 1, 0, 1)  c(0, 0, 1, 1) #>  #> NULL #>  #>  #> Number of types by node #> X K Y  #> 1 2 2  # }"},{"path":"/reference/make_parameters_df.html","id":null,"dir":"Reference","previous_headings":"","what":"function to make a parameters_df from nodal types — make_parameters_df","title":"function to make a parameters_df from nodal types — make_parameters_df","text":"function make parameters_df nodal types","code":""},{"path":"/reference/make_parameters_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"function to make a parameters_df from nodal types — make_parameters_df","text":"","code":"make_parameters_df(nodal_types)"},{"path":"/reference/make_parameters_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"function to make a parameters_df from nodal types — make_parameters_df","text":"nodal_types list nodal types","code":""},{"path":"/reference/make_parameters_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"function to make a parameters_df from nodal types — make_parameters_df","text":"","code":"make_parameters_df(list(X = \"1\", Y = c(\"01\", \"10\"))) #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>   param_names node gen param_set nodal_type given param_value priors #> 1         X.1    X   1         X          1               1.0      1 #> 2        Y.01    Y   2         Y         01               0.5      1 #> 3        Y.10    Y   2         Y         10               0.5      1"},{"path":"/reference/make_parameter_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Make parameter matrix — make_parameter_matrix","title":"Make parameter matrix — make_parameter_matrix","text":"Calculate parameter matrix assuming confounding. parameter matrix maps parameters causal types. models without confounding parameters correspond nodal types.","code":""},{"path":"/reference/make_parameter_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make parameter matrix — make_parameter_matrix","text":"","code":"make_parameter_matrix(model)"},{"path":"/reference/make_parameter_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make parameter matrix — make_parameter_matrix","text":"model causal_model. model object generated make_model.","code":""},{"path":"/reference/make_parameter_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make parameter matrix — make_parameter_matrix","text":"data.frame, parameter matrix, mapping parameters   causal types","code":""},{"path":"/reference/make_parameter_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make parameter matrix — make_parameter_matrix","text":"","code":"model <- make_model('X -> Y') make_parameter_matrix(model) #> Error in make_parameter_matrix(model): could not find function \"make_parameter_matrix\""},{"path":"/reference/make_parmap.html","id":null,"dir":"Reference","previous_headings":"","what":"Make parmap: a matrix mapping from parameters to data types — make_parmap","title":"Make parmap: a matrix mapping from parameters to data types — make_parmap","text":"Generates matrix row per parameter column per data type.","code":""},{"path":"/reference/make_parmap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make parmap: a matrix mapping from parameters to data types — make_parmap","text":"","code":"make_parmap(model, A = NULL, P = NULL)"},{"path":"/reference/make_parmap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make parmap: a matrix mapping from parameters to data types — make_parmap","text":"model causal_model. model object generated make_model. data.frame. Ambiguity matrix. required may provided avoid repeated computation simulations. P data.frame. Parameter matrix. required may provided avoid repeated computation simulations.","code":""},{"path":"/reference/make_parmap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make parmap: a matrix mapping from parameters to data types — make_parmap","text":"matrix","code":""},{"path":"/reference/make_parmap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make parmap: a matrix mapping from parameters to data types — make_parmap","text":"","code":"make_parmap(model = make_model('X->Y')) #> Error in make_parmap(model = make_model(\"X->Y\")): could not find function \"make_parmap\" make_parmap(model = make_model('X->Y; X<->Y')) #> Error in make_parmap(model = make_model(\"X->Y; X<->Y\")): could not find function \"make_parmap\" make_parmap(model = make_model('X->Y; X<->Y')) |> attr(\"map\") #> Error in make_parmap(model = make_model(\"X->Y; X<->Y\")): could not find function \"make_parmap\" make_parmap(model = make_model('X -> M -> Y; X <-> Y')) #> Error in make_parmap(model = make_model(\"X -> M -> Y; X <-> Y\")): could not find function \"make_parmap\" make_parmap(model = make_model('X -> M -> Y; M <-> Y')) #> Error in make_parmap(model = make_model(\"X -> M -> Y; M <-> Y\")): could not find function \"make_parmap\" model <- make_model('X -> M -> Y; M <-> Y; X <-> M') make_parmap(model) #> Error in make_parmap(model): could not find function \"make_parmap\" make_parmap(model) |> attr(\"map\") #> Error in make_parmap(model): could not find function \"make_parmap\" # Any ways (without paths splits) make_parmap(model) %*% (make_parmap(model) |> attr(\"map\")) #> Error in make_parmap(model): could not find function \"make_parmap\"  if (FALSE) { # X1 and X2 are confounded and jointly determine Y1, Y2. # For instance for models in which X and Y take on four values rather than 2. model <- make_model(\"Y2 <- X1 -> Y1; Y2 <- X2 ->Y1; X1 <-> X2; Y1 <-> Y2\") parmap <- make_parmap(model) parmap |> dim()  CausalQueries:::prep_stan_data(   model,   CausalQueries:::minimal_event_data(model))$n_params }"},{"path":"/reference/make_par_values.html","id":null,"dir":"Reference","previous_headings":"","what":"make_par_values — make_par_values","title":"make_par_values — make_par_values","text":"one step function make_priors make_parameters. See make_priors help.","code":""},{"path":"/reference/make_par_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_par_values — make_par_values","text":"","code":"make_par_values(   model,   alter = \"priors\",   x = NA,   alter_at = NA,   node = NA,   label = NA,   nodal_type = NA,   param_set = NA,   given = NA,   statement = NA,   join_by = \"|\",   param_names = NA,   distribution = NA,   normalize = FALSE )"},{"path":"/reference/make_par_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_par_values — make_par_values","text":"model model created make_model alter character vector one \"priors\" \"param_value\" specifying alter x vector real non negative values substituted \"priors\" \"param_value\" alter_at string specifying filtering operations applied parameters_df, yielding logical vector indicating parameters values altered. (see examples) node string indicating nodes altered label string. Label nodal type indicating nodal types values altered. Equivalent nodal_type. nodal_type string. Label nodal type indicating nodal types values altered param_set string indicating  name set parameters altered given string indicates node parameter altered depends statement causal query determines nodal types values altered join_by string specifying logical operator joining expanded types statement contains wildcards. Can take values '&' (logical ) '|' (logical ). param_names vector strings. name specific parameter form , example, 'X.1', 'Y.01' distribution string indicating common prior distribution (uniform, jeffreys certainty) normalize logical. TRUE normalizes param set probabilities sum 1.","code":""},{"path":"/reference/make_par_values.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"make_par_values — make_par_values","text":"","code":"# the below methods can be applied to either priors or # param_values by specifying the desired option in \\code{alter}  model <- CausalQueries::make_model(\"X -> M -> Y; X <-> Y\")  #altering values using \\code{alter_at} CausalQueries:::make_par_values(model = model,                                 x = c(0.5,0.25),                                 alter_at = paste(                                   \"node == 'Y' &\",                                   \"nodal_type %in% c('00','01') &\",                                   \"given == 'X.0'\")) #> Warning: You are altering parameters on confounded nodes. Alterations will be applied across all 'param_sets'. If this is not the alteration behavior you intended, try specifying the 'param_set' or 'given' option to more clearly indicate parameters whose values you wish to alter. #>  [1] 1.00 1.00 1.00 1.00 1.00 1.00 0.50 1.00 0.25 1.00 1.00 1.00 1.00 1.00  #altering values using \\code{param_names} CausalQueries:::make_par_values(model = model,                                 x = c(0.5,0.25),                                 param_names = c(\"Y.10_X.0\",\"Y.10_X.1\")) #> Warning: You are altering parameters on confounded nodes. Alterations will be applied across all 'param_sets'. If this is not the alteration behavior you intended, try specifying the 'param_set' or 'given' option to more clearly indicate parameters whose values you wish to alter. #>  [1] 1.00 1.00 1.00 1.00 1.00 1.00 1.00 0.50 1.00 1.00 1.00 0.25 1.00 1.00  #altering values using \\code{statement} CausalQueries:::make_par_values(model = model,                                 x = c(0.5,0.25),                                 statement = \"Y[M=1] > Y[M=0]\") #> Warning: A specified condition matches multiple parameters. In these cases it is unclear which parameter value should be assigned to which parameter. Assignment thus defaults to the order in which parameters appear in 'parameters_df'. We advise checking that parameter assignment was carried out as you intended.  #> Warning: You are altering parameters on confounded nodes. Alterations will be applied across all 'param_sets'. If this is not the alteration behavior you intended, try specifying the 'param_set' or 'given' option to more clearly indicate parameters whose values you wish to alter. #>  [1] 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 0.50 1.00 1.00 1.00 0.25 1.00  #altering values using a combination of other arguments CausalQueries:::make_par_values(model = model, x = c(0.5,0.25), node = \"Y\", nodal_type = c(\"00\",\"01\"), given = \"X.0\") #>  [1] 1.00 1.00 1.00 1.00 1.00 1.00 0.50 1.00 0.25 1.00 1.00 1.00 1.00 1.00"},{"path":"/reference/make_par_values_stops.html","id":null,"dir":"Reference","previous_headings":"","what":"make_par_values_stops — make_par_values_stops","title":"make_par_values_stops — make_par_values_stops","text":"helper remove stops reduce complexity make_par_values","code":""},{"path":"/reference/make_par_values_stops.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_par_values_stops — make_par_values_stops","text":"","code":"make_par_values_stops(   model,   alter = \"priors\",   x = NA,   alter_at = NA,   node = NA,   label = NA,   nodal_type = NA,   param_set = NA,   given = NA,   statement = NA,   join_by = \"|\",   param_names = NA,   distribution = NA,   normalize = FALSE )"},{"path":"/reference/make_par_values_stops.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_par_values_stops — make_par_values_stops","text":"model model created make_model alter character vector one \"priors\" \"param_value\" specifying alter x vector real non negative values substituted \"priors\" \"param_value\" alter_at string specifying filtering operations applied parameters_df, yielding logical vector indicating parameters values altered. (see examples) node string indicating nodes altered label string. Label nodal type indicating nodal types values altered. Equivalent nodal_type. nodal_type string. Label nodal type indicating nodal types values altered param_set string indicating  name set parameters altered given string indicates node parameter altered depends statement causal query determines nodal types values altered join_by string specifying logical operator joining expanded types statement contains wildcards. Can take values '&' (logical ) '|' (logical ). param_names vector strings. name specific parameter form , example, 'X.1', 'Y.01' distribution string indicating common prior distribution (uniform, jeffreys certainty) normalize logical. TRUE normalizes param set probabilities sum 1.","code":""},{"path":"/reference/make_prior_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a prior distribution from priors — make_prior_distribution","title":"Make a prior distribution from priors — make_prior_distribution","text":"Create `n_param`x `n_draws` database possible lambda draws attached model.","code":""},{"path":"/reference/make_prior_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a prior distribution from priors — make_prior_distribution","text":"","code":"make_prior_distribution(model, n_draws = 4000)"},{"path":"/reference/make_prior_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make a prior distribution from priors — make_prior_distribution","text":"model causal_model. model object generated make_model. n_draws scalar. Number draws.","code":""},{"path":"/reference/make_prior_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make a prior distribution from priors — make_prior_distribution","text":"`data.frame` dimension `n_param`x `n_draws` possible   lambda draws","code":""},{"path":[]},{"path":"/reference/make_prior_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make a prior distribution from priors — make_prior_distribution","text":"","code":"make_model('X -> Y') %>% make_prior_distribution(n_draws = 5) #> Summary statistics of model parameter prior distributions: #> Dimensions: 5 rows (draws) by 6 cols (parameters)     mean   sd #> X.0  0.46 0.24 #> X.1  0.54 0.24 #> Y.00 0.21 0.13 #> Y.10 0.23 0.23 #> Y.01 0.27 0.20 #> Y.11 0.30 0.16"},{"path":"/reference/minimal_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a data frame for case with no data — minimal_data","title":"Creates a data frame for case with no data — minimal_data","text":"Creates data frame case data","code":""},{"path":"/reference/minimal_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a data frame for case with no data — minimal_data","text":"","code":"minimal_data(model)"},{"path":"/reference/minimal_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a data frame for case with no data — minimal_data","text":"model causal_model. model object generated make_model.","code":""},{"path":"/reference/minimal_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a data frame for case with no data — minimal_data","text":"data.frame one row NAs columns named according   nodes model.","code":""},{"path":"/reference/minimal_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a data frame for case with no data — minimal_data","text":"","code":"# \\donttest{ model <- make_model('X -> K -> Y') CausalQueries:::minimal_data(model) #>    X  K  Y #> 1 NA NA NA # }"},{"path":"/reference/minimal_event_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a compact data frame for case with no data — minimal_event_data","title":"Creates a compact data frame for case with no data — minimal_event_data","text":"Creates compact data frame case data","code":""},{"path":"/reference/minimal_event_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a compact data frame for case with no data — minimal_event_data","text":"","code":"minimal_event_data(model)"},{"path":"/reference/minimal_event_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a compact data frame for case with no data — minimal_event_data","text":"model causal_model. model object generated make_model.","code":""},{"path":"/reference/minimal_event_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a compact data frame for case with no data — minimal_event_data","text":"compact data frame row represents element   exhaustive set events model. count event   set zero.","code":""},{"path":"/reference/minimal_event_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a compact data frame for case with no data — minimal_event_data","text":"","code":"# \\donttest{ model <- make_model('X -> K -> Y') CausalQueries:::minimal_event_data(model) #>    event strategy count #> 1 X0K0Y0      XKY     0 #> 2 X1K0Y0      XKY     0 #> 3 X0K1Y0      XKY     0 #> 4 X1K1Y0      XKY     0 #> 5 X0K0Y1      XKY     0 #> 6 X1K0Y1      XKY     0 #> 7 X0K1Y1      XKY     0 #> 8 X1K1Y1      XKY     0 # }"},{"path":"/reference/nodes_in_statement.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify nodes in a statement — nodes_in_statement","title":"Identify nodes in a statement — nodes_in_statement","text":"Identify nodes statement","code":""},{"path":"/reference/nodes_in_statement.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify nodes in a statement — nodes_in_statement","text":"","code":"nodes_in_statement(nodes, statement)"},{"path":"/reference/nodes_in_statement.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify nodes in a statement — nodes_in_statement","text":"nodes vector characters. contain quoted names nodes model statement character. quoted causal statement.","code":""},{"path":"/reference/nodes_in_statement.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify nodes in a statement — nodes_in_statement","text":"Returns name nodes present statement","code":""},{"path":"/reference/non_decreasing.html","id":null,"dir":"Reference","previous_headings":"","what":"Make monotonicity statement (non negative) — non_decreasing","title":"Make monotonicity statement (non negative) — non_decreasing","text":"Generate statement Y weakly monotonic (increasing) X","code":""},{"path":"/reference/non_decreasing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make monotonicity statement (non negative) — non_decreasing","text":"","code":"non_decreasing(X, Y)"},{"path":"/reference/non_decreasing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make monotonicity statement (non negative) — non_decreasing","text":"X character. quoted name input node Y character. quoted name outcome node","code":""},{"path":"/reference/non_decreasing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make monotonicity statement (non negative) — non_decreasing","text":"character statement class statement","code":""},{"path":[]},{"path":"/reference/non_decreasing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make monotonicity statement (non negative) — non_decreasing","text":"","code":"# \\donttest{ non_decreasing('A', 'B') #>  #> Statement:  #> (B[A=1] >= B[A=0]) # }"},{"path":"/reference/non_increasing.html","id":null,"dir":"Reference","previous_headings":"","what":"Make monotonicity statement (non positive) — non_increasing","title":"Make monotonicity statement (non positive) — non_increasing","text":"Generate statement Y weakly monotonic (increasing) X","code":""},{"path":"/reference/non_increasing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make monotonicity statement (non positive) — non_increasing","text":"","code":"non_increasing(X, Y)"},{"path":"/reference/non_increasing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make monotonicity statement (non positive) — non_increasing","text":"X character. quoted name input node Y character. quoted name outcome node","code":""},{"path":"/reference/non_increasing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make monotonicity statement (non positive) — non_increasing","text":"character statement class statement","code":""},{"path":[]},{"path":"/reference/non_increasing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make monotonicity statement (non positive) — non_increasing","text":"","code":"# \\donttest{ non_increasing('A', 'B') #>  #> Statement:  #> (B[A=1] <= B[A=0]) # }"},{"path":"/reference/n_check.html","id":null,"dir":"Reference","previous_headings":"","what":"n_check — n_check","title":"n_check — n_check","text":"n_check","code":""},{"path":"/reference/n_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"n_check — n_check","text":"","code":"n_check(n)"},{"path":"/reference/n_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"n_check — n_check","text":"n integer. Sample size argument.","code":""},{"path":"/reference/n_check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"n_check — n_check","text":"error message n integer less 0.","code":""},{"path":"/reference/n_check.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"n_check — n_check","text":"Checks whether input integer greater 0.","code":""},{"path":"/reference/observe_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Observe data, given a strategy — observe_data","title":"Observe data, given a strategy — observe_data","text":"Observe data, given strategy","code":""},{"path":"/reference/observe_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Observe data, given a strategy — observe_data","text":"","code":"observe_data(   complete_data,   observed = NULL,   nodes_to_observe = NULL,   prob = 1,   m = NULL,   subset = TRUE )"},{"path":"/reference/observe_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Observe data, given a strategy — observe_data","text":"complete_data data.frame. Data observed unobserved. observed data.frame. Data observed. nodes_to_observe list. Nodes observe. prob scalar. Observation probability. m integer. Number units observe; specified, m overrides prob. subset character.  Logical statement can applied rows complete data. instance observation nodes might depend observed values nodes; observation may sought data already observed!","code":""},{"path":"/reference/observe_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Observe data, given a strategy — observe_data","text":"data.frame logical values indicating nodes   observe row `complete_data`.","code":""},{"path":"/reference/observe_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Observe data, given a strategy — observe_data","text":"","code":"model <- make_model(\"X -> Y\") df <- make_data(model, n = 8) # Observe X values only observe_data(complete_data = df, nodes_to_observe = \"X\") #>      X     Y #> 1 TRUE FALSE #> 2 TRUE FALSE #> 3 TRUE FALSE #> 4 TRUE FALSE #> 5 TRUE FALSE #> 6 TRUE FALSE #> 7 TRUE FALSE #> 8 TRUE FALSE # Observe half the Y values for cases with observed X = 1 observe_data(complete_data = df,      observed = observe_data(complete_data = df, nodes_to_observe = \"X\"),      nodes_to_observe = \"Y\", prob = .5,      subset = \"X==1\") #>      X     Y #> 1 TRUE FALSE #> 2 TRUE FALSE #> 3 TRUE FALSE #> 4 TRUE FALSE #> 5 TRUE FALSE #> 6 TRUE FALSE #> 7 TRUE  TRUE #> 8 TRUE  TRUE"},{"path":"/reference/parameter_setting.html","id":null,"dir":"Reference","previous_headings":"","what":"Setting parameters — parameter_setting","title":"Setting parameters — parameter_setting","text":"Functionality altering parameters: vector 'true' parameters; possibly drawn prior posterior. Add true parameter vector model. Parameters can created using arguments passed make_parameters make_priors. Extracts parameters named vector","code":""},{"path":"/reference/parameter_setting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Setting parameters — parameter_setting","text":"","code":"make_parameters(   model,   parameters = NULL,   param_type = NULL,   warning = TRUE,   normalize = TRUE,   ... )  set_parameters(   model,   parameters = NULL,   param_type = NULL,   warning = FALSE,   ... )  get_parameters(model, param_type = NULL)"},{"path":"/reference/parameter_setting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Setting parameters — parameter_setting","text":"model causal_model. model object generated make_model. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn model$parameters_df. param_type character. String specifying type parameters make \"flat\", \"prior_mean\", \"posterior_mean\", \"prior_draw\", \"posterior_draw\", \"define\". param_type set define use arguments passed make_priors; otherwise flat sets equal probabilities nodal type parameter set; prior_mean, prior_draw, posterior_mean, posterior_draw take parameters means draws prior posterior. warning Logical. Whether warn parameter renormalization. normalize Logical. parameter given subset family residual elements normalized parameters param_set sum 1 provided params unaltered. ... Options passed onto make_priors.","code":""},{"path":"/reference/parameter_setting.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Setting parameters — parameter_setting","text":"vector draws prior distribution parameters object class causal_model. essentially returns   list containing elements comprising model   (e.g. 'statement', 'nodal_types' 'DAG') true vector   parameters attached . vector draws prior distribution parameters","code":""},{"path":"/reference/parameter_setting.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Setting parameters — parameter_setting","text":"","code":"# make_parameters examples:  # Simple examples model <- make_model('X -> Y') data  <- make_data(model, n = 2) model <- update_model(model, data) #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 1.8e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.126 seconds (Warm-up) #> Chain 1:                0.114 seconds (Sampling) #> Chain 1:                0.24 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1.9e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.125 seconds (Warm-up) #> Chain 2:                0.119 seconds (Sampling) #> Chain 2:                0.244 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 1.5e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.12 seconds (Warm-up) #> Chain 3:                0.113 seconds (Sampling) #> Chain 3:                0.233 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 2e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.122 seconds (Warm-up) #> Chain 4:                0.098 seconds (Sampling) #> Chain 4:                0.22 seconds (Total) #> Chain 4:  make_parameters(model, parameters = c(.25, .75, 1.25,.25, .25, .25)) #> Model parameters with associated probabilities:  #>  #> X.0 X.1 Y.00 Y.10 Y.01 Y.11 #> 0.25 0.75 0.625 0.125 0.125 0.125 make_parameters(model, param_type = 'flat') #> No specific parameters to alter values for specified. Altering all parameters. #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #> 0.50 0.50 0.25 0.25 0.25 0.25  make_parameters(model, param_type = 'prior_draw') #>        X.0        X.1       Y.00       Y.10       Y.01       Y.11  #> 0.66831931 0.33168069 0.36621192 0.18754605 0.40954567 0.03669637  make_parameters(model, param_type = 'prior_mean') #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #> 0.50 0.50 0.25 0.25 0.25 0.25  make_parameters(model, param_type = 'posterior_draw') #>        X.0        X.1       Y.00       Y.10       Y.01       Y.11  #> 0.80563013 0.19436987 0.48015484 0.22781230 0.20157774 0.09045512  make_parameters(model, param_type = 'posterior_mean') #>       X.0       X.1      Y.00      Y.10      Y.01      Y.11  #> 0.4967758 0.5032242 0.3722884 0.2320339 0.2293647 0.1663129    # \\donttest{  #altering values using \\code{alter_at} make_model(\"X -> Y\") %>% make_parameters(parameters = c(0.5,0.25), alter_at = \"node == 'Y' & nodal_type %in% c('00','01')\") #>   X.0   X.1  Y.00  Y.10  Y.01  Y.11  #> 0.500 0.500 0.500 0.125 0.250 0.125   #altering values using \\code{param_names} make_model(\"X -> Y\") %>% make_parameters(parameters = c(0.5,0.25), param_names = c(\"Y.10\",\"Y.01\")) #>   X.0   X.1  Y.00  Y.10  Y.01  Y.11  #> 0.500 0.500 0.125 0.500 0.250 0.125   #altering values using \\code{statement} make_model(\"X -> Y\") %>% make_parameters(parameters = c(0.5), statement = \"Y[X=1] > Y[X=0]\") #>       X.0       X.1      Y.00      Y.10      Y.01      Y.11  #> 0.5000000 0.5000000 0.1666667 0.1666667 0.5000000 0.1666667   #altering values using a combination of other arguments make_model(\"X -> Y\") %>% make_parameters(parameters = c(0.5,0.25), node = \"Y\", nodal_type = c(\"00\",\"01\")) #>   X.0   X.1  Y.00  Y.10  Y.01  Y.11  #> 0.500 0.500 0.500 0.125 0.250 0.125   # Normalize renormalizes values not set so that value set is not renomalized make_parameters(make_model('X -> Y'),                statement = 'Y[X=1]>Y[X=0]', parameters = .5) #>       X.0       X.1      Y.00      Y.10      Y.01      Y.11  #> 0.5000000 0.5000000 0.1666667 0.1666667 0.5000000 0.1666667  make_parameters(make_model('X -> Y'),                statement = 'Y[X=1]>Y[X=0]', parameters = .5,                normalize = FALSE) #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #>  0.5  0.5  0.2  0.2  0.4  0.2     # }  # set_parameters examples:  make_model('X->Y') %>% set_parameters(1:6) %>% get_parameters() #> Error in get_parameters(.): could not find function \"get_parameters\"  # Simple examples model <- make_model('X -> Y') data  <- make_data(model, n = 2) model <- update_model(model, data) #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.127 seconds (Warm-up) #> Chain 1:                0.117 seconds (Sampling) #> Chain 1:                0.244 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1.9e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.124 seconds (Warm-up) #> Chain 2:                0.117 seconds (Sampling) #> Chain 2:                0.241 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 1.7e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.128 seconds (Warm-up) #> Chain 3:                0.134 seconds (Sampling) #> Chain 3:                0.262 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 1.8e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.119 seconds (Warm-up) #> Chain 4:                0.12 seconds (Sampling) #> Chain 4:                0.239 seconds (Total) #> Chain 4:  set_parameters(model, parameters = c(.25, .75, 1.25,.25, .25, .25)) #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>  #>  #> Model has been updated and contains a posterior distribution with #> 4 chains, each with iter=2000; warmup=1000; thin=1;   #> Use grab(model, object = 'stan_summary') to inspect stan summary  #>  set_parameters(model, param_type = 'flat') #> No specific parameters to alter values for specified. Altering all parameters. #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>  #>  #> Model has been updated and contains a posterior distribution with #> 4 chains, each with iter=2000; warmup=1000; thin=1;   #> Use grab(model, object = 'stan_summary') to inspect stan summary  #>  set_parameters(model, param_type = 'prior_draw') #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>  #>  #> Model has been updated and contains a posterior distribution with #> 4 chains, each with iter=2000; warmup=1000; thin=1;   #> Use grab(model, object = 'stan_summary') to inspect stan summary  #>  set_parameters(model, param_type = 'prior_mean') #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>  #>  #> Model has been updated and contains a posterior distribution with #> 4 chains, each with iter=2000; warmup=1000; thin=1;   #> Use grab(model, object = 'stan_summary') to inspect stan summary  #>  set_parameters(model, param_type = 'posterior_draw') #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>  #>  #> Model has been updated and contains a posterior distribution with #> 4 chains, each with iter=2000; warmup=1000; thin=1;   #> Use grab(model, object = 'stan_summary') to inspect stan summary  #>  set_parameters(model, param_type = 'posterior_mean') #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>  #>  #> Model has been updated and contains a posterior distribution with #> 4 chains, each with iter=2000; warmup=1000; thin=1;   #> Use grab(model, object = 'stan_summary') to inspect stan summary  #>    # \\donttest{  #altering values using \\code{alter_at} make_model(\"X -> Y\") %>% set_parameters(parameters = c(0.5,0.25), alter_at = \"node == 'Y' & nodal_type %in% c('00','01')\") #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>   #altering values using \\code{param_names} make_model(\"X -> Y\") %>% set_parameters(parameters = c(0.5,0.25), param_names = c(\"Y.10\",\"Y.01\")) #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>   #altering values using \\code{statement} make_model(\"X -> Y\") %>% set_parameters(parameters = c(0.5), statement = \"Y[X=1] > Y[X=0]\") #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>   #altering values using a combination of other arguments make_model(\"X -> Y\") %>% set_parameters(parameters = c(0.5,0.25), node = \"Y\", nodal_type = c(\"00\",\"01\")) #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>      # }  # get_parameters examples:  make_model('X -> Y') |> get_parameters() #> Error in get_parameters(make_model(\"X -> Y\")): could not find function \"get_parameters\""},{"path":"/reference/parents_to_int.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper to turn parents_list into a list of data_realizations column positions — parents_to_int","title":"Helper to turn parents_list into a list of data_realizations column positions — parents_to_int","text":"Helper turn parents_list list data_realizations column positions","code":""},{"path":"/reference/parents_to_int.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper to turn parents_list into a list of data_realizations column positions — parents_to_int","text":"","code":"parents_to_int(parents_list, position_set)"},{"path":"/reference/parents_to_int.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper to turn parents_list into a list of data_realizations column positions — parents_to_int","text":"parents_list named list character vectors specifying nodes DAG respective parents","code":""},{"path":"/reference/parents_to_int.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper to turn parents_list into a list of data_realizations column positions — parents_to_int","text":"list column positions","code":""},{"path":"/reference/perm.html","id":null,"dir":"Reference","previous_headings":"","what":"Produces the possible permutations of a set of nodes — perm","title":"Produces the possible permutations of a set of nodes — perm","text":"Produces possible permutations set nodes","code":""},{"path":"/reference/perm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produces the possible permutations of a set of nodes — perm","text":"","code":"perm(max = rep(1, 2))"},{"path":"/reference/perm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produces the possible permutations of a set of nodes — perm","text":"max vector integers. maximum value integer value starting 0. Defaults 1. number permutation defined max's length","code":""},{"path":"/reference/perm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produces the possible permutations of a set of nodes — perm","text":"matrix permutations","code":""},{"path":"/reference/perm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Produces the possible permutations of a set of nodes — perm","text":"","code":"# \\donttest{ CausalQueries:::perm(3) #>     #> 1 0 #> 2 1 #> 3 2 #> 4 3 # }"},{"path":"/reference/plot_dag.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots a DAG in ggplot style using a causal model input — plot_model","title":"Plots a DAG in ggplot style using a causal model input — plot_model","text":"confounds indicated (provided attr(model$P, 'confounds')), represented bidirectional arcs. Builds functionality ggdag dagitty.","code":""},{"path":"/reference/plot_dag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots a DAG in ggplot style using a causal model input — plot_model","text":"","code":"plot_model(   model = NULL,   x_coord = NULL,   y_coord = NULL,   title = \"\",   textcol = \"white\",   textsize = 3.88,   shape = 16,   nodecol = \"black\",   nodesize = 16 )"},{"path":"/reference/plot_dag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots a DAG in ggplot style using a causal model input — plot_model","text":"model causal_model object generated make_model x_coord vector x coordinates DAG nodes. left empty, coordinates randomly generated y_coord vector y coordinates DAG nodes. left empty, coordinates randomly generated title String specifying title graph textcol String specifying color text labels textsize Numeric, size text labels shape Indicates shape node. Defaults circular node. nodecol String indicating color node accepted ggplot's default palette nodesize Size node.","code":""},{"path":"/reference/plot_dag.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots a DAG in ggplot style using a causal model input — plot_model","text":"DAG plot ggplot style.","code":""},{"path":"/reference/plot_dag.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots a DAG in ggplot style using a causal model input — plot_model","text":"","code":"if (FALSE) { model <- make_model('X -> K -> Y; X <-> Y')  model |>   CausalQueries:::plot_model() model |>   CausalQueries:::plot_model(     x_coord = 1:3,     y_coord = 1:3,     title = \"Mixed text and math: $\\\\alpha^2 + \\\\Gamma$\") }"},{"path":"/reference/plot_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots a DAG in ggplot style using a causal model input — plot_model","title":"Plots a DAG in ggplot style using a causal model input — plot_model","text":"confounds indicated (provided attr(model$P, 'confounds')), represented bidirectional arcs. Builds functionality ggdag dagitty.","code":""},{"path":"/reference/plot_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots a DAG in ggplot style using a causal model input — plot_model","text":"","code":"plot_model(   model = NULL,   x_coord = NULL,   y_coord = NULL,   title = \"\",   textcol = \"white\",   textsize = 3.88,   shape = 16,   nodecol = \"black\",   nodesize = 16 )"},{"path":"/reference/plot_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots a DAG in ggplot style using a causal model input — plot_model","text":"model causal_model object generated make_model x_coord vector x coordinates DAG nodes. left empty, coordinates randomly generated y_coord vector y coordinates DAG nodes. left empty, coordinates randomly generated title String specifying title graph textcol String specifying color text labels textsize Numeric, size text labels shape Indicates shape node. Defaults circular node. nodecol String indicating color node accepted ggplot's default palette nodesize Size node.","code":""},{"path":"/reference/plot_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots a DAG in ggplot style using a causal model input — plot_model","text":"DAG plot ggplot style.","code":""},{"path":"/reference/plot_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots a DAG in ggplot style using a causal model input — plot_model","text":"","code":"if (FALSE) { model <- make_model('X -> K -> Y; X <-> Y')  model |>   CausalQueries:::plot_model() model |>   CausalQueries:::plot_model(     x_coord = 1:3,     y_coord = 1:3,     title = \"Mixed text and math: $\\\\alpha^2 + \\\\Gamma$\") }"},{"path":"/reference/prep_stan_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare data for 'stan' — prep_stan_data","title":"Prepare data for 'stan' — prep_stan_data","text":"Create list containing data passed 'stan","code":""},{"path":"/reference/prep_stan_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare data for 'stan' — prep_stan_data","text":"","code":"prep_stan_data(   model,   data,   keep_type_distribution = TRUE,   censored_types = NULL )"},{"path":"/reference/prep_stan_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare data for 'stan' — prep_stan_data","text":"model causal_model. model object generated make_model. data data.frame.  Data nodes can take three values: 0, 1, NA. long form generated make_events","code":""},{"path":"/reference/prep_stan_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare data for 'stan' — prep_stan_data","text":"list containing data passed 'stan'","code":""},{"path":"/reference/prep_stan_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare data for 'stan' — prep_stan_data","text":"","code":"# \\donttest{ model <- make_model('X->Y') data  <-  collapse_data(make_data(model, n = 6), model) CausalQueries:::prep_stan_data(model, data) #> $parmap #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X.0     1    0    1    0 #> X.1     0    1    0    1 #> Y.00    1    1    0    0 #> Y.10    0    1    1    0 #> Y.01    1    0    0    1 #> Y.11    0    0    1    1 #> attr(,\"map\") #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 #>  #> $map #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 #>  #> $n_paths #> [1] 4 #>  #> $n_params #> [1] 6 #>  #> $n_param_sets #> [1] 2 #>  #> $n_param_each #> X Y  #> 2 4  #>  #> $l_starts #> X Y  #> 1 3  #>  #> $l_ends #> X Y  #> 2 6  #>  #> $node_starts #> X Y  #> 1 3  #>  #> $node_ends #> X Y  #> 2 6  #>  #> $n_nodes #> [1] 2 #>  #> $lambdas_prior #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #>    1    1    1    1    1    1  #>  #> $n_data #> [1] 4 #>  #> $n_events #> [1] 4 #>  #> $n_strategies #> [1] 1 #>  #> $strategy_starts #> [1] 1 #>  #> $strategy_ends #> [1] 4 #>  #> $keep_type_distribution #> [1] 1 #>  #> $E #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 #>  #> $Y #> [1] 2 2 0 2 #>  #> $P #>  #> Rows are parameters, grouped in parameter sets #>  #> Columns are causal types #>  #> Cell entries indicate whether a parameter probability isused #> in the calculation of causal type probability #>  #>      X0.Y00 X1.Y00 X0.Y10 X1.Y10 X0.Y01 X1.Y01 X0.Y11 X1.Y11 #> X.0       1      0      1      0      1      0      1      0 #> X.1       0      1      0      1      0      1      0      1 #> Y.00      1      1      0      0      0      0      0      0 #> Y.10      0      0      1      1      0      0      0      0 #> Y.01      0      0      0      0      1      1      0      0 #> Y.11      0      0      0      0      0      0      1      1 #>  #>   #>  param_set  (P) #>   #> $n_types #> [1] 8 #>   model <- make_model('X->Y') |>   set_confound(list(X = 'Y[X=1]>Y[X=0]')) data  <-  collapse_data(make_data(model, n = 6), model) CausalQueries:::prep_stan_data(model, data) #> $parmap #>      X0Y0 X1Y0 X0Y1 X1Y1 #> Y.00    1    1    0    0 #> Y.10    0    1    1    0 #> Y.01    1    0    0    1 #> Y.11    0    0    1    1 #> attr(,\"map\") #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 #>  #> $map #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 #>  #> $n_paths #> [1] 4 #>  #> $n_params #> [1] 4 #>  #> $n_param_sets #> [1] 1 #>  #> $n_param_each #> Y  #> 4  #>  #> $l_starts #> Y  #> 1  #>  #> $l_ends #> Y  #> 4  #>  #> $node_starts #> Y  #> 1  #>  #> $node_ends #> Y  #> 4  #>  #> $n_nodes #> [1] 1 #>  #> $lambdas_prior #> Y.00 Y.10 Y.01 Y.11  #>    1    1    1    1  #>  #> $n_data #> [1] 4 #>  #> $n_events #> [1] 4 #>  #> $n_strategies #> [1] 1 #>  #> $strategy_starts #> [1] 1 #>  #> $strategy_ends #> [1] 4 #>  #> $keep_type_distribution #> [1] 1 #>  #> $E #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 #>  #> $Y #> [1] 0 1 2 3 #>  #> $P #>  #> Rows are parameters, grouped in parameter sets #>  #> Columns are causal types #>  #> Cell entries indicate whether a parameter probability isused #> in the calculation of causal type probability #>  #>      X0.Y00 X1.Y00 X0.Y10 X1.Y10 X0.Y01 X1.Y01 X0.Y11 X1.Y11 #> Y.00      1      1      0      0      0      0      0      0 #> Y.10      0      0      1      1      0      0      0      0 #> Y.01      0      0      0      0      1      1      0      0 #> Y.11      0      0      0      0      0      0      1      1 #>  #>   #>  param_set  (P) #>  Y #> $n_types #> [1] 8 #>  # }"},{"path":"/reference/print.causal_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for a causal model — print.causal_model","title":"Print a short summary for a causal model — print.causal_model","text":"print method class causal_model.","code":""},{"path":"/reference/print.causal_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for a causal model — print.causal_model","text":"","code":"# S3 method for causal_model print(x, ...)"},{"path":"/reference/print.causal_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for a causal model — print.causal_model","text":"x object causal_model class, usually result call make_model update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.causal_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print a short summary for a causal model — print.causal_model","text":"information regarding causal model includes statement describing causal relations using dagitty syntax, number nodal types per parent DAG, number causal types.","code":""},{"path":"/reference/print.causal_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for causal_model causal-types — print.causal_types","title":"Print a short summary for causal_model causal-types — print.causal_types","text":"print method class causal_types.","code":""},{"path":"/reference/print.causal_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for causal_model causal-types — print.causal_types","text":"","code":"# S3 method for causal_types print(x, ...)"},{"path":"/reference/print.causal_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for causal_model causal-types — print.causal_types","text":"x object causal_types class, sub-object object causal_model class produced using make_model update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.dag.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for a causal_model DAG — print.dag","title":"Print a short summary for a causal_model DAG — print.dag","text":"print method class dag.","code":""},{"path":"/reference/print.dag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for a causal_model DAG — print.dag","text":"","code":"# S3 method for dag print(x, ...)"},{"path":"/reference/print.dag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for a causal_model DAG — print.dag","text":"x object dag class, sub-object object causal_model class produced using make_model update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.event_probabilites.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for event probability distributions — print.event_probabilites","title":"Print a short summary for event probability distributions — print.event_probabilites","text":"print method class event_probabilities.","code":""},{"path":"/reference/print.event_probabilites.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for event probability distributions — print.event_probabilites","text":"","code":"# S3 method for event_probabilites print(x, ...)"},{"path":"/reference/print.event_probabilites.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for event probability distributions — print.event_probabilites","text":"x object event_probabilities class, sub-object object causal_model class produced using update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.model_query.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a tightened summary of model queries — print.model_query","title":"Print a tightened summary of model queries — print.model_query","text":"print method class model_query.","code":""},{"path":"/reference/print.model_query.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a tightened summary of model queries — print.model_query","text":"","code":"# S3 method for model_query print(x, digits = 3)"},{"path":"/reference/print.model_query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a tightened summary of model queries — print.model_query","text":"x object model_query class. ... arguments passed methods.","code":""},{"path":"/reference/print.nodal_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for causal_model nodal-types — print.nodal_types","title":"Print a short summary for causal_model nodal-types — print.nodal_types","text":"print method class nodal_types.","code":""},{"path":"/reference/print.nodal_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for causal_model nodal-types — print.nodal_types","text":"","code":"# S3 method for nodal_types print(x, ...)"},{"path":"/reference/print.nodal_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for causal_model nodal-types — print.nodal_types","text":"x object nodal_types class, sub-object object causal_model class produced using make_model update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.nodes.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for a causal_model nodes — print.nodes","title":"Print a short summary for a causal_model nodes — print.nodes","text":"print method class nodes.","code":""},{"path":"/reference/print.nodes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for a causal_model nodes — print.nodes","text":"","code":"# S3 method for nodes print(x, ...)"},{"path":"/reference/print.nodes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for a causal_model nodes — print.nodes","text":"x object nodes class, sub-object object causal_model class produced using make_model update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for causal_model parameters — print.parameters","title":"Print a short summary for causal_model parameters — print.parameters","text":"print method class parameters.","code":""},{"path":"/reference/print.parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for causal_model parameters — print.parameters","text":"","code":"# S3 method for parameters print(x, ...)"},{"path":"/reference/print.parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for causal_model parameters — print.parameters","text":"x object parameters class, sub-object object causal_model class produced using make_model update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.parameters_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for a causal_model parameters data-frame — print.parameters_df","title":"Print a short summary for a causal_model parameters data-frame — print.parameters_df","text":"print method class parameters_df.","code":""},{"path":"/reference/print.parameters_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for a causal_model parameters data-frame — print.parameters_df","text":"","code":"# S3 method for parameters_df print(x, ...)"},{"path":"/reference/print.parameters_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for a causal_model parameters data-frame — print.parameters_df","text":"x object parameters_df class, sub-object object causal_model class produced using make_model update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.parameters_posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for causal_model parameter posterior distributions — print.parameters_posterior","title":"Print a short summary for causal_model parameter posterior distributions — print.parameters_posterior","text":"print method class parameters_posterior.","code":""},{"path":"/reference/print.parameters_posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for causal_model parameter posterior distributions — print.parameters_posterior","text":"","code":"# S3 method for parameters_posterior print(x, ...)"},{"path":"/reference/print.parameters_posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for causal_model parameter posterior distributions — print.parameters_posterior","text":"x object parameters_posterior class, sub-object object causal_model class produced using update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.parameters_prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for causal_model parameter prior distributions — print.parameters_prior","title":"Print a short summary for causal_model parameter prior distributions — print.parameters_prior","text":"print method class parameters_prior.","code":""},{"path":"/reference/print.parameters_prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for causal_model parameter prior distributions — print.parameters_prior","text":"","code":"# S3 method for parameters_prior print(x, ...)"},{"path":"/reference/print.parameters_prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for causal_model parameter prior distributions — print.parameters_prior","text":"x object parameters_prior class, sub-object object causal_model class produced using set_prior_distribution. ... arguments passed methods.","code":""},{"path":"/reference/print.parents_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for a causal_model parents data-frame — print.parents_df","title":"Print a short summary for a causal_model parents data-frame — print.parents_df","text":"print method class parents_df.","code":""},{"path":"/reference/print.parents_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for a causal_model parents data-frame — print.parents_df","text":"","code":"# S3 method for parents_df print(x, ...)"},{"path":"/reference/print.parents_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for a causal_model parents data-frame — print.parents_df","text":"x object parents_df class, sub-object object causal_model class produced using make_model update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.posterior_event_probabilities.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary of posterior_event_probabilities — print.posterior_event_probabilities","title":"Print a short summary of posterior_event_probabilities — print.posterior_event_probabilities","text":"print method class posterior_event_probabilities.","code":""},{"path":"/reference/print.posterior_event_probabilities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary of posterior_event_probabilities — print.posterior_event_probabilities","text":"","code":"# S3 method for posterior_event_probabilities print(x, ...)"},{"path":"/reference/print.posterior_event_probabilities.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary of posterior_event_probabilities — print.posterior_event_probabilities","text":"x object posterior_event_probabilities class. ... arguments passed methods.","code":""},{"path":"/reference/print.stan_fit_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for stan fit — print.stan_fit_summary","title":"Print a short summary for stan fit — print.stan_fit_summary","text":"print method class stan_summary.","code":""},{"path":"/reference/print.stan_fit_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for stan fit — print.stan_fit_summary","text":"","code":"# S3 method for stan_summary print(x, ...)"},{"path":"/reference/print.stan_fit_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for stan fit — print.stan_fit_summary","text":"x object stan_summary class, sub-object object causal_model class produced using update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.stan_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for stan fit — print.stan_summary","title":"Print a short summary for stan fit — print.stan_summary","text":"print method class stan_summary.","code":""},{"path":"/reference/print.stan_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for stan fit — print.stan_summary","text":"","code":"# S3 method for stan_summary print(x, ...)"},{"path":"/reference/print.stan_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for stan fit — print.stan_summary","text":"x object stan_summary class, sub-object object causal_model class produced using update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.statement.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for a causal_model statement — print.statement","title":"Print a short summary for a causal_model statement — print.statement","text":"print method class statement.","code":""},{"path":"/reference/print.statement.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for a causal_model statement — print.statement","text":"","code":"# S3 method for statement print(x, ...)"},{"path":"/reference/print.statement.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for a causal_model statement — print.statement","text":"x object statement class, sub-object object causal_model class produced using make_model update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.type_posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for causal-type posterior distributions — print.type_posterior","title":"Print a short summary for causal-type posterior distributions — print.type_posterior","text":"print method class type_posterior.","code":""},{"path":"/reference/print.type_posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for causal-type posterior distributions — print.type_posterior","text":"","code":"# S3 method for type_posterior print(x, ...)"},{"path":"/reference/print.type_posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for causal-type posterior distributions — print.type_posterior","text":"x object type_posterior class, sub-object object causal_model class produced using get_type_prob_multiple. ... arguments passed methods.","code":""},{"path":"/reference/print.type_prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for causal-type prior distributions — print.type_prior","title":"Print a short summary for causal-type prior distributions — print.type_prior","text":"print method class type_prior.","code":""},{"path":"/reference/print.type_prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for causal-type prior distributions — print.type_prior","text":"","code":"# S3 method for type_prior print(x, ...)"},{"path":"/reference/print.type_prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for causal-type prior distributions — print.type_prior","text":"x object type_prior class, sub-object object causal_model class produced using make_model update_model. ... arguments passed methods.","code":""},{"path":"/reference/prior_setting.html","id":null,"dir":"Reference","previous_headings":"","what":"Setting priors — prior_setting","title":"Setting priors — prior_setting","text":"Functionality altering priors: make_priors Generates priors model. set_priors  Adds priors model. Extracts priors named vector","code":""},{"path":"/reference/prior_setting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Setting priors — prior_setting","text":"","code":"make_priors(   model,   alphas = NA,   distribution = NA,   alter_at = NA,   node = NA,   nodal_type = NA,   label = NA,   param_set = NA,   given = NA,   statement = NA,   join_by = \"|\",   param_names = NA )  set_priors(   model,   alphas = NA,   distribution = NA,   alter_at = NA,   node = NA,   nodal_type = NA,   label = NA,   param_set = NA,   given = NA,   statement = NA,   join_by = \"|\",   param_names = NA )  get_priors(model)"},{"path":"/reference/prior_setting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Setting priors — prior_setting","text":"model model object generated make_model(). alphas Real positive numbers giving hyperparameters Dirichlet distribution distribution string indicating common prior distribution (uniform, jeffreys certainty) alter_at string specifying filtering operations applied parameters_df, yielding logical vector indicating parameters values altered. (see examples) node string indicating nodes altered nodal_type string. Label nodal type indicating nodal types values altered label string. Label nodal type indicating nodal types values altered. Equivalent nodal_type. param_set string indicating  name set parameters altered given string indicates node parameter altered depends statement causal query determines nodal types values altered join_by string specifying logical operator joining expanded types statement contains wildcards. Can take values '&' (logical ) '|' (logical ). param_names vector strings. name specific parameter form , example, 'X.1', 'Y.01'","code":""},{"path":"/reference/prior_setting.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Setting priors — prior_setting","text":"vector indicating parameters prior distribution   nodal types (\"hyperparameters\"). object class causal_model. essentially returns   list containing elements comprising model   (e.g. 'statement', 'nodal_types' 'DAG') `priors` attached   . vector indicating hyperparameters prior distribution   nodal types.","code":""},{"path":"/reference/prior_setting.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Setting priors — prior_setting","text":"Seven arguments govern parameters altered. default '' can reduced specifying * alter_at String specifying filtering operations applied   parameters_df, yielding logical vector indicating parameters   values altered. \"node == 'X' & nodal_type * node, restricts example parameters associated node   'X' * label nodal_type label particular nodal type,   written either form Y0000 Y.Y0000 * param_set param_set parameter. * given Given parameter set parameter. * statement, restricts example nodal types satisfy   statement 'Y[X=1] > Y[X=0]' * param_set, given, useful setting confound   statements produce several sets parameters Two arguments govern values apply: * alphas one non-negative numbers * distribution indicates one common class: uniform, Jeffreys,   'certain' Forbidden statements include: Setting distribution values time. Setting distribution uniform, Jeffreys,     certainty. Setting negative values. specifying alter_at node,     nodal_type, param_set, given, statement,     param_names specifying param_names node,     nodal_type, param_set, given, statement,     alter_at specifying statement node     nodal_type","code":""},{"path":"/reference/prior_setting.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Setting priors — prior_setting","text":"","code":"# make_priors examples:  # Pass all nodal types model <- make_model(\"Y <- X\") make_priors(model, alphas = .4) #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #>  0.4  0.4  0.4  0.4  0.4  0.4  make_priors(model, distribution = \"jeffreys\") #> No specific parameters to alter values for specified. Altering all parameters. #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #>  0.5  0.5  0.5  0.5  0.5  0.5   model <- CausalQueries::make_model(\"X -> M -> Y; X <-> Y\")  #altering values using \\code{alter_at} make_priors(model = model, alphas = c(0.5,0.25), alter_at = \"node == 'Y' & nodal_type %in% c('00','01') & given == 'X.0'\") #> Warning: You are altering parameters on confounded nodes. Alterations will be applied across all 'param_sets'. If this is not the alteration behavior you intended, try specifying the 'param_set' or 'given' option to more clearly indicate parameters whose values you wish to alter. #>      X.0      X.1     M.00     M.10     M.01     M.11 Y.00_X.0 Y.10_X.0  #>     1.00     1.00     1.00     1.00     1.00     1.00     0.50     1.00  #> Y.01_X.0 Y.11_X.0 Y.00_X.1 Y.10_X.1 Y.01_X.1 Y.11_X.1  #>     0.25     1.00     1.00     1.00     1.00     1.00   #altering values using \\code{param_names} make_priors(model = model, alphas = c(0.5,0.25), param_names = c(\"Y.10_X.0\",\"Y.10_X.1\")) #> Warning: You are altering parameters on confounded nodes. Alterations will be applied across all 'param_sets'. If this is not the alteration behavior you intended, try specifying the 'param_set' or 'given' option to more clearly indicate parameters whose values you wish to alter. #>      X.0      X.1     M.00     M.10     M.01     M.11 Y.00_X.0 Y.10_X.0  #>     1.00     1.00     1.00     1.00     1.00     1.00     1.00     0.50  #> Y.01_X.0 Y.11_X.0 Y.00_X.1 Y.10_X.1 Y.01_X.1 Y.11_X.1  #>     1.00     1.00     1.00     0.25     1.00     1.00   #altering values using \\code{statement} make_priors(model = model, alphas = c(0.5,0.25), statement = \"Y[M=1] > Y[M=0]\") #> Warning: A specified condition matches multiple parameters. In these cases it is unclear which parameter value should be assigned to which parameter. Assignment thus defaults to the order in which parameters appear in 'parameters_df'. We advise checking that parameter assignment was carried out as you intended.  #> Warning: You are altering parameters on confounded nodes. Alterations will be applied across all 'param_sets'. If this is not the alteration behavior you intended, try specifying the 'param_set' or 'given' option to more clearly indicate parameters whose values you wish to alter. #>      X.0      X.1     M.00     M.10     M.01     M.11 Y.00_X.0 Y.10_X.0  #>     1.00     1.00     1.00     1.00     1.00     1.00     1.00     1.00  #> Y.01_X.0 Y.11_X.0 Y.00_X.1 Y.10_X.1 Y.01_X.1 Y.11_X.1  #>     0.50     1.00     1.00     1.00     0.25     1.00   #altering values using a combination of other arguments make_priors(model = model, alphas = c(0.5,0.25), node = \"Y\", nodal_type = c(\"00\",\"01\"), given = \"X.0\") #>      X.0      X.1     M.00     M.10     M.01     M.11 Y.00_X.0 Y.10_X.0  #>     1.00     1.00     1.00     1.00     1.00     1.00     0.50     1.00  #> Y.01_X.0 Y.11_X.0 Y.00_X.1 Y.10_X.1 Y.01_X.1 Y.11_X.1  #>     0.25     1.00     1.00     1.00     1.00     1.00   # set_priors examples:  # Pass all nodal types model <- make_model(\"Y <- X\") set_priors(model, alphas = .4) #>  #> Statement:  #> Y <- X #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>  set_priors(model, distribution = \"jeffreys\") #> No specific parameters to alter values for specified. Altering all parameters. #>  #> Statement:  #> Y <- X #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>   model <- CausalQueries::make_model(\"X -> M -> Y; X <-> Y\")  #altering values using \\code{alter_at} set_priors(model = model, alphas = c(0.5,0.25), alter_at = \"node == 'Y' & nodal_type %in% c('00','01') & given == 'X.0'\") #> Warning: You are altering parameters on confounded nodes. Alterations will be applied across all 'param_sets'. If this is not the alteration behavior you intended, try specifying the 'param_set' or 'given' option to more clearly indicate parameters whose values you wish to alter. #>  #> Statement:  #> X -> M -> Y; X <-> Y; Y <-> X #>  #> Number of types by node: #> X M Y  #> 2 4 4  #>  #> Number of unit types: 32 #>   #altering values using \\code{param_names} set_priors(model = model, alphas = c(0.5,0.25), param_names = c(\"Y.10_X.0\",\"Y.10_X.1\")) #> Warning: You are altering parameters on confounded nodes. Alterations will be applied across all 'param_sets'. If this is not the alteration behavior you intended, try specifying the 'param_set' or 'given' option to more clearly indicate parameters whose values you wish to alter. #>  #> Statement:  #> X -> M -> Y; X <-> Y; Y <-> X #>  #> Number of types by node: #> X M Y  #> 2 4 4  #>  #> Number of unit types: 32 #>   #altering values using \\code{statement} set_priors(model = model, alphas = c(0.5,0.25), statement = \"Y[M=1] > Y[M=0]\") #> Warning: A specified condition matches multiple parameters. In these cases it is unclear which parameter value should be assigned to which parameter. Assignment thus defaults to the order in which parameters appear in 'parameters_df'. We advise checking that parameter assignment was carried out as you intended.  #> Warning: You are altering parameters on confounded nodes. Alterations will be applied across all 'param_sets'. If this is not the alteration behavior you intended, try specifying the 'param_set' or 'given' option to more clearly indicate parameters whose values you wish to alter. #>  #> Statement:  #> X -> M -> Y; X <-> Y; Y <-> X #>  #> Number of types by node: #> X M Y  #> 2 4 4  #>  #> Number of unit types: 32 #>   #altering values using a combination of other arguments set_priors(model = model, alphas = c(0.5,0.25), node = \"Y\", nodal_type = c(\"00\",\"01\"), given = \"X.0\") #>  #> Statement:  #> X -> M -> Y; X <-> Y; Y <-> X #>  #> Number of types by node: #> X M Y  #> 2 4 4  #>  #> Number of unit types: 32 #>   # get_priors examples:  get_priors(make_model('X -> Y')) #> Error in get_priors(make_model(\"X -> Y\")): could not find function \"get_priors\""},{"path":"/reference/queries_to_types.html","id":null,"dir":"Reference","previous_headings":"","what":"helper to get types from queries — queries_to_types","title":"helper to get types from queries — queries_to_types","text":"helper get types queries","code":""},{"path":"/reference/queries_to_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"helper to get types from queries — queries_to_types","text":"","code":"queries_to_types(jobs, model, query_col, realisations)"},{"path":"/reference/queries_to_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"helper to get types from queries — queries_to_types","text":"jobs DataFrame argument combinations model list models query_col string specifying name column jobs holding queries evaluated realisations list DataFrame outputs calls realise_outcomes","code":""},{"path":"/reference/queries_to_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"helper to get types from queries — queries_to_types","text":"jobs DataFrame nested column  map_query_to_nodal_type outputs","code":""},{"path":"/reference/query_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate query distribution — query_distribution","title":"Calculate query distribution — query_distribution","text":"Calculated distribution query prior posterior distribution parameters","code":""},{"path":"/reference/query_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate query distribution — query_distribution","text":"","code":"query_distribution(   model,   queries,   given = NULL,   using = \"parameters\",   parameters = NULL,   n_draws = 4000,   join_by = \"|\",   case_level = FALSE,   query = NULL )"},{"path":"/reference/query_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate query distribution — query_distribution","text":"model causal_model. model object generated make_model. queries character vector list character vectors specifying queries potential outcomes \"Y[X=1] - Y[X=0]\" given character vector specifying givens query. given quoted expression evaluates logical statement. given allows query conditioned *observational* distribution. value TRUE interpreted conditioning. using character. Whether use priors, posteriors parameters parameters vector list vectors real numbers [0,1]. true parameter vector used instead parameters attached model case  using specifies parameters n_draws integer. Number draws.rm join_by character. logical operator joining expanded types query contains wildcard (.). Can take values \"&\" (logical ) \"|\" (logical ). restriction contains wildcard (.) join_by specified, defaults \"|\", otherwise defaults NULL. case_level Logical. TRUE estimates probability query case. query alias queries","code":""},{"path":"/reference/query_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate query distribution — query_distribution","text":"DataFrame columns contain draws distribution   potential outcomes specified query","code":""},{"path":"/reference/query_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate query distribution — query_distribution","text":"","code":"model <- make_model(\"X -> Y\") %>%          set_parameters(c(.5, .5, .1, .2, .3, .4))  # \\donttest{  # simple  queries  query_distribution(model, query = \"(Y[X=1] > Y[X=0])\",                     using = \"priors\") |>    head() #>   (Y[X=1] > Y[X=0]) #> 1         0.4949833 #> 2         0.4073183 #> 3         0.0415724 #> 4         0.4344517 #> 5         0.8637861 #> 6         0.3049571   # multiple  queries  query_distribution(model,      query = list(\"(Y[X=1] > Y[X=0])\",                   \"(Y[X=1] < Y[X=0])\"),      using = \"priors\")|>    head() #>   (Y[X=1] > Y[X=0]) (Y[X=1] < Y[X=0]) #> 1        0.09241136         0.3060072 #> 2        0.52672044         0.2169082 #> 3        0.31044891         0.6252908 #> 4        0.31326378         0.3072935 #> 5        0.63320196         0.2024220 #> 6        0.10098846         0.7639153   # multiple queries and givens  query_distribution(model,    query = list(\"(Y[X=1] > Y[X=0])\", \"(Y[X=1] < Y[X=0])\"),    given = list(\"Y==1\", \"(Y[X=1] <= Y[X=0])\"),    using = \"priors\")|>    head() #>   (Y[X=1] > Y[X=0]) | Y==1 (Y[X=1] < Y[X=0]) | (Y[X=1] <= Y[X=0]) #> 1              0.230372777                             0.26931792 #> 2              0.046310742                             0.03116822 #> 3              0.755410299                             0.40469985 #> 4              0.423838008                             0.71253721 #> 5              0.002537272                             0.08124326 #> 6              0.079707704                             0.28529471   # linear queries  query_distribution(model, query = \"(Y[X=1] - Y[X=0])\") #>   (Y[X=1] - Y[X=0]) #> 1               0.1   # queries conditional on observables  query_distribution(model, query = \"(Y[X=1] > Y[X=0])\",                     given = \"X==1 & Y ==1\") #>   (Y[X=1] > Y[X=0]) #> 1         0.4285714   # Linear query conditional on potential outcomes  query_distribution(model, query = \"(Y[X=1] - Y[X=0])\",                     given = \"Y[X=1]==0\") #>   (Y[X=1] - Y[X=0]) #> 1        -0.6666667   # Use join_by to amend query interpretation  query_distribution(model, query = \"(Y[X=.] == 1)\", join_by = \"&\") #> Generated expanded expression: #> (Y[X=0] == 1 | Y[X=1] == 1) #>   (Y[X=.] == 1) #> 1           0.9   # Probability of causation query  query_distribution(model,     query = \"(Y[X=1] > Y[X=0])\",     given = \"X==1 & Y==1\",     using = \"priors\")  |> head() #>   (Y[X=1] > Y[X=0]) #> 1         0.3243476 #> 2         0.8100257 #> 3         0.0287984 #> 4         0.9486432 #> 5         0.2566036 #> 6         0.7279466   # Case level probability of causation query  query_distribution(model,     query = \"(Y[X=1] > Y[X=0])\",     given = \"X==1 & Y==1\",     case_level = TRUE,     using = \"priors\") #>   (Y[X=1] > Y[X=0]) #> 1         0.4930782   # Query posterior  update_model(model, make_data(model, n = 3)) |>  query_distribution(query = \"(Y[X=1] - Y[X=0])\", using = \"posteriors\") |>  head() #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 1.9e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.119 seconds (Warm-up) #> Chain 1:                0.123 seconds (Sampling) #> Chain 1:                0.242 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1.7e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.13 seconds (Warm-up) #> Chain 2:                0.107 seconds (Sampling) #> Chain 2:                0.237 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 1.5e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.126 seconds (Warm-up) #> Chain 3:                0.106 seconds (Sampling) #> Chain 3:                0.232 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 1.6e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.132 seconds (Warm-up) #> Chain 4:                0.133 seconds (Sampling) #> Chain 4:                0.265 seconds (Total) #> Chain 4:  #>   (Y[X=1] - Y[X=0]) #> 1       -0.02255738 #> 2       -0.13757475 #> 3       -0.04571931 #> 4        0.46448376 #> 5       -0.17650957 #> 6       -0.17320323   # Case level queries provide the inference for a case, which is a scalar  # The case level query *updates* on the given information  # For instance, here we have a model for which we are quite sure that X  # causes Y but we do not know whether it works through two positive effects  # or two negative effects. Thus we do not know if M=0 would suggest an  # effect or no effect   set.seed(1)  model <-    make_model(\"X -> M -> Y\") |>    update_model(data.frame(X = rep(0:1, 8), Y = rep(0:1, 8)), iter = 10000) #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.6e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.26 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 10000 [  0%]  (Warmup) #> Chain 1: Iteration: 1000 / 10000 [ 10%]  (Warmup) #> Chain 1: Iteration: 2000 / 10000 [ 20%]  (Warmup) #> Chain 1: Iteration: 3000 / 10000 [ 30%]  (Warmup) #> Chain 1: Iteration: 4000 / 10000 [ 40%]  (Warmup) #> Chain 1: Iteration: 5000 / 10000 [ 50%]  (Warmup) #> Chain 1: Iteration: 5001 / 10000 [ 50%]  (Sampling) #> Chain 1: Iteration: 6000 / 10000 [ 60%]  (Sampling) #> Chain 1: Iteration: 7000 / 10000 [ 70%]  (Sampling) #> Chain 1: Iteration: 8000 / 10000 [ 80%]  (Sampling) #> Chain 1: Iteration: 9000 / 10000 [ 90%]  (Sampling) #> Chain 1: Iteration: 10000 / 10000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 1.319 seconds (Warm-up) #> Chain 1:                1.513 seconds (Sampling) #> Chain 1:                2.832 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 2.1e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 10000 [  0%]  (Warmup) #> Chain 2: Iteration: 1000 / 10000 [ 10%]  (Warmup) #> Chain 2: Iteration: 2000 / 10000 [ 20%]  (Warmup) #> Chain 2: Iteration: 3000 / 10000 [ 30%]  (Warmup) #> Chain 2: Iteration: 4000 / 10000 [ 40%]  (Warmup) #> Chain 2: Iteration: 5000 / 10000 [ 50%]  (Warmup) #> Chain 2: Iteration: 5001 / 10000 [ 50%]  (Sampling) #> Chain 2: Iteration: 6000 / 10000 [ 60%]  (Sampling) #> Chain 2: Iteration: 7000 / 10000 [ 70%]  (Sampling) #> Chain 2: Iteration: 8000 / 10000 [ 80%]  (Sampling) #> Chain 2: Iteration: 9000 / 10000 [ 90%]  (Sampling) #> Chain 2: Iteration: 10000 / 10000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 1.374 seconds (Warm-up) #> Chain 2:                1.41 seconds (Sampling) #> Chain 2:                2.784 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 2.2e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 10000 [  0%]  (Warmup) #> Chain 3: Iteration: 1000 / 10000 [ 10%]  (Warmup) #> Chain 3: Iteration: 2000 / 10000 [ 20%]  (Warmup) #> Chain 3: Iteration: 3000 / 10000 [ 30%]  (Warmup) #> Chain 3: Iteration: 4000 / 10000 [ 40%]  (Warmup) #> Chain 3: Iteration: 5000 / 10000 [ 50%]  (Warmup) #> Chain 3: Iteration: 5001 / 10000 [ 50%]  (Sampling) #> Chain 3: Iteration: 6000 / 10000 [ 60%]  (Sampling) #> Chain 3: Iteration: 7000 / 10000 [ 70%]  (Sampling) #> Chain 3: Iteration: 8000 / 10000 [ 80%]  (Sampling) #> Chain 3: Iteration: 9000 / 10000 [ 90%]  (Sampling) #> Chain 3: Iteration: 10000 / 10000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 1.41 seconds (Warm-up) #> Chain 3:                1.353 seconds (Sampling) #> Chain 3:                2.763 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 2.2e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 10000 [  0%]  (Warmup) #> Chain 4: Iteration: 1000 / 10000 [ 10%]  (Warmup) #> Chain 4: Iteration: 2000 / 10000 [ 20%]  (Warmup) #> Chain 4: Iteration: 3000 / 10000 [ 30%]  (Warmup) #> Chain 4: Iteration: 4000 / 10000 [ 40%]  (Warmup) #> Chain 4: Iteration: 5000 / 10000 [ 50%]  (Warmup) #> Chain 4: Iteration: 5001 / 10000 [ 50%]  (Sampling) #> Chain 4: Iteration: 6000 / 10000 [ 60%]  (Sampling) #> Chain 4: Iteration: 7000 / 10000 [ 70%]  (Sampling) #> Chain 4: Iteration: 8000 / 10000 [ 80%]  (Sampling) #> Chain 4: Iteration: 9000 / 10000 [ 90%]  (Sampling) #> Chain 4: Iteration: 10000 / 10000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 1.385 seconds (Warm-up) #> Chain 4:                2.068 seconds (Sampling) #> Chain 4:                3.453 seconds (Total) #> Chain 4:    Q <- \"Y[X=1] > Y[X=0]\"  G <- \"X==1 & Y==1 & M==1\"  QG <- \"(Y[X=1] > Y[X=0]) & (X==1 & Y==1 & M==1)\"   # In this case these are very different:  query_distribution(model, Q, given = G, using = \"posteriors\")[[1]] |> mean() #> [1] 0.4238768  query_distribution(model, Q, given = G, using = \"posteriors\",    case_level = TRUE) #>   Y[X=1] > Y[X=0] #> 1       0.6715179   # These are equivalent:  # 1. Case level query via function  query_distribution(model, Q, given = G,     using = \"posteriors\", case_level = TRUE) #>   Y[X=1] > Y[X=0] #> 1       0.6715179   # 2. Case level query by hand using Bayes  distribution <- query_distribution(     model, list(QG = QG, G = G), using = \"posteriors\")   mean(distribution$QG)/mean(distribution$G) #> [1] 0.6715179 # }"},{"path":"/reference/query_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate estimands dataframe — query_model","title":"Generate estimands dataframe — query_model","text":"Calculated parameter vector, prior posterior distribution.","code":""},{"path":"/reference/query_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate estimands dataframe — query_model","text":"","code":"query_model(   model,   queries = NULL,   given = NULL,   using = list(\"parameters\"),   parameters = NULL,   stats = NULL,   n_draws = 4000,   expand_grid = FALSE,   case_level = FALSE,   query = NULL,   cred = 95 )"},{"path":"/reference/query_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate estimands dataframe — query_model","text":"model causal_model. model object generated make_model. queries vector strings list strings specifying queries potential outcomes \"Y[X=1] - Y[X=0]\". given vector list strings specifying givens. given quoted expression evaluates logical statement. Allows estimand conditioned *observational* (counterfactual) distribution. using vector list strings. Whether use priors, posteriors parameters. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn model$parameters_df. stats Functions applied estimand distribution. NULL, defaults mean, standard deviation, 95% confidence interval. Functions return single numeric value. n_draws integer. Number draws. expand_grid Logical. TRUE combinations provided lists examined. list cycled separately. Defaults FALSE. case_level Logical. TRUE estimates probability query case. query alias queries cred size credible interval ranging 0 100","code":""},{"path":"/reference/query_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate estimands dataframe — query_model","text":"DataFrame columns Model, Query, Given Using   defined corresponding input values. columns generated   specified stats.","code":""},{"path":"/reference/query_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate estimands dataframe — query_model","text":"Queries can condition observed counterfactual quantities. Nested \"complex\" counterfactual queries form Y[X=1, M[X=0]] allowed.","code":""},{"path":"/reference/query_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate estimands dataframe — query_model","text":"","code":"model <- make_model(\"X -> Y\") query_model(model, \"Y[X=1] - Y[X = 0]\", using = \"priors\") #>  #> Causal queries generated by query_model (all at population level) #>  #> |query             |using  |   mean|   sd| cred.low| cred.high| #> |:-----------------|:------|------:|----:|--------:|---------:| #> |Y[X=1] - Y[X = 0] |priors | -0.004| 0.32|   -0.653|      0.63| #>  query_model(model, \"Y[X=1] > Y[X = 0]\", using = \"parameters\") #>  #> Causal queries generated by query_model (all at population level) #>  #> |query             |using      | mean| #> |:-----------------|:----------|----:| #> |Y[X=1] > Y[X = 0] |parameters | 0.25| #>  query_model(model, \"Y[X=1] > Y[X = 0]\", using = c(\"priors\", \"parameters\")) #>  #> Causal queries generated by query_model (all at population level) #>  #> |query             |using      |  mean|    sd| cred.low| cred.high| #> |:-----------------|:----------|-----:|-----:|--------:|---------:| #> |Y[X=1] > Y[X = 0] |priors     | 0.243| 0.192|    0.008|     0.695| #> |Y[X=1] > Y[X = 0] |parameters | 0.250|    NA|    0.250|     0.250| #>  # \\donttest{  # `expand_grid= TRUE` requests the Cartesian product of arguments  models <- list(  M1 = make_model(\"X -> Y\"),  M2 = make_model(\"X -> Y\") |>    set_restrictions(\"Y[X=1] < Y[X=0]\")  )   query_model(   models,   query = list(ATE = \"Y[X=1] - Y[X=0]\",                Share_positive = \"Y[X=1] > Y[X=0]\"),   given = c(TRUE,  \"Y==1 & X==1\"),   using = c(\"parameters\", \"priors\"),   expand_grid = FALSE) #>  #> Causal queries generated by query_model (all at population level) #>  #> |model |query          |given       |using      |  mean|    sd| cred.low| cred.high| #> |:-----|:--------------|:-----------|:----------|-----:|-----:|--------:|---------:| #> |M1    |ATE            |-           |parameters | 0.000|    NA|    0.000|     0.000| #> |M1    |Share_positive |Y==1 & X==1 |priors     | 0.495| 0.291|    0.024|     0.976| #> |M2    |ATE            |-           |parameters | 0.333|    NA|    0.333|     0.333| #> |M2    |Share_positive |Y==1 & X==1 |priors     | 0.501| 0.286|    0.026|     0.974| #>   query_model(   models,   query = list(ATE = \"Y[X=1] - Y[X=0]\",                Share_positive = \"Y[X=1] > Y[X=0]\"),   given = c(TRUE,  \"Y==1 & X==1\"),   using = c(\"parameters\", \"priors\"),   expand_grid = TRUE) #>  #> Causal queries generated by query_model (all at population level) #>  #> |model |query          |given       |using      |  mean|    sd| cred.low| cred.high| #> |:-----|:--------------|:-----------|:----------|-----:|-----:|--------:|---------:| #> |M1    |ATE            |-           |parameters | 0.000|    NA|    0.000|     0.000| #> |M2    |ATE            |-           |parameters | 0.333|    NA|    0.333|     0.333| #> |M1    |ATE            |-           |priors     | 0.005| 0.321|   -0.637|     0.636| #> |M2    |ATE            |-           |priors     | 0.337| 0.241|    0.012|     0.855| #> |M1    |ATE            |Y==1 & X==1 |parameters | 0.500|    NA|    0.500|     0.500| #> |M2    |ATE            |Y==1 & X==1 |parameters | 0.500|    NA|    0.500|     0.500| #> |M1    |ATE            |Y==1 & X==1 |priors     | 0.509| 0.291|    0.026|     0.971| #> |M2    |ATE            |Y==1 & X==1 |priors     | 0.498| 0.290|    0.024|     0.974| #> |M1    |Share_positive |-           |parameters | 0.250|    NA|    0.250|     0.250| #> |M2    |Share_positive |-           |parameters | 0.333|    NA|    0.333|     0.333| #> |M1    |Share_positive |-           |priors     | 0.256| 0.197|    0.008|     0.712| #> |M2    |Share_positive |-           |priors     | 0.337| 0.241|    0.012|     0.855| #> |M1    |Share_positive |Y==1 & X==1 |parameters | 0.500|    NA|    0.500|     0.500| #> |M2    |Share_positive |Y==1 & X==1 |parameters | 0.500|    NA|    0.500|     0.500| #> |M1    |Share_positive |Y==1 & X==1 |priors     | 0.509| 0.291|    0.026|     0.971| #> |M2    |Share_positive |Y==1 & X==1 |priors     | 0.498| 0.290|    0.024|     0.974| #>   # An example of a custom statistic: uncertainty of token causation f <- function(x) mean(x)*(1-mean(x))  query_model(   model,   using = list( \"parameters\", \"priors\"),   query = \"Y[X=1] > Y[X=0]\",   stats = c(mean = mean, sd = sd, token_variance = f)) #>  #> Causal queries generated by query_model (all at population level) #>  #> |query           |using      |  mean|    sd| token_variance| #> |:---------------|:----------|-----:|-----:|--------------:| #> |Y[X=1] > Y[X=0] |parameters | 0.250|    NA|          0.188| #> |Y[X=1] > Y[X=0] |priors     | 0.254| 0.195|          0.189| #>  # }"},{"path":"/reference/query_to_expression.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper to turn query into a data expression — query_to_expression","title":"Helper to turn query into a data expression — query_to_expression","text":"Helper turn query data expression","code":""},{"path":"/reference/query_to_expression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper to turn query into a data expression — query_to_expression","text":"","code":"query_to_expression(query, node)"},{"path":"/reference/query_to_expression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper to turn query into a data expression — query_to_expression","text":"query character string. expression defining nodal types interrogate realise_outcomes. expression form \"Y[X=1]\" asks value Y X set 1 node character string. quoted name node.","code":""},{"path":"/reference/query_to_expression.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper to turn query into a data expression — query_to_expression","text":"cleaned query expression","code":""},{"path":"/reference/realise_outcomes.html","id":null,"dir":"Reference","previous_headings":"","what":"Realise outcomes — realise_outcomes","title":"Realise outcomes — realise_outcomes","text":"Realise outcomes causal types. Calculated sequentially calculating endogenous nodes. operator applied node takes given value descendants generated accordingly.","code":""},{"path":"/reference/realise_outcomes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Realise outcomes — realise_outcomes","text":"","code":"realise_outcomes(model, dos = NULL, node = NULL, add_rownames = TRUE)"},{"path":"/reference/realise_outcomes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Realise outcomes — realise_outcomes","text":"model causal_model. model object generated make_model. dos named list. actions defining node values, e.g., list(X = 0, M = 1). node character. optional quoted name node whose outcome revealed. specified values parents need specified via dos. add_rownames logical indicating whether add causal types rownames output","code":""},{"path":"/reference/realise_outcomes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Realise outcomes — realise_outcomes","text":"data.frame object revealed data node (columns)   given causal / nodal type (rows) .","code":""},{"path":"/reference/realise_outcomes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Realise outcomes — realise_outcomes","text":"node specified outcomes realised possible causal types consistent model. node specified outcomes Y returned conditional different values parents, whether values parents obtain given restrictions model. realise_outcomes starts creating types   (via get_nodal_types). takes types endogenous   reveals outcome based value parents took.   Exogenous nodes outcomes correspond type.","code":""},{"path":"/reference/realise_outcomes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Realise outcomes — realise_outcomes","text":"","code":"# \\donttest{ make_model(\"X -> Y\") |>   realise_outcomes() #>      X Y #> 0.00 0 0 #> 1.00 1 0 #> 0.10 0 1 #> 1.10 1 0 #> 0.01 0 0 #> 1.01 1 1 #> 0.11 0 1 #> 1.11 1 1  make_model(\"X -> Y <- W\") |> set_restrictions(labels = list(X = \"1\", Y=\"0010\"), keep = TRUE) |>  realise_outcomes() #>          W X Y #> 0.1.0010 0 1 1 #> 1.1.0010 1 1 0  make_model(\"X1->Y; X2->M; M->Y\") |> realise_outcomes(dos = list(X1 = 1, M = 0)) #>             X1 X2 M Y #> 0.0.00.0000  1  0 0 0 #> 1.0.00.0000  1  0 0 0 #> 0.1.00.0000  1  1 0 0 #> 1.1.00.0000  1  1 0 0 #> 0.0.10.0000  1  0 0 0 #> 1.0.10.0000  1  0 0 0 #> 0.1.10.0000  1  1 0 0 #> 1.1.10.0000  1  1 0 0 #> 0.0.01.0000  1  0 0 0 #> 1.0.01.0000  1  0 0 0 #> 0.1.01.0000  1  1 0 0 #> 1.1.01.0000  1  1 0 0 #> 0.0.11.0000  1  0 0 0 #> 1.0.11.0000  1  0 0 0 #> 0.1.11.0000  1  1 0 0 #> 1.1.11.0000  1  1 0 0 #> 0.0.00.1000  1  0 0 0 #> 1.0.00.1000  1  0 0 0 #> 0.1.00.1000  1  1 0 0 #> 1.1.00.1000  1  1 0 0 #> 0.0.10.1000  1  0 0 0 #> 1.0.10.1000  1  0 0 0 #> 0.1.10.1000  1  1 0 0 #> 1.1.10.1000  1  1 0 0 #> 0.0.01.1000  1  0 0 0 #> 1.0.01.1000  1  0 0 0 #> 0.1.01.1000  1  1 0 0 #> 1.1.01.1000  1  1 0 0 #> 0.0.11.1000  1  0 0 0 #> 1.0.11.1000  1  0 0 0 #> 0.1.11.1000  1  1 0 0 #> 1.1.11.1000  1  1 0 0 #> 0.0.00.0100  1  0 0 1 #> 1.0.00.0100  1  0 0 1 #> 0.1.00.0100  1  1 0 1 #> 1.1.00.0100  1  1 0 1 #> 0.0.10.0100  1  0 0 1 #> 1.0.10.0100  1  0 0 1 #> 0.1.10.0100  1  1 0 1 #> 1.1.10.0100  1  1 0 1 #> 0.0.01.0100  1  0 0 1 #> 1.0.01.0100  1  0 0 1 #> 0.1.01.0100  1  1 0 1 #> 1.1.01.0100  1  1 0 1 #> 0.0.11.0100  1  0 0 1 #> 1.0.11.0100  1  0 0 1 #> 0.1.11.0100  1  1 0 1 #> 1.1.11.0100  1  1 0 1 #> 0.0.00.1100  1  0 0 1 #> 1.0.00.1100  1  0 0 1 #> 0.1.00.1100  1  1 0 1 #> 1.1.00.1100  1  1 0 1 #> 0.0.10.1100  1  0 0 1 #> 1.0.10.1100  1  0 0 1 #> 0.1.10.1100  1  1 0 1 #> 1.1.10.1100  1  1 0 1 #> 0.0.01.1100  1  0 0 1 #> 1.0.01.1100  1  0 0 1 #> 0.1.01.1100  1  1 0 1 #> 1.1.01.1100  1  1 0 1 #> 0.0.11.1100  1  0 0 1 #> 1.0.11.1100  1  0 0 1 #> 0.1.11.1100  1  1 0 1 #> 1.1.11.1100  1  1 0 1 #> 0.0.00.0010  1  0 0 0 #> 1.0.00.0010  1  0 0 0 #> 0.1.00.0010  1  1 0 0 #> 1.1.00.0010  1  1 0 0 #> 0.0.10.0010  1  0 0 0 #> 1.0.10.0010  1  0 0 0 #> 0.1.10.0010  1  1 0 0 #> 1.1.10.0010  1  1 0 0 #> 0.0.01.0010  1  0 0 0 #> 1.0.01.0010  1  0 0 0 #> 0.1.01.0010  1  1 0 0 #> 1.1.01.0010  1  1 0 0 #> 0.0.11.0010  1  0 0 0 #> 1.0.11.0010  1  0 0 0 #> 0.1.11.0010  1  1 0 0 #> 1.1.11.0010  1  1 0 0 #> 0.0.00.1010  1  0 0 0 #> 1.0.00.1010  1  0 0 0 #> 0.1.00.1010  1  1 0 0 #> 1.1.00.1010  1  1 0 0 #> 0.0.10.1010  1  0 0 0 #> 1.0.10.1010  1  0 0 0 #> 0.1.10.1010  1  1 0 0 #> 1.1.10.1010  1  1 0 0 #> 0.0.01.1010  1  0 0 0 #> 1.0.01.1010  1  0 0 0 #> 0.1.01.1010  1  1 0 0 #> 1.1.01.1010  1  1 0 0 #> 0.0.11.1010  1  0 0 0 #> 1.0.11.1010  1  0 0 0 #> 0.1.11.1010  1  1 0 0 #> 1.1.11.1010  1  1 0 0 #> 0.0.00.0110  1  0 0 1 #> 1.0.00.0110  1  0 0 1 #> 0.1.00.0110  1  1 0 1 #> 1.1.00.0110  1  1 0 1 #> 0.0.10.0110  1  0 0 1 #> 1.0.10.0110  1  0 0 1 #> 0.1.10.0110  1  1 0 1 #> 1.1.10.0110  1  1 0 1 #> 0.0.01.0110  1  0 0 1 #> 1.0.01.0110  1  0 0 1 #> 0.1.01.0110  1  1 0 1 #> 1.1.01.0110  1  1 0 1 #> 0.0.11.0110  1  0 0 1 #> 1.0.11.0110  1  0 0 1 #> 0.1.11.0110  1  1 0 1 #> 1.1.11.0110  1  1 0 1 #> 0.0.00.1110  1  0 0 1 #> 1.0.00.1110  1  0 0 1 #> 0.1.00.1110  1  1 0 1 #> 1.1.00.1110  1  1 0 1 #> 0.0.10.1110  1  0 0 1 #> 1.0.10.1110  1  0 0 1 #> 0.1.10.1110  1  1 0 1 #> 1.1.10.1110  1  1 0 1 #> 0.0.01.1110  1  0 0 1 #> 1.0.01.1110  1  0 0 1 #> 0.1.01.1110  1  1 0 1 #> 1.1.01.1110  1  1 0 1 #> 0.0.11.1110  1  0 0 1 #> 1.0.11.1110  1  0 0 1 #> 0.1.11.1110  1  1 0 1 #> 1.1.11.1110  1  1 0 1 #> 0.0.00.0001  1  0 0 0 #> 1.0.00.0001  1  0 0 0 #> 0.1.00.0001  1  1 0 0 #> 1.1.00.0001  1  1 0 0 #> 0.0.10.0001  1  0 0 0 #> 1.0.10.0001  1  0 0 0 #> 0.1.10.0001  1  1 0 0 #> 1.1.10.0001  1  1 0 0 #> 0.0.01.0001  1  0 0 0 #> 1.0.01.0001  1  0 0 0 #> 0.1.01.0001  1  1 0 0 #> 1.1.01.0001  1  1 0 0 #> 0.0.11.0001  1  0 0 0 #> 1.0.11.0001  1  0 0 0 #> 0.1.11.0001  1  1 0 0 #> 1.1.11.0001  1  1 0 0 #> 0.0.00.1001  1  0 0 0 #> 1.0.00.1001  1  0 0 0 #> 0.1.00.1001  1  1 0 0 #> 1.1.00.1001  1  1 0 0 #> 0.0.10.1001  1  0 0 0 #> 1.0.10.1001  1  0 0 0 #> 0.1.10.1001  1  1 0 0 #> 1.1.10.1001  1  1 0 0 #> 0.0.01.1001  1  0 0 0 #> 1.0.01.1001  1  0 0 0 #> 0.1.01.1001  1  1 0 0 #> 1.1.01.1001  1  1 0 0 #> 0.0.11.1001  1  0 0 0 #> 1.0.11.1001  1  0 0 0 #> 0.1.11.1001  1  1 0 0 #> 1.1.11.1001  1  1 0 0 #> 0.0.00.0101  1  0 0 1 #> 1.0.00.0101  1  0 0 1 #> 0.1.00.0101  1  1 0 1 #> 1.1.00.0101  1  1 0 1 #> 0.0.10.0101  1  0 0 1 #> 1.0.10.0101  1  0 0 1 #> 0.1.10.0101  1  1 0 1 #> 1.1.10.0101  1  1 0 1 #> 0.0.01.0101  1  0 0 1 #> 1.0.01.0101  1  0 0 1 #> 0.1.01.0101  1  1 0 1 #> 1.1.01.0101  1  1 0 1 #> 0.0.11.0101  1  0 0 1 #> 1.0.11.0101  1  0 0 1 #> 0.1.11.0101  1  1 0 1 #> 1.1.11.0101  1  1 0 1 #> 0.0.00.1101  1  0 0 1 #> 1.0.00.1101  1  0 0 1 #> 0.1.00.1101  1  1 0 1 #> 1.1.00.1101  1  1 0 1 #> 0.0.10.1101  1  0 0 1 #> 1.0.10.1101  1  0 0 1 #> 0.1.10.1101  1  1 0 1 #> 1.1.10.1101  1  1 0 1 #> 0.0.01.1101  1  0 0 1 #> 1.0.01.1101  1  0 0 1 #> 0.1.01.1101  1  1 0 1 #> 1.1.01.1101  1  1 0 1 #> 0.0.11.1101  1  0 0 1 #> 1.0.11.1101  1  0 0 1 #> 0.1.11.1101  1  1 0 1 #> 1.1.11.1101  1  1 0 1 #> 0.0.00.0011  1  0 0 0 #> 1.0.00.0011  1  0 0 0 #> 0.1.00.0011  1  1 0 0 #> 1.1.00.0011  1  1 0 0 #> 0.0.10.0011  1  0 0 0 #> 1.0.10.0011  1  0 0 0 #> 0.1.10.0011  1  1 0 0 #> 1.1.10.0011  1  1 0 0 #> 0.0.01.0011  1  0 0 0 #> 1.0.01.0011  1  0 0 0 #> 0.1.01.0011  1  1 0 0 #> 1.1.01.0011  1  1 0 0 #> 0.0.11.0011  1  0 0 0 #> 1.0.11.0011  1  0 0 0 #> 0.1.11.0011  1  1 0 0 #> 1.1.11.0011  1  1 0 0 #> 0.0.00.1011  1  0 0 0 #> 1.0.00.1011  1  0 0 0 #> 0.1.00.1011  1  1 0 0 #> 1.1.00.1011  1  1 0 0 #> 0.0.10.1011  1  0 0 0 #> 1.0.10.1011  1  0 0 0 #> 0.1.10.1011  1  1 0 0 #> 1.1.10.1011  1  1 0 0 #> 0.0.01.1011  1  0 0 0 #> 1.0.01.1011  1  0 0 0 #> 0.1.01.1011  1  1 0 0 #> 1.1.01.1011  1  1 0 0 #> 0.0.11.1011  1  0 0 0 #> 1.0.11.1011  1  0 0 0 #> 0.1.11.1011  1  1 0 0 #> 1.1.11.1011  1  1 0 0 #> 0.0.00.0111  1  0 0 1 #> 1.0.00.0111  1  0 0 1 #> 0.1.00.0111  1  1 0 1 #> 1.1.00.0111  1  1 0 1 #> 0.0.10.0111  1  0 0 1 #> 1.0.10.0111  1  0 0 1 #> 0.1.10.0111  1  1 0 1 #> 1.1.10.0111  1  1 0 1 #> 0.0.01.0111  1  0 0 1 #> 1.0.01.0111  1  0 0 1 #> 0.1.01.0111  1  1 0 1 #> 1.1.01.0111  1  1 0 1 #> 0.0.11.0111  1  0 0 1 #> 1.0.11.0111  1  0 0 1 #> 0.1.11.0111  1  1 0 1 #> 1.1.11.0111  1  1 0 1 #> 0.0.00.1111  1  0 0 1 #> 1.0.00.1111  1  0 0 1 #> 0.1.00.1111  1  1 0 1 #> 1.1.00.1111  1  1 0 1 #> 0.0.10.1111  1  0 0 1 #> 1.0.10.1111  1  0 0 1 #> 0.1.10.1111  1  1 0 1 #> 1.1.10.1111  1  1 0 1 #> 0.0.01.1111  1  0 0 1 #> 1.0.01.1111  1  0 0 1 #> 0.1.01.1111  1  1 0 1 #> 1.1.01.1111  1  1 0 1 #> 0.0.11.1111  1  0 0 1 #> 1.0.11.1111  1  0 0 1 #> 0.1.11.1111  1  1 0 1 #> 1.1.11.1111  1  1 0 1  # With node specified make_model(\"X->M->Y\") |> realise_outcomes(node = \"Y\") #>      M Y #> 0.00 0 0 #> 1.00 1 0 #> 0.10 0 1 #> 1.10 1 0 #> 0.01 0 0 #> 1.01 1 1 #> 0.11 0 1 #> 1.11 1 1  make_model(\"X->M->Y\") |> realise_outcomes(dos = list(M = 1), node = \"Y\") #>      M Y #> 1.00 1 0 #> 1.10 1 0 #> 1.01 1 1 #> 1.11 1 1 # }"},{"path":"/reference/restrict_by_labels.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduce nodal types using labels — restrict_by_labels","title":"Reduce nodal types using labels — restrict_by_labels","text":"Reduce nodal types using labels","code":""},{"path":"/reference/restrict_by_labels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduce nodal types using labels — restrict_by_labels","text":"","code":"restrict_by_labels(model, labels, given = NULL, keep = FALSE)"},{"path":"/reference/restrict_by_labels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduce nodal types using labels — restrict_by_labels","text":"model causal_model. model object generated make_model. labels list character vectors specifying nodal types kept removed model. given character vector list character vectors specifying nodes parameter set restricted depends. mixing labels restricted given ones , labels without given restrictions given specified one NULL, NA, \"\" \" \". keep Logical. `FALSE`, removes `TRUE` keeps causal types specified restriction.","code":""},{"path":"/reference/restrict_by_labels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reduce nodal types using labels — restrict_by_labels","text":"list two components: 1. vector parameters names   parameters implicated restrictions, 2. vector subsetting   instructions used identify implicated causal types","code":""},{"path":[]},{"path":"/reference/restrict_by_query.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduce nodal types using statement — restrict_by_query","title":"Reduce nodal types using statement — restrict_by_query","text":"Reduce nodal types using statement","code":""},{"path":"/reference/restrict_by_query.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduce nodal types using statement — restrict_by_query","text":"","code":"restrict_by_query(model, statement, join_by = \"|\", given = NULL, keep = FALSE)"},{"path":"/reference/restrict_by_query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduce nodal types using statement — restrict_by_query","text":"model model created make_model() statement list character vectors specifying nodal types removed model. Use get_nodal_types see syntax. join_by string list strings. logical operator joining expanded types statement contains wildcard (.). Can take values '&' (logical ) '|' (logical ). restriction contains wildcard (.) join_by specified, defaults '|', otherwise defaults NULL. given character vector list character vectors specifying nodes parameter set restricted depends. given must either NULL length statement. mixing statements restricted given ones , statements without given restrictions given specified one NULL, NA, \"\" \" \". keep Logical. `FALSE`, removes `TRUE` keeps causal types specified restriction.","code":""},{"path":"/reference/restrict_by_query.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reduce nodal types using statement — restrict_by_query","text":"list two components: 1. vector parameters names   parameters implicated restrictions, 2. vector subsetting   instructions used identify implicated causal types","code":""},{"path":[]},{"path":"/reference/reveal_outcomes.html","id":null,"dir":"Reference","previous_headings":"","what":"Reveal outcomes — reveal_outcomes","title":"Reveal outcomes — reveal_outcomes","text":"`r lifecycle::badge(\"deprecated\")` function deprecated name causes clashes DeclareDesign. Use realise_outcomes instead.","code":""},{"path":"/reference/reveal_outcomes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reveal outcomes — reveal_outcomes","text":"","code":"reveal_outcomes(model, dos = NULL, node = NULL)"},{"path":"/reference/set_ambiguities_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Set ambiguity matrix — set_ambiguities_matrix","title":"Set ambiguity matrix — set_ambiguities_matrix","text":"Add ambiguities matrix model","code":""},{"path":"/reference/set_ambiguities_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set ambiguity matrix — set_ambiguities_matrix","text":"","code":"set_ambiguities_matrix(model, A = NULL)"},{"path":"/reference/set_ambiguities_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set ambiguity matrix — set_ambiguities_matrix","text":"model causal_model. model object generated make_model. data.frame. Ambiguity matrix. required may provided avoid repeated computation simulations.","code":""},{"path":"/reference/set_ambiguities_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set ambiguity matrix — set_ambiguities_matrix","text":"object type causal_model   ambiguities matrix attached","code":""},{"path":"/reference/set_ambiguities_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set ambiguity matrix — set_ambiguities_matrix","text":"","code":"model <- make_model('X -> Y') %>%          set_ambiguities_matrix() #> Error in set_ambiguities_matrix(.): could not find function \"set_ambiguities_matrix\" model$A #> Error in eval(expr, envir, enclos): object 'model' not found"},{"path":"/reference/set_confound.html","id":null,"dir":"Reference","previous_headings":"","what":"Set confound — set_confound","title":"Set confound — set_confound","text":"Adjust parameter matrix allow confounding.","code":""},{"path":"/reference/set_confound.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set confound — set_confound","text":"","code":"set_confound(model, confound = NULL)"},{"path":"/reference/set_confound.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set confound — set_confound","text":"model causal_model. model object generated make_model. confound list statements indicating pairs nodes whose types jointly distributed (e.g. list(\"<-> B\", \"C <-> D\")).","code":""},{"path":"/reference/set_confound.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set confound — set_confound","text":"object class causal_model updated parameters_df   parameter matrix.","code":""},{"path":"/reference/set_confound.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set confound — set_confound","text":"Confounding X Y arises nodal types X Y independently distributed. X -> Y graph, instance, 2 nodal types X 4 Y. thus 8 joint nodal types: table 8 interior elements unconstrained joint distribution 7 degrees freedom. confounding assumption means Pr(t^X | t^Y) = Pr(t^X),  Pr(t^X, t^Y) = Pr(t^X)Pr(t^Y). case 3 degrees freedom Y 1 X, totaling 4 rather 7. set_confound lets relax assumption increasing number parameters characterizing joint distribution. Using fact P(,B) = P()P(B|) new parameters introduced capture P(B|=) rather simply P(B). instance two parameters (one degree freedom) govern distribution types X  four parameters (3 degrees freedom) govern  types Y given type X total 1+3+3 = 7 degrees freedom.","code":"|          | t^X                |                    |           | |-----|----|--------------------|--------------------|-----------| |     |    | 0                  | 1                  | Sum       | |-----|----|--------------------|--------------------|-----------| | t^Y | 00 | Pr(t^X=0 & t^Y=00) | Pr(t^X=1 & t^Y=00) | Pr(t^Y=00)| |     | 10 | .                  | .                  | .         | |     | 01 | .                  | .                  | .         | |     | 11 | .                  | .                  | .         | |-----|----|--------------------|--------------------|-----------| |     |Sum | Pr(t^X=0)          | Pr(t^X=1)          | 1         |"},{"path":"/reference/set_confound.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set confound — set_confound","text":"","code":"make_model('X -> Y; X <-> Y') |> get_parameters() #> Error in get_parameters(make_model(\"X -> Y; X <-> Y\")): could not find function \"get_parameters\"  make_model('X -> M -> Y; X <-> Y') |> get_parameters() #> Error in get_parameters(make_model(\"X -> M -> Y; X <-> Y\")): could not find function \"get_parameters\"  model <- make_model('X -> M -> Y; X <-> Y; M <-> Y') model$parameters_df #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>  #>  first 10 rows:  #>      param_names node gen  param_set nodal_type     given param_value priors #> 1            X.0    X   1          X          0                  0.50      1 #> 2            X.1    X   1          X          1                  0.50      1 #> 3           M.00    M   2          M         00                  0.25      1 #> 4           M.10    M   2          M         10                  0.25      1 #> 5           M.01    M   2          M         01                  0.25      1 #> 6           M.11    M   2          M         11                  0.25      1 #> 7  Y.00_M.00_X.0    Y   3 Y.M.00.X.0         00 M.00, X.0        0.25      1 #> 8  Y.10_M.00_X.0    Y   3 Y.M.00.X.0         10 M.00, X.0        0.25      1 #> 9  Y.01_M.00_X.0    Y   3 Y.M.00.X.0         01 M.00, X.0        0.25      1 #> 10 Y.11_M.00_X.0    Y   3 Y.M.00.X.0         11 M.00, X.0        0.25      1  # Example where set_confound is implemented after restrictions make_model(\"A -> B -> C\") |> set_restrictions(increasing(\"A\", \"B\")) |> set_confound(\"B <-> C\") |> get_parameters() #> Error in get_parameters(set_confound(set_restrictions(make_model(\"A -> B -> C\"),     increasing(\"A\", \"B\")), \"B <-> C\")): could not find function \"get_parameters\"  # Example where two parents are confounded make_model('A -> B <- C; A <-> C') |>   set_parameters(node = \"C\", c(0.05, .95, .95, 0.05)) |>   make_data(n = 50) |>   cor() #> Warning: A specified condition matches multiple parameters. In these cases it is unclear which parameter value should be assigned to which parameter. Assignment thus defaults to the order in which parameters appear in 'parameters_df'. We advise checking that parameter assignment was carried out as you intended.  #> Warning: You are altering parameters on confounded nodes. Alterations will be applied across all 'param_sets'. If this is not the alteration behavior you intended, try specifying the 'param_set' or 'given' option to more clearly indicate parameters whose values you wish to alter. #>             A           C           B #> A  1.00000000 -0.91987179 -0.08353438 #> C -0.91987179  1.00000000  0.08353438 #> B -0.08353438  0.08353438  1.00000000   # Example with two confounds, added sequentially model <- make_model('A -> B -> C') |>   set_confound(list(\"A <-> B\", \"B <-> C\")) model$statement #> [1] \"A -> B -> C; B <-> A; C <-> B\" # plot(model)"},{"path":"/reference/set_parameter_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Set parameter matrix — set_parameter_matrix","title":"Set parameter matrix — set_parameter_matrix","text":"Add parameter matrix model","code":""},{"path":"/reference/set_parameter_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set parameter matrix — set_parameter_matrix","text":"","code":"set_parameter_matrix(model, P = NULL)"},{"path":"/reference/set_parameter_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set parameter matrix — set_parameter_matrix","text":"model causal_model. model object generated make_model. P data.frame. Parameter matrix. required may provided avoid repeated computation simulations.","code":""},{"path":"/reference/set_parameter_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set parameter matrix — set_parameter_matrix","text":"object class causal_model. essentially returns   list containing elements comprising model   (e.g. 'statement', 'nodal_types' 'DAG') parameter matrix   attached .","code":""},{"path":"/reference/set_parameter_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set parameter matrix — set_parameter_matrix","text":"","code":"model <- make_model('X -> Y') P <- diag(8) colnames(P) <- rownames(model$causal_types) model <- set_parameter_matrix(model, P = P)"},{"path":"/reference/set_parmap.html","id":null,"dir":"Reference","previous_headings":"","what":"Set parmap: a matrix mapping from parameters to data types — set_parmap","title":"Set parmap: a matrix mapping from parameters to data types — set_parmap","text":"Generates adds parmap model","code":""},{"path":"/reference/set_parmap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set parmap: a matrix mapping from parameters to data types — set_parmap","text":"","code":"set_parmap(model)"},{"path":"/reference/set_parmap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set parmap: a matrix mapping from parameters to data types — set_parmap","text":"model causal_model. model object generated make_model.","code":""},{"path":"/reference/set_parmap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set parmap: a matrix mapping from parameters to data types — set_parmap","text":"matrix","code":""},{"path":"/reference/set_parmap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set parmap: a matrix mapping from parameters to data types — set_parmap","text":"","code":"set_parmap(model = make_model('X->Y')) #> Error in set_parmap(model = make_model(\"X->Y\")): could not find function \"set_parmap\""},{"path":"/reference/set_prior_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Add prior distribution draws — set_prior_distribution","title":"Add prior distribution draws — set_prior_distribution","text":"Add `n_param x n_draws` database possible parameter draws model.","code":""},{"path":"/reference/set_prior_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add prior distribution draws — set_prior_distribution","text":"","code":"set_prior_distribution(model, n_draws = 4000)"},{"path":"/reference/set_prior_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add prior distribution draws — set_prior_distribution","text":"model causal_model. model object generated make_model. n_draws scalar. Number draws.","code":""},{"path":"/reference/set_prior_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add prior distribution draws — set_prior_distribution","text":"object class causal_model `prior_distribution`   attached .","code":""},{"path":[]},{"path":"/reference/set_prior_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add prior distribution draws — set_prior_distribution","text":"","code":"make_model('X -> Y') %>%   set_prior_distribution(n_draws = 5) %>%   get_prior_distribution() #> Error in get_prior_distribution(.): could not find function \"get_prior_distribution\""},{"path":"/reference/set_restrictions.html","id":null,"dir":"Reference","previous_headings":"","what":"Restrict a model — set_restrictions","title":"Restrict a model — set_restrictions","text":"Restrict model's parameter space. reduces number nodal types consequence number unit causal types.","code":""},{"path":"/reference/set_restrictions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Restrict a model — set_restrictions","text":"","code":"set_restrictions(   model,   statement = NULL,   join_by = \"|\",   labels = NULL,   param_names = NULL,   given = NULL,   keep = FALSE )"},{"path":"/reference/set_restrictions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Restrict a model — set_restrictions","text":"model causal_model. model object generated make_model. statement quoted expressions defining restriction. values parents specified, statements surrounded parentheses, instance (Y[= 1] > Y[=0]) interpreted combinations parents Y set possible levels might take. join_by string. logical operator joining expanded types statement contains wildcard (.). Can take values '&' (logical ) '|' (logical ). restriction contains wildcard (.) join_by specified, defaults '|', otherwise defaults NULL. Note join_by joins within statements, across statements. labels list character vectors specifying nodal types kept removed model. Use get_nodal_types see syntax. Note labels gets overwritten statement statement NULL. param_names character vector names parameters restrict . given character vector list character vectors specifying nodes parameter set restricted depends. restricting statement, given must either NULL length statement. mixing statements restricted given ones , statements without given restrictions given specified one NULL, NA, \"\" \" \". keep Logical. `FALSE`, removes `TRUE` keeps causal types specified statement labels.","code":""},{"path":"/reference/set_restrictions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Restrict a model — set_restrictions","text":"object class model. causal types nodal types   model reduced according stated restriction.","code":""},{"path":"/reference/set_restrictions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Restrict a model — set_restrictions","text":"Restrictions made nodal types, unit causal types. Thus instance model X -> M -> Y, one apply simple restriction Y nondecreasing  X, however one can restrict M nondecreasing X Y nondecreasing M. restriction Y nondecreasing X otherwise require restrictions causal types, nodal types, implies form undeclared confounding (.e. cases M decreasing X, Y decreasing M). Since restrictions nodal types, parents node implicitly fixed.  Thus model make_model(`X -> Y <- W`) request set_restrictions(`(Y[X=1] == 0)`) interpreted set_restrictions(`(Y[X=1, W=0] == 0 | Y[X=1, W=1] == 0)`). Statements implicitly controlled nodes surrounded parentheses, examples. Note prior probabilities redistributed remaining types.","code":""},{"path":[]},{"path":"/reference/set_restrictions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Restrict a model — set_restrictions","text":"","code":"# 1. Restrict parameter space using statements model <- make_model('X->Y') %>%   set_restrictions(statement = c('X[] == 0'))  model <- make_model('X->Y') %>%   set_restrictions(non_increasing('X', 'Y'))  model <- make_model('X -> Y <- W') %>%   set_restrictions(c(decreasing('X', 'Y'), substitutes('X', 'W', 'Y')))  model$parameters_df #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>  #>  first 10 rows:  #>    param_names node gen param_set nodal_type given param_value priors #> 1          W.0    W   1         W          0         0.5000000      1 #> 2          W.1    W   1         W          1         0.5000000      1 #> 3          X.0    X   2         X          0         0.5000000      1 #> 4          X.1    X   2         X          1         0.5000000      1 #> 5       Y.0000    Y   3         Y       0000         0.1428571      1 #> 10      Y.1010    Y   3         Y       1010         0.1428571      1 #> 13      Y.0001    Y   3         Y       0001         0.1428571      1 #> 15      Y.0101    Y   3         Y       0101         0.1428571      1 #> 17      Y.0011    Y   3         Y       0011         0.1428571      1 #> 18      Y.1011    Y   3         Y       1011         0.1428571      1  model <- make_model('X-> Y <- W') %>%   set_restrictions(statement = decreasing('X', 'Y')) model$parameters_df #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>  #>  first 10 rows:  #>    param_names node gen param_set nodal_type given param_value priors #> 1          W.0    W   1         W          0         0.5000000      1 #> 2          W.1    W   1         W          1         0.5000000      1 #> 3          X.0    X   2         X          0         0.5000000      1 #> 4          X.1    X   2         X          1         0.5000000      1 #> 5       Y.0000    Y   3         Y       0000         0.1111111      1 #> 9       Y.0010    Y   3         Y       0010         0.1111111      1 #> 10      Y.1010    Y   3         Y       1010         0.1111111      1 #> 13      Y.0001    Y   3         Y       0001         0.1111111      1 #> 15      Y.0101    Y   3         Y       0101         0.1111111      1 #> 17      Y.0011    Y   3         Y       0011         0.1111111      1  model <- make_model('X->Y') %>%   set_restrictions(decreasing('X', 'Y')) model$parameters_df #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>   param_names node gen param_set nodal_type given param_value priors #> 1         X.0    X   1         X          0         0.5000000      1 #> 2         X.1    X   1         X          1         0.5000000      1 #> 3        Y.00    Y   2         Y         00         0.3333333      1 #> 5        Y.01    Y   2         Y         01         0.3333333      1 #> 6        Y.11    Y   2         Y         11         0.3333333      1  model <- make_model('X->Y') %>%   set_restrictions(c(increasing('X', 'Y'), decreasing('X', 'Y'))) model$parameters_df #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>   param_names node gen param_set nodal_type given param_value priors #> 1         X.0    X   1         X          0               0.5      1 #> 2         X.1    X   1         X          1               0.5      1 #> 3        Y.00    Y   2         Y         00               0.5      1 #> 6        Y.11    Y   2         Y         11               0.5      1 # \\donttest{ # Restrict to define a model with monotonicity model <- make_model('X->Y') %>% set_restrictions(statement = c('Y[X=1] < Y[X=0]')) get_parameter_matrix(model) #> Error in get_parameter_matrix(model): could not find function \"get_parameter_matrix\"  # Restrict to a single type in endogenous node model <- make_model('X->Y') %>% set_restrictions(statement =  '(Y[X = 1] == 1)', join_by = '&', keep = TRUE) get_parameter_matrix(model) #> Error in get_parameter_matrix(model): could not find function \"get_parameter_matrix\"  #  Use of | and & # Keep node if *for some value of B* Y[A = 1] == 1 model <- make_model('A->Y<-B') %>% set_restrictions(statement =  '(Y[A = 1] == 1)', join_by = '|', keep = TRUE) dim(get_parameter_matrix(model)) #> Error in get_parameter_matrix(model): could not find function \"get_parameter_matrix\"   # Keep node if *for all values of B* Y[A = 1] == 1 model <- make_model('A->Y<-B') %>% set_restrictions(statement =  '(Y[A = 1] == 1)', join_by = '&', keep = TRUE) dim(get_parameter_matrix(model)) #> Error in get_parameter_matrix(model): could not find function \"get_parameter_matrix\"  # Restrict multiple nodes model <- make_model('X->Y<-M; X -> M' ) %>% set_restrictions(statement =  c('(Y[X = 1] == 1)', '(M[X = 1] == 1)'),                  join_by = '&', keep = TRUE) get_parameter_matrix(model) #> Error in get_parameter_matrix(model): could not find function \"get_parameter_matrix\"  # Restrict using statements and given: model <- make_model(\"X -> Y -> Z; X <-> Z\") %>%  set_restrictions(list(decreasing('X','Y'), decreasing('Y','Z')),                   given = c(NA,'X.0')) get_parameter_matrix(model) #> Error in get_parameter_matrix(model): could not find function \"get_parameter_matrix\"  # Restrictions on levels for endogenous nodes aren't allowed if (FALSE) { model <- make_model('X->Y') %>% set_restrictions(statement =  '(Y == 1)') }  # 2. Restrict parameter space Using labels: model <- make_model('X->Y') %>% set_restrictions(labels = list(X = '0', Y = '00'))  # Restrictions can be  with wildcards model <- make_model('X->Y') %>% set_restrictions(labels = list(Y = '?0')) get_parameter_matrix(model) #> Error in get_parameter_matrix(model): could not find function \"get_parameter_matrix\"  # Deterministic model model <- make_model('S -> C -> Y <- R <- X; X -> C -> R') %>% set_restrictions(labels = list(C = '1000', R = '0001', Y = '0001'),                  keep = TRUE) get_parameter_matrix(model) #> Error in get_parameter_matrix(model): could not find function \"get_parameter_matrix\"  # Restrict using labels and given: model <- make_model(\"X -> Y -> Z; X <-> Z\") %>%  set_restrictions(labels = list(X = '0', Z = '00'), given = c(NA,'X.0')) get_parameter_matrix(model) #> Error in get_parameter_matrix(model): could not find function \"get_parameter_matrix\" # }"},{"path":"/reference/set_sampling_args.html","id":null,"dir":"Reference","previous_headings":"","what":"set_sampling_args\r\nFrom 'rstanarm' (November 1st, 2019) — set_sampling_args","title":"set_sampling_args\r\nFrom 'rstanarm' (November 1st, 2019) — set_sampling_args","text":"set_sampling_args 'rstanarm' (November 1st, 2019)","code":""},{"path":"/reference/set_sampling_args.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"set_sampling_args\r\nFrom 'rstanarm' (November 1st, 2019) — set_sampling_args","text":"","code":"set_sampling_args(object, user_dots = list(), user_adapt_delta = NULL, ...)"},{"path":"/reference/set_sampling_args.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"set_sampling_args\r\nFrom 'rstanarm' (November 1st, 2019) — set_sampling_args","text":"object stanfit object. user_dots list. User commands. user_adapt_delta double 0 1. Adapt delta passed user ... arguments passed 'stan'","code":""},{"path":"/reference/set_sampling_args.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"set_sampling_args\r\nFrom 'rstanarm' (November 1st, 2019) — set_sampling_args","text":"list arguments passed stan","code":""},{"path":"/reference/set_sampling_args.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"set_sampling_args\r\nFrom 'rstanarm' (November 1st, 2019) — set_sampling_args","text":"Set sampling arguments","code":""},{"path":"/reference/simulate_data.html","id":null,"dir":"Reference","previous_headings":"","what":"simulate_data is an alias for make_data — simulate_data","title":"simulate_data is an alias for make_data — simulate_data","text":"simulate_data alias make_data","code":""},{"path":"/reference/simulate_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"simulate_data is an alias for make_data — simulate_data","text":"","code":"simulate_data(...)"},{"path":"/reference/simulate_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"simulate_data is an alias for make_data — simulate_data","text":"... arguments make_model","code":""},{"path":"/reference/simulate_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"simulate_data is an alias for make_data — simulate_data","text":"data.frame simulated data.","code":""},{"path":"/reference/simulate_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"simulate_data is an alias for make_data — simulate_data","text":"","code":"simulate_data(make_model(\"X->Y\")) #>   X Y #> 1 0 1"},{"path":"/reference/st_within.html","id":null,"dir":"Reference","previous_headings":"","what":"Get string between two regular expression patterns — st_within","title":"Get string between two regular expression patterns — st_within","text":"Returns substring enclosed two regular expression patterns. default returns name arguments indexed squared brackets ([]) string containing expression.","code":""},{"path":"/reference/st_within.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get string between two regular expression patterns — st_within","text":"","code":"st_within(   x,   left = \"[^_[:^punct:]]|\\\\b\",   right = \"\\\\[\",   rm_left = 0,   rm_right = -1 )"},{"path":"/reference/st_within.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get string between two regular expression patterns — st_within","text":"x character string. left character string. Regular expression serve look ahead. right character string. Regular expression serve look behind. rm_left integer. Number bites left-side match remove result. Defaults -1. rm_right integer. Number bites right-side match remove result. Defaults 0.","code":""},{"path":"/reference/st_within.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get string between two regular expression patterns — st_within","text":"character vector.","code":""},{"path":"/reference/st_within.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get string between two regular expression patterns — st_within","text":"","code":"a <- '(XX[Y=0] == 1) > (XX[Y=1] == 0)' CausalQueries:::st_within(a) #> [1] \"XX\" \"XX\" b <- '(XXX[[Y=0]] == 1 + XXX[[Y=1]] == 0)' CausalQueries:::st_within(b) #> [1] \"XXX\" \"XXX\""},{"path":"/reference/substitutes.html","id":null,"dir":"Reference","previous_headings":"","what":"Make statement for substitutes — substitutes","title":"Make statement for substitutes — substitutes","text":"Generate statement X1, X1 substitute production Y","code":""},{"path":"/reference/substitutes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make statement for substitutes — substitutes","text":"","code":"substitutes(X1, X2, Y)"},{"path":"/reference/substitutes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make statement for substitutes — substitutes","text":"X1 character. quoted name input node 1. X2 character. quoted name input node 2. Y character. quoted name outcome node.","code":""},{"path":"/reference/substitutes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make statement for substitutes — substitutes","text":"character statement class statement","code":""},{"path":[]},{"path":"/reference/substitutes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make statement for substitutes — substitutes","text":"","code":"# \\donttest{ get_query_types(model = make_model('A -> B <- C'),          query = substitutes('A', 'C', 'B'),map = \"causal_type\") #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  ((B[A=1,C=1])-(B[A=0,C=1]))<((B[A=1,C=0])-(B[A=0,C=0]))  #>  #> A0.C0.B0100  A1.C0.B0100 #> A0.C1.B0100  A1.C1.B0100 #> A0.C0.B0010  A1.C0.B0010 #> A0.C1.B0010  A1.C1.B0010 #> A0.C0.B0110  A1.C0.B0110 #> A0.C1.B0110  A1.C1.B0110 #> A0.C0.B1110  A1.C0.B1110 #> A0.C1.B1110  A1.C1.B1110 #> A0.C0.B0111  A1.C0.B0111 #> A0.C1.B0111  A1.C1.B0111 #>  #>  #>  Number of causal types that meet condition(s) =  20 #>  Total number of causal types in model =  64  query_model(model = make_model('A -> B <- C'),          queries = substitutes('A', 'C', 'B'),          using = 'parameters') #>  #> Causal queries generated by query_model (all at population level) #>  #> |query                                                                             |using      |  mean| #> |:---------------------------------------------------------------------------------|:----------|-----:| #> |((B[A = 1, C = 1]) - (B[A = 0, C = 1])) < ((B[A = 1, C = 0]) - (B[A = 0, C = 0])) |parameters | 0.312| #>  # }"},{"path":"/reference/summarise_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"helper to compute mean and sd of a distribution data.frame — summarise_distribution","title":"helper to compute mean and sd of a distribution data.frame — summarise_distribution","text":"helper compute mean sd distribution data.frame","code":""},{"path":"/reference/summarise_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"helper to compute mean and sd of a distribution data.frame — summarise_distribution","text":"","code":"summarise_distribution(x)"},{"path":"/reference/summary.causal_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing causal models — summary.causal_model","title":"Summarizing causal models — summary.causal_model","text":"summary method class causal_model.","code":""},{"path":"/reference/summary.causal_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing causal models — summary.causal_model","text":"","code":"# S3 method for causal_model summary(object, ...)  # S3 method for summary.causal_model print(x, stanfit = FALSE, ...)"},{"path":"/reference/summary.causal_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing causal models — summary.causal_model","text":"object object causal_model class produced using make_model update_model. ... arguments passed methods. x object summary.causal_model class, usually result call summary.causal_model. stanfit Logical. Whether include readable summary stanfit produced updating model via update_model. Defaults `FALSE`.","code":""},{"path":"/reference/summary.causal_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarizing causal models — summary.causal_model","text":"print.summary.causal_model reports DAG data frame, full specification nodal types summary model restrictions addition standard print.causal_model output.","code":""},{"path":"/reference/te.html","id":null,"dir":"Reference","previous_headings":"","what":"Make treatment effect statement (positive) — te","title":"Make treatment effect statement (positive) — te","text":"Generate statement (Y(1) - Y(0)). statement applied model returns element (1,0,-1) set cases. useful purposes querying model, uses require list types, set_restrictions.","code":""},{"path":"/reference/te.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make treatment effect statement (positive) — te","text":"","code":"te(X, Y)"},{"path":"/reference/te.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make treatment effect statement (positive) — te","text":"X character. quoted name input node Y character. quoted name outcome node","code":""},{"path":"/reference/te.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make treatment effect statement (positive) — te","text":"character statement class statement","code":""},{"path":[]},{"path":"/reference/te.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make treatment effect statement (positive) — te","text":"","code":"# \\donttest{ te('A', 'B') #>  #> Statement:  #> (B[A=1] - B[A=0])  model <- make_model('X->Y') %>% set_restrictions(increasing('X', 'Y')) query_model(model, list(ate = te('X', 'Y')),  using = 'parameters') #>  #> Causal queries generated by query_model (all at population level) #>  #> |query |using      |   mean| #> |:-----|:----------|------:| #> |ate   |parameters | -0.333| #>   # set_restrictions  breaks with te because it requires a listing # of causal types, not numeric output. # } if (FALSE) { model <- make_model('X->Y') %>% set_restrictions(te('X', 'Y')) }"},{"path":"/reference/type_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate type matrix — type_matrix","title":"Generate type matrix — type_matrix","text":"Generate type matrix","code":""},{"path":"/reference/type_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate type matrix — type_matrix","text":"","code":"type_matrix(parent_n)"},{"path":"/reference/type_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate type matrix — type_matrix","text":"parent_n integer. Number parents given child.","code":""},{"path":"/reference/type_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate type matrix — type_matrix","text":"data.frame whose rows contain digits   causal types model","code":""},{"path":"/reference/type_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate type matrix — type_matrix","text":"","code":"# \\donttest{ CausalQueries:::type_matrix(2) #>    00 10 01 11 #> 1   0  0  0  0 #> 2   1  0  0  0 #> 3   0  1  0  0 #> 4   1  1  0  0 #> 5   0  0  1  0 #> 6   1  0  1  0 #> 7   0  1  1  0 #> 8   1  1  1  0 #> 9   0  0  0  1 #> 10  1  0  0  1 #> 11  0  1  0  1 #> 12  1  1  0  1 #> 13  0  0  1  1 #> 14  1  0  1  1 #> 15  0  1  1  1 #> 16  1  1  1  1 # }"},{"path":"/reference/uncollapse_nodal_types.html","id":null,"dir":"Reference","previous_headings":"","what":"uncollapse nodal types — uncollapse_nodal_types","title":"uncollapse nodal types — uncollapse_nodal_types","text":"uncollapse nodal types","code":""},{"path":"/reference/uncollapse_nodal_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"uncollapse nodal types — uncollapse_nodal_types","text":"","code":"uncollapse_nodal_types(nodal_types)"},{"path":"/reference/uncollapse_nodal_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"uncollapse nodal types — uncollapse_nodal_types","text":"nodal_types list nodal types collapsed form ('01', '11') etc..","code":""},{"path":"/reference/uncollapse_nodal_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"uncollapse nodal types — uncollapse_nodal_types","text":"list containing nodes nodal types data.frame form","code":""},{"path":"/reference/uncollapse_nodal_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"uncollapse nodal types — uncollapse_nodal_types","text":"","code":"model <- make_model('X -> K -> Y') (nodal_types <- get_nodal_types(model , collapse = TRUE)) #> Error in get_nodal_types(model, collapse = TRUE): could not find function \"get_nodal_types\" CausalQueries:::uncollapse_nodal_types(nodal_types) #> Error in lapply(nodal_types, stringr::str_split, \"\"): object 'nodal_types' not found"},{"path":"/reference/unpack_wildcard.html","id":null,"dir":"Reference","previous_headings":"","what":"Unpack a wild card — unpack_wildcard","title":"Unpack a wild card — unpack_wildcard","text":"Unpack wild card","code":""},{"path":"/reference/unpack_wildcard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unpack a wild card — unpack_wildcard","text":"","code":"unpack_wildcard(x)"},{"path":"/reference/unpack_wildcard.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unpack a wild card — unpack_wildcard","text":"x character. nodal type containing one wildcard characters '?' unpacked.","code":""},{"path":"/reference/unpack_wildcard.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unpack a wild card — unpack_wildcard","text":"type label wildcard characters '?' substituted 0 1.","code":""},{"path":"/reference/update_causal_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Update causal types based on nodal types — update_causal_types","title":"Update causal types based on nodal types — update_causal_types","text":"Update causal types based nodal types","code":""},{"path":"/reference/update_causal_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update causal types based on nodal types — update_causal_types","text":"","code":"update_causal_types(model, restrict_given = NULL)"},{"path":"/reference/update_causal_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update causal types based on nodal types — update_causal_types","text":"model causal_model. model object generated make_model. restrict_given character vector subsetting instructions rows dropped causal types data.frame.","code":""},{"path":"/reference/update_causal_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update causal types based on nodal types — update_causal_types","text":"data.frame containing updated causal types model","code":""},{"path":"/reference/update_causal_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update causal types based on nodal types — update_causal_types","text":"","code":"CausalQueries:::update_causal_types(make_model('X->Y')) #>  #> Causal Types:  #> cartesian product of nodal types #>  #>        X  Y #> X0.Y00 0 00 #> X1.Y00 1 00 #> X0.Y10 0 10 #> X1.Y10 1 10 #> X0.Y01 0 01 #> X1.Y01 1 01 #> X0.Y11 0 11 #> X1.Y11 1 11"},{"path":"/reference/update_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit causal model using 'stan' — update_model","title":"Fit causal model using 'stan' — update_model","text":"Takes model data returns model object data attached posterior model","code":""},{"path":"/reference/update_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit causal model using 'stan' — update_model","text":"","code":"update_model(   model,   data = NULL,   data_type = NULL,   keep_type_distribution = TRUE,   keep_event_probabilities = FALSE,   keep_fit = FALSE,   censored_types = NULL,   ... )"},{"path":"/reference/update_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit causal model using 'stan' — update_model","text":"model causal_model. model object generated make_model. data data.frame.  Data nodes can take three values: 0, 1, NA. long form generated make_events data_type Either 'long' (made make_data) 'compact' (made collapse_data). Compact data must entries member strategy family produce valid simplex. long form data provided missingness, missing data assumed missing random. keep_type_distribution Logical. Whether keep (transformed) distribution causal types.  Defaults `TRUE` keep_event_probabilities Logical. Whether keep (transformed) distribution event probabilities. Defaults `FALSE` keep_fit Logical. Whether keep stanfit object produced rstan::sampling inspection. See ?stanfit details. Defaults `FALSE`. Note  stanfit object internal names parameters (lambda), event probabilities (w), type distribution (types) censored_types vector data types selected data, e.g. c(\"X0Y0\") ... Options passed onto sampling call. details see ?rstan::sampling","code":""},{"path":"/reference/update_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit causal model using 'stan' — update_model","text":"object class causal_model. returned model   list containing elements comprising model   (e.g. 'statement', 'nodal_types' 'DAG')  posterior_distribution returned stan attached .","code":""},{"path":[]},{"path":"/reference/update_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit causal model using 'stan' — update_model","text":"","code":"model <- make_model('X->Y')  data_long   <- simulate_data(model, n = 4)  data_short  <- collapse_data(data_long, model)  # \\donttest{  model <-  update_model(model, data_long) #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 1.9e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.123 seconds (Warm-up) #> Chain 1:                0.109 seconds (Sampling) #> Chain 1:                0.232 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1.7e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.13 seconds (Warm-up) #> Chain 2:                0.127 seconds (Sampling) #> Chain 2:                0.257 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 1.7e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.134 seconds (Warm-up) #> Chain 3:                0.171 seconds (Sampling) #> Chain 3:                0.305 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 1.6e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.124 seconds (Warm-up) #> Chain 4:                0.128 seconds (Sampling) #> Chain 4:                0.252 seconds (Total) #> Chain 4:   model <-  update_model(model, data_short) #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.3e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.121 seconds (Warm-up) #> Chain 1:                0.106 seconds (Sampling) #> Chain 1:                0.227 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1.8e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.12 seconds (Warm-up) #> Chain 2:                0.114 seconds (Sampling) #> Chain 2:                0.234 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 1.7e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.133 seconds (Warm-up) #> Chain 3:                0.116 seconds (Sampling) #> Chain 3:                0.249 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 1.6e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.115 seconds (Warm-up) #> Chain 4:                0.117 seconds (Sampling) #> Chain 4:                0.232 seconds (Total) #> Chain 4:   # }  if (FALSE) {    # It is possible to implement updating without data, in which    # case the posterior is a stan object that reflects the prior    update_model(model)     data <- data.frame(X=rep(0:1, 10), Y=rep(0:1,10))     # Censored data types    # We update less than we might because we are aware of filtered data    uncensored <-      make_model(\"X->Y\") |>      update_model(data) |>      query_model(te(\"X\", \"Y\"), using = \"posteriors\")     censored <-      make_model(\"X->Y\") |>      update_model(        data,        censored_types = c(\"X1Y0\")) |>      query_model(te(\"X\", \"Y\"), using = \"posteriors\")      # Censored data: We learn nothing because the data    # we see is the only data we could ever see    make_model(\"X->Y\") |>      update_model(        data,        censored_types = c(\"X1Y0\", \"X0Y0\", \"X0Y1\")) |>      query_model(te(\"X\", \"Y\"), using = \"posteriors\")  }"},{"path":"/news/index.html","id":"causalqueries-102","dir":"Changelog","previous_headings":"","what":"CausalQueries 1.0.2","title":"CausalQueries 1.0.2","text":"CRAN release: 2024-01-15","code":""},{"path":[]},{"path":"/news/index.html","id":"id_1-passing-nodal_types-to-make_model-now-implements-correct-error-handling-1-0-2","dir":"Changelog","previous_headings":"Bug Fixes","what":"1. passing nodal_types to make_model() now implements correct error handling","title":"CausalQueries 1.0.2","text":"Previously make_model(\"X -> Y\" , nodal_types = list(Y = c(\"0\", \"1\"))) permissible leading setting nodal_types: led undefined behavior unhelpful downstream error messages. passing nodal_types make_model() users now forced specify set nodal_types node.","code":"$X NULL  $Y [1] \"0\" \"1\""},{"path":[]},{"path":"/news/index.html","id":"id_3-node-naming-checks-are-operational-in-make_model-1-0-2","dir":"Changelog","previous_headings":"Bug Fixes","what":"3. node naming checks are operational in make_model()","title":"CausalQueries 1.0.2","text":"Previously hyphenated names throw error corrupted silently conversion model definition strings dagitty objects. Checks correct variable naming now reinstated.","code":"make_model(\"institutions -> political-inequality\")  Statement:  [1] \"institutions -> political-inequality\"  DAG:          parent  children 1 institutions political"},{"path":[]},{"path":"/news/index.html","id":"id_1-type-safety-1-0-2","dir":"Changelog","previous_headings":"Improvements","what":"1. type safety","title":"CausalQueries 1.0.2","text":"Calls sapply() ben replaced vapply() wherever possible enforce type safety.","code":""},{"path":"/news/index.html","id":"id_2-range-based-looping-1-0-2","dir":"Changelog","previous_headings":"Improvements","what":"2. range based looping","title":"CausalQueries 1.0.2","text":"Looping via index replaced range based looping wherever possible guard 0 length exceptions.","code":""},{"path":"/news/index.html","id":"id_3-goodpracticegp-1-0-2","dir":"Changelog","previous_headings":"Improvements","what":"3. goodpractice::gp()","title":"CausalQueries 1.0.2","text":"goodpractice code improvements implemented.","code":""},{"path":"/news/index.html","id":"causalqueries-100","dir":"Changelog","previous_headings":"","what":"CausalQueries 1.0.0","title":"CausalQueries 1.0.0","text":"CRAN release: 2023-10-13","code":""},{"path":"/news/index.html","id":"non-backwards-compatible-changes-1-0-0","dir":"Changelog","previous_headings":"","what":"Non Backwards Compatible Changes","title":"CausalQueries 1.0.0","text":"query_distribution() now supports use multiple queries one function call thus returns DataFrame distribution draws instead single numeric vector.","code":""},{"path":[]},{"path":"/news/index.html","id":"querying-1-0-0","dir":"Changelog","previous_headings":"New Functionality","what":"Querying","title":"CausalQueries 1.0.0","text":"query_distribution(): now supports specification multiple queries givens evaluated single model one function call. query_model(): now supports specification multiple models evaluate set queries one function call. eliminates need redundant function calls querying models substantially improves computation time computationally expensive function calls produce data structures required querying now reduced minimum via redundancy elimination caching.","code":"model <- make_model(\"X -> Y\")    query_distribution(model,    query = list(\"(Y[X=1] > Y[X=0])\", \"(Y[X=1] < Y[X=0])\"),    given = list(\"Y==1\", \"(Y[X=1] <= Y[X=0])\"),    using = \"priors\")|>  head() models <- list(   M1 = make_model(\"X -> Y\"),   M2 = make_model(\"X -> Y\") |> set_restrictions(\"Y[X=1] < Y[X=0]\")   )     query_model(   models,   query = list(ATE = \"Y[X=1] - Y[X=0]\", Share_positive = \"Y[X=1] > Y[X=0]\"),   given = c(TRUE,  \"Y==1 & X==1\"),   using = c(\"parameters\", \"priors\"),   expand_grid = FALSE)   query_model(   models,   query = list(ATE = \"Y[X=1] - Y[X=0]\", Share_positive = \"Y[X=1] > Y[X=0]\"),   given = c(TRUE,  \"Y==1 & X==1\"),   using = c(\"parameters\", \"priors\"),   expand_grid = TRUE)"},{"path":"/news/index.html","id":"realising-outcomes-and-interpreting-nodal-causal-types-1-0-0","dir":"Changelog","previous_headings":"New Functionality","what":"Realising Outcomes and Interpreting Nodal-/Causal-Types","title":"CausalQueries 1.0.0","text":"realise_outcomes(): specifying node option now produces DataFrame detailing specified node responds parents presence absence operations. produces reduced form usual realise_outcomes() output detailing causal-types; aids interpretation nodal- causal-types. update resolves previous bugs errors relating specification nodes multiple parents node option.","code":"model <- make_model(\"X1 -> M -> Y -> Z; X2 -> Y\") |>   realise_outcomes(dos = list(M = 1), node = \"Y\")"},{"path":[]},{"path":"/news/index.html","id":"id_1-setting-parameters-and-priors-1-0-0","dir":"Changelog","previous_headings":"Bug Fixes","what":"1. Setting Parameters and Priors","title":"CausalQueries 1.0.0","text":"Previously set_parameters() set_priors() default applying changes order parameters appeared parameters_df DataFrame; regardless order changes specified aforementioned functions. Calling: results following parameters_df. Now changes parameters values get applied order specified function call; resulting following parameters_df example: Additionally implemented helpful warnings instructions identifying parameters updated specified. particularly useful setting priors parameters models confounding changes may inadvertently applied across param_sets.","code":"model <- make_model(\"X -> Y\")  set_priors(model, alphas = c(3,4), nodal_type = c(\"10\",00)) param_names node    gen param_set nodal_type given param_value priors   <chr>       <chr> <int> <chr>     <chr>      <chr>       <dbl>  <dbl> 1 X.0         X         1 X         0          \"\"           0.5       1 2 X.1         X         1 X         1          \"\"           0.5       1 3 Y.00        Y         2 Y         00         \"\"           0.25      3 4 Y.10        Y         2 Y         10         \"\"           0.25      4 5 Y.01        Y         2 Y         01         \"\"           0.25      1 6 Y.11        Y         2 Y         11         \"\"           0.25      1 param_names node    gen param_set nodal_type given param_value priors   <chr>       <chr> <int> <chr>     <chr>      <chr>       <dbl>  <dbl> 1 X.0         X         1 X         0          \"\"           0.5       1 2 X.1         X         1 X         1          \"\"           0.5       1 3 Y.00        Y         2 Y         00         \"\"           0.25      4 4 Y.10        Y         2 Y         10         \"\"           0.25      3 5 Y.01        Y         2 Y         01         \"\"           0.25      1 6 Y.11        Y         2 Y         11         \"\"           0.25      1"},{"path":"/news/index.html","id":"id_2-updating-with-censored-types-1-0-0","dir":"Changelog","previous_headings":"Bug Fixes","what":"2. Updating with Censored Types","title":"CausalQueries 1.0.0","text":"Previously updating models censored types fail 0s w vector induced censoring evaluate -Inf Stan MCMC algorithm began sampling posterior multinational distribution. resolved issue pruning w vector multinomial run. preserves true w vector (event probabilities without censoring) still updating censored data-","code":""},{"path":"/news/index.html","id":"id_3-setting-restrictions-with-wild-cards-1-0-0","dir":"Changelog","previous_headings":"Bug Fixes","what":"3. Setting Restrictions with Wild Cards","title":"CausalQueries 1.0.0","text":"Previously wildcards set_restrictions() erroneously interpreted valid nodal types, leading errors undefined behavior. Proper unpacking mapping wildcards existing nodal types restored.","code":""},{"path":"/news/index.html","id":"id_4-checks-for-misspecified-queries-1-0-0","dir":"Changelog","previous_headings":"Bug Fixes","what":"4. Checks for Misspecified Queries","title":"CausalQueries 1.0.0","text":"Previously misspecifications queries like Y[X==1]=1 lead undefined behavior mapping queries nodal causal types. now correct misspecified queries internally warn misspecification. example; running: now produces","code":"model <- CausalQueries::make_model(\"X -> Y\") get_query_types(model, \"Y[X=1]=1\") Causal types satisfying query's condition(s)     query =  Y[X=1]==1   X0.Y01  X1.Y01 X0.Y11  X1.Y11    Number of causal types that meet condition(s) =  4  Total number of causal types in model =  8 Warning message: In check_query(query) :   statements to the effect that the realization of a node should equal some value should be specified with `==` not `=`.    The query has been changed accordingly: Y[X=1]==1"},{"path":"/news/index.html","id":"id_5-allowing-overwriting-of-a-parameter-matrix-1-0-0","dir":"Changelog","previous_headings":"Bug Fixes","what":"5. Allowing overwriting of a Parameter Matrix","title":"CausalQueries 1.0.0","text":"Previously parameter matrix P attached causal_model object overwritten. Overwrites now possible.","code":""},{"path":[]},{"path":"/news/index.html","id":"id_1-fast-realise_outcomes-1-0-0","dir":"Changelog","previous_headings":"Improvements","what":"1. Fast realise_outcomes()","title":"CausalQueries 1.0.0","text":"achieved ~100 fold speed gain realise_outcomes() functionality. Nodal types given node generated Cartesian product parent realizations. Consider meaning nodal types node Y 3 parents [X1,X2,X3]: row DataFrame corresponds digit Y's nodal types. first digit nodal type Y (see first row ), corresponds realization Y X1 = 0, X2 = 0, X3 = 0. fourth digit nodal type Y (see fourth row ), corresponds realization Y X1 = 1, X2 = 1, X3 = 0. Finding position realization value Y nodal type given parent realizations equivalent finding row number Cartesian product DataFrame. definition Cartesian product, number consecutive 0 1 elements given column 2columnindex, indexing columns 0. Given set parent realizations R indexed 0, corresponding row number DataFrame indexed 0 can thus computed via: $$row = (\\sum_{= 0}^{|R| - 1} (2^{} \\times R_i))$$. implement fast C++ version computing powers 2 via bit shifting.","code":""},{"path":"/news/index.html","id":"id_2-stan-update-1-0-0","dir":"Changelog","previous_headings":"Improvements","what":"2. Stan update","title":"CausalQueries 1.0.0","text":"updated new array syntax introduced Stan v2.33.0","code":""}]
