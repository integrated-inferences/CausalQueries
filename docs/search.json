[{"path":"/articles/1 getting-started.html","id":"make-a-model","dir":"Articles","previous_headings":"","what":"Make a model","title":"Getting Started","text":"Generating: make model need provide DAG statement make_model. instance \"X->Y\" \"X -> M -> Y <- X\" \"Z -> X -> Y <-> X\". Graphing: made model can inspect DAG:  Inspecting: model set parameters default distribution . Tailoring: features can edited using set_restrictions, set_priors set_parameters. example setting monotonicity restriction (see ?set_restrictions ): example setting monotonicity restriction (see ?set_restrictions ): example setting priors (see ?set_priors ): Simulation: Data can drawn model like :","code":"# examples of models xy_model <- make_model(\"X -> Y\") iv_model <- make_model(\"Z -> X -> Y <-> X\") plot(iv_model) xy_model |> grab(\"parameters_df\") |> kable() iv_model <-    iv_model |> set_restrictions(decreasing('Z', 'X')) iv_model <-    iv_model |> set_priors(distribution = \"jeffreys\") #> No specific parameters to alter values for specified. Altering all parameters. data <- make_data(iv_model, n = 4)   data |> kable()"},{"path":"/articles/1 getting-started.html","id":"model-updating","dir":"Articles","previous_headings":"","what":"Model updating","title":"Getting Started","text":"Updating: Update using update_model. can pass rstan arguments update_model. Inspecting: can access posterior distribution model parameters directly thus: row draw parameters.","code":"df <- fabricatr::fabricate(N = 100, X = rbinom(N, 1, .5), Y = rbinom(N, 1, .25 + X*.5))  xy_model <-    xy_model |>    update_model(df, refresh = 0) xy_model |> grab(\"posterior_distribution\") |>    head() |> kable()"},{"path":"/articles/1 getting-started.html","id":"query-model","dir":"Articles","previous_headings":"","what":"Query model","title":"Getting Started","text":"Querying: ask arbitrary causal queries model. Examples unconditional queries: Examples conditional queries: Queries can even conditional counterfactual quantities. probability positive effect given effect:","code":"xy_model |>    query_model(\"Y[X=1] > Y[X=0]\", using = c(\"priors\", \"posteriors\")) |>   kable() xy_model |>    query_model(\"Y[X=1] > Y[X=0]\", using = c(\"priors\", \"posteriors\"),               given = \"X==1 & Y == 1\") |>   kable() xy_model |>    query_model(\"Y[X=1] > Y[X=0]\", using = c(\"priors\", \"posteriors\"),               given = \"Y[X=1] != Y[X=0]\") |>   kable()"},{"path":"/articles/1-getting-started.html","id":"make-a-model","dir":"Articles","previous_headings":"","what":"Make a model","title":"Getting Started","text":"Generating: make model need provide DAG statement make_model. instance \"X->Y\" \"X -> M -> Y <- X\" \"Z -> X -> Y <-> X\". Graphing: made model can inspect DAG:  Inspecting: model set parameters default distribution . Tailoring: features can edited using set_restrictions, set_priors set_parameters. example setting monotonicity restriction (see ?set_restrictions ): example setting monotonicity restriction (see ?set_restrictions ): example setting priors (see ?set_priors ): Simulation: Data can drawn model like :","code":"# examples of models xy_model <- make_model(\"X -> Y\") iv_model <- make_model(\"Z -> X -> Y <-> X\") plot(iv_model) xy_model |> grab(\"parameters_df\") |> kable() iv_model <-    iv_model |> set_restrictions(decreasing('Z', 'X')) iv_model <-    iv_model |> set_priors(distribution = \"jeffreys\") #> No specific parameters to alter values for specified. Altering all parameters. data <- make_data(iv_model, n = 4)   data |> kable()"},{"path":"/articles/1-getting-started.html","id":"model-updating","dir":"Articles","previous_headings":"","what":"Model updating","title":"Getting Started","text":"Updating: Update using update_model. can pass rstan arguments update_model. Inspecting: can access posterior distribution model parameters directly thus: row draw parameters.","code":"df <- fabricatr::fabricate(N = 100, X = rbinom(N, 1, .5), Y = rbinom(N, 1, .25 + X*.5))  xy_model <-    xy_model |>    update_model(df, refresh = 0) xy_model |> grab(\"posterior_distribution\") |>    head() |> kable()"},{"path":"/articles/1-getting-started.html","id":"query-model","dir":"Articles","previous_headings":"","what":"Query model","title":"Getting Started","text":"Querying: ask arbitrary causal queries model. Examples unconditional queries: Examples conditional queries: Queries can even conditional counterfactual quantities. probability positive effect given effect:","code":"xy_model |>    query_model(\"Y[X=1] > Y[X=0]\", using = c(\"priors\", \"posteriors\")) |>   kable() xy_model |>    query_model(\"Y[X=1] > Y[X=0]\", using = c(\"priors\", \"posteriors\"),               given = \"X==1 & Y == 1\") |>   kable() xy_model |>    query_model(\"Y[X=1] > Y[X=0]\", using = c(\"priors\", \"posteriors\"),               given = \"Y[X=1] != Y[X=0]\") |>   kable()"},{"path":"/articles/2-front-door.html","id":"try-it","dir":"Articles","previous_headings":"","what":"Try it","title":"Through the front door","text":"Say X, M, Y perfectly correlated. average treatment effect identified?","code":""},{"path":"/articles/3-inspecting-posteriors.html","id":"accessing-the-posterior","dir":"Articles","previous_headings":"","what":"Accessing the posterior","title":"Inspecting posteriors","text":"update model using CausalQueries, CausalQueries generates updates stan model saves posterior distribution parameters model. basic usage : posterior parameters can accessed thus: querying model can request use posterior distribution using argument:","code":"data <- data.frame(X = rep(c(0:1), 10), Y = rep(c(0:1), 10))  model <- make_model(\"X -> Y\") |>    update_model(data) grab(model, \"posterior_distribution\") #> Summary statistics of model parameter posterior distributions: #> : 4000 rows (draws) by 6 cols (parameters) #>  #>      mean   sd #> X.0  0.50 0.10 #> X.1  0.50 0.10 #> Y.00 0.08 0.07 #> Y.10 0.04 0.04 #> Y.01 0.80 0.11 #> Y.11 0.08 0.07 model |>    query_model(     query = \"Y[X=1] > Y[X=0]\",     using = c(\"priors\", \"posteriors\")) |>   kable(digits = 2)"},{"path":"/articles/3-inspecting-posteriors.html","id":"summary-of-stan-performance","dir":"Articles","previous_headings":"","what":"Summary of stan performance","title":"Inspecting posteriors","text":"can access summary parameter values convergence information produced stan thus: summary provides information distribution parameters well convergence diagnostics, summarized Rhat column. printout first 6 rows show distribution model parameters; next 8 rows show distribution transformed parameters, causal types. last row shows unnormalized log density Stan’s unconstrained space , described Stan documentation intended diagnose sampling efficiency evaluate approximations. See stan documentation details.","code":"grab(model, \"stan_summary\") #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>              mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> X.0          0.50    0.00 0.10   0.30   0.43   0.50   0.57   0.69  2154    1 #> X.1          0.50    0.00 0.10   0.31   0.43   0.50   0.57   0.70  2154    1 #> Y.00         0.08    0.00 0.07   0.00   0.02   0.06   0.11   0.26  1773    1 #> Y.10         0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  4250    1 #> Y.01         0.80    0.00 0.11   0.54   0.74   0.82   0.88   0.96  4103    1 #> Y.11         0.08    0.00 0.07   0.00   0.02   0.06   0.11   0.27  4101    1 #> X0.Y00       0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  1876    1 #> X1.Y00       0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  1739    1 #> X0.Y10       0.02    0.00 0.02   0.00   0.01   0.01   0.03   0.07  4079    1 #> X1.Y10       0.02    0.00 0.02   0.00   0.01   0.01   0.03   0.08  4044    1 #> X0.Y01       0.40    0.00 0.10   0.22   0.33   0.40   0.47   0.59  2385    1 #> X1.Y01       0.40    0.00 0.10   0.22   0.33   0.40   0.46   0.60  2649    1 #> X0.Y11       0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  3893    1 #> X1.Y11       0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  3897    1 #> lp__       -14.60    0.04 1.57 -18.64 -15.34 -14.23 -13.45 -12.65  1232    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Mar 25 23:50:39 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1)."},{"path":"/articles/3-inspecting-posteriors.html","id":"advanced-diagnostics","dir":"Articles","previous_headings":"","what":"Advanced diagnostics","title":"Inspecting posteriors","text":"interested advanced diagnostics performance can save access raw stan output. Note summary raw output shows labels used generic stan model: lambda vector parameters, corresponding parameters parameters dataframe (grab(model, \"parameters_df\")), , saved, vector types causal types (see grab(model, \"causal_types\")) w event probabilities (grab(model, \"event_probabilities\")). can use diagnostic packages bayesplot.","code":"model <- make_model(\"X -> Y\") |>    update_model(data, keep_fit = TRUE) model |> grab(\"stan_fit\") #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>              mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> lambdas[1]   0.50    0.00 0.10   0.30   0.43   0.50   0.57   0.71  1864    1 #> lambdas[2]   0.50    0.00 0.10   0.29   0.43   0.50   0.57   0.70  1864    1 #> lambdas[3]   0.08    0.00 0.08   0.00   0.03   0.06   0.12   0.29  2483    1 #> lambdas[4]   0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  4442    1 #> lambdas[5]   0.80    0.00 0.11   0.53   0.73   0.82   0.88   0.95  4524    1 #> lambdas[6]   0.08    0.00 0.07   0.00   0.03   0.06   0.11   0.27  4297    1 #> types[1]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  2354    1 #> types[2]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  2528    1 #> types[3]     0.02    0.00 0.02   0.00   0.01   0.01   0.03   0.08  4353    1 #> types[4]     0.02    0.00 0.02   0.00   0.01   0.01   0.03   0.08  4018    1 #> types[5]     0.40    0.00 0.10   0.21   0.33   0.40   0.47   0.60  2398    1 #> types[6]     0.39    0.00 0.10   0.20   0.33   0.39   0.46   0.60  2363    1 #> types[7]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  4085    1 #> types[8]     0.04    0.00 0.04   0.00   0.01   0.03   0.05   0.14  3689    1 #> lp__       -14.56    0.04 1.51 -18.32 -15.33 -14.21 -13.43 -12.65  1567    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Mar 25 23:50:43 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). model |> grab(\"stan_fit\") |>   bayesplot::mcmc_pairs(pars = c(\"lambdas[3]\", \"lambdas[4]\", \"lambdas[5]\", \"lambdas[6]\")) np <- model |> grab(\"stan_fit\") |> bayesplot::nuts_params() head(np) |> kable() model |> grab(\"stan_fit\") |>   bayesplot::mcmc_trace(pars = \"lambdas[5]\", np = np)  #> No divergences to plot."},{"path":"/articles/front-door.html","id":"try-it","dir":"Articles","previous_headings":"","what":"Try it","title":"Through the front door","text":"Say X, M, Y perfectly correlated. average treatment effect identified?","code":""},{"path":"/articles/getting-started.html","id":"make-a-model","dir":"Articles","previous_headings":"","what":"Make a model","title":"1 Getting Started","text":"Generating: make model need provide DAG statement make_model. instance \"X->Y\" \"X -> M -> Y <- X\" \"Z -> X -> Y <-> X\". Graphing: made model can inspect DAG:  Inspecting: model set parameters default distribution . Tailoring: features can edited using set_restrictions, set_priors set_parameters. example setting monotonicity restriction (see ?set_restrictions ): example setting monotonicity restriction (see ?set_restrictions ): example setting priors (see ?set_priors ): Simulation: Data can drawn model like :","code":"# examples of models xy_model <- make_model(\"X -> Y\") iv_model <- make_model(\"Z -> X -> Y <-> X\") plot(iv_model) xy_model |> grab(\"parameters_df\") |> kable() iv_model <-    iv_model |> set_restrictions(decreasing('Z', 'X')) iv_model <-    iv_model |> set_priors(distribution = \"jeffreys\") #> No specific parameters to alter values for specified. Altering all parameters. data <- make_data(iv_model, n = 4)   data |> kable()"},{"path":"/articles/getting-started.html","id":"model-updating","dir":"Articles","previous_headings":"","what":"Model updating","title":"1 Getting Started","text":"Updating: Update using update_model. can pass rstan arguments update_model. Inspecting: can access posterior distribution model parameters directly thus: row draw parameters.","code":"df <- fabricatr::fabricate(N = 100, X = rbinom(N, 1, .5), Y = rbinom(N, 1, .25 + X*.5))  xy_model <-    xy_model |>    update_model(df, refresh = 0) xy_model |> grab(\"posterior_distribution\") |>    head() |> kable()"},{"path":"/articles/getting-started.html","id":"query-model","dir":"Articles","previous_headings":"","what":"Query model","title":"1 Getting Started","text":"Querying: ask arbitrary causal queries model. Examples unconditional queries: Examples conditional queries: Queries can even conditional counterfactual quantities. probability positive effect given effect:","code":"xy_model |>    query_model(\"Y[X=1] > Y[X=0]\", using = c(\"priors\", \"posteriors\")) |>   kable() xy_model |>    query_model(\"Y[X=1] > Y[X=0]\", using = c(\"priors\", \"posteriors\"),               given = \"X==1 & Y == 1\") |>   kable() xy_model |>    query_model(\"Y[X=1] > Y[X=0]\", using = c(\"priors\", \"posteriors\"),               given = \"Y[X=1] != Y[X=0]\") |>   kable()"},{"path":"/articles/inspecting-posteriors.html","id":"accessing-the-posterior","dir":"Articles","previous_headings":"","what":"Accessing the posterior","title":"Inspecting posteriors","text":"update model using CausalQueries, CausalQueries generates updates stan model saves posterior distribution parameters model. basic usage : posterior parameters can accessed thus: querying model can request use posterior distribution using argument:","code":"data <- data.frame(X = rep(c(0:1), 10), Y = rep(c(0:1), 10))  model <- make_model(\"X -> Y\") |>    update_model(data) grab(model, \"posterior_distribution\") #> Summary statistics of model parameter posterior distributions: #> Draws: 4000 #> rows are parameters #>      mean   sd #> X.0  0.50 0.10 #> X.1  0.50 0.10 #> Y.00 0.08 0.07 #> Y.10 0.04 0.04 #> Y.01 0.80 0.11 #> Y.11 0.08 0.07 model |>    query_model(     query = \"Y[X=1] > Y[X=0]\",     using = c(\"priors\", \"posteriors\")) |>   kable(digits = 2)"},{"path":"/articles/inspecting-posteriors.html","id":"summary-of-stan-performance","dir":"Articles","previous_headings":"","what":"Summary of stan performance","title":"Inspecting posteriors","text":"can access summary parameter values convergence information produced stan thus: summary provides information distribution parameters well convergence diagnostics, summarized Rhat column. printout first 6 rows show distribution model parameters; next 8 rows show distribution transformed parameters, causal types. last row shows unnormalized log density Stan’s unconstrained space , described Stan documentation intended diagnose sampling efficiency evaluate approximations. See stan documentation details.","code":"grab(model, \"stan_summary\") #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>              mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> X.0          0.50    0.00 0.10   0.30   0.43   0.50   0.57   0.70  1954    1 #> X.1          0.50    0.00 0.10   0.30   0.43   0.50   0.57   0.70  1954    1 #> Y.00         0.08    0.00 0.07   0.00   0.03   0.06   0.12   0.28  1917    1 #> Y.10         0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  4003    1 #> Y.01         0.80    0.00 0.11   0.52   0.73   0.81   0.88   0.95  3952    1 #> Y.11         0.08    0.00 0.07   0.00   0.02   0.06   0.11   0.28  4293    1 #> X0.Y00       0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  1930    1 #> X1.Y00       0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  1911    1 #> X0.Y10       0.02    0.00 0.02   0.00   0.01   0.01   0.03   0.07  3998    1 #> X1.Y10       0.02    0.00 0.02   0.00   0.01   0.01   0.03   0.08  3710    1 #> X0.Y01       0.40    0.00 0.10   0.21   0.32   0.40   0.46   0.59  2639    1 #> X1.Y01       0.40    0.00 0.10   0.21   0.33   0.40   0.47   0.59  2382    1 #> X0.Y11       0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  3842    1 #> X1.Y11       0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  4209    1 #> lp__       -14.60    0.04 1.55 -18.53 -15.38 -14.23 -13.48 -12.66  1196    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Mar 25 14:53:46 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1)."},{"path":"/articles/inspecting-posteriors.html","id":"advanced-diagnostics","dir":"Articles","previous_headings":"","what":"Advanced diagnostics","title":"Inspecting posteriors","text":"interested advanced diagnostics performance can save access raw stan output. Note summary raw output shows labels used generic stan model: lambda vector parameters, corresponding parameters parameters dataframe (grab(model, \"parameters_df\")), , saved, vector types causal types (see grab(model, \"causal_types\")) w event probabilities (grab(model, \"event_probabilities\")). can use diagnostic packages bayesplot.","code":"model <- make_model(\"X -> Y\") |>    update_model(data, keep_fit = TRUE) model |> grab(\"stan_fit\") #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>              mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> lambdas[1]   0.50    0.00 0.11   0.30   0.42   0.50   0.58   0.71  1923    1 #> lambdas[2]   0.50    0.00 0.11   0.29   0.42   0.50   0.58   0.70  1923    1 #> lambdas[3]   0.08    0.00 0.07   0.00   0.02   0.06   0.11   0.27  1634    1 #> lambdas[4]   0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  4226    1 #> lambdas[5]   0.80    0.00 0.11   0.54   0.73   0.82   0.88   0.95  4238    1 #> lambdas[6]   0.08    0.00 0.08   0.00   0.02   0.06   0.12   0.29  4573    1 #> types[1]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  1668    1 #> types[2]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  1823    1 #> types[3]     0.02    0.00 0.02   0.00   0.01   0.01   0.03   0.07  3539    1 #> types[4]     0.02    0.00 0.02   0.00   0.01   0.01   0.03   0.08  4250    1 #> types[5]     0.40    0.00 0.10   0.21   0.33   0.40   0.47   0.60  2312    1 #> types[6]     0.40    0.00 0.10   0.21   0.33   0.39   0.47   0.60  2378    1 #> types[7]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  4166    1 #> types[8]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  4452    1 #> lp__       -14.71    0.06 1.69 -18.84 -15.48 -14.34 -13.51 -12.69   813    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Mar 25 14:53:48 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). model |> grab(\"stan_fit\") |>   bayesplot::mcmc_pairs(pars = c(\"lambdas[3]\", \"lambdas[4]\", \"lambdas[5]\", \"lambdas[6]\")) np <- model |> grab(\"stan_fit\") |> bayesplot::nuts_params() head(np) |> kable() model |> grab(\"stan_fit\") |>   bayesplot::mcmc_trace(pars = \"lambdas[5]\", np = np)  #> No divergences to plot."},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Clara Bicalho. Contributor. Jasper Cooper. Contributor. Macartan Humphreys. Author. Till Tietz. Author, maintainer. Alan Jacobs. Author. Merlin Heidemanns. Contributor. Lily Medina. Author. Julio Solis. Contributor. Georgiy Syunyaev. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Humphreys M, Tietz T, Jacobs , Medina L, Syunyaev G (2024). CausalQueries: Make, Update, Query Binary Causal Models. R package version 1.0.2.","code":"@Manual{,   title = {CausalQueries: Make, Update, and Query Binary Causal Models},   author = {Macartan Humphreys and Till Tietz and Alan Jacobs and Lily Medina and Georgiy Syunyaev},   year = {2024},   note = {R package version 1.0.2}, }"},{"path":"/index.html","id":"causalqueries","dir":"","previous_headings":"","what":"Make, Update, and Query Binary Causal Models","title":"Make, Update, and Query Binary Causal Models","text":"https://integrated-inferences.github.io/CausalQueries/ CausalQueries package lets declare binary causal models, update beliefs causal types given data calculate arbitrary estimands. Model definition makes use dagitty functionality. Updating implemented stan. See vignettes guide getting started. See guide using CausalQueries along many examples causal models","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Make, Update, and Query Binary Causal Models","text":"install latest stable release CausalQueries: install latest development release :","code":"install.packages(\"CausalQueries\") install.packages(\"devtools\") devtools::install_github(\"integrated-inferences/CausalQueries\")"},{"path":"/index.html","id":"causal-models","dir":"","previous_headings":"","what":"Causal models","title":"Make, Update, and Query Binary Causal Models","text":"Causal models defined : directed acyclic graph (DAG), provides set variables, causal ordering , set assumptions regarding conditional independence. arrow B change never induces change B. Functional forms. Functional forms describe causal relationships nodes. often make strong assumptions specify functional form; fortunately however variables categorical need functional forms usual sense. DAG implies set “causal types.” Units can classed together causal type respond way variables. instance, type might set units X=1 Y=1 X=1. set causal types grows rapidly number nodes number nodes pointing given node. setting imposing functional forms placing restrictions causal types: restrictions reduce complexity require substantive assumptions. example restriction might “Y monotonic X.” Priors. standard case, DAG plus restrictions imply set parameters combine form causal types. parameters want learn . learn first provide priors parameters. priors specified causal model complete (“probabilistic causal model”) ready inference. Setting priors done using set_priors function many examples can seen typing ? set_priors.R. wrinkle: possible nodes related ways captured DAG. cases dotted curves sometimes placed nodes graph. possible specify possible unobservable confounding causal model. implications parameter space.","code":""},{"path":"/index.html","id":"inference","dir":"","previous_headings":"","what":"Inference","title":"Make, Update, and Query Binary Causal Models","text":"goal form beliefs parameters also substantive estimands: causal model hand data available nodes, possible make use generic stan model generates posteriors parameter vector. Given updated (prior) beliefs parameters possible calculate causal estimands inference causal model. example “probability X cause Y given X=1, Y=1 Z=1.”","code":""},{"path":"/index.html","id":"credits-etc","dir":"","previous_headings":"","what":"Credits etc","title":"Make, Update, and Query Binary Causal Models","text":"approach used CausalQueries developed Humphreys Jacobs 2023 drawing work probabilistic causal models described Pearl’s Causality (Pearl, 2009). thank Ben Goodrich provided generous insights using stan project. thank Alan M Jacobs key work developing framework underlying package. thanks Jasper Cooper contributions generating generic function create Stan code, Clara Bicalho helped figure syntax causal statements, Julio S. Solís Arce made many key contributions figuring simplify specification priors, Merlin Heidemanns figured rstantools integration made myriad code improvements.","code":""},{"path":"/reference/add_dots.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper to fill in missing do operators in causal expression — add_dots","title":"Helper to fill in missing do operators in causal expression — add_dots","text":"Helper fill missing operators causal expression","code":""},{"path":"/reference/add_dots.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper to fill in missing do operators in causal expression — add_dots","text":"","code":"add_dots(q, model)"},{"path":"/reference/add_dots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper to fill in missing do operators in causal expression — add_dots","text":"q character string. Causal query least one parent node missing operator. model causal_model. model object generated make_model.","code":""},{"path":"/reference/add_dots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper to fill in missing do operators in causal expression — add_dots","text":"causal query expression parents nodes set   either 0, 1 wildcard '.'.","code":""},{"path":"/reference/add_dots.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helper to fill in missing do operators in causal expression — add_dots","text":"","code":"# \\donttest{ model <- make_model('X -> Y <- M') CausalQueries:::add_dots('Y[X=1]', model) #> [1] \"Y[X=1, M = . ]\" CausalQueries:::add_dots('Y[]', model) #> [1] \"Y[M = . , X = . ]\" # }"},{"path":"/reference/add_wildcard.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds a wildcard for every missing parent — add_wildcard","title":"Adds a wildcard for every missing parent — add_wildcard","text":"Adds wildcard every missing parent","code":""},{"path":"/reference/add_wildcard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds a wildcard for every missing parent — add_wildcard","text":"","code":"add_wildcard(node, statement, parents, missing_parents)"},{"path":"/reference/add_wildcard.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds a wildcard for every missing parent — add_wildcard","text":"node character string. quoted name node. statement character string. quoted causal statement. parents vector characters. node's parents missing_parents vector characters.  node's missing parents","code":""},{"path":"/reference/add_wildcard.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adds a wildcard for every missing parent — add_wildcard","text":"causal query expression parents nodes set  either 0, 1 wildcard '.'","code":""},{"path":"/reference/CausalQueries-package.html","id":null,"dir":"Reference","previous_headings":"","what":"'CausalQueries' — CausalQueries-package","title":"'CausalQueries' — CausalQueries-package","text":"'CausalQueries' package lets generate binary causal models, update models given data calculate arbitrary causal queries. Model definition makes use dagitty syntax. Updating implemented 'stan'.","code":""},{"path":"/reference/CausalQueries_internal_inherit_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Create parameter documentation to inherit — CausalQueries_internal_inherit_params","title":"Create parameter documentation to inherit — CausalQueries_internal_inherit_params","text":"Create parameter documentation inherit","code":""},{"path":"/reference/CausalQueries_internal_inherit_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create parameter documentation to inherit — CausalQueries_internal_inherit_params","text":"","code":"CausalQueries_internal_inherit_params(   model,   query,   join_by,   parameters,   P,   A,   data,   data_events,   node,   statement,   using,   n_draws )"},{"path":"/reference/CausalQueries_internal_inherit_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create parameter documentation to inherit — CausalQueries_internal_inherit_params","text":"model causal_model. model object generated make_model. query character string. expression defining nodal types interrogate realise_outcomes. expression form \"Y[X=1]\" asks value Y X set 1 join_by logical operator. Used connect causal statements: ('&') ('|'). Defaults '|'. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn model$parameters_df. P data.frame. Parameter matrix. required may provided avoid repeated computation simulations. data.frame. Ambiguity matrix. required may provided avoid repeated computation simulations. data data.frame.  Data nodes can take three values: 0, 1, NA. long form generated make_events data_events data.frame. must compatible nodes model. default columns event, strategy count. node character string. quoted name node. statement character string. quoted causal statement. using character string. Indicates whether use `priors`, `posteriors` `parameters`. n_draws integer. prior distribution provided, generate prior distribution n_draws number draws.","code":""},{"path":"/reference/CausalQueries_internal_inherit_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create parameter documentation to inherit — CausalQueries_internal_inherit_params","text":"function return anything. used   inherit roxygen documentation","code":""},{"path":"/reference/causal_type_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Names for causal types — causal_type_names","title":"Names for causal types — causal_type_names","text":"Names causal types","code":""},{"path":"/reference/causal_type_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Names for causal types — causal_type_names","text":"","code":"causal_type_names(causal_types)"},{"path":"/reference/causal_type_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Names for causal types — causal_type_names","text":"causal_types data.frame whose rows containing 0-1 digits conform causal types.","code":""},{"path":"/reference/causal_type_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Names for causal types — causal_type_names","text":"data.frame whose rows contain character values   conform causal type model.","code":""},{"path":"/reference/causal_type_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Names for causal types — causal_type_names","text":"","code":"# \\donttest{ model <- make_model('X -> Y') possible_types <- grab(model, \"nodal_types\") df <- data.frame(expand.grid(possible_types, stringsAsFactors = FALSE)) CausalQueries:::causal_type_names(df) #>    X   Y #> 1 X0 Y00 #> 2 X1 Y00 #> 3 X0 Y10 #> 4 X1 Y10 #> 5 X0 Y01 #> 6 X1 Y01 #> 7 X0 Y11 #> 8 X1 Y11 # }"},{"path":"/reference/check_args.html","id":null,"dir":"Reference","previous_headings":"","what":"helper to check arguments — check_args","title":"helper to check arguments — check_args","text":"helper check arguments","code":""},{"path":"/reference/check_args.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"helper to check arguments — check_args","text":"","code":"check_args(model, using, given, queries, case_level, fun)"},{"path":"/reference/check_args.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"helper to check arguments — check_args","text":"model passed parent function using passed parent function given passed parent function queries passed parent function fun string specifying name parent function","code":""},{"path":"/reference/check_args.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"helper to check arguments — check_args","text":"list altered arguments","code":""},{"path":"/reference/check_query.html","id":null,"dir":"Reference","previous_headings":"","what":"Warn about improper query specification and apply fixes — check_query","title":"Warn about improper query specification and apply fixes — check_query","text":"Warn improper query specification apply fixes","code":""},{"path":"/reference/check_query.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Warn about improper query specification and apply fixes — check_query","text":"","code":"check_query(query)"},{"path":"/reference/check_query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Warn about improper query specification and apply fixes — check_query","text":"query string specifying query","code":""},{"path":"/reference/check_query.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Warn about improper query specification and apply fixes — check_query","text":"fixed query string","code":""},{"path":"/reference/check_string_input.html","id":null,"dir":"Reference","previous_headings":"","what":"Check string_input — check_string_input","title":"Check string_input — check_string_input","text":"Check string_input","code":""},{"path":"/reference/check_string_input.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check string_input — check_string_input","text":"","code":"check_string_input(param_list = list(), call_name = NULL)"},{"path":"/reference/check_string_input.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check string_input — check_string_input","text":"param_list List parameters call_name Name call.","code":""},{"path":"/reference/check_string_input.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check string_input — check_string_input","text":"appropriate, returns error message.","code":""},{"path":"/reference/clean_condition.html","id":null,"dir":"Reference","previous_headings":"","what":"Clean condition — clean_condition","title":"Clean condition — clean_condition","text":"Takes string specifying condition returns properly spaced string.","code":""},{"path":"/reference/clean_condition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clean condition — clean_condition","text":"","code":"clean_condition(condition)"},{"path":"/reference/clean_condition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clean condition — clean_condition","text":"condition character string. Condition refers unique position (possible outcome) nodal type.","code":""},{"path":"/reference/clean_condition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clean condition — clean_condition","text":"properly spaced string.","code":""},{"path":"/reference/clean_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Check parameters sum to 1 in param_set; normalize if needed; add\r\nnames if needed — clean_params","title":"Check parameters sum to 1 in param_set; normalize if needed; add\r\nnames if needed — clean_params","text":"Check parameters sum 1 param_set; normalize needed; add names needed","code":""},{"path":"/reference/clean_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check parameters sum to 1 in param_set; normalize if needed; add\r\nnames if needed — clean_params","text":"","code":"clean_params(parameters_df, warning = TRUE)"},{"path":"/reference/clean_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check parameters sum to 1 in param_set; normalize if needed; add\r\nnames if needed — clean_params","text":"parameters_df data.frame. object first generated make_model. warning Logical. Whether print warning () console. Defaults TRUE","code":""},{"path":"/reference/clean_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check parameters sum to 1 in param_set; normalize if needed; add\r\nnames if needed — clean_params","text":"parameters data.frame  names parameters   sum 1.","code":""},{"path":"/reference/clean_params.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check parameters sum to 1 in param_set; normalize if needed; add\r\nnames if needed — clean_params","text":"","code":"# \\donttest{ model <- make_model('X->Y') model$parameters_df$param_value <- 1:6 CausalQueries:::clean_params(model$parameters_df, warning = TRUE) #> Parameters in set X do not sum to 1. Using normalized parameters #> Parameters in set Y do not sum to 1. Using normalized parameters #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>   param_names node gen param_set nodal_type given param_value priors #> 1         X.0    X   1         X          0         0.3333333      1 #> 2         X.1    X   1         X          1         0.6666667      1 #> 3        Y.00    Y   2         Y         00         0.1666667      1 #> 4        Y.10    Y   2         Y         10         0.2222222      1 #> 5        Y.01    Y   2         Y         01         0.2777778      1 #> 6        Y.11    Y   2         Y         11         0.3333333      1 # }"},{"path":"/reference/clean_param_vector.html","id":null,"dir":"Reference","previous_headings":"","what":"Clean parameter vector — clean_param_vector","title":"Clean parameter vector — clean_param_vector","text":"Clean parameter vector","code":""},{"path":"/reference/clean_param_vector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clean parameter vector — clean_param_vector","text":"","code":"clean_param_vector(model, parameters)"},{"path":"/reference/clean_param_vector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clean parameter vector — clean_param_vector","text":"model causal_model. model object generated make_model. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn model$parameters_df.","code":""},{"path":"/reference/clean_param_vector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clean parameter vector — clean_param_vector","text":"vector named parameters summing 1.","code":""},{"path":"/reference/collapse_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Make compact data with data strategies — collapse_data","title":"Make compact data with data strategies — collapse_data","text":"Take `data.frame` return compact `data.frame` event types strategies.","code":""},{"path":"/reference/collapse_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make compact data with data strategies — collapse_data","text":"","code":"collapse_data(   data,   model,   drop_NA = TRUE,   drop_family = FALSE,   summary = FALSE )"},{"path":"/reference/collapse_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make compact data with data strategies — collapse_data","text":"data data.frame.  Data nodes can take three values: 0, 1, NA. long form generated make_events model causal_model. model object generated make_model. drop_NA Logical. Whether exclude strategy families contain observed data. Exceptionally data provided, minimal data data first node returned. Defaults `TRUE` drop_family Logical. Whether remove column strategy output. Defaults `FALSE`. summary Logical. Whether return summary data. See details. Defaults `FALSE`.","code":""},{"path":"/reference/collapse_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make compact data with data strategies — collapse_data","text":"vector data events summary = TRUE `collapse_data` returns list containing   following components: data_events compact data.frame event types strategies. observed_events vector character strings specifying events      observed data unobserved_events vector character strings specifying      events observed data","code":""},{"path":"/reference/collapse_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make compact data with data strategies — collapse_data","text":"","code":"# \\donttest{  model <- make_model('X -> Y')  df <- data.frame(X = c(0,1,NA), Y = c(0,0,1))  df %>% collapse_data(model) #>   event strategy count #> 1  X0Y0       XY     1 #> 2  X1Y0       XY     1 #> 3  X0Y1       XY     0 #> 4  X1Y1       XY     0 #> 5    Y0        Y     0 #> 6    Y1        Y     1   collapse_data(df, model, drop_NA = FALSE) #>   event strategy count #> 1  X0Y0       XY     1 #> 2  X1Y0       XY     1 #> 3  X0Y1       XY     0 #> 4  X1Y1       XY     0 #> 5    Y0        Y     0 #> 6    Y1        Y     1 #> 7    X0        X     0 #> 8    X1        X     0  collapse_data(df, model, drop_family = TRUE) #>   event count #> 1  X0Y0     1 #> 2  X1Y0     1 #> 3  X0Y1     0 #> 4  X1Y1     0 #> 5    Y0     0 #> 6    Y1     1  collapse_data(df, model, summary = TRUE) #> $data_events #>   event strategy count #> 1  X0Y0       XY     1 #> 2  X1Y0       XY     1 #> 3  X0Y1       XY     0 #> 4  X1Y1       XY     0 #> 5    Y0        Y     0 #> 6    Y1        Y     1 #>  #> $observed_events #> [1] \"X0Y0\" \"X1Y0\" \"Y1\"   #>  #> $unobserved_events #> [1] \"X0Y1\" \"X1Y1\" \"Y0\"   #>   data <- make_data(model, n = 0) collapse_data(data, model) #>   event strategy count #> 1  X0Y0       XY     0 #> 2  X1Y0       XY     0 #> 3  X0Y1       XY     0 #> 4  X1Y1       XY     0  model <- make_model('X -> Y') %>% set_restrictions('X[]==1') df <- make_data(model, n = 10) df[1,1] <- '' collapse_data(df, model) #>   event strategy count #> 1  X0Y0       XY     4 #> 2  X0Y1       XY     5 #> 3    Y0        Y     1 #> 4    Y1        Y     0 data <- data.frame(X= 0:1) collapse_data(data, model) #> X1 data is inconsistent with model and ignored #>   event strategy count #> 1    X0        X     1  # }"},{"path":"/reference/collapse_nodal_types.html","id":null,"dir":"Reference","previous_headings":"","what":"collapse nodal types — collapse_nodal_types","title":"collapse nodal types — collapse_nodal_types","text":"collapse nodal types","code":""},{"path":"/reference/collapse_nodal_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"collapse nodal types — collapse_nodal_types","text":"","code":"collapse_nodal_types(nodal_types, include_node_names = FALSE)"},{"path":"/reference/collapse_nodal_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"collapse nodal types — collapse_nodal_types","text":"nodal_types list nodal types. include_node_names Logical, TRUE returns names X0, X1; otherwise returns 0, 1","code":""},{"path":"/reference/collapse_nodal_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"collapse nodal types — collapse_nodal_types","text":"list containing nodes nodal types vector form.","code":""},{"path":"/reference/collapse_nodal_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"collapse nodal types — collapse_nodal_types","text":"","code":"model <- make_model('X -> K -> Y') (nodal_types <- grab(model, \"nodal_types\", collapse = FALSE)) #> Nodal types:  #> $X #> c(0, 1) #>  #> NULL #>  #> $K #> c(0, 1, 0, 1)  c(0, 0, 1, 1) #>  #> NULL #>  #> $Y #> c(0, 1, 0, 1)  c(0, 0, 1, 1) #>  #> NULL #>  #>  #> Number of types by node #> X K Y  #> 1 2 2  CausalQueries:::collapse_nodal_types(nodal_types ) #> Nodal types:  #> $X #> 0  1 #>  #> NULL #>  #> $K #> 00  10  01  11 #>  #> NULL #>  #> $Y #> 00  10  01  11 #>  #> NULL #>  #>  #> Number of types by node #> X K Y  #> 2 4 4"},{"path":"/reference/complements.html","id":null,"dir":"Reference","previous_headings":"","what":"Make statement for complements — complements","title":"Make statement for complements — complements","text":"Generate statement X1, X1 complement production Y","code":""},{"path":"/reference/complements.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make statement for complements — complements","text":"","code":"complements(X1, X2, Y)"},{"path":"/reference/complements.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make statement for complements — complements","text":"X1 character. quoted name input node 1. X2 character. quoted name input node 2. Y character. quoted name outcome node.","code":""},{"path":"/reference/complements.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make statement for complements — complements","text":"character statement class statement","code":""},{"path":[]},{"path":"/reference/complements.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make statement for complements — complements","text":"","code":"# \\donttest{ complements('A', 'B', 'W') #>  #> Statement:  #> ((W[A =1, B = 1]) - (W[A = 0, B = 1])) > ((W[A =1, B = 0]) - (W[A = 0, B = 0])) # }"},{"path":"/reference/construct_commands_alter_at.html","id":null,"dir":"Reference","previous_headings":"","what":"make_par_values — construct_commands_alter_at","title":"make_par_values — construct_commands_alter_at","text":"helper generate filter commands specifying rows parameters_df altered given alter_at statement","code":""},{"path":"/reference/construct_commands_alter_at.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_par_values — construct_commands_alter_at","text":"","code":"construct_commands_alter_at(alter_at)"},{"path":"/reference/construct_commands_alter_at.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_par_values — construct_commands_alter_at","text":"alter_at string specifying filtering operations applied parameters_df, yielding logical vector indicating parameters values altered.","code":""},{"path":"/reference/construct_commands_alter_at.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"make_par_values — construct_commands_alter_at","text":"string specifying filter command","code":""},{"path":"/reference/construct_commands_other_args.html","id":null,"dir":"Reference","previous_headings":"","what":"make_par_values — construct_commands_other_args","title":"make_par_values — construct_commands_other_args","text":"helper generate filter commands specifying rows parameters_df altered given combinations nodes, nodal_types, param_sets, givens statements","code":""},{"path":"/reference/construct_commands_other_args.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_par_values — construct_commands_other_args","text":"","code":"construct_commands_other_args(   node,   nodal_type,   param_set,   given,   statement,   model,   join_by )"},{"path":"/reference/construct_commands_other_args.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_par_values — construct_commands_other_args","text":"node string indicating nodes altered nodal_type string. Label nodal type indicating nodal types values altered param_set string indicating  name set parameters altered given string indicates node parameter altered depends statement causal query determines nodal types values altered model model created make_model join_by string specifying logical operator joining expanded types statement contains wildcards. Can take values '&' (logical ) '|' (logical ).","code":""},{"path":"/reference/construct_commands_other_args.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"make_par_values — construct_commands_other_args","text":"string specifying filter command","code":""},{"path":"/reference/construct_commands_param_names.html","id":null,"dir":"Reference","previous_headings":"","what":"make_par_values — construct_commands_param_names","title":"make_par_values — construct_commands_param_names","text":"helper generate filter commands specifying rows parameters_df altered given vector parameter names","code":""},{"path":"/reference/construct_commands_param_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_par_values — construct_commands_param_names","text":"","code":"construct_commands_param_names(param_names, model_param_names)"},{"path":"/reference/construct_commands_param_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_par_values — construct_commands_param_names","text":"param_names vector strings. name specific parameter form , example, 'X.1', 'Y.01' model_param_names vector strings. Parameter names found model.","code":""},{"path":"/reference/construct_commands_param_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"make_par_values — construct_commands_param_names","text":"string specifying filter command","code":""},{"path":"/reference/data_to_data.html","id":null,"dir":"Reference","previous_headings":"","what":"helper to generate a matrix mapping from names of M to names of A — data_to_data","title":"helper to generate a matrix mapping from names of M to names of A — data_to_data","text":"helper generate matrix mapping names M names ","code":""},{"path":"/reference/data_to_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"helper to generate a matrix mapping from names of M to names of A — data_to_data","text":"","code":"data_to_data(M, A)"},{"path":"/reference/data_to_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"helper to generate a matrix mapping from names of M to names of A — data_to_data","text":"M matrix matrix","code":""},{"path":"/reference/data_to_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"helper to generate a matrix mapping from names of M to names of A — data_to_data","text":"matrix","code":""},{"path":"/reference/data_type_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Data type names — data_type_names","title":"Data type names — data_type_names","text":"Provides names data types","code":""},{"path":"/reference/data_type_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data type names — data_type_names","text":"","code":"data_type_names(model, data)"},{"path":"/reference/data_type_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data type names — data_type_names","text":"model causal_model. model object generated make_model. data data.frame.  Data nodes can take three values: 0, 1, NA. long form generated make_events","code":""},{"path":"/reference/data_type_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data type names — data_type_names","text":"vector strings data types","code":""},{"path":"/reference/data_type_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data type names — data_type_names","text":"","code":"model <- make_model('X -> Y') data <- make_data(model, n = 2) data_type_names(model, data) #> [1] \"X0Y1\" \"X1Y1\""},{"path":"/reference/decreasing.html","id":null,"dir":"Reference","previous_headings":"","what":"Make monotonicity statement (negative) — decreasing","title":"Make monotonicity statement (negative) — decreasing","text":"Generate statement Y monotonic (decreasing) X","code":""},{"path":"/reference/decreasing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make monotonicity statement (negative) — decreasing","text":"","code":"decreasing(X, Y)"},{"path":"/reference/decreasing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make monotonicity statement (negative) — decreasing","text":"X character. quoted name input node Y character. quoted name outcome node","code":""},{"path":"/reference/decreasing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make monotonicity statement (negative) — decreasing","text":"character statement class statement","code":""},{"path":[]},{"path":"/reference/decreasing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make monotonicity statement (negative) — decreasing","text":"","code":"# \\donttest{ decreasing('A', 'B') #>  #> Statement:  #> (B[A=1] < B[A=0]) # }"},{"path":"/reference/default_stan_control.html","id":null,"dir":"Reference","previous_headings":"","what":"default_stan_control — default_stan_control","title":"default_stan_control — default_stan_control","text":"default_stan_control","code":""},{"path":"/reference/default_stan_control.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"default_stan_control — default_stan_control","text":"","code":"default_stan_control(adapt_delta = NULL, max_treedepth = 15L)"},{"path":"/reference/default_stan_control.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"default_stan_control — default_stan_control","text":"adapt_delta double 0 1. determines adapt_delta max_treedepth positive integer. determines maximum_tree_depth","code":""},{"path":"/reference/default_stan_control.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"default_stan_control — default_stan_control","text":"list containing arguments passed stan","code":""},{"path":"/reference/default_stan_control.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"default_stan_control — default_stan_control","text":"Sets controls default unless otherwise specified.","code":""},{"path":"/reference/democracy_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Development and Democratization: Data for replication of analysis in\r\n*Integrated Inferences* — democracy_data","title":"Development and Democratization: Data for replication of analysis in\r\n*Integrated Inferences* — democracy_data","text":"dataset containing information inequality, democracy, mobilization, international pressure. Made devtools::use_data(democracy_data, CausalQueries)","code":""},{"path":"/reference/democracy_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Development and Democratization: Data for replication of analysis in\r\n*Integrated Inferences* — democracy_data","text":"","code":"democracy_data"},{"path":"/reference/democracy_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Development and Democratization: Data for replication of analysis in\r\n*Integrated Inferences* — democracy_data","text":"data frame 84 rows 5 nodes: Case Case D Democracy Inequality P International Pressure M Mobilization","code":""},{"path":"/reference/democracy_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Development and Democratization: Data for replication of analysis in\r\n*Integrated Inferences* — democracy_data","text":"https://www.cambridge.org/core/journals/american-political-science-review/article/inequality--regime-change-democratic-transitions---stability--democratic-rule/C39AAF4CF274445555FF41F7CC896AE3#fndtn-supplementary-materials/","code":""},{"path":"/reference/draw_causal_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw a single causal type given a parameter vector — draw_causal_type","title":"Draw a single causal type given a parameter vector — draw_causal_type","text":"Output parameter dataframe recording parameters (case level priors) case level causal type.","code":""},{"path":"/reference/draw_causal_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw a single causal type given a parameter vector — draw_causal_type","text":"","code":"draw_causal_type(model, ...)"},{"path":"/reference/draw_causal_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw a single causal type given a parameter vector — draw_causal_type","text":"model causal_model. model object generated make_model. ... Arguments passed  `set_parameters`","code":""},{"path":"/reference/draw_causal_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw a single causal type given a parameter vector — draw_causal_type","text":"","code":"# Simple draw using model's parameter vector make_model(\"X -> M -> Y\") %>% draw_causal_type(.) #> # A tibble: 10 × 9 #>    param_names node    gen param_set nodal_type given param_value priors #>    <chr>       <chr> <int> <chr>     <chr>      <chr>       <dbl>  <dbl> #>  1 X.0         X         1 X         0          \"\"           0.5       1 #>  2 X.1         X         1 X         1          \"\"           0.5       1 #>  3 M.00        M         2 M         00         \"\"           0.25      1 #>  4 M.10        M         2 M         10         \"\"           0.25      1 #>  5 M.01        M         2 M         01         \"\"           0.25      1 #>  6 M.11        M         2 M         11         \"\"           0.25      1 #>  7 Y.00        Y         3 Y         00         \"\"           0.25      1 #>  8 Y.10        Y         3 Y         10         \"\"           0.25      1 #>  9 Y.01        Y         3 Y         01         \"\"           0.25      1 #> 10 Y.11        Y         3 Y         11         \"\"           0.25      1 #> # ℹ 1 more variable: causal_type <int>  # Draw parameters from priors and draw type from parameters make_model(\"X -> M -> Y\") %>% draw_causal_type(., param_type = \"prior_draw\") #> # A tibble: 10 × 9 #>    param_names node    gen param_set nodal_type given param_value priors #>    <chr>       <chr> <int> <chr>     <chr>      <chr>       <dbl>  <dbl> #>  1 X.0         X         1 X         0          \"\"       0.144         1 #>  2 X.1         X         1 X         1          \"\"       0.856         1 #>  3 M.00        M         2 M         00         \"\"       0.439         1 #>  4 M.10        M         2 M         10         \"\"       0.132         1 #>  5 M.01        M         2 M         01         \"\"       0.383         1 #>  6 M.11        M         2 M         11         \"\"       0.0465        1 #>  7 Y.00        Y         3 Y         00         \"\"       0.0224        1 #>  8 Y.10        Y         3 Y         10         \"\"       0.178         1 #>  9 Y.01        Y         3 Y         01         \"\"       0.000677      1 #> 10 Y.11        Y         3 Y         11         \"\"       0.799         1 #> # ℹ 1 more variable: causal_type <int>  # Draw type given specified parameters make_model(\"X -> M -> Y\") %>% draw_causal_type(., parameters = 1:10) #> # A tibble: 10 × 9 #>    param_names node    gen param_set nodal_type given param_value priors #>    <chr>       <chr> <int> <chr>     <chr>      <chr>       <dbl>  <dbl> #>  1 X.0         X         1 X         0          \"\"          0.333      1 #>  2 X.1         X         1 X         1          \"\"          0.667      1 #>  3 M.00        M         2 M         00         \"\"          0.167      1 #>  4 M.10        M         2 M         10         \"\"          0.222      1 #>  5 M.01        M         2 M         01         \"\"          0.278      1 #>  6 M.11        M         2 M         11         \"\"          0.333      1 #>  7 Y.00        Y         3 Y         00         \"\"          0.206      1 #>  8 Y.10        Y         3 Y         10         \"\"          0.235      1 #>  9 Y.01        Y         3 Y         01         \"\"          0.265      1 #> 10 Y.11        Y         3 Y         11         \"\"          0.294      1 #> # ℹ 1 more variable: causal_type <int>  # Define a causal type and reveal data model <- make_model(\"X -> Y; X <-> Y\") type <- model %>% draw_causal_type() make_data(model, parameters = type$causal_type) #>   X Y #> 1 1 0"},{"path":"/reference/drop_empty_families.html","id":null,"dir":"Reference","previous_headings":"","what":"Drop empty families — drop_empty_families","title":"Drop empty families — drop_empty_families","text":"Drop empty families","code":""},{"path":"/reference/drop_empty_families.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Drop empty families — drop_empty_families","text":"","code":"drop_empty_families(data_events)"},{"path":"/reference/drop_empty_families.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Drop empty families — drop_empty_families","text":"data_events data.frame. must compatible nodes model. default columns event, strategy count.","code":""},{"path":"/reference/drop_empty_families.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Drop empty families — drop_empty_families","text":"Returns data events strategies (excluding  strategy families   contain observed data)","code":""},{"path":"/reference/drop_empty_families.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Drop empty families — drop_empty_families","text":"","code":"# \\donttest{ data_events <- data.frame(event = c('X0Y0', 'Y0'),                           strategy = c('XY', 'Y'),                           count = 1:0) CausalQueries:::drop_empty_families(data_events) #>   event strategy count #> 1  X0Y0       XY     1 # }"},{"path":"/reference/expand_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand compact data object to data frame — expand_data","title":"Expand compact data object to data frame — expand_data","text":"Expand compact data object data frame","code":""},{"path":"/reference/expand_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand compact data object to data frame — expand_data","text":"","code":"expand_data(data_events = NULL, model)"},{"path":"/reference/expand_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand compact data object to data frame — expand_data","text":"data_events data.frame. must compatible nodes model. default columns event, strategy count. model causal_model. model object generated make_model.","code":""},{"path":"/reference/expand_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand compact data object to data frame — expand_data","text":"data.frame rows data observation","code":""},{"path":"/reference/expand_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand compact data object to data frame — expand_data","text":"","code":"# \\donttest{ model <- make_model('X->M->Y') make_events(model, n = 5) %>%   expand_data(model) #>   X M Y #> 1 0 0 0 #> 2 0 1 1 #> 3 1 0 0 #> 4 1 1 1 #> 5 1 1 1 make_events(model, n = 0) %>%   expand_data(model) #>    X  M  Y #> 1 NA NA NA  # }"},{"path":"/reference/expand_nodal_expression.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper to expand nodal expression — expand_nodal_expression","title":"Helper to expand nodal expression — expand_nodal_expression","text":"Helper expand nodal expression","code":""},{"path":"/reference/expand_nodal_expression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper to expand nodal expression — expand_nodal_expression","text":"","code":"expand_nodal_expression(model, query, node, join_by = \"|\")"},{"path":"/reference/expand_nodal_expression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper to expand nodal expression — expand_nodal_expression","text":"model causal_model. model object generated make_model. query character string. expression defining nodal types interrogate realise_outcomes. expression form \"Y[X=1]\" asks value Y X set 1 node character string. quoted name node. join_by logical operator. Used connect causal statements: ('&') ('|'). Defaults '|'.","code":""},{"path":"/reference/expand_nodal_expression.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper to expand nodal expression — expand_nodal_expression","text":"nodal expression missing parents","code":""},{"path":"/reference/expand_wildcard.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand wildcard — expand_wildcard","title":"Expand wildcard — expand_wildcard","text":"Expand statement containing wildcard","code":""},{"path":"/reference/expand_wildcard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand wildcard — expand_wildcard","text":"","code":"expand_wildcard(to_expand, join_by = \"|\", verbose = TRUE)"},{"path":"/reference/expand_wildcard.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand wildcard — expand_wildcard","text":"to_expand character vector length 1L. join_by logical operator. Used connect causal statements: ('&') ('|'). Defaults '|'. verbose Logical. Whether print expanded query console.","code":""},{"path":"/reference/expand_wildcard.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand wildcard — expand_wildcard","text":"character string expanded expression.   Wildcard '.' replaced 0 1.","code":""},{"path":"/reference/expand_wildcard.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand wildcard — expand_wildcard","text":"","code":"# Position of parentheses matters for type of expansion # In the \"global expansion\" versions of the entire statement are joined expand_wildcard('(Y[X=1, M=.] > Y[X=1, M=.])') #> Error in expand_wildcard(\"(Y[X=1, M=.] > Y[X=1, M=.])\"): could not find function \"expand_wildcard\" # In the \"local expansion\" versions of indicated parts are joined expand_wildcard('(Y[X=1, M=.]) > (Y[X=1, M=.])') #> Error in expand_wildcard(\"(Y[X=1, M=.]) > (Y[X=1, M=.])\"): could not find function \"expand_wildcard\"  # If parentheses are missing global expansion used. expand_wildcard('Y[X=1, M=.] > Y[X=1, M=.]') #> Error in expand_wildcard(\"Y[X=1, M=.] > Y[X=1, M=.]\"): could not find function \"expand_wildcard\"  # Expressions not requiring expansion are allowed expand_wildcard('(Y[X=1])') #> Error in expand_wildcard(\"(Y[X=1])\"): could not find function \"expand_wildcard\""},{"path":"/reference/find_rounding_threshold.html","id":null,"dir":"Reference","previous_headings":"","what":"helper to find rounding thresholds for print methods — find_rounding_threshold","title":"helper to find rounding thresholds for print methods — find_rounding_threshold","text":"helper find rounding thresholds print methods","code":""},{"path":"/reference/find_rounding_threshold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"helper to find rounding thresholds for print methods — find_rounding_threshold","text":"","code":"find_rounding_threshold(x)"},{"path":"/reference/find_rounding_threshold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"helper to find rounding thresholds for print methods — find_rounding_threshold","text":"x object rounding","code":""},{"path":"/reference/get_all_data_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Get all data types — get_all_data_types","title":"Get all data types — get_all_data_types","text":"Creates dataframe data types (including NA types) possible model.","code":""},{"path":"/reference/get_all_data_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get all data types — get_all_data_types","text":"","code":"get_all_data_types(   model,   complete_data = FALSE,   possible_data = FALSE,   given = NULL )"},{"path":"/reference/get_all_data_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get all data types — get_all_data_types","text":"model causal_model. model object generated make_model. complete_data Logical. `TRUE` returns complete data types (NAs). Defaults `FALSE`. possible_data Logical. `TRUE` returns complete data types (NAs) *possible* given model restrictions. Note principle intervention make observationally impossible data types arise. Defaults `FALSE`. given character.  quoted statement evaluates logical. Data conditional specific values.","code":""},{"path":"/reference/get_all_data_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get all data types — get_all_data_types","text":"data.frame data types (including NA types)   possible model.","code":""},{"path":"/reference/get_all_data_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get all data types — get_all_data_types","text":"","code":"# \\donttest{ make_model('X -> Y') |> get_all_data_types() #>      event  X  Y #> X0Y0  X0Y0  0  0 #> X1Y0  X1Y0  1  0 #> X0Y1  X0Y1  0  1 #> X1Y1  X1Y1  1  1 #> Y0      Y0 NA  0 #> Y1      Y1 NA  1 #> X0      X0  0 NA #> X1      X1  1 NA #> None  None NA NA model <- make_model('X -> Y') %>%   set_restrictions(labels = list(Y = '00'), keep = TRUE)   get_all_data_types(model) #>      event  X  Y #> X0Y0  X0Y0  0  0 #> X1Y0  X1Y0  1  0 #> X0Y1  X0Y1  0  1 #> X1Y1  X1Y1  1  1 #> Y0      Y0 NA  0 #> Y1      Y1 NA  1 #> X0      X0  0 NA #> X1      X1  1 NA #> None  None NA NA   get_all_data_types(model, complete_data = TRUE) #>      event X Y #> X0Y0  X0Y0 0 0 #> X1Y0  X1Y0 1 0 #> X0Y1  X0Y1 0 1 #> X1Y1  X1Y1 1 1   get_all_data_types(model, possible_data = TRUE) #>      event X Y #> X0Y0  X0Y0 0 0 #> X1Y0  X1Y0 1 0   get_all_data_types(model, given  = 'X==1') #>      event X  Y #> X1Y0  X1Y0 1  0 #> X1Y1  X1Y1 1  1 #> X1      X1 1 NA   get_all_data_types(model, given  = 'X==1 & Y==1') #>      event X Y #> X1Y1  X1Y1 1 1 # }"},{"path":"/reference/get_ambiguities_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Get ambiguities matrix — get_ambiguities_matrix","title":"Get ambiguities matrix — get_ambiguities_matrix","text":"Return ambiguities matrix exists; otherwise calculate assuming confounding.ambiguities matrix maps causal types data types.","code":""},{"path":"/reference/get_ambiguities_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get ambiguities matrix — get_ambiguities_matrix","text":"","code":"get_ambiguities_matrix(model)"},{"path":"/reference/get_ambiguities_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get ambiguities matrix — get_ambiguities_matrix","text":"model causal_model. model object generated make_model.","code":""},{"path":"/reference/get_ambiguities_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get ambiguities matrix — get_ambiguities_matrix","text":"data.frame. Causal types (rows) corresponding possible data realizations (columns).","code":""},{"path":"/reference/get_ambiguities_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get ambiguities matrix — get_ambiguities_matrix","text":"","code":"model <- make_model('X -> Y') get_ambiguities_matrix(model = model) #> Error in get_ambiguities_matrix(model = model): could not find function \"get_ambiguities_matrix\""},{"path":"/reference/get_causal_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Get causal types — get_causal_types","title":"Get causal types — get_causal_types","text":"Return data frame types produced combinations possible data produced DAG.","code":""},{"path":"/reference/get_causal_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get causal types — get_causal_types","text":"","code":"get_causal_types(model)"},{"path":"/reference/get_causal_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get causal types — get_causal_types","text":"model causal_model. model object generated make_model.","code":""},{"path":"/reference/get_causal_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get causal types — get_causal_types","text":"data.frame indicating causal types model","code":""},{"path":"/reference/get_causal_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get causal types — get_causal_types","text":"","code":"get_causal_types(make_model('X -> Y')) #> Error in get_causal_types(make_model(\"X -> Y\")): could not find function \"get_causal_types\""},{"path":"/reference/get_data_families.html","id":null,"dir":"Reference","previous_headings":"","what":"get_data_families — get_data_families","title":"get_data_families — get_data_families","text":"Get possible data types","code":""},{"path":"/reference/get_data_families.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get_data_families — get_data_families","text":"","code":"get_data_families(   model,   drop_impossible = TRUE,   drop_all_NA = TRUE,   mapping_only = FALSE )"},{"path":"/reference/get_data_families.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get_data_families — get_data_families","text":"model causal_model. model object generated make_model. drop_impossible Logical. Whether drop data impossible given model restrictions. Defaults `TRUE`. drop_all_NA Logical. Whether drop row `NA`s. Defaults `TRUE` mapping_only Logical. Whether return data mapping matrix . Defaults `FALSE`.","code":""},{"path":"/reference/get_data_families.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"get_data_families — get_data_families","text":"Returns indices ambiguity matrix","code":""},{"path":"/reference/get_data_families.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"get_data_families — get_data_families","text":"","code":"# \\donttest{ CausalQueries:::get_data_families(model = make_model('X->Y')) #>      event strategy X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0  X0Y0       XY    1    0    0    0 #> X1Y0  X1Y0       XY    0    1    0    0 #> X0Y1  X0Y1       XY    0    0    1    0 #> X1Y1  X1Y1       XY    0    0    0    1 #> Y0      Y0        Y    1    1    0    0 #> Y1      Y1        Y    0    0    1    1 #> X0      X0        X    1    0    1    0 #> X1      X1        X    0    1    0    1 CausalQueries:::get_data_families(model = make_model('X->Y'),                                   mapping_only = TRUE) #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 #> Y0      1    1    0    0 #> Y1      0    0    1    1 #> X0      1    0    1    0 #> X1      0    1    0    1 CausalQueries:::get_data_families(model = make_model('X-> M -> Y')) #>         event strategy X0M0Y0 X1M0Y0 X0M1Y0 X1M1Y0 X0M0Y1 X1M0Y1 X0M1Y1 X1M1Y1 #> X0M0Y0 X0M0Y0      XMY      1      0      0      0      0      0      0      0 #> X1M0Y0 X1M0Y0      XMY      0      1      0      0      0      0      0      0 #> X0M1Y0 X0M1Y0      XMY      0      0      1      0      0      0      0      0 #> X1M1Y0 X1M1Y0      XMY      0      0      0      1      0      0      0      0 #> X0M0Y1 X0M0Y1      XMY      0      0      0      0      1      0      0      0 #> X1M0Y1 X1M0Y1      XMY      0      0      0      0      0      1      0      0 #> X0M1Y1 X0M1Y1      XMY      0      0      0      0      0      0      1      0 #> X1M1Y1 X1M1Y1      XMY      0      0      0      0      0      0      0      1 #> M0Y0     M0Y0       MY      1      1      0      0      0      0      0      0 #> M1Y0     M1Y0       MY      0      0      1      1      0      0      0      0 #> M0Y1     M0Y1       MY      0      0      0      0      1      1      0      0 #> M1Y1     M1Y1       MY      0      0      0      0      0      0      1      1 #> X0Y0     X0Y0       XY      1      0      1      0      0      0      0      0 #> X1Y0     X1Y0       XY      0      1      0      1      0      0      0      0 #> X0Y1     X0Y1       XY      0      0      0      0      1      0      1      0 #> X1Y1     X1Y1       XY      0      0      0      0      0      1      0      1 #> X0M0     X0M0       XM      1      0      0      0      1      0      0      0 #> X1M0     X1M0       XM      0      1      0      0      0      1      0      0 #> X0M1     X0M1       XM      0      0      1      0      0      0      1      0 #> X1M1     X1M1       XM      0      0      0      1      0      0      0      1 #> Y0         Y0        Y      1      1      1      1      0      0      0      0 #> Y1         Y1        Y      0      0      0      0      1      1      1      1 #> M0         M0        M      1      1      0      0      1      1      0      0 #> M1         M1        M      0      0      1      1      0      0      1      1 #> X0         X0        X      1      0      1      0      1      0      1      0 #> X1         X1        X      0      1      0      1      0      1      0      1  # }"},{"path":"/reference/get_estimands.html","id":null,"dir":"Reference","previous_headings":"","what":"helper to get estimands — get_estimands","title":"helper to get estimands — get_estimands","text":"helper get estimands","code":""},{"path":"/reference/get_estimands.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"helper to get estimands — get_estimands","text":"","code":"get_estimands(jobs, given_types, query_types, type_distributions)"},{"path":"/reference/get_estimands.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"helper to get estimands — get_estimands","text":"jobs DataFrame argument combinations given_types output queries_to_types query_types output queries_to_types type_distributions output get_type_distributions","code":""},{"path":"/reference/get_estimands.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"helper to get estimands — get_estimands","text":"list estimands","code":""},{"path":"/reference/get_event_probabilities.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw event probabilities — get_event_probabilities","title":"Draw event probabilities — get_event_probabilities","text":"`get_event_probabilities` draws event probability vector `w` given single realization parameters","code":""},{"path":"/reference/get_event_probabilities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw event probabilities — get_event_probabilities","text":"","code":"get_event_probabilities(   model,   parameters = NULL,   A = NULL,   P = NULL,   given = NULL )"},{"path":"/reference/get_event_probabilities.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw event probabilities — get_event_probabilities","text":"model causal_model. model object generated make_model. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn model$parameters_df. data.frame. Ambiguity matrix. required may provided avoid repeated computation simulations. P data.frame. Parameter matrix. required may provided avoid repeated computation simulations. given string specifying known values nodes, e.g. \"X==1 & Y==1\"","code":""},{"path":"/reference/get_event_probabilities.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw event probabilities — get_event_probabilities","text":"array event probabilities","code":""},{"path":"/reference/get_event_probabilities.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw event probabilities — get_event_probabilities","text":"","code":"# \\donttest{ model <- make_model('X -> Y') get_event_probabilities(model = model) #>  #> The probability of observing a given combination of data  #> realizations for a given set of parameter values. #>  #>      event_probs #> X0Y0        0.25 #> X1Y0        0.25 #> X0Y1        0.25 #> X1Y1        0.25 get_event_probabilities(model = model, given = \"X==1\") #>  #> The probability of observing a given combination of data  #> realizations for a given set of parameter values. #>  #>      event_probs #> X0Y0         0.0 #> X1Y0         0.5 #> X0Y1         0.0 #> X1Y1         0.5 get_event_probabilities(model = model, parameters = rep(1, 6)) #>  #> The probability of observing a given combination of data  #> realizations for a given set of parameter values. #>  #>      event_probs #> X0Y0        0.25 #> X1Y0        0.25 #> X0Y1        0.25 #> X1Y1        0.25 get_event_probabilities(model = model, parameters = 1:6) #>  #> The probability of observing a given combination of data  #> realizations for a given set of parameter values. #>  #>      event_probs #> X0Y0   0.1481481 #> X1Y0   0.2592593 #> X0Y1   0.1851852 #> X1Y1   0.4074074 # }"},{"path":"/reference/get_nodal_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Get list of types for nodes in a DAG — get_nodal_types","title":"Get list of types for nodes in a DAG — get_nodal_types","text":"type labels hard interpret large models, type list includes attribute help interpret . See  attr(types, interpret)","code":""},{"path":"/reference/get_nodal_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get list of types for nodes in a DAG — get_nodal_types","text":"","code":"get_nodal_types(model, collapse = TRUE)"},{"path":"/reference/get_nodal_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get list of types for nodes in a DAG — get_nodal_types","text":"model causal_model. model object generated make_model. collapse Logical. `TRUE`, shows unique nodal types node. `FALSE`, shows node matrix nodal types rows parent types columns, applicable. Defaults `TRUE`.","code":""},{"path":"/reference/get_nodal_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get list of types for nodes in a DAG — get_nodal_types","text":"named list nodal types parent DAG","code":""},{"path":"/reference/get_nodal_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get list of types for nodes in a DAG — get_nodal_types","text":"","code":"# \\donttest{ model <- make_model('X -> K -> Y') get_nodal_types(model) #> Error in get_nodal_types(model): could not find function \"get_nodal_types\"  model <- make_model('X -> K -> Y') %>%    set_restrictions(statement = 'K[X=1]>K[X=0]') %>%    set_confound(list(K = 'Y[K=1]>Y[K=0]')) get_nodal_types(model) #> Error in get_nodal_types(model): could not find function \"get_nodal_types\" # }"},{"path":"/reference/get_parameter_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Get parameter matrix — get_parameter_matrix","title":"Get parameter matrix — get_parameter_matrix","text":"Return parameter matrix exists; otherwise calculate assuming confounding. parameter matrix  maps parameters causal types. models without confounding parameters correspond nodal types.","code":""},{"path":"/reference/get_parameter_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get parameter matrix — get_parameter_matrix","text":"","code":"get_parameter_matrix(model)"},{"path":"/reference/get_parameter_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get parameter matrix — get_parameter_matrix","text":"model model created make_model()","code":""},{"path":"/reference/get_parameter_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get parameter matrix — get_parameter_matrix","text":"data.frame, parameter matrix, mapping   parameters causal types","code":""},{"path":"/reference/get_parameter_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get parameter matrix — get_parameter_matrix","text":"","code":"model <- make_model('X -> Y') get_parameter_matrix(model) #> Error in get_parameter_matrix(model): could not find function \"get_parameter_matrix\""},{"path":"/reference/get_parameter_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Get parameter names — get_parameter_names","title":"Get parameter names — get_parameter_names","text":"Parameter names taken P matrix model P  matrix provided","code":""},{"path":"/reference/get_parameter_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get parameter names — get_parameter_names","text":"","code":"get_parameter_names(model, include_paramset = TRUE)"},{"path":"/reference/get_parameter_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get parameter names — get_parameter_names","text":"model causal_model. model object generated make_model. include_paramset Logical. Whether include param set prefix part name.","code":""},{"path":"/reference/get_parameter_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get parameter names — get_parameter_names","text":"character vector names parameters model","code":""},{"path":"/reference/get_parameter_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get parameter names — get_parameter_names","text":"","code":"get_parameter_names(make_model('X->Y')) #> Error in get_parameter_names(make_model(\"X->Y\")): could not find function \"get_parameter_names\""},{"path":"/reference/get_param_dist.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a distribution of model parameters — get_param_dist","title":"Get a distribution of model parameters — get_param_dist","text":"Using parameters, priors, posteriors","code":""},{"path":"/reference/get_param_dist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a distribution of model parameters — get_param_dist","text":"","code":"get_param_dist(model, using, n_draws = 4000)"},{"path":"/reference/get_param_dist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a distribution of model parameters — get_param_dist","text":"model causal_model. model object generated make_model. using character string. Indicates whether use `priors`, `posteriors` `parameters`. n_draws integer. prior distribution provided, generate prior distribution n_draws number draws.","code":""},{"path":"/reference/get_param_dist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a distribution of model parameters — get_param_dist","text":"matrix distribution parameters model","code":""},{"path":"/reference/get_param_dist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get a distribution of model parameters — get_param_dist","text":"","code":"get_param_dist(model = make_model('X->Y'), using = 'priors', n_draws = 4) #> Error in get_param_dist(model = make_model(\"X->Y\"), using = \"priors\",     n_draws = 4): could not find function \"get_param_dist\" get_param_dist(model = make_model('X->Y'), using = 'parameters') #> Error in get_param_dist(model = make_model(\"X->Y\"), using = \"parameters\"): could not find function \"get_param_dist\""},{"path":"/reference/get_parents.html","id":null,"dir":"Reference","previous_headings":"","what":"Get list of parents of all nodes in a model — get_parents","title":"Get list of parents of all nodes in a model — get_parents","text":"Get list parents nodes model","code":""},{"path":"/reference/get_parents.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get list of parents of all nodes in a model — get_parents","text":"","code":"get_parents(model)"},{"path":"/reference/get_parents.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get list of parents of all nodes in a model — get_parents","text":"model causal_model. model object generated make_model.","code":""},{"path":"/reference/get_parents.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get list of parents of all nodes in a model — get_parents","text":"list parents DAG","code":""},{"path":"/reference/get_parents.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get list of parents of all nodes in a model — get_parents","text":"","code":"model <- make_model('X -> K -> Y') get_parents(model) #> Error in get_parents(model): could not find function \"get_parents\""},{"path":"/reference/get_parmap.html","id":null,"dir":"Reference","previous_headings":"","what":"Get parmap: a matrix mapping from parameters to data types — get_parmap","title":"Get parmap: a matrix mapping from parameters to data types — get_parmap","text":"Gets parmap model, generates available.","code":""},{"path":"/reference/get_parmap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get parmap: a matrix mapping from parameters to data types — get_parmap","text":"","code":"get_parmap(model, A = NULL, P = NULL)"},{"path":"/reference/get_parmap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get parmap: a matrix mapping from parameters to data types — get_parmap","text":"model causal_model. model object generated make_model. data.frame. Ambiguity matrix. required may provided avoid repeated computation simulations. P data.frame. Parameter matrix. required may provided avoid repeated computation simulations.","code":""},{"path":"/reference/get_parmap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get parmap: a matrix mapping from parameters to data types — get_parmap","text":"matrix","code":""},{"path":"/reference/get_parmap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get parmap: a matrix mapping from parameters to data types — get_parmap","text":"","code":"get_parmap(model = make_model('X->Y')) #> Error in get_parmap(model = make_model(\"X->Y\")): could not find function \"get_parmap\""},{"path":"/reference/get_posterior_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the posterior distribution from a model — get_posterior_distribution","title":"Get the posterior distribution from a model — get_posterior_distribution","text":"Access posterior distribution model one added via `update_model`.","code":""},{"path":"/reference/get_posterior_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the posterior distribution from a model — get_posterior_distribution","text":"","code":"get_posterior_distribution(model)"},{"path":"/reference/get_posterior_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the posterior distribution from a model — get_posterior_distribution","text":"model causal_model. model object generated make_model.","code":""},{"path":"/reference/get_posterior_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the posterior distribution from a model — get_posterior_distribution","text":"`data.frame` parameters draws","code":""},{"path":"/reference/get_posterior_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the posterior distribution from a model — get_posterior_distribution","text":"","code":"make_model('X -> Y') |>   update_model()  |>   get_posterior_distribution() #> Error in get_posterior_distribution(update_model(make_model(\"X -> Y\"))): could not find function \"get_posterior_distribution\""},{"path":"/reference/get_prior_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a prior distribution from model — get_prior_distribution","title":"Get a prior distribution from model — get_prior_distribution","text":"Access prior distribution model one added via `set_prior_distribution`. Otherwise call  `make_prior_distribution` generate return `n_draws x n_param`  prior distribution.","code":""},{"path":"/reference/get_prior_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a prior distribution from model — get_prior_distribution","text":"","code":"get_prior_distribution(model, n_draws = 4000)"},{"path":"/reference/get_prior_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a prior distribution from model — get_prior_distribution","text":"model causal_model. model object generated make_model. n_draws scalar. Number draws.","code":""},{"path":"/reference/get_prior_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a prior distribution from model — get_prior_distribution","text":"`data.frame` dimension `n_param`x `n_draws` possible   lambda draws","code":""},{"path":[]},{"path":"/reference/get_prior_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get a prior distribution from model — get_prior_distribution","text":"","code":"make_model('X -> Y') %>%   set_prior_distribution(n_draws = 5) %>%   get_prior_distribution() #> Error in get_prior_distribution(.): could not find function \"get_prior_distribution\" make_model('X -> Y') %>%   get_prior_distribution(3) #> Error in get_prior_distribution(., 3): could not find function \"get_prior_distribution\""},{"path":"/reference/get_query_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Look up query types — get_query_types","title":"Look up query types — get_query_types","text":"Find nodal causal types satisfied query.","code":""},{"path":"/reference/get_query_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Look up query types — get_query_types","text":"","code":"get_query_types(model, query, map = \"causal_type\", join_by = \"|\")"},{"path":"/reference/get_query_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Look up query types — get_query_types","text":"model causal_model. model object generated make_model. query character string. expression defining nodal types interrogate realise_outcomes. expression form \"Y[X=1]\" asks value Y X set 1 map Types query. Either nodal_type causal_type. Default causal_type. join_by logical operator. Used connect causal statements: ('&') ('|'). Defaults '|'.","code":""},{"path":"/reference/get_query_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Look up query types — get_query_types","text":"list containing following elements types named vector logical values indicating whether   nodal_type causal_type satisfy `query` query character string specified user expanded_query character string expanded query.   differs `query` contains wildcard '.' evaluated_nodes Value nodes take given query node character string node whose   nodal types queried type_list List causal types satisfied query","code":""},{"path":"/reference/get_query_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Look up query types — get_query_types","text":"","code":"model <- make_model('X -> M -> Y; X->Y') query <- '(Y[X=0] > Y[X=1])' # \\donttest{ get_query_types(model, query, map=\"nodal_type\") #>  #> Nodal types adding weight to query #>  #>  query :  (Y[X=0,M=0]>Y[X=1,M=0] | Y[X=0,M=1]>Y[X=1,M=1])  #>  #>  1000   0010 #>  1010   0110 #>  1110   1001 #>  1011    #>  #>  #>  Number of nodal types that add weight to query = 7 #>  Total number of nodal types related to Y = 16 get_query_types(model, query, map=\"causal_type\") #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  (Y[X=0]>Y[X=1])  #>  #> X0.M00.Y1000  X1.M00.Y1000 #> X0.M01.Y1000  X1.M01.Y1000 #> X0.M01.Y1100  X1.M01.Y1100 #> X0.M10.Y0010  X1.M10.Y0010 #> X0.M11.Y0010  X1.M11.Y0010 #> X0.M00.Y1010  X1.M00.Y1010 #> X0.M10.Y1010  X1.M10.Y1010 #> X0.M01.Y1010  X1.M01.Y1010 #> X0.M11.Y1010  X1.M11.Y1010 #> X0.M11.Y0110  X1.M11.Y0110 #> X0.M01.Y1110  X1.M01.Y1110 #> X0.M11.Y1110  X1.M11.Y1110 #> X0.M00.Y1001  X1.M00.Y1001 #> X0.M10.Y0011  X1.M10.Y0011 #> X0.M00.Y1011  X1.M00.Y1011 #> X0.M10.Y1011  X1.M10.Y1011 #>  #>  #>  Number of causal types that meet condition(s) =  32 #>  Total number of causal types in model =  128 get_query_types(model, query) #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  (Y[X=0]>Y[X=1])  #>  #> X0.M00.Y1000  X1.M00.Y1000 #> X0.M01.Y1000  X1.M01.Y1000 #> X0.M01.Y1100  X1.M01.Y1100 #> X0.M10.Y0010  X1.M10.Y0010 #> X0.M11.Y0010  X1.M11.Y0010 #> X0.M00.Y1010  X1.M00.Y1010 #> X0.M10.Y1010  X1.M10.Y1010 #> X0.M01.Y1010  X1.M01.Y1010 #> X0.M11.Y1010  X1.M11.Y1010 #> X0.M11.Y0110  X1.M11.Y0110 #> X0.M01.Y1110  X1.M01.Y1110 #> X0.M11.Y1110  X1.M11.Y1110 #> X0.M00.Y1001  X1.M00.Y1001 #> X0.M10.Y0011  X1.M10.Y0011 #> X0.M00.Y1011  X1.M00.Y1011 #> X0.M10.Y1011  X1.M10.Y1011 #>  #>  #>  Number of causal types that meet condition(s) =  32 #>  Total number of causal types in model =  128  # Examples with map = \"nodal_type\"  query <- '(Y[X=0, M = .] > Y[X=1, M = 0])' get_query_types(model, query, map=\"nodal_type\") #>  #> Nodal types adding weight to query #>  #>  query :  (Y[X=0,M=0]>Y[X=1,M=0] | Y[X=0,M=1]>Y[X=1,M=0])  #>  #>  1000   0010 #>  1010   1001 #>  0011   1011 #>  #>  #>  Number of nodal types that add weight to query = 6 #>  Total number of nodal types related to Y = 16  query <- '(Y[] == 1)' get_query_types(model, query, map=\"nodal_type\") #>  #> Nodal types adding weight to query #>  #>  query :  (Y[X=0,M=0]==1 | Y[X=1,M=0]==1 | Y[X=0,M=1]==1 | Y[X=1,M=1]==1)  #>  #>  1000   0100 #>  1100   0010 #>  1010   0110 #>  1110   0001 #>  1001   0101 #>  1101   0011 #>  1011   0111 #>  1111    #>  #>  #>  Number of nodal types that add weight to query = 15 #>  Total number of nodal types related to Y = 16 get_query_types(model, query, map=\"nodal_type\", join_by = '&') #>  #> Nodal types adding weight to query #>  #>  query :  (Y[X=0,M=0]==1 & Y[X=1,M=0]==1 & Y[X=0,M=1]==1 & Y[X=1,M=1]==1)  #>  #>  1111    #>  #>  #>  Number of nodal types that add weight to query = 1 #>  Total number of nodal types related to Y = 16  # Root nodes specified with [] get_query_types(model, '(X[] == 1)', map=\"nodal_type\") #>  #> Nodal types adding weight to query #>  #>  query :  (X[]==1)  #>  #>  1    #>  #>  #>  Number of nodal types that add weight to query = 1 #>  Total number of nodal types related to X = 2  query <- '(M[X=1] == M[X=0])' get_query_types(model, query, map=\"nodal_type\") #>  #> Nodal types adding weight to query #>  #>  query :  (M[X=1]==M[X=0])  #>  #>  00   11 #>  #>  #>  Number of nodal types that add weight to query = 2 #>  Total number of nodal types related to M = 4  # Nested do operations get_query_types(  model = make_model('A -> B -> C -> D'),  query = '(D[C=C[B=B[A=1]], A=0] > D[C=C[B=B[A=0]], A=0])') #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  (D[C=C[B=B[A=1]],A=0]>D[C=C[B=B[A=0]],A=0])  #>  #> A0.B01.C10.D10  A1.B01.C10.D10 #> A0.B10.C01.D10  A1.B10.C01.D10 #> A0.B10.C10.D01  A1.B10.C10.D01 #> A0.B01.C01.D01  A1.B01.C01.D01 #>  #>  #>  Number of causal types that meet condition(s) =  8 #>  Total number of causal types in model =  128  # Helpers model <- make_model('M->Y; X->Y') query <- complements('X', 'M', 'Y') get_query_types(model, query, map=\"nodal_type\") #>  #> Nodal types adding weight to query #>  #>  query :  ((Y[X=1,M=1])-(Y[X=0,M=1]))>((Y[X=1,M=0])-(Y[X=0,M=0]))  #>  #>  1000   0001 #>  1001   1101 #>  1011    #>  #>  #>  Number of nodal types that add weight to query = 5 #>  Total number of nodal types related to Y = 16  # Examples with map = \"causal_type\"  model <- make_model('X -> M -> Y; X->Y') query <- 'Y[M=M[X=0], X=1]==1' get_query_types(model, query, map= \"causal_type\") #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  Y[M=M[X=0],X=1]==1  #>  #> X0.M00.Y0100  X1.M00.Y0100 #> X0.M01.Y0100  X1.M01.Y0100 #> X0.M00.Y1100  X1.M00.Y1100 #> X0.M01.Y1100  X1.M01.Y1100 #> X0.M00.Y0110  X1.M00.Y0110 #> X0.M01.Y0110  X1.M01.Y0110 #> X0.M00.Y1110  X1.M00.Y1110 #> X0.M01.Y1110  X1.M01.Y1110 #> X0.M10.Y0001  X1.M10.Y0001 #> X0.M11.Y0001  X1.M11.Y0001 #> X0.M10.Y1001  X1.M10.Y1001 #> X0.M11.Y1001  X1.M11.Y1001 #> X0.M00.Y0101  X1.M00.Y0101 #> X0.M10.Y0101  X1.M10.Y0101 #> X0.M01.Y0101  X1.M01.Y0101 #> X0.M11.Y0101  X1.M11.Y0101 #> X0.M00.Y1101  X1.M00.Y1101 #> X0.M10.Y1101  X1.M10.Y1101 #> X0.M01.Y1101  X1.M01.Y1101 #> X0.M11.Y1101  X1.M11.Y1101 #> X0.M10.Y0011  X1.M10.Y0011 #> X0.M11.Y0011  X1.M11.Y0011 #> X0.M10.Y1011  X1.M10.Y1011 #> X0.M11.Y1011  X1.M11.Y1011 #> X0.M00.Y0111  X1.M00.Y0111 #> X0.M10.Y0111  X1.M10.Y0111 #> X0.M01.Y0111  X1.M01.Y0111 #> X0.M11.Y0111  X1.M11.Y0111 #> X0.M00.Y1111  X1.M00.Y1111 #> X0.M10.Y1111  X1.M10.Y1111 #> X0.M01.Y1111  X1.M01.Y1111 #> X0.M11.Y1111  X1.M11.Y1111 #>  #>  #>  Number of causal types that meet condition(s) =  64 #>  Total number of causal types in model =  128  query <- '(Y[X = 1, M = 1] >  Y[X = 0, M = 1]) &           (Y[X = 1, M = 0] >  Y[X = 0, M = 0])' get_query_types(model, query, \"causal_type\") #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  (Y[X=1,M=1]>Y[X=0,M=1])& #> (Y[X=1,M=0]>Y[X=0,M=0])  #>  #> X0.M00.Y0101  X1.M00.Y0101 #> X0.M10.Y0101  X1.M10.Y0101 #> X0.M01.Y0101  X1.M01.Y0101 #> X0.M11.Y0101  X1.M11.Y0101 #>  #>  #>  Number of causal types that meet condition(s) =  8 #>  Total number of causal types in model =  128  query <- 'Y[X=1] == Y[X=0]' get_query_types(model, query, \"causal_type\") #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  Y[X=1]==Y[X=0]  #>  #> X0.M00.Y0000  X1.M00.Y0000 #> X0.M10.Y0000  X1.M10.Y0000 #> X0.M01.Y0000  X1.M01.Y0000 #> X0.M11.Y0000  X1.M11.Y0000 #> X0.M10.Y1000  X1.M10.Y1000 #> X0.M11.Y1000  X1.M11.Y1000 #> X0.M01.Y0100  X1.M01.Y0100 #> X0.M11.Y0100  X1.M11.Y0100 #> X0.M00.Y1100  X1.M00.Y1100 #> X0.M11.Y1100  X1.M11.Y1100 #> X0.M00.Y0010  X1.M00.Y0010 #> X0.M01.Y0010  X1.M01.Y0010 #> X0.M10.Y0110  X1.M10.Y0110 #> X0.M01.Y0110  X1.M01.Y0110 #> X0.M00.Y1110  X1.M00.Y1110 #> X0.M10.Y1110  X1.M10.Y1110 #> X0.M00.Y0001  X1.M00.Y0001 #> X0.M10.Y0001  X1.M10.Y0001 #> X0.M10.Y1001  X1.M10.Y1001 #> X0.M01.Y1001  X1.M01.Y1001 #> X0.M00.Y1101  X1.M00.Y1101 #> X0.M01.Y1101  X1.M01.Y1101 #> X0.M00.Y0011  X1.M00.Y0011 #> X0.M11.Y0011  X1.M11.Y0011 #> X0.M01.Y1011  X1.M01.Y1011 #> X0.M11.Y1011  X1.M11.Y1011 #> X0.M10.Y0111  X1.M10.Y0111 #> X0.M11.Y0111  X1.M11.Y0111 #> X0.M00.Y1111  X1.M00.Y1111 #> X0.M10.Y1111  X1.M10.Y1111 #> X0.M01.Y1111  X1.M01.Y1111 #> X0.M11.Y1111  X1.M11.Y1111 #>  #>  #>  Number of causal types that meet condition(s) =  64 #>  Total number of causal types in model =  128  query <- '(X == 1) & (M==1) & (Y ==1) & (Y[X=0] ==1)' get_query_types(model, query, \"causal_type\") #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  (X==1)&(M==1)&(Y==1)&(Y[X=0]==1)  #>  #> X1.M01.Y1001  X1.M01.Y1101 #> X1.M11.Y0011  X1.M01.Y1011 #> X1.M11.Y1011  X1.M11.Y0111 #> X1.M01.Y1111  X1.M11.Y1111 #>  #>  #>  Number of causal types that meet condition(s) =  8 #>  Total number of causal types in model =  128  query <- '(Y[X = .]==1)' get_query_types(model, query, \"causal_type\") #> Generated expanded expression: #> (Y[X=0]==1 | Y[X=1]==1) #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  (Y[X=0]==1|Y[X=1]==1)  #>  #> X0.M00.Y1000  X1.M00.Y1000 #> X0.M01.Y1000  X1.M01.Y1000 #> X0.M00.Y0100  X1.M00.Y0100 #> X0.M10.Y0100  X1.M10.Y0100 #> X0.M00.Y1100  X1.M00.Y1100 #> X0.M10.Y1100  X1.M10.Y1100 #> X0.M01.Y1100  X1.M01.Y1100 #> X0.M10.Y0010  X1.M10.Y0010 #> X0.M11.Y0010  X1.M11.Y0010 #> X0.M00.Y1010  X1.M00.Y1010 #> X0.M10.Y1010  X1.M10.Y1010 #> X0.M01.Y1010  X1.M01.Y1010 #> X0.M11.Y1010  X1.M11.Y1010 #> X0.M00.Y0110  X1.M00.Y0110 #> X0.M10.Y0110  X1.M10.Y0110 #> X0.M11.Y0110  X1.M11.Y0110 #> X0.M00.Y1110  X1.M00.Y1110 #> X0.M10.Y1110  X1.M10.Y1110 #> X0.M01.Y1110  X1.M01.Y1110 #> X0.M11.Y1110  X1.M11.Y1110 #> X0.M01.Y0001  X1.M01.Y0001 #> X0.M11.Y0001  X1.M11.Y0001 #> X0.M00.Y1001  X1.M00.Y1001 #> X0.M01.Y1001  X1.M01.Y1001 #> X0.M11.Y1001  X1.M11.Y1001 #> X0.M00.Y0101  X1.M00.Y0101 #> X0.M10.Y0101  X1.M10.Y0101 #> X0.M01.Y0101  X1.M01.Y0101 #> X0.M11.Y0101  X1.M11.Y0101 #> X0.M00.Y1101  X1.M00.Y1101 #> X0.M10.Y1101  X1.M10.Y1101 #> X0.M01.Y1101  X1.M01.Y1101 #> X0.M11.Y1101  X1.M11.Y1101 #> X0.M10.Y0011  X1.M10.Y0011 #> X0.M01.Y0011  X1.M01.Y0011 #> X0.M11.Y0011  X1.M11.Y0011 #> X0.M00.Y1011  X1.M00.Y1011 #> X0.M10.Y1011  X1.M10.Y1011 #> X0.M01.Y1011  X1.M01.Y1011 #> X0.M11.Y1011  X1.M11.Y1011 #> X0.M00.Y0111  X1.M00.Y0111 #> X0.M10.Y0111  X1.M10.Y0111 #> X0.M01.Y0111  X1.M01.Y0111 #> X0.M11.Y0111  X1.M11.Y0111 #> X0.M00.Y1111  X1.M00.Y1111 #> X0.M10.Y1111  X1.M10.Y1111 #> X0.M01.Y1111  X1.M01.Y1111 #> X0.M11.Y1111  X1.M11.Y1111 #>  #>  #>  Number of causal types that meet condition(s) =  96 #>  Total number of causal types in model =  128 # }"},{"path":"/reference/get_type_distributions.html","id":null,"dir":"Reference","previous_headings":"","what":"helper to get type distributions — get_type_distributions","title":"helper to get type distributions — get_type_distributions","text":"helper get type distributions","code":""},{"path":"/reference/get_type_distributions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"helper to get type distributions — get_type_distributions","text":"","code":"get_type_distributions(jobs, model, n_draws, parameters = NULL)"},{"path":"/reference/get_type_distributions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"helper to get type distributions — get_type_distributions","text":"jobs DataFrame argument combinations model list models n_draws integer specifying number draws prior distribution parameters optional list parameter vectors","code":""},{"path":"/reference/get_type_distributions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"helper to get type distributions — get_type_distributions","text":"jobs DataFrame nested column type distributions","code":""},{"path":"/reference/get_type_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Get type names — get_type_names","title":"Get type names — get_type_names","text":"Get type names","code":""},{"path":"/reference/get_type_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get type names — get_type_names","text":"","code":"get_type_names(nodal_types)"},{"path":"/reference/get_type_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get type names — get_type_names","text":"nodal_types Nodal types model. See get_nodal_types.","code":""},{"path":"/reference/get_type_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get type names — get_type_names","text":"vector containing causal type names","code":""},{"path":"/reference/get_type_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get type names — get_type_names","text":"","code":"model <- make_model('A->Y<-B') CausalQueries:::get_type_names(model$nodal_types) #>  [1] \"A.0\"    \"A.1\"    \"B.0\"    \"B.1\"    \"Y.0000\" \"Y.1000\" \"Y.0100\" \"Y.1100\" #>  [9] \"Y.0010\" \"Y.1010\" \"Y.0110\" \"Y.1110\" \"Y.0001\" \"Y.1001\" \"Y.0101\" \"Y.1101\" #> [17] \"Y.0011\" \"Y.1011\" \"Y.0111\" \"Y.1111\""},{"path":"/reference/get_type_prob.html","id":null,"dir":"Reference","previous_headings":"","what":"Get type probabilities — get_type_prob","title":"Get type probabilities — get_type_prob","text":"Gets probability vector causal types given single realization parameters, possibly drawn model priors.","code":""},{"path":"/reference/get_type_prob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get type probabilities — get_type_prob","text":"","code":"get_type_prob(model, P = NULL, parameters = NULL)"},{"path":"/reference/get_type_prob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get type probabilities — get_type_prob","text":"model causal_model. model object generated make_model. P data.frame. Parameter matrix. required may provided avoid repeated computation simulations. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn model$parameters_df.","code":""},{"path":"/reference/get_type_prob.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get type probabilities — get_type_prob","text":"vector probabilities vector causal types","code":""},{"path":"/reference/get_type_prob.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get type probabilities — get_type_prob","text":"default, parameters drawn `using` argument (either priors, posteriors, model$parameters)","code":""},{"path":"/reference/get_type_prob.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get type probabilities — get_type_prob","text":"","code":"get_type_prob(model = make_model('X->Y')) #> Error in get_type_prob(model = make_model(\"X->Y\")): could not find function \"get_type_prob\" get_type_prob(model = make_model('X->Y'), parameters = 1:6) #> Error in get_type_prob(model = make_model(\"X->Y\"), parameters = 1:6): could not find function \"get_type_prob\""},{"path":"/reference/get_type_prob_c.html","id":null,"dir":"Reference","previous_headings":"","what":"generates one draw from type probability distribution for each type in P — get_type_prob_c","title":"generates one draw from type probability distribution for each type in P — get_type_prob_c","text":"generates one draw type probability distribution type P","code":""},{"path":"/reference/get_type_prob_c.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"generates one draw from type probability distribution for each type in P — get_type_prob_c","text":"","code":"get_type_prob_c(P, parameters)"},{"path":"/reference/get_type_prob_c.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"generates one draw from type probability distribution for each type in P — get_type_prob_c","text":"P parameter_matrix parameters causal types parameters, priors posteriors","code":""},{"path":"/reference/get_type_prob_c.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"generates one draw from type probability distribution for each type in P — get_type_prob_c","text":"draw type distribution type P","code":""},{"path":"/reference/get_type_prob_multiple.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw matrix of type probabilities, before or after estimation — get_type_prob_multiple","title":"Draw matrix of type probabilities, before or after estimation — get_type_prob_multiple","text":"Draw matrix type probabilities, estimation","code":""},{"path":"/reference/get_type_prob_multiple.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw matrix of type probabilities, before or after estimation — get_type_prob_multiple","text":"","code":"get_type_prob_multiple(   model,   using = \"priors\",   parameters = NULL,   n_draws = 4000,   param_dist = NULL,   P = NULL )"},{"path":"/reference/get_type_prob_multiple.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw matrix of type probabilities, before or after estimation — get_type_prob_multiple","text":"model causal_model. model object generated make_model. using character. indicates whether use `priors`, `posteriors` `parameters`. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn model$parameters_df. n_draws integer. prior distribution provided, generate prior distribution n_draws number draws. param_dist matrix.  Distribution parameters. Optional speed. P data.frame. Parameter matrix. required may provided avoid repeated computation simulations.","code":""},{"path":"/reference/get_type_prob_multiple.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw matrix of type probabilities, before or after estimation — get_type_prob_multiple","text":"matrix type probabilities.","code":""},{"path":"/reference/get_type_prob_multiple.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw matrix of type probabilities, before or after estimation — get_type_prob_multiple","text":"","code":"model <- make_model('X -> Y') get_type_prob_multiple(model, using = 'priors', n_draws = 3) #> Error in get_type_prob_multiple(model, using = \"priors\", n_draws = 3): could not find function \"get_type_prob_multiple\" get_type_prob_multiple(model, using = 'parameters', n_draws = 3) #> Error in get_type_prob_multiple(model, using = \"parameters\", n_draws = 3): could not find function \"get_type_prob_multiple\""},{"path":"/reference/get_type_prob_multiple_c.html","id":null,"dir":"Reference","previous_headings":"","what":"generates n draws from type probability distribution for each type in P — get_type_prob_multiple_c","title":"generates n draws from type probability distribution for each type in P — get_type_prob_multiple_c","text":"generates n draws type probability distribution type P","code":""},{"path":"/reference/get_type_prob_multiple_c.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"generates n draws from type probability distribution for each type in P — get_type_prob_multiple_c","text":"","code":"get_type_prob_multiple_c(params, P)"},{"path":"/reference/get_type_prob_multiple_c.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"generates n draws from type probability distribution for each type in P — get_type_prob_multiple_c","text":"params parameters, priors posteriors P parameter_matrix parameters causal types","code":""},{"path":"/reference/get_type_prob_multiple_c.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"generates n draws from type probability distribution for each type in P — get_type_prob_multiple_c","text":"draws type distribution type P","code":""},{"path":"/reference/grab.html","id":null,"dir":"Reference","previous_headings":"","what":"Grab — grab","title":"Grab — grab","text":"Returns specified elements causal_model. Users can use grab extract model's components objects implied model structure including nodal types, causal types, parameter priors, parameter posteriors, type priors, type posteriors, relevant elements. See argument object ","code":""},{"path":"/reference/grab.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Grab — grab","text":"","code":"grab(model, object = NULL, ...)"},{"path":"/reference/grab.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Grab — grab","text":"model causal_model. model object generated make_model. object character string specifying component retrieve. Available options : \"causal_statement\" character. Statement describing causal relations using dagitty syntax, \"dag\" data frame columns ‘parent’ ‘children’ indicating nodes relate , \"nodes\" list containing nodes model, \"parents\" table listing nodes, whether root nodes , number names parents , \"parameters_df\" data frame containing parameter information, \"causal_types\" data frame listing causal types nodal types produce , \"nodal_types\" list nodal types model, \"data_types\" list data  types consistent model; options see \"?get_all_data_types\", \"event_probabilities\"  vector data (event) probabilities given parameter vector; options see \"?get_event_probabilities\", \"ambiguities_matrix\" matrix mapping causal types data types, \"parameters\" vector 'true' parameters, \"parameter_names\"  vector names parameters, \"parameter_mapping\"  matrix mapping parameters data types, \"parameter_matrix\" matrix mapping parameters causal types, \"prior_hyperparameters\"  vector alpha values used parameterize Dirichlet prior distributions, \"prior_distribution\"  data frame parameter prior distribution, \"posterior_distribution\"  data frame parameter posterior distribution, \"posterior_event_probabilities\" sample data (event) probabilities posterior, \"stan_objects\"  stan_objects list Stan outputs can include stanfit object, data used, distributions causal types event probabilities. \"stan_fit\" stanfit object generated Stan, \"stan_summary\" summary stanfit object generated Stan, \"type_prior\" matrix type probabilities using priors, \"type_posterior\" matrix type probabilities using posteriors, ... arguments passed helper \"get_*\" functions.","code":""},{"path":"/reference/grab.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Grab — grab","text":"Objects causal_model specified.","code":""},{"path":"/reference/grab.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Grab — grab","text":"","code":"# \\donttest{ model <-   make_model('X -> Y') |>    update_model(    keep_event_probabilities = TRUE,    keep_fit = TRUE,    refresh = 0 ) #> No data provided  grab(model, object = \"causal_statement\") #>  #> Statement:  #> X -> Y grab(model, object = \"dag\") #>  #> Dag:  #>   parent children #> 1      X        Y grab(model, object = \"nodes\") #>  #> Nodes:  #> X, Y grab(model, object = \"parents\") #>   node  root parents parent_nodes #> 1    X  TRUE       0              #> 2    Y FALSE       1            X grab(model, object = \"parameters_df\") #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>   param_names node gen param_set nodal_type given param_value priors #> 1         X.0    X   1         X          0              0.50      1 #> 2         X.1    X   1         X          1              0.50      1 #> 3        Y.00    Y   2         Y         00              0.25      1 #> 4        Y.10    Y   2         Y         10              0.25      1 #> 5        Y.01    Y   2         Y         01              0.25      1 #> 6        Y.11    Y   2         Y         11              0.25      1 grab(model, object = \"causal_types\") #>  #> Causal Types:  #> cartesian product of nodal types #>  #>        X  Y #> X0.Y00 0 00 #> X1.Y00 1 00 #> X0.Y10 0 10 #> X1.Y10 1 10 #> X0.Y01 0 01 #> X1.Y01 1 01 #> X0.Y11 0 11 #> X1.Y11 1 11 grab(model, object = \"nodal_types\") #> Nodal types:  #> $X #> 0  1 #>  #>   node position display interpretation #> 1    X       NA      X0          X = 0 #> 2    X       NA      X1          X = 1 #>  #> $Y #> 00  10  01  11 #>  #>   node position display interpretation #> 1    Y        1   Y[*]*      Y | X = 0 #> 2    Y        2   Y*[*]      Y | X = 1 #>  #>  #> Number of types by node #> X Y  #> 2 4  grab(model, object = \"data_types\") #>      event  X  Y #> X0Y0  X0Y0  0  0 #> X1Y0  X1Y0  1  0 #> X0Y1  X0Y1  0  1 #> X1Y1  X1Y1  1  1 #> Y0      Y0 NA  0 #> Y1      Y1 NA  1 #> X0      X0  0 NA #> X1      X1  1 NA #> None  None NA NA grab(model, object = \"event_probabilities\") #>  #> The probability of observing a given combination of data  #> realizations for a given set of parameter values. #>  #>      event_probs #> X0Y0        0.25 #> X1Y0        0.25 #> X0Y1        0.25 #> X1Y1        0.25 grab(model, object = \"ambiguities_matrix\") #>       X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y00    1    0    0    0 #> X1Y00    0    1    0    0 #> X0Y10    0    0    1    0 #> X1Y10    0    1    0    0 #> X0Y01    1    0    0    0 #> X1Y01    0    0    0    1 #> X0Y11    0    0    1    0 #> X1Y11    0    0    0    1 grab(model, object = \"parameters\") #> Model parameters with associated probabilities:  #>  #> X.0 X.1 Y.00 Y.10 Y.01 Y.11 #> 0.5 0.5 0.25 0.25 0.25 0.25 grab(model, object = \"parameter_names\") #> [1] \"X.0\"  \"X.1\"  \"Y.00\" \"Y.10\" \"Y.01\" \"Y.11\" grab(model, object = \"parameter_mapping\") #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X.0     1    0    1    0 #> X.1     0    1    0    1 #> Y.00    1    1    0    0 #> Y.10    0    1    1    0 #> Y.01    1    0    0    1 #> Y.11    0    0    1    1 #> attr(,\"map\") #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 grab(model, object = \"parameter_matrix\") #>  #> Rows are parameters, grouped in parameter sets #>  #> Columns are causal types #>  #> Cell entries indicate whether a parameter probability isused #> in the calculation of causal type probability #>  #>      X0.Y00 X1.Y00 X0.Y10 X1.Y10 X0.Y01 X1.Y01 X0.Y11 X1.Y11 #> X.0       1      0      1      0      1      0      1      0 #> X.1       0      1      0      1      0      1      0      1 #> Y.00      1      1      0      0      0      0      0      0 #> Y.10      0      0      1      1      0      0      0      0 #> Y.01      0      0      0      0      1      1      0      0 #> Y.11      0      0      0      0      0      0      1      1 #>  #>   #>  param_set  (P) #>   grab(model, object = \"prior_hyperparameters\") #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #>    1    1    1    1    1    1  grab(model, object = \"prior_distribution\") #> Prior distribution added to model #> Summary statistics of model parameter prior distributions: #> Dimensions: 4000 rows (draws) by 6 cols (parameters)  #>  #> Summary:  #>  #>      mean   sd #> X.0  0.51 0.29 #> X.1  0.49 0.29 #> Y.00 0.25 0.20 #> Y.10 0.25 0.19 #> Y.01 0.25 0.20 #> Y.11 0.25 0.19 grab(model, object = \"posterior_distribution\") #> Summary statistics of model parameter posterior distributions: #> : 4000 rows (draws) by 6 cols (parameters) #>  #>      mean   sd #> X.0  0.50 0.29 #> X.1  0.50 0.29 #> Y.00 0.25 0.20 #> Y.10 0.25 0.20 #> Y.01 0.25 0.20 #> Y.11 0.25 0.20 grab(model, object = \"posterior_event_probabilities\") #>  #> Posterior draws of event probabilities (transformed parameters) #>  #> Dimensions: 4000 rows (draws) by 4 cols (data types) #>  #> Summary:  #>  #>       mean    sd #> X0Y0 0.250 0.197 #> X1Y0 0.254 0.199 #> X0Y1 0.245 0.192 #> X1Y1 0.250 0.195 grab(model, object = \"stan_objects\") #> $data #> NULL #>  #> $stanfit #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>             mean se_mean   sd   2.5%   25%   50%   75% 97.5% n_eff Rhat #> lambdas[1]  0.50    0.01 0.29   0.02  0.24  0.50  0.75  0.98  2775    1 #> lambdas[2]  0.50    0.01 0.29   0.02  0.25  0.50  0.76  0.98  2775    1 #> lambdas[3]  0.25    0.00 0.20   0.01  0.09  0.21  0.37  0.72  1748    1 #> lambdas[4]  0.25    0.00 0.20   0.01  0.09  0.20  0.37  0.71  4574    1 #> lambdas[5]  0.25    0.00 0.20   0.01  0.09  0.20  0.36  0.73  4614    1 #> lambdas[6]  0.25    0.00 0.20   0.01  0.09  0.20  0.38  0.71  4043    1 #> w[1]        0.25    0.00 0.20   0.01  0.09  0.21  0.38  0.71  3130    1 #> w[2]        0.25    0.00 0.20   0.01  0.09  0.21  0.38  0.72  2767    1 #> w[3]        0.25    0.00 0.19   0.01  0.09  0.20  0.36  0.70  2894    1 #> w[4]        0.25    0.00 0.19   0.01  0.09  0.21  0.37  0.72  2581    1 #> types[1]    0.13    0.00 0.14   0.00  0.03  0.08  0.19  0.50  2152    1 #> types[2]    0.13    0.00 0.13   0.00  0.03  0.08  0.18  0.50  1949    1 #> types[3]    0.12    0.00 0.13   0.00  0.02  0.08  0.17  0.47  3403    1 #> types[4]    0.13    0.00 0.14   0.00  0.02  0.08  0.19  0.49  3566    1 #> types[5]    0.12    0.00 0.13   0.00  0.03  0.08  0.18  0.49  3682    1 #> types[6]    0.13    0.00 0.14   0.00  0.03  0.08  0.18  0.51  3455    1 #> types[7]    0.13    0.00 0.14   0.00  0.02  0.08  0.18  0.50  3242    1 #> types[8]    0.12    0.00 0.13   0.00  0.03  0.08  0.17  0.48  3074    1 #> lp__       -7.59    0.05 1.72 -11.86 -8.43 -7.17 -6.34 -5.43  1148    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Mar 25 23:46:14 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #>  #> $type_distribution #> Posterior draws of causal types (transformed parameters) #> Dimensions: 8 rows (draws) by 4000 cols (types)  #>  #> Summary:  #>  #>      mean   sd #> 1    0.12 0.15 #> 2    0.12 0.12 #> 3    0.12 0.20 #> 4    0.13 0.13 #> 5    0.12 0.10 #> 6    0.12 0.07 #> 7    0.12 0.13 #> 8    0.12 0.14 #> 9    0.12 0.15 #> 10   0.13 0.11 #> 11   0.13 0.16 #> 12   0.12 0.10 #> 13   0.12 0.18 #> 14   0.12 0.10 #> 15   0.13 0.13 #> 16   0.12 0.08 #> 17   0.13 0.13 #> 18   0.12 0.17 #> 19   0.12 0.08 #> 20   0.12 0.16 #> 21   0.12 0.16 #> 22   0.13 0.12 #> 23   0.12 0.15 #> 24   0.13 0.13 #> 25   0.12 0.10 #> 26   0.12 0.09 #> 27   0.12 0.15 #> 28   0.12 0.08 #> 29   0.13 0.11 #> 30   0.12 0.18 #> 31   0.12 0.06 #> 32   0.12 0.07 #> 33   0.12 0.18 #> 34   0.13 0.11 #> 35   0.13 0.12 #> 36   0.12 0.24 #> 37   0.12 0.16 #> 38   0.12 0.11 #> 39   0.12 0.15 #> 40   0.13 0.16 #> 41   0.12 0.02 #> 42   0.12 0.17 #> 43   0.13 0.12 #> 44   0.13 0.18 #> 45   0.13 0.16 #> 46   0.12 0.17 #> 47   0.12 0.11 #> 48   0.12 0.17 #> 49   0.12 0.08 #> 50   0.12 0.24 #> 51   0.13 0.13 #> 52   0.13 0.09 #> 53   0.12 0.12 #> 54   0.12 0.15 #> 55   0.12 0.13 #> 56   0.13 0.08 #> 57   0.13 0.09 #> 58   0.12 0.15 #> 59   0.12 0.11 #> 60   0.13 0.04 #> 61   0.12 0.12 #> 62   0.12 0.12 #> 63   0.12 0.12 #> 64   0.12 0.21 #> 65   0.12 0.12 #> 66   0.12 0.10 #> 67   0.12 0.15 #> 68   0.12 0.07 #> 69   0.13 0.23 #> 70   0.12 0.17 #> 71   0.12 0.23 #> 72   0.12 0.15 #> 73   0.12 0.09 #> 74   0.12 0.16 #> 75   0.13 0.14 #> 76   0.12 0.06 #> 77   0.12 0.10 #> 78   0.12 0.19 #> 79   0.12 0.15 #> 80   0.12 0.20 #> 81   0.12 0.10 #> 82   0.13 0.08 #> 83   0.12 0.15 #> 84   0.12 0.12 #> 85   0.12 0.13 #> 86   0.12 0.14 #> 87   0.12 0.14 #> 88   0.12 0.11 #> 89   0.13 0.10 #> 90   0.12 0.15 #> 91   0.13 0.09 #> 92   0.12 0.20 #> 93   0.12 0.12 #> 94   0.12 0.18 #> 95   0.13 0.12 #> 96   0.12 0.14 #> 97   0.12 0.21 #> 98   0.12 0.07 #> 99   0.12 0.14 #> 100  0.12 0.25 #> 101  0.12 0.11 #> 102  0.12 0.09 #> 103  0.12 0.17 #> 104  0.12 0.19 #> 105  0.12 0.15 #> 106  0.13 0.16 #> 107  0.12 0.28 #> 108  0.13 0.16 #> 109  0.12 0.03 #> 110  0.12 0.11 #> 111  0.12 0.07 #> 112  0.12 0.13 #> 113  0.12 0.15 #> 114  0.13 0.10 #> 115  0.12 0.10 #> 116  0.13 0.16 #> 117  0.12 0.15 #> 118  0.13 0.21 #> 119  0.12 0.09 #> 120  0.13 0.15 #> 121  0.12 0.24 #> 122  0.12 0.13 #> 123  0.12 0.12 #> 124  0.12 0.10 #> 125  0.13 0.10 #> 126  0.12 0.04 #> 127  0.12 0.15 #> 128  0.12 0.13 #> 129  0.12 0.16 #> 130  0.12 0.11 #> 131  0.12 0.12 #> 132  0.12 0.14 #> 133  0.12 0.14 #> 134  0.12 0.07 #> 135  0.12 0.18 #> 136  0.13 0.16 #> 137  0.12 0.11 #> 138  0.13 0.14 #> 139  0.13 0.16 #> 140  0.13 0.14 #> 141  0.12 0.10 #> 142  0.12 0.06 #> 143  0.12 0.14 #> 144  0.12 0.14 #> 145  0.12 0.15 #> 146  0.12 0.20 #> 147  0.12 0.09 #> 148  0.12 0.15 #> 149  0.12 0.22 #> 150  0.12 0.05 #> 151  0.12 0.17 #> 152  0.12 0.26 #> 153  0.12 0.03 #> 154  0.12 0.13 #> 155  0.12 0.16 #> 156  0.12 0.12 #> 157  0.12 0.11 #> 158  0.12 0.13 #> 159  0.12 0.13 #> 160  0.12 0.01 #> 161  0.12 0.06 #> 162  0.12 0.10 #> 163  0.12 0.14 #> 164  0.13 0.10 #> 165  0.12 0.10 #> 166  0.12 0.21 #> 167  0.12 0.13 #> 168  0.12 0.16 #> 169  0.13 0.09 #> 170  0.12 0.07 #> 171  0.12 0.18 #> 172  0.12 0.20 #> 173  0.13 0.08 #> 174  0.12 0.20 #> 175  0.12 0.17 #> 176  0.13 0.20 #> 177  0.13 0.16 #> 178  0.12 0.09 #> 179  0.12 0.18 #> 180  0.12 0.14 #> 181  0.12 0.09 #> 182  0.12 0.04 #> 183  0.13 0.12 #> 184  0.12 0.12 #> 185  0.13 0.10 #> 186  0.12 0.12 #> 187  0.12 0.19 #> 188  0.12 0.14 #> 189  0.12 0.10 #> 190  0.12 0.12 #> 191  0.12 0.14 #> 192  0.12 0.17 #> 193  0.12 0.09 #> 194  0.12 0.08 #> 195  0.13 0.07 #> 196  0.12 0.17 #> 197  0.12 0.14 #> 198  0.12 0.14 #> 199  0.13 0.09 #> 200  0.12 0.15 #> 201  0.13 0.15 #> 202  0.13 0.10 #> 203  0.12 0.12 #> 204  0.12 0.10 #> 205  0.12 0.14 #> 206  0.12 0.12 #> 207  0.12 0.13 #> 208  0.12 0.13 #> 209  0.12 0.09 #> 210  0.12 0.06 #> 211  0.12 0.12 #> 212  0.12 0.25 #> 213  0.12 0.16 #> 214  0.12 0.12 #> 215  0.13 0.16 #> 216  0.13 0.14 #> 217  0.13 0.14 #> 218  0.13 0.11 #> 219  0.13 0.14 #> 220  0.13 0.06 #> 221  0.12 0.11 #> 222  0.12 0.16 #> 223  0.12 0.05 #> 224  0.12 0.15 #> 225  0.12 0.18 #> 226  0.13 0.13 #> 227  0.12 0.23 #> 228  0.12 0.20 #> 229  0.12 0.12 #> 230  0.12 0.17 #> 231  0.12 0.16 #> 232  0.13 0.08 #> 233  0.13 0.12 #> 234  0.12 0.18 #> 235  0.12 0.07 #> 236  0.13 0.15 #> 237  0.12 0.17 #> 238  0.12 0.15 #> 239  0.12 0.15 #> 240  0.12 0.10 #> 241  0.12 0.08 #> 242  0.12 0.12 #> 243  0.12 0.19 #> 244  0.12 0.08 #> 245  0.12 0.13 #> 246  0.12 0.08 #> 247  0.12 0.09 #> 248  0.12 0.08 #> 249  0.12 0.07 #> 250  0.13 0.19 #> 251  0.12 0.11 #> 252  0.12 0.15 #> 253  0.12 0.20 #> 254  0.13 0.10 #> 255  0.12 0.08 #> 256  0.13 0.07 #> 257  0.12 0.23 #> 258  0.12 0.16 #> 259  0.13 0.18 #> 260  0.12 0.25 #> 261  0.12 0.14 #> 262  0.13 0.08 #> 263  0.12 0.17 #> 264  0.13 0.11 #> 265  0.12 0.17 #> 266  0.12 0.18 #> 267  0.12 0.07 #> 268  0.12 0.08 #> 269  0.13 0.14 #> 270  0.12 0.14 #> 271  0.12 0.12 #> 272  0.12 0.17 #> 273  0.12 0.13 #> 274  0.12 0.10 #> 275  0.13 0.11 #> 276  0.13 0.17 #> 277  0.12 0.13 #> 278  0.12 0.24 #> 279  0.12 0.13 #> 280  0.13 0.13 #> 281  0.12 0.14 #> 282  0.12 0.12 #> 283  0.12 0.21 #> 284  0.12 0.15 #> 285  0.13 0.11 #> 286  0.12 0.12 #> 287  0.13 0.09 #> 288  0.12 0.12 #> 289  0.12 0.15 #> 290  0.12 0.17 #> 291  0.13 0.07 #> 292  0.12 0.20 #> 293  0.12 0.18 #> 294  0.12 0.17 #> 295  0.13 0.15 #> 296  0.12 0.13 #> 297  0.12 0.13 #> 298  0.12 0.16 #> 299  0.12 0.17 #> 300  0.12 0.14 #> 301  0.13 0.04 #> 302  0.13 0.16 #> 303  0.12 0.08 #> 304  0.13 0.08 #> 305  0.12 0.15 #> 306  0.12 0.11 #> 307  0.12 0.10 #> 308  0.12 0.18 #> 309  0.13 0.07 #> 310  0.12 0.15 #> 311  0.12 0.20 #> 312  0.12 0.14 #> 313  0.12 0.10 #> 314  0.12 0.13 #> 315  0.12 0.16 #> 316  0.13 0.09 #> 317  0.12 0.12 #> 318  0.13 0.12 #> 319  0.13 0.10 #> 320  0.12 0.17 #> 321  0.12 0.19 #> 322  0.12 0.10 #> 323  0.12 0.11 #> 324  0.12 0.16 #> 325  0.12 0.02 #> 326  0.12 0.12 #> 327  0.12 0.18 #> 328  0.12 0.10 #> 329  0.12 0.15 #> 330  0.12 0.11 #> 331  0.13 0.17 #> 332  0.12 0.06 #> 333  0.12 0.17 #> 334  0.12 0.11 #> 335  0.12 0.07 #> 336  0.12 0.15 #> 337  0.13 0.14 #> 338  0.12 0.15 #> 339  0.12 0.09 #> 340  0.13 0.09 #> 341  0.12 0.10 #> 342  0.12 0.15 #> 343  0.12 0.05 #> 344  0.13 0.14 #> 345  0.12 0.13 #> 346  0.13 0.12 #> 347  0.13 0.14 #> 348  0.12 0.03 #> 349  0.12 0.18 #> 350  0.12 0.19 #> 351  0.12 0.20 #> 352  0.12 0.15 #> 353  0.13 0.10 #> 354  0.12 0.25 #> 355  0.12 0.12 #> 356  0.13 0.12 #> 357  0.12 0.18 #> 358  0.12 0.14 #> 359  0.12 0.05 #> 360  0.12 0.09 #> 361  0.12 0.16 #> 362  0.12 0.13 #> 363  0.12 0.20 #> 364  0.12 0.08 #> 365  0.13 0.18 #> 366  0.12 0.05 #> 367  0.13 0.07 #> 368  0.12 0.13 #> 369  0.12 0.24 #> 370  0.13 0.16 #> 371  0.13 0.15 #> 372  0.12 0.14 #> 373  0.12 0.12 #> 374  0.13 0.13 #> 375  0.13 0.10 #> 376  0.12 0.08 #> 377  0.13 0.20 #> 378  0.12 0.13 #> 379  0.12 0.13 #> 380  0.12 0.13 #> 381  0.12 0.10 #> 382  0.13 0.21 #> 383  0.12 0.08 #> 384  0.13 0.07 #> 385  0.12 0.16 #> 386  0.13 0.06 #> 387  0.13 0.05 #> 388  0.12 0.12 #> 389  0.13 0.12 #> 390  0.12 0.10 #> 391  0.12 0.10 #> 392  0.12 0.09 #> 393  0.12 0.13 #> 394  0.12 0.16 #> 395  0.12 0.16 #> 396  0.12 0.13 #> 397  0.12 0.08 #> 398  0.13 0.15 #> 399  0.13 0.15 #> 400  0.12 0.11 #> 401  0.12 0.17 #> 402  0.12 0.11 #> 403  0.12 0.12 #> 404  0.12 0.09 #> 405  0.13 0.07 #> 406  0.12 0.16 #> 407  0.12 0.11 #> 408  0.12 0.08 #> 409  0.12 0.19 #> 410  0.13 0.10 #> 411  0.13 0.14 #> 412  0.13 0.19 #> 413  0.12 0.16 #> 414  0.12 0.16 #> 415  0.12 0.17 #> 416  0.12 0.12 #> 417  0.12 0.14 #> 418  0.13 0.16 #> 419  0.12 0.16 #> 420  0.13 0.16 #> 421  0.12 0.18 #> 422  0.13 0.10 #> 423  0.13 0.12 #> 424  0.12 0.18 #> 425  0.12 0.09 #> 426  0.12 0.12 #> 427  0.12 0.14 #> 428  0.12 0.11 #> 429  0.12 0.11 #> 430  0.12 0.18 #> 431  0.12 0.13 #> 432  0.12 0.16 #> 433  0.12 0.17 #> 434  0.12 0.19 #> 435  0.13 0.01 #> 436  0.12 0.05 #> 437  0.12 0.11 #> 438  0.13 0.13 #> 439  0.12 0.22 #> 440  0.12 0.09 #> 441  0.12 0.16 #> 442  0.12 0.15 #> 443  0.12 0.09 #> 444  0.12 0.21 #> 445  0.12 0.14 #> 446  0.13 0.22 #> 447  0.13 0.16 #> 448  0.12 0.11 #> 449  0.12 0.05 #> 450  0.12 0.14 #> 451  0.12 0.17 #> 452  0.12 0.14 #> 453  0.12 0.13 #> 454  0.12 0.10 #> 455  0.13 0.15 #> 456  0.13 0.17 #> 457  0.13 0.09 #> 458  0.12 0.06 #> 459  0.12 0.16 #> 460  0.12 0.15 #> 461  0.12 0.11 #> 462  0.13 0.08 #> 463  0.13 0.13 #> 464  0.12 0.13 #> 465  0.12 0.22 #> 466  0.12 0.15 #> 467  0.12 0.17 #> 468  0.13 0.16 #> 469  0.12 0.19 #> 470  0.12 0.09 #> 471  0.12 0.19 #> 472  0.12 0.13 #> 473  0.12 0.11 #> 474  0.12 0.22 #> 475  0.12 0.14 #> 476  0.12 0.13 #> 477  0.12 0.06 #> 478  0.12 0.07 #> 479  0.13 0.18 #> 480  0.12 0.15 #> 481  0.12 0.18 #> 482  0.12 0.20 #> 483  0.12 0.14 #> 484  0.12 0.06 #> 485  0.12 0.08 #> 486  0.13 0.15 #> 487  0.12 0.15 #> 488  0.12 0.16 #> 489  0.13 0.17 #> 490  0.12 0.10 #> 491  0.13 0.24 #> 492  0.12 0.14 #> 493  0.13 0.10 #> 494  0.12 0.26 #> 495  0.13 0.15 #> 496  0.12 0.10 #> 497  0.13 0.10 #> 498  0.12 0.18 #> 499  0.12 0.17 #> 500  0.13 0.08 #> 501  0.13 0.11 #> 502  0.12 0.22 #> 503  0.13 0.11 #> 504  0.13 0.17 #> 505  0.13 0.13 #> 506  0.13 0.11 #> 507  0.13 0.16 #> 508  0.13 0.10 #> 509  0.13 0.17 #> 510  0.12 0.15 #> 511  0.12 0.10 #> 512  0.13 0.16 #> 513  0.12 0.20 #> 514  0.12 0.15 #> 515  0.12 0.14 #> 516  0.12 0.17 #> 517  0.12 0.12 #> 518  0.12 0.10 #> 519  0.12 0.11 #> 520  0.13 0.15 #> 521  0.12 0.13 #> 522  0.12 0.13 #> 523  0.13 0.14 #> 524  0.13 0.06 #> 525  0.12 0.09 #> 526  0.12 0.14 #> 527  0.12 0.15 #> 528  0.12 0.11 #> 529  0.12 0.09 #> 530  0.12 0.19 #> 531  0.13 0.21 #> 532  0.12 0.26 #> 533  0.12 0.10 #> 534  0.13 0.07 #> 535  0.12 0.21 #> 536  0.13 0.15 #> 537  0.13 0.08 #> 538  0.12 0.16 #> 539  0.12 0.14 #> 540  0.12 0.13 #> 541  0.12 0.06 #> 542  0.12 0.07 #> 543  0.12 0.13 #> 544  0.12 0.10 #> 545  0.13 0.17 #> 546  0.12 0.12 #> 547  0.12 0.09 #> 548  0.12 0.15 #> 549  0.13 0.08 #> 550  0.13 0.16 #> 551  0.12 0.20 #> 552  0.12 0.09 #> 553  0.12 0.23 #> 554  0.12 0.14 #> 555  0.12 0.13 #> 556  0.12 0.08 #> 557  0.12 0.12 #> 558  0.12 0.24 #> 559  0.12 0.12 #> 560  0.12 0.09 #> 561  0.12 0.18 #> 562  0.12 0.09 #> 563  0.12 0.07 #> 564  0.12 0.13 #> 565  0.13 0.16 #> 566  0.13 0.15 #> 567  0.13 0.12 #> 568  0.13 0.15 #> 569  0.12 0.14 #> 570  0.12 0.09 #> 571  0.12 0.15 #> 572  0.13 0.15 #> 573  0.12 0.10 #> 574  0.12 0.19 #> 575  0.12 0.10 #> 576  0.12 0.08 #> 577  0.12 0.17 #> 578  0.12 0.07 #> 579  0.13 0.27 #> 580  0.13 0.09 #> 581  0.12 0.13 #> 582  0.12 0.10 #> 583  0.13 0.07 #> 584  0.12 0.18 #> 585  0.13 0.11 #> 586  0.12 0.11 #> 587  0.13 0.10 #> 588  0.12 0.12 #> 589  0.12 0.15 #> 590  0.12 0.16 #> 591  0.12 0.14 #> 592  0.12 0.15 #> 593  0.12 0.13 #> 594  0.12 0.19 #> 595  0.12 0.17 #> 596  0.12 0.11 #> 597  0.12 0.09 #> 598  0.12 0.15 #> 599  0.13 0.12 #> 600  0.13 0.19 #> 601  0.12 0.14 #> 602  0.12 0.17 #> 603  0.13 0.08 #> 604  0.12 0.16 #> 605  0.12 0.10 #> 606  0.12 0.07 #> 607  0.12 0.11 #> 608  0.12 0.15 #> 609  0.13 0.21 #> 610  0.12 0.19 #> 611  0.13 0.15 #> 612  0.12 0.08 #> 613  0.13 0.07 #> 614  0.13 0.12 #> 615  0.12 0.18 #> 616  0.12 0.07 #> 617  0.12 0.14 #> 618  0.12 0.18 #> 619  0.12 0.15 #> 620  0.12 0.20 #> 621  0.12 0.12 #> 622  0.13 0.07 #> 623  0.12 0.13 #> 624  0.12 0.15 #> 625  0.12 0.14 #> 626  0.12 0.14 #> 627  0.12 0.14 #> 628  0.13 0.18 #> 629  0.12 0.14 #> 630  0.12 0.23 #> 631  0.12 0.16 #> 632  0.12 0.13 #> 633  0.12 0.17 #> 634  0.12 0.18 #> 635  0.12 0.09 #> 636  0.12 0.12 #> 637  0.12 0.19 #> 638  0.12 0.19 #> 639  0.12 0.19 #> 640  0.13 0.10 #> 641  0.12 0.07 #> 642  0.13 0.13 #> 643  0.12 0.12 #> 644  0.12 0.16 #> 645  0.12 0.17 #> 646  0.12 0.08 #> 647  0.13 0.10 #> 648  0.12 0.12 #> 649  0.12 0.09 #> 650  0.13 0.10 #> 651  0.12 0.21 #> 652  0.13 0.08 #> 653  0.12 0.15 #> 654  0.13 0.13 #> 655  0.12 0.16 #> 656  0.12 0.10 #> 657  0.13 0.18 #> 658  0.13 0.15 #> 659  0.12 0.14 #> 660  0.13 0.13 #> 661  0.13 0.08 #> 662  0.13 0.11 #> 663  0.12 0.10 #> 664  0.13 0.15 #> 665  0.12 0.17 #> 666  0.12 0.17 #> 667  0.13 0.16 #> 668  0.12 0.10 #> 669  0.13 0.06 #> 670  0.13 0.14 #> 671  0.12 0.04 #> 672  0.12 0.14 #> 673  0.13 0.14 #> 674  0.12 0.12 #> 675  0.12 0.10 #> 676  0.12 0.16 #> 677  0.12 0.15 #> 678  0.12 0.16 #> 679  0.13 0.11 #> 680  0.12 0.14 #> 681  0.12 0.17 #> 682  0.12 0.10 #> 683  0.12 0.15 #> 684  0.12 0.11 #> 685  0.12 0.16 #> 686  0.12 0.09 #> 687  0.12 0.15 #> 688  0.13 0.18 #> 689  0.12 0.20 #> 690  0.12 0.17 #> 691  0.12 0.18 #> 692  0.12 0.07 #> 693  0.12 0.15 #> 694  0.13 0.09 #> 695  0.12 0.13 #> 696  0.13 0.13 #> 697  0.12 0.17 #> 698  0.12 0.20 #> 699  0.12 0.15 #> 700  0.12 0.17 #> 701  0.12 0.10 #> 702  0.12 0.10 #> 703  0.12 0.16 #> 704  0.12 0.11 #> 705  0.12 0.16 #> 706  0.12 0.15 #> 707  0.13 0.21 #> 708  0.13 0.17 #> 709  0.12 0.19 #> 710  0.13 0.10 #> 711  0.12 0.15 #> 712  0.12 0.14 #> 713  0.12 0.05 #> 714  0.12 0.11 #> 715  0.12 0.15 #> 716  0.12 0.08 #> 717  0.12 0.05 #> 718  0.12 0.16 #> 719  0.13 0.16 #> 720  0.13 0.04 #> 721  0.13 0.09 #> 722  0.12 0.09 #> 723  0.12 0.07 #> 724  0.12 0.08 #> 725  0.12 0.09 #> 726  0.12 0.16 #> 727  0.13 0.11 #> 728  0.13 0.13 #> 729  0.12 0.08 #> 730  0.13 0.11 #> 731  0.12 0.15 #> 732  0.12 0.13 #> 733  0.13 0.04 #> 734  0.12 0.18 #> 735  0.12 0.04 #> 736  0.13 0.09 #> 737  0.12 0.20 #> 738  0.12 0.18 #> 739  0.12 0.10 #> 740  0.12 0.06 #> 741  0.12 0.11 #> 742  0.12 0.14 #> 743  0.12 0.17 #> 744  0.13 0.13 #> 745  0.12 0.08 #> 746  0.12 0.17 #> 747  0.12 0.07 #> 748  0.12 0.24 #> 749  0.12 0.12 #> 750  0.12 0.12 #> 751  0.12 0.09 #> 752  0.12 0.15 #> 753  0.12 0.19 #> 754  0.12 0.07 #> 755  0.12 0.12 #> 756  0.12 0.05 #> 757  0.12 0.23 #> 758  0.12 0.14 #> 759  0.13 0.21 #> 760  0.12 0.19 #> 761  0.13 0.20 #> 762  0.12 0.13 #> 763  0.13 0.11 #> 764  0.13 0.15 #> 765  0.12 0.25 #> 766  0.12 0.14 #> 767  0.12 0.16 #> 768  0.12 0.16 #> 769  0.12 0.19 #> 770  0.12 0.15 #> 771  0.13 0.11 #> 772  0.12 0.10 #> 773  0.12 0.08 #> 774  0.12 0.11 #> 775  0.12 0.08 #> 776  0.12 0.17 #> 777  0.12 0.08 #> 778  0.13 0.11 #> 779  0.12 0.20 #> 780  0.12 0.21 #> 781  0.12 0.24 #> 782  0.12 0.11 #> 783  0.13 0.05 #> 784  0.13 0.15 #> 785  0.13 0.12 #> 786  0.12 0.12 #> 787  0.12 0.17 #> 788  0.12 0.21 #> 789  0.12 0.07 #> 790  0.12 0.03 #> 791  0.12 0.12 #> 792  0.12 0.19 #> 793  0.12 0.06 #> 794  0.12 0.08 #> 795  0.12 0.14 #> 796  0.12 0.05 #> 797  0.12 0.11 #> 798  0.12 0.16 #> 799  0.13 0.21 #> 800  0.13 0.12 #> 801  0.12 0.19 #> 802  0.13 0.17 #> 803  0.12 0.16 #> 804  0.12 0.16 #> 805  0.12 0.13 #> 806  0.12 0.15 #> 807  0.12 0.15 #> 808  0.13 0.21 #> 809  0.12 0.18 #> 810  0.13 0.13 #> 811  0.12 0.16 #> 812  0.12 0.04 #> 813  0.12 0.16 #> 814  0.12 0.12 #> 815  0.13 0.14 #> 816  0.12 0.07 #> 817  0.12 0.10 #> 818  0.12 0.19 #> 819  0.12 0.09 #> 820  0.12 0.14 #> 821  0.13 0.09 #> 822  0.12 0.15 #> 823  0.12 0.09 #> 824  0.12 0.10 #> 825  0.13 0.13 #> 826  0.12 0.09 #> 827  0.12 0.09 #> 828  0.12 0.15 #> 829  0.12 0.11 #> 830  0.12 0.17 #> 831  0.12 0.17 #> 832  0.13 0.10 #> 833  0.12 0.14 #> 834  0.13 0.11 #> 835  0.12 0.13 #> 836  0.12 0.14 #> 837  0.12 0.09 #> 838  0.12 0.14 #> 839  0.13 0.18 #> 840  0.12 0.15 #> 841  0.12 0.11 #> 842  0.12 0.15 #> 843  0.12 0.16 #> 844  0.12 0.11 #> 845  0.13 0.10 #> 846  0.12 0.10 #> 847  0.12 0.24 #> 848  0.12 0.07 #> 849  0.13 0.20 #> 850  0.12 0.15 #> 851  0.12 0.16 #> 852  0.13 0.26 #> 853  0.12 0.13 #> 854  0.12 0.07 #> 855  0.13 0.09 #> 856  0.12 0.27 #> 857  0.12 0.14 #> 858  0.12 0.15 #> 859  0.12 0.17 #> 860  0.12 0.20 #> 861  0.12 0.06 #> 862  0.13 0.12 #> 863  0.12 0.10 #> 864  0.13 0.10 #> 865  0.12 0.08 #> 866  0.12 0.08 #> 867  0.12 0.15 #> 868  0.12 0.12 #> 869  0.12 0.04 #> 870  0.12 0.14 #> 871  0.12 0.08 #> 872  0.12 0.26 #> 873  0.13 0.18 #> 874  0.12 0.14 #> 875  0.12 0.07 #> 876  0.13 0.10 #> 877  0.12 0.06 #> 878  0.12 0.23 #> 879  0.12 0.18 #> 880  0.13 0.10 #> 881  0.12 0.09 #> 882  0.13 0.16 #> 883  0.12 0.14 #> 884  0.13 0.21 #> 885  0.13 0.14 #> 886  0.12 0.17 #> 887  0.12 0.13 #> 888  0.12 0.11 #> 889  0.13 0.12 #> 890  0.12 0.08 #> 891  0.12 0.13 #> 892  0.12 0.18 #> 893  0.12 0.10 #> 894  0.12 0.11 #> 895  0.13 0.12 #> 896  0.12 0.08 #> 897  0.12 0.15 #> 898  0.12 0.11 #> 899  0.12 0.14 #> 900  0.13 0.23 #> 901  0.12 0.09 #> 902  0.12 0.11 #> 903  0.12 0.17 #> 904  0.12 0.16 #> 905  0.12 0.11 #> 906  0.12 0.04 #> 907  0.12 0.10 #> 908  0.12 0.18 #> 909  0.12 0.14 #> 910  0.12 0.15 #> 911  0.12 0.17 #> 912  0.12 0.13 #> 913  0.12 0.14 #> 914  0.12 0.12 #> 915  0.12 0.16 #> 916  0.12 0.21 #> 917  0.12 0.08 #> 918  0.13 0.18 #> 919  0.13 0.12 #> 920  0.12 0.07 #> 921  0.12 0.04 #> 922  0.12 0.13 #> 923  0.12 0.16 #> 924  0.12 0.07 #> 925  0.13 0.12 #> 926  0.12 0.09 #> 927  0.12 0.10 #> 928  0.12 0.18 #> 929  0.12 0.22 #> 930  0.13 0.14 #> 931  0.12 0.18 #> 932  0.12 0.14 #> 933  0.12 0.14 #> 934  0.13 0.11 #> 935  0.13 0.11 #> 936  0.12 0.08 #> 937  0.12 0.16 #> 938  0.12 0.07 #> 939  0.12 0.15 #> 940  0.12 0.14 #> 941  0.12 0.07 #> 942  0.12 0.21 #> 943  0.12 0.18 #> 944  0.12 0.11 #> 945  0.12 0.17 #> 946  0.12 0.15 #> 947  0.13 0.17 #> 948  0.12 0.16 #> 949  0.12 0.06 #> 950  0.12 0.19 #> 951  0.12 0.14 #> 952  0.12 0.11 #> 953  0.12 0.13 #> 954  0.12 0.10 #> 955  0.13 0.11 #> 956  0.12 0.10 #> 957  0.12 0.18 #> 958  0.12 0.12 #> 959  0.12 0.26 #> 960  0.12 0.23 #> 961  0.13 0.15 #> 962  0.12 0.09 #> 963  0.12 0.14 #> 964  0.12 0.07 #> 965  0.12 0.12 #> 966  0.12 0.10 #> 967  0.12 0.15 #> 968  0.13 0.19 #> 969  0.12 0.20 #> 970  0.12 0.13 #> 971  0.12 0.08 #> 972  0.12 0.13 #> 973  0.12 0.16 #> 974  0.13 0.16 #> 975  0.12 0.13 #> 976  0.13 0.15 #> 977  0.12 0.17 #> 978  0.13 0.08 #> 979  0.12 0.18 #> 980  0.13 0.05 #> 981  0.12 0.17 #> 982  0.12 0.13 #> 983  0.12 0.14 #> 984  0.13 0.05 #> 985  0.12 0.17 #> 986  0.12 0.19 #> 987  0.12 0.12 #> 988  0.13 0.15 #> 989  0.12 0.12 #> 990  0.12 0.09 #> 991  0.12 0.16 #> 992  0.12 0.16 #> 993  0.13 0.17 #> 994  0.12 0.12 #> 995  0.12 0.23 #> 996  0.12 0.07 #> 997  0.13 0.04 #> 998  0.12 0.12 #> 999  0.12 0.05 #> 1000 0.12 0.07 #> 1001 0.13 0.17 #> 1002 0.12 0.16 #> 1003 0.13 0.12 #> 1004 0.12 0.15 #> 1005 0.12 0.18 #> 1006 0.12 0.06 #> 1007 0.13 0.08 #> 1008 0.12 0.05 #> 1009 0.12 0.20 #> 1010 0.12 0.20 #> 1011 0.12 0.17 #> 1012 0.12 0.18 #> 1013 0.12 0.05 #> 1014 0.13 0.07 #> 1015 0.12 0.18 #> 1016 0.12 0.14 #> 1017 0.12 0.15 #> 1018 0.12 0.13 #> 1019 0.12 0.08 #> 1020 0.12 0.08 #> 1021 0.12 0.14 #> 1022 0.12 0.11 #> 1023 0.12 0.13 #> 1024 0.12 0.09 #> 1025 0.13 0.20 #> 1026 0.12 0.16 #> 1027 0.12 0.11 #> 1028 0.13 0.13 #> 1029 0.12 0.12 #> 1030 0.12 0.12 #> 1031 0.12 0.09 #> 1032 0.12 0.13 #> 1033 0.12 0.15 #> 1034 0.12 0.09 #> 1035 0.12 0.25 #> 1036 0.12 0.10 #> 1037 0.13 0.16 #> 1038 0.12 0.11 #> 1039 0.13 0.19 #> 1040 0.12 0.17 #> 1041 0.12 0.15 #> 1042 0.13 0.14 #> 1043 0.13 0.18 #> 1044 0.12 0.13 #> 1045 0.13 0.17 #> 1046 0.12 0.13 #> 1047 0.13 0.14 #> 1048 0.12 0.08 #> 1049 0.12 0.20 #> 1050 0.12 0.10 #> 1051 0.12 0.15 #> 1052 0.12 0.08 #> 1053 0.13 0.15 #> 1054 0.12 0.22 #> 1055 0.13 0.12 #> 1056 0.12 0.16 #> 1057 0.13 0.15 #> 1058 0.13 0.16 #> 1059 0.12 0.10 #> 1060 0.12 0.10 #> 1061 0.12 0.14 #> 1062 0.12 0.07 #> 1063 0.12 0.16 #> 1064 0.12 0.13 #> 1065 0.12 0.12 #> 1066 0.12 0.16 #> 1067 0.12 0.06 #> 1068 0.12 0.13 #> 1069 0.12 0.07 #> 1070 0.13 0.20 #> 1071 0.12 0.11 #> 1072 0.13 0.14 #> 1073 0.12 0.08 #> 1074 0.13 0.15 #> 1075 0.12 0.11 #> 1076 0.12 0.10 #> 1077 0.12 0.14 #> 1078 0.12 0.11 #> 1079 0.12 0.13 #> 1080 0.12 0.12 #> 1081 0.12 0.14 #> 1082 0.13 0.12 #> 1083 0.13 0.14 #> 1084 0.12 0.08 #> 1085 0.13 0.11 #> 1086 0.12 0.11 #> 1087 0.12 0.14 #> 1088 0.12 0.08 #> 1089 0.12 0.13 #> 1090 0.12 0.14 #> 1091 0.12 0.08 #> 1092 0.12 0.15 #> 1093 0.12 0.12 #> 1094 0.12 0.17 #> 1095 0.12 0.14 #> 1096 0.12 0.18 #> 1097 0.13 0.15 #> 1098 0.12 0.11 #> 1099 0.13 0.15 #> 1100 0.12 0.22 #> 1101 0.12 0.13 #> 1102 0.12 0.13 #> 1103 0.12 0.22 #> 1104 0.12 0.19 #> 1105 0.13 0.19 #> 1106 0.12 0.14 #> 1107 0.12 0.08 #> 1108 0.12 0.23 #> 1109 0.12 0.08 #> 1110 0.12 0.19 #> 1111 0.12 0.07 #> 1112 0.12 0.13 #> 1113 0.13 0.09 #> 1114 0.12 0.11 #> 1115 0.13 0.18 #> 1116 0.12 0.09 #> 1117 0.12 0.13 #> 1118 0.13 0.05 #> 1119 0.13 0.10 #> 1120 0.12 0.17 #> 1121 0.12 0.04 #> 1122 0.12 0.18 #> 1123 0.12 0.15 #> 1124 0.13 0.11 #> 1125 0.12 0.11 #> 1126 0.12 0.16 #> 1127 0.12 0.13 #> 1128 0.12 0.16 #> 1129 0.12 0.11 #> 1130 0.13 0.15 #> 1131 0.12 0.08 #> 1132 0.12 0.18 #> 1133 0.13 0.12 #> 1134 0.12 0.12 #> 1135 0.13 0.17 #> 1136 0.12 0.13 #> 1137 0.12 0.17 #> 1138 0.12 0.14 #> 1139 0.13 0.17 #> 1140 0.12 0.14 #> 1141 0.13 0.08 #> 1142 0.12 0.12 #> 1143 0.12 0.15 #> 1144 0.13 0.15 #> 1145 0.13 0.13 #> 1146 0.12 0.12 #> 1147 0.13 0.13 #> 1148 0.12 0.15 #> 1149 0.12 0.10 #> 1150 0.12 0.02 #> 1151 0.12 0.11 #> 1152 0.12 0.14 #> 1153 0.13 0.11 #> 1154 0.12 0.17 #> 1155 0.12 0.15 #> 1156 0.12 0.15 #> 1157 0.12 0.18 #> 1158 0.12 0.26 #> 1159 0.12 0.11 #> 1160 0.12 0.19 #> 1161 0.12 0.16 #> 1162 0.12 0.13 #> 1163 0.12 0.15 #> 1164 0.12 0.20 #> 1165 0.13 0.13 #> 1166 0.12 0.10 #> 1167 0.12 0.16 #> 1168 0.12 0.07 #> 1169 0.12 0.21 #> 1170 0.12 0.08 #> 1171 0.12 0.14 #> 1172 0.12 0.15 #> 1173 0.12 0.07 #> 1174 0.12 0.23 #> 1175 0.12 0.15 #> 1176 0.12 0.13 #> 1177 0.12 0.10 #> 1178 0.12 0.18 #> 1179 0.13 0.13 #> 1180 0.12 0.14 #> 1181 0.12 0.14 #> 1182 0.12 0.08 #> 1183 0.12 0.05 #> 1184 0.13 0.11 #> 1185 0.12 0.15 #> 1186 0.12 0.12 #> 1187 0.12 0.16 #> 1188 0.12 0.19 #> 1189 0.12 0.05 #> 1190 0.12 0.07 #> 1191 0.13 0.24 #> 1192 0.12 0.16 #> 1193 0.12 0.08 #> 1194 0.12 0.10 #> 1195 0.12 0.06 #> 1196 0.12 0.12 #> 1197 0.12 0.14 #> 1198 0.12 0.13 #> 1199 0.13 0.10 #> 1200 0.12 0.20 #> 1201 0.12 0.14 #> 1202 0.13 0.20 #> 1203 0.13 0.13 #> 1204 0.12 0.15 #> 1205 0.12 0.04 #> 1206 0.12 0.19 #> 1207 0.13 0.12 #> 1208 0.12 0.15 #> 1209 0.12 0.14 #> 1210 0.12 0.10 #> 1211 0.13 0.21 #> 1212 0.13 0.18 #> 1213 0.12 0.20 #> 1214 0.12 0.13 #> 1215 0.12 0.08 #> 1216 0.12 0.16 #> 1217 0.12 0.10 #> 1218 0.12 0.17 #> 1219 0.12 0.20 #> 1220 0.12 0.16 #> 1221 0.12 0.12 #> 1222 0.12 0.07 #> 1223 0.12 0.16 #> 1224 0.12 0.11 #> 1225 0.13 0.14 #> 1226 0.12 0.24 #> 1227 0.13 0.15 #> 1228 0.12 0.17 #> 1229 0.12 0.21 #> 1230 0.12 0.10 #> 1231 0.12 0.18 #> 1232 0.12 0.15 #> 1233 0.12 0.09 #> 1234 0.12 0.10 #> 1235 0.12 0.13 #> 1236 0.12 0.13 #> 1237 0.12 0.11 #> 1238 0.12 0.08 #> 1239 0.13 0.10 #> 1240 0.12 0.13 #> 1241 0.12 0.14 #> 1242 0.12 0.04 #> 1243 0.12 0.13 #> 1244 0.12 0.10 #> 1245 0.12 0.10 #> 1246 0.12 0.11 #> 1247 0.12 0.16 #> 1248 0.12 0.17 #> 1249 0.12 0.19 #> 1250 0.12 0.21 #> 1251 0.12 0.06 #> 1252 0.12 0.17 #> 1253 0.12 0.14 #> 1254 0.12 0.19 #> 1255 0.12 0.17 #> 1256 0.12 0.21 #> 1257 0.12 0.04 #> 1258 0.12 0.11 #> 1259 0.12 0.11 #> 1260 0.12 0.11 #> 1261 0.12 0.14 #> 1262 0.12 0.20 #> 1263 0.12 0.11 #> 1264 0.13 0.16 #> 1265 0.13 0.15 #> 1266 0.12 0.14 #> 1267 0.12 0.13 #> 1268 0.12 0.17 #> 1269 0.12 0.10 #> 1270 0.12 0.12 #> 1271 0.12 0.18 #> 1272 0.12 0.16 #> 1273 0.13 0.11 #> 1274 0.12 0.09 #> 1275 0.12 0.12 #> 1276 0.13 0.18 #> 1277 0.12 0.18 #> 1278 0.12 0.18 #> 1279 0.12 0.11 #> 1280 0.12 0.09 #> 1281 0.12 0.17 #> 1282 0.12 0.14 #> 1283 0.12 0.11 #> 1284 0.12 0.18 #> 1285 0.12 0.07 #> 1286 0.12 0.16 #> 1287 0.12 0.19 #> 1288 0.12 0.16 #> 1289 0.13 0.14 #> 1290 0.13 0.14 #> 1291 0.13 0.10 #> 1292 0.12 0.19 #> 1293 0.12 0.20 #> 1294 0.12 0.19 #> 1295 0.12 0.11 #> 1296 0.13 0.06 #> 1297 0.12 0.15 #> 1298 0.12 0.14 #> 1299 0.12 0.10 #> 1300 0.12 0.15 #> 1301 0.12 0.14 #> 1302 0.12 0.12 #> 1303 0.12 0.17 #> 1304 0.13 0.10 #> 1305 0.12 0.09 #> 1306 0.13 0.19 #> 1307 0.12 0.12 #> 1308 0.12 0.18 #> 1309 0.13 0.10 #> 1310 0.12 0.19 #> 1311 0.12 0.11 #> 1312 0.12 0.11 #> 1313 0.12 0.11 #> 1314 0.12 0.18 #> 1315 0.12 0.03 #> 1316 0.12 0.16 #> 1317 0.12 0.13 #> 1318 0.13 0.08 #> 1319 0.12 0.09 #> 1320 0.12 0.16 #> 1321 0.12 0.15 #> 1322 0.12 0.20 #> 1323 0.12 0.07 #> 1324 0.12 0.16 #> 1325 0.12 0.12 #> 1326 0.12 0.19 #> 1327 0.12 0.09 #> 1328 0.12 0.15 #> 1329 0.12 0.10 #> 1330 0.12 0.10 #> 1331 0.12 0.12 #> 1332 0.12 0.11 #> 1333 0.13 0.15 #> 1334 0.13 0.12 #> 1335 0.13 0.11 #> 1336 0.13 0.15 #> 1337 0.13 0.11 #> 1338 0.12 0.18 #> 1339 0.13 0.10 #> 1340 0.12 0.08 #> 1341 0.12 0.09 #> 1342 0.12 0.10 #> 1343 0.12 0.13 #> 1344 0.12 0.09 #> 1345 0.12 0.06 #> 1346 0.12 0.18 #> 1347 0.12 0.13 #> 1348 0.12 0.11 #> 1349 0.13 0.10 #> 1350 0.12 0.15 #> 1351 0.12 0.08 #> 1352 0.12 0.17 #> 1353 0.12 0.18 #> 1354 0.12 0.10 #> 1355 0.12 0.14 #> 1356 0.12 0.05 #> 1357 0.13 0.15 #> 1358 0.12 0.07 #> 1359 0.12 0.21 #> 1360 0.13 0.09 #> 1361 0.13 0.14 #> 1362 0.12 0.11 #> 1363 0.12 0.08 #> 1364 0.13 0.13 #> 1365 0.12 0.11 #> 1366 0.12 0.11 #> 1367 0.12 0.08 #> 1368 0.13 0.10 #> 1369 0.12 0.23 #> 1370 0.13 0.13 #> 1371 0.12 0.17 #> 1372 0.13 0.14 #> 1373 0.12 0.03 #> 1374 0.13 0.17 #> 1375 0.13 0.06 #> 1376 0.12 0.13 #> 1377 0.12 0.17 #> 1378 0.13 0.14 #> 1379 0.12 0.09 #> 1380 0.13 0.08 #> 1381 0.12 0.08 #> 1382 0.12 0.13 #> 1383 0.12 0.16 #> 1384 0.13 0.11 #> 1385 0.12 0.23 #> 1386 0.13 0.18 #> 1387 0.12 0.09 #> 1388 0.13 0.09 #> 1389 0.12 0.09 #> 1390 0.13 0.21 #> 1391 0.12 0.13 #> 1392 0.12 0.16 #> 1393 0.13 0.16 #> 1394 0.13 0.21 #> 1395 0.12 0.17 #> 1396 0.12 0.08 #> 1397 0.12 0.15 #> 1398 0.13 0.10 #> 1399 0.12 0.15 #> 1400 0.12 0.14 #> 1401 0.12 0.19 #> 1402 0.13 0.19 #> 1403 0.13 0.21 #> 1404 0.13 0.14 #> 1405 0.12 0.09 #> 1406 0.12 0.24 #> 1407 0.12 0.11 #> 1408 0.12 0.15 #> 1409 0.12 0.13 #> 1410 0.12 0.18 #> 1411 0.12 0.15 #> 1412 0.12 0.12 #> 1413 0.12 0.09 #> 1414 0.12 0.11 #> 1415 0.13 0.10 #> 1416 0.12 0.17 #> 1417 0.13 0.13 #> 1418 0.12 0.13 #> 1419 0.12 0.20 #> 1420 0.13 0.20 #> 1421 0.12 0.16 #> 1422 0.12 0.12 #> 1423 0.12 0.12 #> 1424 0.13 0.19 #> 1425 0.12 0.19 #> 1426 0.12 0.18 #> 1427 0.12 0.16 #> 1428 0.13 0.13 #> 1429 0.12 0.12 #> 1430 0.13 0.08 #> 1431 0.12 0.14 #> 1432 0.13 0.25 #> 1433 0.12 0.10 #> 1434 0.12 0.11 #> 1435 0.13 0.12 #> 1436 0.12 0.18 #> 1437 0.12 0.16 #> 1438 0.12 0.20 #> 1439 0.12 0.17 #> 1440 0.13 0.16 #> 1441 0.12 0.09 #> 1442 0.13 0.14 #> 1443 0.12 0.10 #> 1444 0.12 0.19 #> 1445 0.12 0.19 #> 1446 0.12 0.13 #> 1447 0.12 0.09 #> 1448 0.12 0.16 #> 1449 0.12 0.16 #> 1450 0.12 0.14 #> 1451 0.12 0.10 #> 1452 0.12 0.12 #> 1453 0.12 0.23 #> 1454 0.12 0.16 #> 1455 0.12 0.20 #> 1456 0.12 0.25 #> 1457 0.13 0.24 #> 1458 0.13 0.06 #> 1459 0.12 0.19 #> 1460 0.12 0.13 #> 1461 0.13 0.14 #> 1462 0.12 0.18 #> 1463 0.13 0.12 #> 1464 0.13 0.17 #> 1465 0.12 0.12 #> 1466 0.12 0.17 #> 1467 0.12 0.22 #> 1468 0.12 0.10 #> 1469 0.12 0.13 #> 1470 0.12 0.16 #> 1471 0.12 0.14 #> 1472 0.12 0.21 #> 1473 0.12 0.07 #> 1474 0.12 0.18 #> 1475 0.12 0.19 #> 1476 0.12 0.12 #> 1477 0.12 0.15 #> 1478 0.12 0.11 #> 1479 0.13 0.17 #> 1480 0.12 0.15 #> 1481 0.13 0.07 #> 1482 0.12 0.08 #> 1483 0.12 0.12 #> 1484 0.12 0.12 #> 1485 0.12 0.08 #> 1486 0.12 0.19 #> 1487 0.13 0.12 #> 1488 0.12 0.16 #> 1489 0.12 0.20 #> 1490 0.12 0.19 #> 1491 0.12 0.11 #> 1492 0.13 0.17 #> 1493 0.12 0.08 #> 1494 0.12 0.12 #> 1495 0.12 0.22 #> 1496 0.12 0.13 #> 1497 0.13 0.13 #> 1498 0.13 0.17 #> 1499 0.12 0.14 #> 1500 0.12 0.16 #> 1501 0.12 0.23 #> 1502 0.12 0.17 #> 1503 0.12 0.12 #> 1504 0.13 0.13 #> 1505 0.13 0.04 #> 1506 0.13 0.19 #> 1507 0.12 0.07 #> 1508 0.12 0.14 #> 1509 0.12 0.20 #> 1510 0.12 0.15 #> 1511 0.13 0.14 #> 1512 0.12 0.15 #> 1513 0.12 0.13 #> 1514 0.13 0.22 #> 1515 0.12 0.09 #> 1516 0.12 0.13 #> 1517 0.12 0.16 #> 1518 0.12 0.23 #> 1519 0.12 0.18 #> 1520 0.12 0.12 #> 1521 0.12 0.13 #> 1522 0.12 0.12 #> 1523 0.12 0.12 #> 1524 0.12 0.01 #> 1525 0.12 0.12 #> 1526 0.12 0.11 #> 1527 0.12 0.13 #> 1528 0.13 0.09 #> 1529 0.12 0.11 #> 1530 0.12 0.14 #> 1531 0.12 0.09 #> 1532 0.12 0.14 #> 1533 0.13 0.23 #> 1534 0.12 0.20 #> 1535 0.12 0.13 #> 1536 0.12 0.13 #> 1537 0.12 0.09 #> 1538 0.12 0.13 #> 1539 0.12 0.14 #> 1540 0.13 0.09 #> 1541 0.13 0.09 #> 1542 0.12 0.09 #> 1543 0.13 0.10 #> 1544 0.12 0.18 #> 1545 0.12 0.10 #> 1546 0.12 0.16 #> 1547 0.12 0.12 #> 1548 0.12 0.13 #> 1549 0.12 0.12 #> 1550 0.12 0.20 #> 1551 0.12 0.04 #> 1552 0.12 0.13 #> 1553 0.12 0.09 #> 1554 0.12 0.06 #> 1555 0.13 0.09 #> 1556 0.12 0.12 #> 1557 0.13 0.13 #> 1558 0.12 0.15 #> 1559 0.12 0.12 #> 1560 0.12 0.10 #> 1561 0.12 0.19 #> 1562 0.12 0.20 #> 1563 0.12 0.05 #> 1564 0.13 0.23 #> 1565 0.12 0.10 #> 1566 0.12 0.16 #> 1567 0.12 0.11 #> 1568 0.12 0.09 #> 1569 0.12 0.11 #> 1570 0.12 0.08 #> 1571 0.12 0.25 #> 1572 0.12 0.11 #> 1573 0.12 0.13 #> 1574 0.12 0.13 #> 1575 0.12 0.09 #> 1576 0.12 0.13 #> 1577 0.13 0.13 #> 1578 0.13 0.11 #> 1579 0.12 0.12 #> 1580 0.12 0.21 #> 1581 0.13 0.14 #> 1582 0.12 0.12 #> 1583 0.12 0.07 #> 1584 0.13 0.18 #> 1585 0.12 0.08 #> 1586 0.12 0.13 #> 1587 0.12 0.16 #> 1588 0.12 0.12 #> 1589 0.12 0.12 #> 1590 0.12 0.06 #> 1591 0.12 0.09 #> 1592 0.12 0.10 #> 1593 0.12 0.09 #> 1594 0.12 0.07 #> 1595 0.12 0.11 #> 1596 0.13 0.22 #> 1597 0.13 0.09 #> 1598 0.12 0.10 #> 1599 0.12 0.20 #> 1600 0.12 0.21 #> 1601 0.13 0.15 #> 1602 0.12 0.14 #> 1603 0.12 0.15 #> 1604 0.12 0.22 #> 1605 0.12 0.18 #> 1606 0.12 0.07 #> 1607 0.12 0.10 #> 1608 0.13 0.14 #> 1609 0.12 0.12 #> 1610 0.13 0.11 #> 1611 0.12 0.08 #> 1612 0.13 0.09 #> 1613 0.12 0.08 #> 1614 0.12 0.18 #> 1615 0.12 0.20 #> 1616 0.13 0.13 #> 1617 0.12 0.11 #> 1618 0.12 0.18 #> 1619 0.12 0.15 #> 1620 0.12 0.12 #> 1621 0.12 0.13 #> 1622 0.13 0.08 #> 1623 0.13 0.15 #> 1624 0.12 0.12 #> 1625 0.12 0.19 #> 1626 0.12 0.26 #> 1627 0.12 0.16 #> 1628 0.12 0.15 #> 1629 0.12 0.15 #> 1630 0.12 0.12 #> 1631 0.12 0.17 #> 1632 0.12 0.13 #> 1633 0.12 0.16 #> 1634 0.12 0.10 #> 1635 0.12 0.09 #> 1636 0.12 0.10 #> 1637 0.13 0.12 #> 1638 0.12 0.12 #> 1639 0.12 0.25 #> 1640 0.12 0.07 #> 1641 0.12 0.13 #> 1642 0.12 0.17 #> 1643 0.12 0.32 #> 1644 0.12 0.14 #> 1645 0.13 0.16 #> 1646 0.12 0.14 #> 1647 0.13 0.12 #> 1648 0.12 0.08 #> 1649 0.12 0.12 #> 1650 0.13 0.11 #> 1651 0.12 0.22 #> 1652 0.12 0.14 #> 1653 0.12 0.18 #> 1654 0.13 0.10 #> 1655 0.12 0.12 #> 1656 0.12 0.11 #> 1657 0.12 0.10 #> 1658 0.12 0.18 #> 1659 0.12 0.14 #> 1660 0.12 0.09 #> 1661 0.12 0.11 #> 1662 0.12 0.18 #> 1663 0.13 0.14 #> 1664 0.12 0.15 #> 1665 0.12 0.11 #> 1666 0.13 0.14 #> 1667 0.12 0.15 #> 1668 0.12 0.13 #> 1669 0.13 0.16 #> 1670 0.12 0.11 #> 1671 0.12 0.08 #> 1672 0.12 0.17 #> 1673 0.13 0.13 #> 1674 0.13 0.11 #> 1675 0.12 0.09 #> 1676 0.12 0.17 #> 1677 0.12 0.06 #> 1678 0.12 0.16 #> 1679 0.12 0.11 #> 1680 0.13 0.16 #> 1681 0.12 0.14 #> 1682 0.13 0.13 #> 1683 0.12 0.27 #> 1684 0.13 0.11 #> 1685 0.12 0.16 #> 1686 0.13 0.04 #> 1687 0.12 0.14 #> 1688 0.13 0.09 #> 1689 0.12 0.16 #> 1690 0.12 0.12 #> 1691 0.12 0.19 #> 1692 0.12 0.11 #> 1693 0.12 0.03 #> 1694 0.12 0.14 #> 1695 0.13 0.18 #> 1696 0.12 0.08 #> 1697 0.12 0.11 #> 1698 0.12 0.18 #> 1699 0.12 0.09 #> 1700 0.12 0.11 #> 1701 0.12 0.22 #> 1702 0.12 0.18 #> 1703 0.12 0.13 #> 1704 0.12 0.18 #> 1705 0.12 0.18 #> 1706 0.12 0.16 #> 1707 0.12 0.23 #> 1708 0.12 0.13 #> 1709 0.12 0.07 #> 1710 0.13 0.12 #> 1711 0.12 0.14 #> 1712 0.12 0.12 #> 1713 0.12 0.14 #> 1714 0.13 0.18 #> 1715 0.12 0.14 #> 1716 0.12 0.11 #> 1717 0.12 0.16 #> 1718 0.13 0.11 #> 1719 0.12 0.14 #> 1720 0.12 0.10 #> 1721 0.13 0.11 #> 1722 0.12 0.19 #> 1723 0.13 0.13 #> 1724 0.12 0.22 #> 1725 0.12 0.10 #> 1726 0.12 0.13 #> 1727 0.12 0.17 #> 1728 0.12 0.11 #> 1729 0.12 0.11 #> 1730 0.12 0.08 #> 1731 0.13 0.13 #> 1732 0.12 0.13 #> 1733 0.12 0.16 #> 1734 0.13 0.20 #> 1735 0.13 0.19 #> 1736 0.12 0.09 #> 1737 0.12 0.16 #> 1738 0.12 0.16 #> 1739 0.13 0.05 #> 1740 0.12 0.13 #> 1741 0.12 0.23 #> 1742 0.12 0.13 #> 1743 0.12 0.18 #> 1744 0.13 0.16 #> 1745 0.12 0.15 #> 1746 0.12 0.15 #> 1747 0.12 0.14 #> 1748 0.12 0.14 #> 1749 0.12 0.14 #> 1750 0.12 0.17 #> 1751 0.12 0.16 #> 1752 0.12 0.17 #> 1753 0.13 0.15 #> 1754 0.12 0.19 #> 1755 0.12 0.17 #> 1756 0.13 0.17 #> 1757 0.13 0.20 #> 1758 0.12 0.15 #> 1759 0.12 0.09 #> 1760 0.12 0.16 #> 1761 0.12 0.09 #> 1762 0.12 0.16 #> 1763 0.12 0.13 #> 1764 0.12 0.06 #> 1765 0.12 0.21 #> 1766 0.12 0.13 #> 1767 0.12 0.14 #> 1768 0.12 0.19 #> 1769 0.12 0.11 #> 1770 0.12 0.05 #> 1771 0.12 0.14 #> 1772 0.13 0.09 #> 1773 0.12 0.23 #> 1774 0.12 0.08 #> 1775 0.12 0.12 #> 1776 0.12 0.13 #> 1777 0.12 0.16 #> 1778 0.12 0.10 #> 1779 0.12 0.15 #> 1780 0.12 0.14 #> 1781 0.12 0.18 #> 1782 0.12 0.09 #> 1783 0.13 0.13 #> 1784 0.13 0.09 #> 1785 0.12 0.14 #> 1786 0.12 0.15 #> 1787 0.12 0.14 #> 1788 0.13 0.07 #> 1789 0.12 0.11 #> 1790 0.12 0.17 #> 1791 0.12 0.07 #> 1792 0.13 0.08 #> 1793 0.13 0.16 #> 1794 0.13 0.19 #> 1795 0.12 0.11 #> 1796 0.12 0.08 #> 1797 0.13 0.11 #> 1798 0.12 0.14 #> 1799 0.12 0.11 #> 1800 0.12 0.11 #> 1801 0.12 0.16 #> 1802 0.12 0.11 #> 1803 0.12 0.18 #> 1804 0.12 0.09 #> 1805 0.12 0.03 #> 1806 0.12 0.13 #> 1807 0.12 0.16 #> 1808 0.12 0.15 #> 1809 0.13 0.11 #> 1810 0.13 0.13 #> 1811 0.12 0.09 #> 1812 0.12 0.12 #> 1813 0.12 0.15 #> 1814 0.12 0.10 #> 1815 0.12 0.14 #> 1816 0.13 0.19 #> 1817 0.12 0.17 #> 1818 0.12 0.13 #> 1819 0.12 0.15 #> 1820 0.12 0.10 #> 1821 0.12 0.19 #> 1822 0.12 0.14 #> 1823 0.13 0.12 #> 1824 0.12 0.08 #> 1825 0.12 0.10 #> 1826 0.12 0.17 #> 1827 0.12 0.11 #> 1828 0.12 0.05 #> 1829 0.13 0.19 #> 1830 0.12 0.12 #> 1831 0.12 0.10 #> 1832 0.13 0.17 #> 1833 0.13 0.10 #> 1834 0.12 0.10 #> 1835 0.12 0.08 #> 1836 0.12 0.10 #> 1837 0.12 0.19 #> 1838 0.13 0.09 #> 1839 0.12 0.25 #> 1840 0.12 0.04 #> 1841 0.12 0.18 #> 1842 0.13 0.20 #> 1843 0.13 0.12 #> 1844 0.13 0.10 #> 1845 0.13 0.08 #> 1846 0.12 0.08 #> 1847 0.12 0.19 #> 1848 0.12 0.17 #> 1849 0.12 0.14 #> 1850 0.12 0.12 #> 1851 0.12 0.15 #> 1852 0.12 0.10 #> 1853 0.12 0.17 #> 1854 0.12 0.13 #> 1855 0.12 0.24 #> 1856 0.13 0.18 #> 1857 0.13 0.10 #> 1858 0.13 0.10 #> 1859 0.13 0.17 #> 1860 0.13 0.11 #> 1861 0.12 0.14 #> 1862 0.12 0.08 #> 1863 0.12 0.20 #> 1864 0.13 0.10 #> 1865 0.13 0.18 #> 1866 0.12 0.20 #> 1867 0.12 0.08 #> 1868 0.12 0.23 #> 1869 0.12 0.20 #> 1870 0.13 0.18 #> 1871 0.12 0.09 #> 1872 0.13 0.07 #> 1873 0.12 0.13 #> 1874 0.13 0.23 #> 1875 0.13 0.15 #> 1876 0.12 0.07 #> 1877 0.13 0.08 #> 1878 0.12 0.19 #> 1879 0.12 0.12 #> 1880 0.12 0.22 #> 1881 0.12 0.26 #> 1882 0.12 0.09 #> 1883 0.12 0.14 #> 1884 0.12 0.15 #> 1885 0.12 0.13 #> 1886 0.13 0.17 #> 1887 0.12 0.11 #> 1888 0.13 0.11 #> 1889 0.12 0.16 #> 1890 0.12 0.08 #> 1891 0.12 0.12 #> 1892 0.12 0.14 #> 1893 0.12 0.08 #> 1894 0.12 0.12 #> 1895 0.12 0.17 #> 1896 0.12 0.09 #> 1897 0.12 0.19 #> 1898 0.12 0.06 #> 1899 0.12 0.12 #> 1900 0.12 0.08 #> 1901 0.13 0.15 #> 1902 0.12 0.07 #> 1903 0.12 0.18 #> 1904 0.12 0.11 #> 1905 0.13 0.10 #> 1906 0.12 0.15 #> 1907 0.12 0.08 #> 1908 0.12 0.16 #> 1909 0.13 0.11 #> 1910 0.13 0.20 #> 1911 0.12 0.19 #> 1912 0.12 0.10 #> 1913 0.12 0.09 #> 1914 0.12 0.17 #> 1915 0.12 0.19 #> 1916 0.12 0.11 #> 1917 0.12 0.09 #> 1918 0.12 0.09 #> 1919 0.13 0.10 #> 1920 0.12 0.14 #> 1921 0.12 0.14 #> 1922 0.13 0.11 #> 1923 0.13 0.12 #> 1924 0.12 0.14 #> 1925 0.12 0.14 #> 1926 0.13 0.15 #> 1927 0.12 0.10 #> 1928 0.12 0.18 #> 1929 0.12 0.11 #> 1930 0.12 0.13 #> 1931 0.12 0.12 #> 1932 0.13 0.13 #> 1933 0.12 0.20 #> 1934 0.12 0.10 #> 1935 0.12 0.07 #> 1936 0.12 0.14 #> 1937 0.12 0.16 #> 1938 0.12 0.12 #> 1939 0.13 0.08 #> 1940 0.12 0.10 #> 1941 0.12 0.10 #> 1942 0.13 0.16 #> 1943 0.12 0.10 #> 1944 0.13 0.06 #> 1945 0.13 0.16 #> 1946 0.12 0.11 #> 1947 0.12 0.10 #> 1948 0.12 0.10 #> 1949 0.12 0.13 #> 1950 0.13 0.16 #> 1951 0.12 0.11 #> 1952 0.12 0.14 #> 1953 0.12 0.10 #> 1954 0.13 0.08 #> 1955 0.12 0.12 #> 1956 0.12 0.12 #> 1957 0.12 0.22 #> 1958 0.12 0.12 #> 1959 0.12 0.07 #> 1960 0.13 0.13 #> 1961 0.13 0.10 #> 1962 0.13 0.16 #> 1963 0.12 0.11 #> 1964 0.12 0.19 #> 1965 0.13 0.10 #> 1966 0.12 0.09 #> 1967 0.13 0.10 #> 1968 0.12 0.10 #> 1969 0.12 0.06 #> 1970 0.12 0.16 #> 1971 0.12 0.16 #> 1972 0.12 0.08 #> 1973 0.12 0.07 #> 1974 0.12 0.09 #> 1975 0.12 0.13 #> 1976 0.12 0.10 #> 1977 0.12 0.22 #> 1978 0.12 0.20 #> 1979 0.13 0.08 #> 1980 0.12 0.21 #> 1981 0.13 0.28 #> 1982 0.12 0.11 #> 1983 0.12 0.12 #> 1984 0.13 0.13 #> 1985 0.13 0.08 #> 1986 0.13 0.26 #> 1987 0.12 0.20 #> 1988 0.13 0.09 #> 1989 0.13 0.08 #> 1990 0.12 0.09 #> 1991 0.13 0.13 #> 1992 0.12 0.08 #> 1993 0.12 0.18 #> 1994 0.13 0.13 #> 1995 0.13 0.12 #> 1996 0.12 0.24 #> 1997 0.13 0.16 #> 1998 0.12 0.12 #> 1999 0.12 0.10 #> 2000 0.13 0.12 #> 2001 0.12 0.11 #> 2002 0.12 0.03 #> 2003 0.12 0.16 #> 2004 0.12 0.04 #> 2005 0.12 0.17 #> 2006 0.12 0.12 #> 2007 0.12 0.10 #> 2008 0.12 0.10 #> 2009 0.12 0.14 #> 2010 0.12 0.12 #> 2011 0.12 0.10 #> 2012 0.13 0.09 #> 2013 0.12 0.17 #> 2014 0.12 0.08 #> 2015 0.13 0.11 #> 2016 0.12 0.11 #> 2017 0.12 0.06 #> 2018 0.13 0.14 #> 2019 0.13 0.25 #> 2020 0.12 0.06 #> 2021 0.13 0.18 #> 2022 0.12 0.09 #> 2023 0.12 0.13 #> 2024 0.12 0.22 #> 2025 0.12 0.10 #> 2026 0.12 0.09 #> 2027 0.12 0.10 #> 2028 0.12 0.13 #> 2029 0.12 0.10 #> 2030 0.12 0.10 #> 2031 0.12 0.11 #> 2032 0.12 0.13 #> 2033 0.12 0.13 #> 2034 0.12 0.16 #> 2035 0.12 0.30 #> 2036 0.12 0.12 #> 2037 0.12 0.06 #> 2038 0.13 0.13 #> 2039 0.12 0.10 #> 2040 0.12 0.16 #> 2041 0.12 0.19 #> 2042 0.12 0.26 #> 2043 0.12 0.19 #> 2044 0.12 0.14 #> 2045 0.12 0.23 #> 2046 0.12 0.12 #> 2047 0.13 0.20 #> 2048 0.13 0.15 #> 2049 0.12 0.22 #> 2050 0.12 0.19 #> 2051 0.12 0.11 #> 2052 0.12 0.09 #> 2053 0.13 0.13 #> 2054 0.13 0.28 #> 2055 0.12 0.15 #> 2056 0.13 0.08 #> 2057 0.13 0.16 #> 2058 0.12 0.15 #> 2059 0.12 0.13 #> 2060 0.12 0.16 #> 2061 0.12 0.11 #> 2062 0.12 0.12 #> 2063 0.12 0.13 #> 2064 0.12 0.19 #> 2065 0.12 0.23 #> 2066 0.12 0.05 #> 2067 0.12 0.10 #> 2068 0.12 0.09 #> 2069 0.12 0.12 #> 2070 0.12 0.08 #> 2071 0.13 0.16 #> 2072 0.12 0.09 #> 2073 0.12 0.21 #> 2074 0.12 0.15 #> 2075 0.12 0.16 #> 2076 0.12 0.11 #> 2077 0.13 0.24 #> 2078 0.12 0.14 #> 2079 0.12 0.13 #> 2080 0.12 0.16 #> 2081 0.13 0.15 #> 2082 0.13 0.15 #> 2083 0.13 0.12 #> 2084 0.13 0.12 #> 2085 0.13 0.19 #> 2086 0.12 0.10 #> 2087 0.12 0.06 #> 2088 0.12 0.10 #> 2089 0.12 0.09 #> 2090 0.13 0.17 #> 2091 0.12 0.09 #> 2092 0.12 0.11 #> 2093 0.12 0.19 #> 2094 0.13 0.19 #> 2095 0.13 0.11 #> 2096 0.13 0.19 #> 2097 0.13 0.15 #> 2098 0.13 0.11 #> 2099 0.12 0.13 #> 2100 0.13 0.11 #> 2101 0.13 0.16 #> 2102 0.13 0.12 #> 2103 0.12 0.10 #> 2104 0.12 0.19 #> 2105 0.13 0.15 #> 2106 0.12 0.13 #> 2107 0.13 0.17 #> 2108 0.12 0.07 #> 2109 0.13 0.10 #> 2110 0.12 0.06 #> 2111 0.12 0.12 #> 2112 0.12 0.17 #> 2113 0.13 0.12 #> 2114 0.12 0.11 #> 2115 0.13 0.20 #> 2116 0.12 0.14 #> 2117 0.12 0.18 #> 2118 0.12 0.12 #> 2119 0.12 0.08 #> 2120 0.12 0.21 #> 2121 0.13 0.19 #> 2122 0.13 0.18 #> 2123 0.13 0.14 #> 2124 0.13 0.11 #> 2125 0.12 0.20 #> 2126 0.12 0.09 #> 2127 0.12 0.14 #> 2128 0.13 0.12 #> 2129 0.12 0.11 #> 2130 0.13 0.15 #> 2131 0.12 0.11 #> 2132 0.12 0.13 #> 2133 0.12 0.10 #> 2134 0.12 0.13 #> 2135 0.12 0.15 #> 2136 0.12 0.23 #> 2137 0.12 0.13 #> 2138 0.13 0.20 #> 2139 0.12 0.11 #> 2140 0.13 0.06 #> 2141 0.12 0.04 #> 2142 0.12 0.13 #> 2143 0.13 0.08 #> 2144 0.12 0.16 #> 2145 0.12 0.15 #> 2146 0.13 0.10 #> 2147 0.12 0.05 #> 2148 0.12 0.17 #> 2149 0.12 0.22 #> 2150 0.12 0.08 #> 2151 0.12 0.12 #> 2152 0.12 0.14 #> 2153 0.12 0.14 #> 2154 0.12 0.23 #> 2155 0.12 0.07 #> 2156 0.12 0.10 #> 2157 0.12 0.14 #> 2158 0.12 0.10 #> 2159 0.12 0.13 #> 2160 0.12 0.14 #> 2161 0.13 0.10 #> 2162 0.12 0.14 #> 2163 0.13 0.18 #> 2164 0.12 0.18 #> 2165 0.12 0.15 #> 2166 0.12 0.12 #> 2167 0.12 0.20 #> 2168 0.12 0.10 #> 2169 0.13 0.10 #> 2170 0.12 0.12 #> 2171 0.12 0.17 #> 2172 0.13 0.12 #> 2173 0.12 0.14 #> 2174 0.12 0.08 #> 2175 0.12 0.12 #> 2176 0.12 0.14 #> 2177 0.12 0.18 #> 2178 0.12 0.16 #> 2179 0.12 0.19 #> 2180 0.12 0.17 #> 2181 0.12 0.15 #> 2182 0.12 0.13 #> 2183 0.12 0.13 #> 2184 0.13 0.10 #> 2185 0.12 0.14 #> 2186 0.12 0.11 #> 2187 0.12 0.12 #> 2188 0.12 0.10 #> 2189 0.12 0.12 #> 2190 0.12 0.16 #> 2191 0.12 0.17 #> 2192 0.12 0.09 #> 2193 0.12 0.18 #> 2194 0.13 0.20 #> 2195 0.13 0.11 #> 2196 0.12 0.12 #> 2197 0.12 0.13 #> 2198 0.12 0.13 #> 2199 0.13 0.11 #> 2200 0.12 0.27 #> 2201 0.12 0.22 #> 2202 0.12 0.11 #> 2203 0.13 0.20 #> 2204 0.13 0.20 #> 2205 0.13 0.09 #> 2206 0.13 0.18 #> 2207 0.12 0.11 #> 2208 0.13 0.10 #> 2209 0.12 0.20 #> 2210 0.13 0.27 #> 2211 0.12 0.20 #> 2212 0.12 0.23 #> 2213 0.12 0.21 #> 2214 0.12 0.15 #> 2215 0.12 0.10 #> 2216 0.12 0.06 #> 2217 0.12 0.19 #> 2218 0.12 0.08 #> 2219 0.13 0.17 #> 2220 0.13 0.10 #> 2221 0.12 0.10 #> 2222 0.12 0.14 #> 2223 0.12 0.14 #> 2224 0.12 0.04 #> 2225 0.13 0.10 #> 2226 0.12 0.05 #> 2227 0.12 0.12 #> 2228 0.12 0.18 #> 2229 0.12 0.16 #> 2230 0.12 0.14 #> 2231 0.12 0.14 #> 2232 0.13 0.14 #> 2233 0.12 0.13 #> 2234 0.12 0.13 #> 2235 0.12 0.11 #> 2236 0.13 0.12 #> 2237 0.12 0.20 #> 2238 0.12 0.15 #> 2239 0.12 0.15 #> 2240 0.12 0.20 #> 2241 0.12 0.15 #> 2242 0.12 0.16 #> 2243 0.12 0.17 #> 2244 0.13 0.20 #> 2245 0.12 0.15 #> 2246 0.12 0.12 #> 2247 0.13 0.16 #> 2248 0.12 0.07 #> 2249 0.12 0.14 #> 2250 0.12 0.10 #> 2251 0.12 0.11 #> 2252 0.12 0.16 #> 2253 0.12 0.12 #> 2254 0.13 0.18 #> 2255 0.12 0.17 #> 2256 0.12 0.15 #> 2257 0.12 0.10 #> 2258 0.13 0.20 #> 2259 0.12 0.09 #> 2260 0.12 0.15 #> 2261 0.12 0.11 #> 2262 0.12 0.14 #> 2263 0.12 0.16 #> 2264 0.12 0.10 #> 2265 0.13 0.19 #> 2266 0.13 0.12 #> 2267 0.13 0.20 #> 2268 0.12 0.11 #> 2269 0.12 0.16 #> 2270 0.12 0.09 #> 2271 0.12 0.13 #> 2272 0.12 0.10 #> 2273 0.12 0.24 #> 2274 0.12 0.05 #> 2275 0.13 0.16 #> 2276 0.12 0.18 #> 2277 0.12 0.16 #> 2278 0.12 0.13 #> 2279 0.13 0.11 #> 2280 0.12 0.20 #> 2281 0.13 0.16 #> 2282 0.12 0.12 #> 2283 0.12 0.10 #> 2284 0.12 0.17 #> 2285 0.13 0.14 #> 2286 0.12 0.14 #> 2287 0.12 0.12 #> 2288 0.13 0.13 #> 2289 0.12 0.17 #> 2290 0.13 0.13 #> 2291 0.13 0.15 #> 2292 0.12 0.14 #> 2293 0.13 0.13 #> 2294 0.13 0.14 #> 2295 0.13 0.17 #> 2296 0.12 0.11 #> 2297 0.13 0.11 #> 2298 0.12 0.11 #> 2299 0.12 0.13 #> 2300 0.12 0.15 #> 2301 0.12 0.18 #> 2302 0.12 0.14 #> 2303 0.12 0.13 #> 2304 0.12 0.13 #> 2305 0.12 0.12 #> 2306 0.12 0.20 #> 2307 0.12 0.15 #> 2308 0.12 0.04 #> 2309 0.13 0.12 #> 2310 0.12 0.22 #> 2311 0.12 0.13 #> 2312 0.12 0.13 #> 2313 0.12 0.13 #> 2314 0.12 0.09 #> 2315 0.12 0.13 #> 2316 0.12 0.14 #> 2317 0.12 0.17 #> 2318 0.13 0.15 #> 2319 0.12 0.14 #> 2320 0.12 0.18 #> 2321 0.12 0.15 #> 2322 0.12 0.15 #> 2323 0.12 0.12 #> 2324 0.13 0.18 #> 2325 0.12 0.15 #> 2326 0.12 0.15 #> 2327 0.12 0.19 #> 2328 0.12 0.11 #> 2329 0.12 0.18 #> 2330 0.12 0.16 #> 2331 0.13 0.17 #> 2332 0.12 0.11 #> 2333 0.12 0.07 #> 2334 0.12 0.15 #> 2335 0.12 0.12 #> 2336 0.13 0.12 #> 2337 0.13 0.11 #> 2338 0.12 0.15 #> 2339 0.12 0.19 #> 2340 0.13 0.12 #> 2341 0.12 0.10 #> 2342 0.13 0.14 #> 2343 0.13 0.08 #> 2344 0.13 0.07 #> 2345 0.12 0.17 #> 2346 0.12 0.17 #> 2347 0.12 0.19 #> 2348 0.12 0.11 #> 2349 0.13 0.07 #> 2350 0.12 0.15 #> 2351 0.12 0.11 #> 2352 0.12 0.15 #> 2353 0.12 0.16 #> 2354 0.12 0.13 #> 2355 0.12 0.12 #> 2356 0.12 0.14 #> 2357 0.12 0.12 #> 2358 0.12 0.10 #> 2359 0.12 0.12 #> 2360 0.13 0.13 #> 2361 0.13 0.16 #> 2362 0.13 0.10 #> 2363 0.13 0.16 #> 2364 0.12 0.04 #> 2365 0.13 0.10 #> 2366 0.12 0.14 #> 2367 0.13 0.11 #> 2368 0.13 0.08 #> 2369 0.12 0.14 #> 2370 0.12 0.17 #> 2371 0.12 0.12 #> 2372 0.12 0.17 #> 2373 0.12 0.19 #> 2374 0.12 0.15 #> 2375 0.12 0.14 #> 2376 0.12 0.28 #> 2377 0.12 0.10 #> 2378 0.12 0.17 #> 2379 0.12 0.17 #> 2380 0.12 0.12 #> 2381 0.12 0.20 #> 2382 0.13 0.14 #> 2383 0.13 0.08 #> 2384 0.13 0.07 #> 2385 0.12 0.09 #> 2386 0.13 0.14 #> 2387 0.12 0.09 #> 2388 0.12 0.07 #> 2389 0.12 0.10 #> 2390 0.12 0.24 #> 2391 0.12 0.10 #> 2392 0.12 0.16 #> 2393 0.13 0.09 #> 2394 0.12 0.24 #> 2395 0.12 0.16 #> 2396 0.12 0.08 #> 2397 0.12 0.13 #> 2398 0.13 0.07 #> 2399 0.13 0.22 #> 2400 0.12 0.15 #> 2401 0.12 0.12 #> 2402 0.12 0.19 #> 2403 0.12 0.19 #> 2404 0.12 0.16 #> 2405 0.12 0.17 #> 2406 0.12 0.12 #> 2407 0.12 0.09 #> 2408 0.12 0.11 #> 2409 0.12 0.17 #> 2410 0.12 0.12 #> 2411 0.12 0.10 #> 2412 0.12 0.22 #> 2413 0.12 0.16 #> 2414 0.12 0.21 #> 2415 0.12 0.18 #> 2416 0.12 0.13 #> 2417 0.12 0.15 #> 2418 0.12 0.20 #> 2419 0.13 0.20 #> 2420 0.13 0.16 #> 2421 0.12 0.16 #> 2422 0.12 0.13 #> 2423 0.13 0.18 #> 2424 0.12 0.10 #> 2425 0.12 0.21 #> 2426 0.12 0.08 #> 2427 0.12 0.11 #> 2428 0.12 0.13 #> 2429 0.13 0.11 #> 2430 0.12 0.07 #> 2431 0.12 0.10 #> 2432 0.12 0.16 #> 2433 0.13 0.06 #> 2434 0.12 0.11 #> 2435 0.13 0.20 #> 2436 0.12 0.08 #> 2437 0.12 0.12 #> 2438 0.13 0.10 #> 2439 0.12 0.14 #> 2440 0.12 0.15 #> 2441 0.12 0.16 #> 2442 0.13 0.10 #> 2443 0.13 0.23 #> 2444 0.12 0.11 #> 2445 0.12 0.10 #> 2446 0.13 0.07 #> 2447 0.12 0.06 #> 2448 0.13 0.13 #> 2449 0.12 0.12 #> 2450 0.12 0.11 #> 2451 0.12 0.11 #> 2452 0.12 0.10 #> 2453 0.12 0.21 #> 2454 0.12 0.12 #> 2455 0.12 0.13 #> 2456 0.13 0.12 #> 2457 0.12 0.13 #> 2458 0.12 0.15 #> 2459 0.12 0.13 #> 2460 0.12 0.08 #> 2461 0.12 0.09 #> 2462 0.13 0.15 #> 2463 0.12 0.10 #> 2464 0.12 0.11 #> 2465 0.12 0.11 #> 2466 0.12 0.18 #> 2467 0.13 0.20 #> 2468 0.12 0.22 #> 2469 0.12 0.20 #> 2470 0.13 0.13 #> 2471 0.12 0.07 #> 2472 0.13 0.15 #> 2473 0.12 0.26 #> 2474 0.13 0.08 #> 2475 0.13 0.15 #> 2476 0.12 0.08 #> 2477 0.12 0.07 #> 2478 0.12 0.09 #> 2479 0.12 0.25 #> 2480 0.12 0.12 #> 2481 0.12 0.17 #> 2482 0.13 0.07 #> 2483 0.13 0.15 #> 2484 0.12 0.19 #> 2485 0.12 0.16 #> 2486 0.12 0.10 #> 2487 0.12 0.07 #> 2488 0.12 0.14 #> 2489 0.12 0.15 #> 2490 0.12 0.16 #> 2491 0.13 0.13 #> 2492 0.13 0.10 #> 2493 0.13 0.15 #> 2494 0.13 0.07 #> 2495 0.13 0.05 #> 2496 0.12 0.11 #> 2497 0.12 0.12 #> 2498 0.12 0.13 #> 2499 0.13 0.14 #> 2500 0.13 0.11 #> 2501 0.12 0.14 #> 2502 0.12 0.16 #> 2503 0.12 0.14 #> 2504 0.12 0.12 #> 2505 0.12 0.14 #> 2506 0.12 0.12 #> 2507 0.13 0.09 #> 2508 0.12 0.18 #> 2509 0.12 0.09 #> 2510 0.12 0.30 #> 2511 0.12 0.17 #> 2512 0.12 0.10 #> 2513 0.12 0.16 #> 2514 0.13 0.10 #> 2515 0.12 0.19 #> 2516 0.12 0.12 #> 2517 0.13 0.15 #> 2518 0.13 0.16 #> 2519 0.12 0.13 #> 2520 0.12 0.18 #> 2521 0.12 0.06 #> 2522 0.12 0.11 #> 2523 0.12 0.14 #> 2524 0.12 0.12 #> 2525 0.12 0.08 #> 2526 0.12 0.12 #> 2527 0.13 0.23 #> 2528 0.12 0.17 #> 2529 0.12 0.11 #> 2530 0.12 0.16 #> 2531 0.12 0.11 #> 2532 0.12 0.18 #> 2533 0.12 0.11 #> 2534 0.12 0.17 #> 2535 0.12 0.22 #> 2536 0.12 0.13 #> 2537 0.12 0.13 #> 2538 0.12 0.18 #> 2539 0.12 0.19 #> 2540 0.12 0.17 #> 2541 0.12 0.15 #> 2542 0.12 0.13 #> 2543 0.12 0.20 #> 2544 0.13 0.17 #> 2545 0.12 0.11 #> 2546 0.12 0.09 #> 2547 0.13 0.07 #> 2548 0.12 0.13 #> 2549 0.13 0.18 #> 2550 0.12 0.17 #> 2551 0.12 0.08 #> 2552 0.12 0.20 #> 2553 0.12 0.07 #> 2554 0.12 0.11 #> 2555 0.12 0.18 #> 2556 0.12 0.16 #> 2557 0.12 0.14 #> 2558 0.13 0.15 #> 2559 0.12 0.12 #> 2560 0.12 0.19 #> 2561 0.12 0.08 #> 2562 0.13 0.12 #> 2563 0.12 0.15 #> 2564 0.13 0.19 #> 2565 0.12 0.15 #> 2566 0.12 0.26 #> 2567 0.12 0.21 #> 2568 0.12 0.13 #> 2569 0.12 0.12 #> 2570 0.12 0.25 #> 2571 0.12 0.13 #> 2572 0.12 0.14 #> 2573 0.12 0.10 #> 2574 0.12 0.20 #> 2575 0.13 0.12 #> 2576 0.12 0.15 #> 2577 0.12 0.18 #> 2578 0.12 0.12 #> 2579 0.12 0.08 #> 2580 0.12 0.12 #> 2581 0.13 0.15 #> 2582 0.12 0.14 #> 2583 0.12 0.12 #> 2584 0.13 0.13 #> 2585 0.13 0.14 #> 2586 0.12 0.09 #> 2587 0.13 0.14 #> 2588 0.13 0.05 #> 2589 0.12 0.13 #> 2590 0.13 0.08 #> 2591 0.12 0.14 #> 2592 0.12 0.13 #> 2593 0.12 0.09 #> 2594 0.12 0.15 #> 2595 0.12 0.22 #> 2596 0.12 0.03 #> 2597 0.12 0.16 #> 2598 0.12 0.16 #> 2599 0.13 0.13 #> 2600 0.12 0.09 #> 2601 0.12 0.20 #> 2602 0.13 0.14 #> 2603 0.12 0.25 #> 2604 0.12 0.20 #> 2605 0.13 0.11 #> 2606 0.12 0.15 #> 2607 0.12 0.09 #> 2608 0.12 0.15 #> 2609 0.12 0.15 #> 2610 0.12 0.15 #> 2611 0.12 0.17 #> 2612 0.13 0.10 #> 2613 0.12 0.11 #> 2614 0.12 0.16 #> 2615 0.12 0.10 #> 2616 0.12 0.20 #> 2617 0.13 0.17 #> 2618 0.12 0.15 #> 2619 0.12 0.19 #> 2620 0.12 0.11 #> 2621 0.13 0.16 #> 2622 0.12 0.19 #> 2623 0.12 0.20 #> 2624 0.13 0.18 #> 2625 0.13 0.18 #> 2626 0.12 0.09 #> 2627 0.12 0.17 #> 2628 0.12 0.16 #> 2629 0.12 0.20 #> 2630 0.12 0.06 #> 2631 0.13 0.08 #> 2632 0.12 0.15 #> 2633 0.12 0.07 #> 2634 0.12 0.15 #> 2635 0.12 0.19 #> 2636 0.12 0.07 #> 2637 0.12 0.09 #> 2638 0.13 0.22 #> 2639 0.12 0.14 #> 2640 0.12 0.24 #> 2641 0.12 0.14 #> 2642 0.12 0.12 #> 2643 0.12 0.16 #> 2644 0.13 0.14 #> 2645 0.12 0.08 #> 2646 0.12 0.17 #> 2647 0.12 0.12 #> 2648 0.12 0.06 #> 2649 0.12 0.18 #> 2650 0.12 0.15 #> 2651 0.13 0.17 #> 2652 0.12 0.15 #> 2653 0.12 0.10 #> 2654 0.12 0.16 #> 2655 0.12 0.10 #> 2656 0.12 0.07 #> 2657 0.12 0.11 #> 2658 0.12 0.14 #> 2659 0.12 0.26 #> 2660 0.12 0.10 #> 2661 0.13 0.07 #> 2662 0.13 0.13 #> 2663 0.12 0.14 #> 2664 0.12 0.21 #> 2665 0.12 0.10 #> 2666 0.13 0.09 #> 2667 0.12 0.19 #> 2668 0.13 0.21 #> 2669 0.12 0.09 #> 2670 0.12 0.14 #> 2671 0.13 0.09 #> 2672 0.12 0.12 #> 2673 0.12 0.13 #> 2674 0.12 0.09 #> 2675 0.13 0.25 #> 2676 0.13 0.14 #> 2677 0.12 0.20 #> 2678 0.12 0.14 #> 2679 0.13 0.19 #> 2680 0.13 0.14 #> 2681 0.12 0.12 #> 2682 0.12 0.16 #> 2683 0.12 0.13 #> 2684 0.12 0.15 #> 2685 0.12 0.15 #> 2686 0.12 0.13 #> 2687 0.12 0.11 #> 2688 0.13 0.11 #> 2689 0.12 0.16 #> 2690 0.12 0.17 #> 2691 0.12 0.19 #> 2692 0.13 0.08 #> 2693 0.12 0.16 #> 2694 0.12 0.11 #> 2695 0.13 0.14 #> 2696 0.12 0.12 #> 2697 0.12 0.14 #> 2698 0.12 0.11 #> 2699 0.13 0.16 #> 2700 0.12 0.21 #> 2701 0.12 0.11 #> 2702 0.13 0.16 #> 2703 0.13 0.11 #> 2704 0.13 0.07 #> 2705 0.12 0.11 #> 2706 0.13 0.15 #> 2707 0.12 0.05 #> 2708 0.13 0.15 #> 2709 0.13 0.18 #> 2710 0.13 0.20 #> 2711 0.13 0.14 #> 2712 0.12 0.17 #> 2713 0.13 0.11 #> 2714 0.13 0.12 #> 2715 0.12 0.13 #> 2716 0.12 0.08 #> 2717 0.12 0.18 #> 2718 0.13 0.08 #> 2719 0.12 0.18 #> 2720 0.12 0.14 #> 2721 0.13 0.08 #> 2722 0.13 0.17 #> 2723 0.13 0.08 #> 2724 0.13 0.08 #> 2725 0.12 0.10 #> 2726 0.12 0.16 #> 2727 0.12 0.16 #> 2728 0.13 0.14 #> 2729 0.12 0.11 #> 2730 0.13 0.12 #> 2731 0.12 0.22 #> 2732 0.13 0.06 #> 2733 0.12 0.10 #> 2734 0.12 0.16 #> 2735 0.12 0.25 #> 2736 0.12 0.18 #> 2737 0.13 0.17 #> 2738 0.12 0.09 #> 2739 0.12 0.15 #> 2740 0.12 0.21 #> 2741 0.13 0.10 #> 2742 0.12 0.07 #> 2743 0.12 0.20 #> 2744 0.12 0.12 #> 2745 0.12 0.14 #> 2746 0.12 0.21 #> 2747 0.13 0.11 #> 2748 0.12 0.14 #> 2749 0.12 0.10 #> 2750 0.12 0.23 #> 2751 0.12 0.25 #> 2752 0.12 0.18 #> 2753 0.12 0.12 #> 2754 0.12 0.21 #> 2755 0.13 0.13 #> 2756 0.12 0.09 #> 2757 0.12 0.21 #> 2758 0.12 0.20 #> 2759 0.12 0.13 #> 2760 0.12 0.15 #> 2761 0.12 0.13 #> 2762 0.13 0.11 #> 2763 0.12 0.09 #> 2764 0.12 0.07 #> 2765 0.12 0.12 #> 2766 0.12 0.15 #> 2767 0.12 0.20 #> 2768 0.12 0.17 #> 2769 0.12 0.11 #> 2770 0.12 0.15 #> 2771 0.13 0.11 #> 2772 0.12 0.16 #> 2773 0.12 0.09 #> 2774 0.13 0.11 #> 2775 0.12 0.10 #> 2776 0.12 0.12 #> 2777 0.12 0.13 #> 2778 0.12 0.14 #> 2779 0.13 0.12 #> 2780 0.12 0.10 #> 2781 0.13 0.10 #> 2782 0.12 0.19 #> 2783 0.12 0.19 #> 2784 0.12 0.12 #> 2785 0.13 0.19 #> 2786 0.12 0.06 #> 2787 0.12 0.09 #> 2788 0.12 0.10 #> 2789 0.12 0.06 #> 2790 0.12 0.08 #> 2791 0.12 0.20 #> 2792 0.12 0.18 #> 2793 0.13 0.11 #> 2794 0.12 0.16 #> 2795 0.12 0.15 #> 2796 0.12 0.07 #> 2797 0.12 0.15 #> 2798 0.12 0.05 #> 2799 0.12 0.09 #> 2800 0.12 0.17 #> 2801 0.12 0.17 #> 2802 0.12 0.17 #> 2803 0.13 0.10 #> 2804 0.13 0.18 #> 2805 0.12 0.07 #> 2806 0.12 0.19 #> 2807 0.12 0.15 #> 2808 0.13 0.11 #> 2809 0.12 0.13 #> 2810 0.13 0.07 #> 2811 0.12 0.13 #> 2812 0.13 0.17 #> 2813 0.12 0.20 #> 2814 0.12 0.20 #> 2815 0.12 0.17 #> 2816 0.13 0.10 #> 2817 0.12 0.23 #> 2818 0.13 0.10 #> 2819 0.13 0.07 #> 2820 0.13 0.18 #> 2821 0.12 0.16 #> 2822 0.13 0.16 #> 2823 0.12 0.14 #> 2824 0.12 0.14 #> 2825 0.12 0.24 #> 2826 0.12 0.14 #> 2827 0.12 0.14 #> 2828 0.13 0.11 #> 2829 0.13 0.14 #> 2830 0.12 0.08 #> 2831 0.12 0.27 #> 2832 0.12 0.08 #> 2833 0.13 0.20 #> 2834 0.13 0.17 #> 2835 0.12 0.09 #> 2836 0.12 0.03 #> 2837 0.12 0.21 #> 2838 0.13 0.10 #> 2839 0.12 0.21 #> 2840 0.12 0.05 #> 2841 0.12 0.17 #> 2842 0.12 0.12 #> 2843 0.12 0.20 #> 2844 0.12 0.12 #> 2845 0.13 0.18 #> 2846 0.13 0.14 #> 2847 0.13 0.03 #> 2848 0.12 0.13 #> 2849 0.12 0.14 #> 2850 0.12 0.16 #> 2851 0.12 0.10 #> 2852 0.13 0.15 #> 2853 0.12 0.10 #> 2854 0.12 0.16 #> 2855 0.13 0.12 #> 2856 0.12 0.13 #> 2857 0.12 0.12 #> 2858 0.12 0.14 #> 2859 0.12 0.14 #> 2860 0.13 0.15 #> 2861 0.12 0.14 #> 2862 0.12 0.15 #> 2863 0.12 0.13 #> 2864 0.12 0.21 #> 2865 0.12 0.21 #> 2866 0.12 0.11 #> 2867 0.12 0.10 #> 2868 0.12 0.09 #> 2869 0.12 0.10 #> 2870 0.12 0.24 #> 2871 0.13 0.15 #> 2872 0.13 0.11 #> 2873 0.12 0.21 #> 2874 0.13 0.07 #> 2875 0.12 0.10 #> 2876 0.12 0.11 #> 2877 0.12 0.12 #> 2878 0.12 0.19 #> 2879 0.12 0.05 #> 2880 0.13 0.13 #> 2881 0.12 0.16 #> 2882 0.13 0.02 #> 2883 0.12 0.16 #> 2884 0.12 0.12 #> 2885 0.13 0.14 #> 2886 0.13 0.17 #> 2887 0.12 0.16 #> 2888 0.12 0.14 #> 2889 0.12 0.14 #> 2890 0.13 0.18 #> 2891 0.13 0.13 #> 2892 0.13 0.14 #> 2893 0.12 0.14 #> 2894 0.12 0.25 #> 2895 0.12 0.16 #> 2896 0.12 0.16 #> 2897 0.12 0.11 #> 2898 0.12 0.08 #> 2899 0.12 0.17 #> 2900 0.12 0.14 #> 2901 0.12 0.11 #> 2902 0.12 0.20 #> 2903 0.12 0.06 #> 2904 0.13 0.15 #> 2905 0.12 0.10 #> 2906 0.12 0.08 #> 2907 0.12 0.13 #> 2908 0.12 0.14 #> 2909 0.13 0.11 #> 2910 0.12 0.07 #> 2911 0.12 0.22 #> 2912 0.12 0.15 #> 2913 0.12 0.12 #> 2914 0.13 0.13 #> 2915 0.13 0.18 #> 2916 0.13 0.13 #> 2917 0.12 0.11 #> 2918 0.12 0.15 #> 2919 0.12 0.12 #> 2920 0.12 0.09 #> 2921 0.13 0.14 #> 2922 0.12 0.22 #> 2923 0.13 0.18 #> 2924 0.12 0.05 #> 2925 0.12 0.18 #> 2926 0.13 0.09 #> 2927 0.13 0.24 #> 2928 0.12 0.10 #> 2929 0.12 0.06 #> 2930 0.12 0.08 #> 2931 0.12 0.12 #> 2932 0.13 0.11 #> 2933 0.12 0.24 #> 2934 0.12 0.15 #> 2935 0.12 0.14 #> 2936 0.13 0.14 #> 2937 0.13 0.08 #> 2938 0.12 0.15 #> 2939 0.12 0.12 #> 2940 0.13 0.26 #> 2941 0.12 0.10 #> 2942 0.12 0.16 #> 2943 0.12 0.18 #> 2944 0.12 0.17 #> 2945 0.12 0.16 #> 2946 0.12 0.09 #> 2947 0.12 0.17 #> 2948 0.12 0.18 #> 2949 0.13 0.16 #> 2950 0.12 0.07 #> 2951 0.13 0.11 #> 2952 0.12 0.19 #> 2953 0.12 0.12 #> 2954 0.12 0.12 #> 2955 0.12 0.15 #> 2956 0.12 0.14 #> 2957 0.12 0.11 #> 2958 0.13 0.08 #> 2959 0.12 0.06 #> 2960 0.12 0.12 #> 2961 0.12 0.16 #> 2962 0.13 0.09 #> 2963 0.13 0.13 #> 2964 0.12 0.14 #> 2965 0.12 0.19 #> 2966 0.13 0.12 #> 2967 0.13 0.20 #> 2968 0.12 0.13 #> 2969 0.12 0.20 #> 2970 0.12 0.20 #> 2971 0.12 0.17 #> 2972 0.12 0.19 #> 2973 0.12 0.20 #> 2974 0.13 0.11 #> 2975 0.13 0.15 #> 2976 0.12 0.10 #> 2977 0.12 0.17 #> 2978 0.13 0.13 #> 2979 0.12 0.07 #> 2980 0.12 0.21 #> 2981 0.12 0.20 #> 2982 0.13 0.16 #> 2983 0.13 0.11 #> 2984 0.12 0.12 #> 2985 0.12 0.12 #> 2986 0.12 0.26 #> 2987 0.12 0.11 #> 2988 0.12 0.13 #> 2989 0.12 0.08 #> 2990 0.12 0.15 #> 2991 0.12 0.15 #> 2992 0.12 0.12 #> 2993 0.12 0.08 #> 2994 0.12 0.10 #> 2995 0.13 0.12 #> 2996 0.12 0.13 #> 2997 0.12 0.11 #> 2998 0.12 0.15 #> 2999 0.12 0.18 #> 3000 0.12 0.05 #> 3001 0.13 0.16 #> 3002 0.12 0.10 #> 3003 0.12 0.25 #> 3004 0.13 0.21 #> 3005 0.12 0.16 #> 3006 0.12 0.27 #> 3007 0.12 0.25 #> 3008 0.12 0.06 #> 3009 0.12 0.19 #> 3010 0.12 0.16 #> 3011 0.12 0.13 #> 3012 0.13 0.15 #> 3013 0.12 0.13 #> 3014 0.12 0.15 #> 3015 0.13 0.09 #> 3016 0.12 0.17 #> 3017 0.13 0.19 #> 3018 0.13 0.09 #> 3019 0.13 0.17 #> 3020 0.12 0.11 #> 3021 0.12 0.06 #> 3022 0.12 0.22 #> 3023 0.13 0.23 #> 3024 0.12 0.18 #> 3025 0.12 0.10 #> 3026 0.13 0.18 #> 3027 0.12 0.10 #> 3028 0.12 0.11 #> 3029 0.12 0.09 #> 3030 0.13 0.17 #> 3031 0.12 0.19 #> 3032 0.12 0.09 #> 3033 0.12 0.05 #> 3034 0.12 0.17 #> 3035 0.12 0.12 #> 3036 0.12 0.10 #> 3037 0.12 0.15 #> 3038 0.12 0.06 #> 3039 0.12 0.14 #> 3040 0.13 0.15 #> 3041 0.12 0.10 #> 3042 0.12 0.19 #> 3043 0.12 0.15 #> 3044 0.13 0.05 #> 3045 0.13 0.14 #> 3046 0.12 0.10 #> 3047 0.12 0.13 #> 3048 0.13 0.09 #> 3049 0.12 0.11 #> 3050 0.13 0.14 #> 3051 0.12 0.07 #> 3052 0.12 0.18 #> 3053 0.13 0.11 #> 3054 0.12 0.10 #> 3055 0.13 0.09 #> 3056 0.12 0.09 #> 3057 0.12 0.16 #> 3058 0.12 0.08 #> 3059 0.12 0.23 #> 3060 0.12 0.13 #> 3061 0.13 0.16 #> 3062 0.13 0.10 #> 3063 0.12 0.10 #> 3064 0.12 0.09 #> 3065 0.12 0.19 #> 3066 0.12 0.26 #> 3067 0.12 0.09 #> 3068 0.12 0.14 #> 3069 0.12 0.15 #> 3070 0.13 0.05 #> 3071 0.12 0.12 #> 3072 0.13 0.20 #> 3073 0.13 0.20 #> 3074 0.12 0.11 #> 3075 0.12 0.12 #> 3076 0.12 0.14 #> 3077 0.13 0.14 #> 3078 0.12 0.15 #> 3079 0.12 0.14 #> 3080 0.12 0.12 #> 3081 0.12 0.13 #> 3082 0.12 0.13 #> 3083 0.12 0.15 #> 3084 0.13 0.12 #> 3085 0.12 0.12 #> 3086 0.12 0.21 #> 3087 0.12 0.16 #> 3088 0.12 0.08 #> 3089 0.12 0.14 #> 3090 0.12 0.13 #> 3091 0.12 0.16 #> 3092 0.13 0.07 #> 3093 0.12 0.05 #> 3094 0.12 0.11 #> 3095 0.12 0.17 #> 3096 0.12 0.18 #> 3097 0.12 0.12 #> 3098 0.12 0.16 #> 3099 0.12 0.14 #> 3100 0.13 0.14 #> 3101 0.12 0.06 #> 3102 0.12 0.14 #> 3103 0.12 0.19 #> 3104 0.12 0.23 #> 3105 0.12 0.20 #> 3106 0.12 0.08 #> 3107 0.13 0.11 #> 3108 0.12 0.17 #> 3109 0.12 0.13 #> 3110 0.12 0.07 #> 3111 0.13 0.18 #> 3112 0.13 0.16 #> 3113 0.12 0.03 #> 3114 0.12 0.12 #> 3115 0.12 0.17 #> 3116 0.12 0.07 #> 3117 0.12 0.10 #> 3118 0.12 0.04 #> 3119 0.12 0.08 #> 3120 0.12 0.12 #> 3121 0.12 0.14 #> 3122 0.12 0.08 #> 3123 0.12 0.22 #> 3124 0.12 0.15 #> 3125 0.12 0.17 #> 3126 0.12 0.07 #> 3127 0.12 0.09 #> 3128 0.13 0.13 #> 3129 0.12 0.16 #> 3130 0.12 0.12 #> 3131 0.12 0.10 #> 3132 0.12 0.14 #> 3133 0.12 0.13 #> 3134 0.12 0.11 #> 3135 0.12 0.08 #> 3136 0.13 0.15 #> 3137 0.12 0.07 #> 3138 0.12 0.14 #> 3139 0.13 0.11 #> 3140 0.12 0.17 #> 3141 0.13 0.14 #> 3142 0.12 0.11 #> 3143 0.12 0.17 #> 3144 0.12 0.11 #> 3145 0.12 0.09 #> 3146 0.12 0.13 #> 3147 0.12 0.11 #> 3148 0.12 0.20 #> 3149 0.12 0.07 #> 3150 0.12 0.05 #> 3151 0.13 0.18 #> 3152 0.12 0.19 #> 3153 0.13 0.14 #> 3154 0.12 0.22 #> 3155 0.12 0.08 #> 3156 0.13 0.15 #> 3157 0.12 0.07 #> 3158 0.12 0.13 #> 3159 0.12 0.27 #> 3160 0.12 0.24 #> 3161 0.13 0.11 #> 3162 0.12 0.13 #> 3163 0.12 0.06 #> 3164 0.12 0.18 #> 3165 0.12 0.09 #> 3166 0.13 0.10 #> 3167 0.13 0.22 #> 3168 0.13 0.10 #> 3169 0.12 0.20 #> 3170 0.12 0.16 #> 3171 0.13 0.10 #> 3172 0.12 0.05 #> 3173 0.12 0.28 #> 3174 0.12 0.14 #> 3175 0.12 0.07 #> 3176 0.12 0.16 #> 3177 0.12 0.13 #> 3178 0.12 0.21 #> 3179 0.12 0.15 #> 3180 0.12 0.16 #> 3181 0.12 0.13 #> 3182 0.12 0.10 #> 3183 0.12 0.18 #> 3184 0.12 0.19 #> 3185 0.12 0.17 #> 3186 0.12 0.04 #> 3187 0.12 0.21 #> 3188 0.12 0.17 #> 3189 0.13 0.19 #> 3190 0.12 0.12 #> 3191 0.12 0.11 #> 3192 0.12 0.16 #> 3193 0.12 0.24 #> 3194 0.12 0.12 #> 3195 0.13 0.17 #> 3196 0.13 0.13 #> 3197 0.12 0.18 #> 3198 0.13 0.26 #> 3199 0.12 0.15 #> 3200 0.12 0.04 #> 3201 0.13 0.24 #> 3202 0.12 0.24 #> 3203 0.12 0.08 #> 3204 0.12 0.12 #> 3205 0.12 0.09 #> 3206 0.12 0.06 #> 3207 0.13 0.09 #> 3208 0.13 0.16 #> 3209 0.12 0.11 #> 3210 0.12 0.08 #> 3211 0.12 0.21 #> 3212 0.12 0.07 #> 3213 0.12 0.27 #> 3214 0.12 0.17 #> 3215 0.12 0.12 #> 3216 0.12 0.16 #> 3217 0.12 0.12 #> 3218 0.12 0.18 #> 3219 0.12 0.22 #> 3220 0.13 0.10 #> 3221 0.12 0.12 #> 3222 0.12 0.06 #> 3223 0.12 0.20 #> 3224 0.12 0.16 #> 3225 0.13 0.07 #> 3226 0.12 0.26 #> 3227 0.12 0.24 #> 3228 0.12 0.22 #> 3229 0.12 0.18 #> 3230 0.12 0.15 #> 3231 0.12 0.12 #> 3232 0.12 0.22 #> 3233 0.12 0.18 #> 3234 0.13 0.14 #> 3235 0.13 0.19 #> 3236 0.12 0.17 #> 3237 0.13 0.21 #> 3238 0.13 0.20 #> 3239 0.12 0.17 #> 3240 0.12 0.14 #> 3241 0.13 0.18 #> 3242 0.13 0.06 #> 3243 0.13 0.16 #> 3244 0.12 0.16 #> 3245 0.12 0.12 #> 3246 0.12 0.11 #> 3247 0.12 0.18 #> 3248 0.13 0.10 #> 3249 0.12 0.08 #> 3250 0.12 0.15 #> 3251 0.12 0.13 #> 3252 0.12 0.16 #> 3253 0.13 0.18 #> 3254 0.12 0.20 #> 3255 0.12 0.17 #> 3256 0.13 0.20 #> 3257 0.13 0.20 #> 3258 0.12 0.13 #> 3259 0.12 0.09 #> 3260 0.12 0.13 #> 3261 0.12 0.12 #> 3262 0.12 0.16 #> 3263 0.12 0.05 #> 3264 0.12 0.15 #> 3265 0.12 0.14 #> 3266 0.12 0.17 #> 3267 0.12 0.05 #> 3268 0.13 0.14 #> 3269 0.12 0.20 #> 3270 0.12 0.17 #> 3271 0.12 0.10 #> 3272 0.13 0.06 #> 3273 0.12 0.06 #> 3274 0.12 0.13 #> 3275 0.13 0.14 #> 3276 0.12 0.16 #> 3277 0.12 0.13 #> 3278 0.12 0.14 #> 3279 0.12 0.09 #> 3280 0.12 0.09 #> 3281 0.12 0.14 #> 3282 0.12 0.26 #> 3283 0.13 0.11 #> 3284 0.12 0.16 #> 3285 0.12 0.16 #> 3286 0.12 0.14 #> 3287 0.12 0.12 #> 3288 0.12 0.13 #> 3289 0.12 0.07 #> 3290 0.12 0.18 #> 3291 0.12 0.23 #> 3292 0.12 0.08 #> 3293 0.12 0.14 #> 3294 0.12 0.09 #> 3295 0.12 0.11 #> 3296 0.12 0.19 #> 3297 0.12 0.10 #> 3298 0.12 0.13 #> 3299 0.13 0.19 #> 3300 0.13 0.08 #> 3301 0.12 0.14 #> 3302 0.13 0.14 #> 3303 0.12 0.15 #> 3304 0.12 0.10 #> 3305 0.12 0.08 #> 3306 0.12 0.09 #> 3307 0.12 0.09 #> 3308 0.12 0.13 #> 3309 0.13 0.22 #> 3310 0.12 0.13 #> 3311 0.13 0.19 #> 3312 0.12 0.18 #> 3313 0.12 0.10 #> 3314 0.13 0.14 #> 3315 0.12 0.10 #> 3316 0.12 0.12 #> 3317 0.12 0.18 #> 3318 0.12 0.10 #> 3319 0.13 0.15 #> 3320 0.12 0.19 #> 3321 0.12 0.14 #> 3322 0.13 0.15 #> 3323 0.13 0.10 #> 3324 0.12 0.17 #> 3325 0.12 0.26 #> 3326 0.12 0.06 #> 3327 0.13 0.15 #> 3328 0.12 0.12 #> 3329 0.12 0.10 #> 3330 0.12 0.17 #> 3331 0.12 0.16 #> 3332 0.12 0.09 #> 3333 0.13 0.12 #> 3334 0.13 0.13 #> 3335 0.12 0.08 #> 3336 0.12 0.10 #> 3337 0.13 0.20 #> 3338 0.12 0.19 #> 3339 0.12 0.10 #> 3340 0.13 0.13 #> 3341 0.13 0.12 #> 3342 0.12 0.19 #> 3343 0.13 0.08 #> 3344 0.12 0.23 #> 3345 0.13 0.18 #> 3346 0.12 0.10 #> 3347 0.12 0.08 #> 3348 0.12 0.21 #> 3349 0.12 0.10 #> 3350 0.12 0.17 #> 3351 0.12 0.17 #> 3352 0.12 0.12 #> 3353 0.12 0.09 #> 3354 0.12 0.29 #> 3355 0.12 0.08 #> 3356 0.13 0.18 #> 3357 0.12 0.26 #> 3358 0.12 0.15 #> 3359 0.13 0.10 #> 3360 0.12 0.27 #> 3361 0.12 0.11 #> 3362 0.13 0.19 #> 3363 0.12 0.21 #> 3364 0.12 0.12 #> 3365 0.13 0.11 #> 3366 0.12 0.12 #> 3367 0.12 0.14 #> 3368 0.13 0.10 #> 3369 0.12 0.17 #> 3370 0.13 0.15 #> 3371 0.12 0.16 #> 3372 0.13 0.15 #> 3373 0.13 0.15 #> 3374 0.12 0.16 #> 3375 0.12 0.12 #> 3376 0.13 0.10 #> 3377 0.12 0.13 #> 3378 0.13 0.10 #> 3379 0.12 0.18 #> 3380 0.12 0.15 #> 3381 0.12 0.12 #> 3382 0.12 0.16 #> 3383 0.12 0.06 #> 3384 0.12 0.16 #> 3385 0.12 0.21 #> 3386 0.13 0.14 #> 3387 0.13 0.13 #> 3388 0.13 0.29 #> 3389 0.12 0.10 #> 3390 0.13 0.16 #> 3391 0.12 0.12 #> 3392 0.13 0.12 #> 3393 0.12 0.20 #> 3394 0.12 0.10 #> 3395 0.13 0.14 #> 3396 0.12 0.13 #> 3397 0.12 0.15 #> 3398 0.13 0.26 #> 3399 0.12 0.09 #> 3400 0.12 0.12 #> 3401 0.12 0.14 #> 3402 0.12 0.23 #> 3403 0.13 0.19 #> 3404 0.12 0.12 #> 3405 0.13 0.08 #> 3406 0.13 0.19 #> 3407 0.12 0.17 #> 3408 0.12 0.14 #> 3409 0.12 0.09 #> 3410 0.12 0.15 #> 3411 0.13 0.18 #> 3412 0.12 0.10 #> 3413 0.12 0.13 #> 3414 0.12 0.12 #> 3415 0.13 0.13 #> 3416 0.12 0.13 #> 3417 0.12 0.11 #> 3418 0.12 0.08 #> 3419 0.12 0.14 #> 3420 0.12 0.09 #> 3421 0.13 0.18 #> 3422 0.12 0.11 #> 3423 0.12 0.15 #> 3424 0.12 0.15 #> 3425 0.12 0.06 #> 3426 0.12 0.09 #> 3427 0.13 0.09 #> 3428 0.12 0.28 #> 3429 0.12 0.13 #> 3430 0.12 0.13 #> 3431 0.12 0.10 #> 3432 0.12 0.17 #> 3433 0.12 0.18 #> 3434 0.12 0.10 #> 3435 0.12 0.21 #> 3436 0.12 0.11 #> 3437 0.12 0.09 #> 3438 0.13 0.17 #> 3439 0.12 0.13 #> 3440 0.12 0.19 #> 3441 0.12 0.20 #> 3442 0.12 0.07 #> 3443 0.13 0.13 #> 3444 0.13 0.13 #> 3445 0.12 0.08 #> 3446 0.13 0.17 #> 3447 0.12 0.14 #> 3448 0.12 0.08 #> 3449 0.12 0.25 #> 3450 0.12 0.21 #> 3451 0.13 0.12 #> 3452 0.13 0.14 #> 3453 0.12 0.14 #> 3454 0.12 0.26 #> 3455 0.12 0.07 #> 3456 0.12 0.13 #> 3457 0.12 0.17 #> 3458 0.12 0.09 #> 3459 0.12 0.16 #> 3460 0.12 0.14 #> 3461 0.12 0.10 #> 3462 0.12 0.19 #> 3463 0.12 0.07 #> 3464 0.12 0.08 #> 3465 0.12 0.13 #> 3466 0.12 0.10 #> 3467 0.13 0.16 #> 3468 0.13 0.04 #> 3469 0.13 0.12 #> 3470 0.13 0.16 #> 3471 0.12 0.15 #> 3472 0.12 0.04 #> 3473 0.12 0.10 #> 3474 0.13 0.11 #> 3475 0.13 0.20 #> 3476 0.13 0.19 #> 3477 0.13 0.05 #> 3478 0.12 0.16 #> 3479 0.12 0.13 #> 3480 0.12 0.17 #> 3481 0.12 0.18 #> 3482 0.13 0.08 #> 3483 0.13 0.13 #> 3484 0.12 0.14 #> 3485 0.13 0.10 #> 3486 0.13 0.17 #> 3487 0.12 0.18 #> 3488 0.12 0.13 #> 3489 0.12 0.20 #> 3490 0.12 0.11 #> 3491 0.12 0.13 #> 3492 0.12 0.12 #> 3493 0.13 0.19 #> 3494 0.12 0.02 #> 3495 0.12 0.15 #> 3496 0.12 0.15 #> 3497 0.13 0.15 #> 3498 0.12 0.20 #> 3499 0.13 0.17 #> 3500 0.12 0.10 #> 3501 0.12 0.11 #> 3502 0.13 0.08 #> 3503 0.12 0.15 #> 3504 0.13 0.19 #> 3505 0.12 0.15 #> 3506 0.12 0.08 #> 3507 0.12 0.08 #> 3508 0.12 0.16 #> 3509 0.12 0.16 #> 3510 0.12 0.13 #> 3511 0.12 0.14 #> 3512 0.12 0.15 #> 3513 0.12 0.10 #> 3514 0.12 0.21 #> 3515 0.12 0.20 #> 3516 0.12 0.09 #> 3517 0.12 0.15 #> 3518 0.12 0.16 #> 3519 0.12 0.15 #> 3520 0.12 0.06 #> 3521 0.12 0.11 #> 3522 0.13 0.10 #> 3523 0.13 0.10 #> 3524 0.13 0.06 #> 3525 0.13 0.12 #> 3526 0.13 0.30 #> 3527 0.12 0.08 #> 3528 0.12 0.16 #> 3529 0.12 0.17 #> 3530 0.12 0.14 #> 3531 0.12 0.15 #> 3532 0.13 0.11 #> 3533 0.12 0.13 #> 3534 0.13 0.09 #> 3535 0.12 0.05 #> 3536 0.12 0.10 #> 3537 0.12 0.08 #> 3538 0.12 0.16 #> 3539 0.12 0.09 #> 3540 0.13 0.11 #> 3541 0.13 0.11 #> 3542 0.12 0.10 #> 3543 0.13 0.12 #> 3544 0.12 0.11 #> 3545 0.12 0.09 #> 3546 0.12 0.05 #> 3547 0.13 0.08 #> 3548 0.12 0.14 #> 3549 0.12 0.15 #> 3550 0.13 0.10 #> 3551 0.12 0.04 #> 3552 0.12 0.18 #> 3553 0.12 0.14 #> 3554 0.13 0.14 #> 3555 0.12 0.19 #> 3556 0.12 0.13 #> 3557 0.13 0.13 #> 3558 0.12 0.09 #> 3559 0.13 0.19 #> 3560 0.12 0.14 #> 3561 0.12 0.11 #> 3562 0.12 0.18 #> 3563 0.13 0.13 #> 3564 0.12 0.06 #> 3565 0.12 0.19 #> 3566 0.12 0.07 #> 3567 0.12 0.12 #> 3568 0.12 0.08 #> 3569 0.13 0.22 #> 3570 0.12 0.24 #> 3571 0.12 0.19 #> 3572 0.12 0.19 #> 3573 0.12 0.19 #> 3574 0.12 0.10 #> 3575 0.13 0.16 #> 3576 0.12 0.08 #> 3577 0.12 0.15 #> 3578 0.12 0.12 #> 3579 0.12 0.10 #> 3580 0.12 0.15 #> 3581 0.13 0.17 #> 3582 0.12 0.14 #> 3583 0.12 0.13 #> 3584 0.12 0.12 #> 3585 0.13 0.11 #> 3586 0.12 0.17 #> 3587 0.12 0.23 #> 3588 0.12 0.16 #> 3589 0.12 0.18 #> 3590 0.12 0.14 #> 3591 0.12 0.08 #> 3592 0.13 0.08 #> 3593 0.12 0.14 #> 3594 0.13 0.08 #> 3595 0.12 0.11 #> 3596 0.12 0.16 #> 3597 0.13 0.14 #> 3598 0.13 0.12 #> 3599 0.12 0.09 #> 3600 0.12 0.12 #> 3601 0.13 0.17 #> 3602 0.12 0.10 #> 3603 0.12 0.15 #> 3604 0.12 0.10 #> 3605 0.13 0.15 #> 3606 0.12 0.12 #> 3607 0.13 0.07 #> 3608 0.12 0.15 #> 3609 0.13 0.18 #> 3610 0.12 0.22 #> 3611 0.13 0.04 #> 3612 0.12 0.20 #> 3613 0.12 0.07 #> 3614 0.13 0.10 #> 3615 0.12 0.07 #> 3616 0.12 0.11 #> 3617 0.12 0.17 #> 3618 0.12 0.16 #> 3619 0.12 0.16 #> 3620 0.12 0.16 #> 3621 0.12 0.19 #> 3622 0.13 0.14 #> 3623 0.12 0.08 #> 3624 0.12 0.07 #> 3625 0.12 0.15 #> 3626 0.13 0.12 #> 3627 0.12 0.15 #> 3628 0.12 0.09 #> 3629 0.12 0.13 #> 3630 0.12 0.13 #> 3631 0.12 0.19 #> 3632 0.12 0.11 #> 3633 0.12 0.12 #> 3634 0.12 0.15 #> 3635 0.13 0.18 #> 3636 0.13 0.12 #> 3637 0.12 0.16 #> 3638 0.13 0.18 #> 3639 0.12 0.11 #> 3640 0.12 0.11 #> 3641 0.13 0.07 #> 3642 0.12 0.14 #> 3643 0.13 0.19 #> 3644 0.12 0.21 #> 3645 0.12 0.18 #> 3646 0.12 0.10 #> 3647 0.12 0.22 #> 3648 0.12 0.13 #> 3649 0.12 0.14 #> 3650 0.12 0.11 #> 3651 0.12 0.12 #> 3652 0.12 0.12 #> 3653 0.12 0.14 #> 3654 0.12 0.12 #> 3655 0.12 0.16 #> 3656 0.12 0.20 #> 3657 0.12 0.15 #> 3658 0.12 0.09 #> 3659 0.13 0.09 #> 3660 0.12 0.10 #> 3661 0.12 0.10 #> 3662 0.13 0.12 #> 3663 0.12 0.10 #> 3664 0.12 0.17 #> 3665 0.12 0.09 #> 3666 0.13 0.17 #> 3667 0.12 0.10 #> 3668 0.12 0.17 #> 3669 0.13 0.15 #> 3670 0.12 0.10 #> 3671 0.12 0.15 #> 3672 0.12 0.03 #> 3673 0.12 0.25 #> 3674 0.12 0.11 #> 3675 0.12 0.10 #> 3676 0.12 0.16 #> 3677 0.12 0.11 #> 3678 0.12 0.11 #> 3679 0.12 0.10 #> 3680 0.13 0.13 #> 3681 0.13 0.17 #> 3682 0.12 0.09 #> 3683 0.13 0.18 #> 3684 0.12 0.10 #> 3685 0.12 0.10 #> 3686 0.12 0.14 #> 3687 0.12 0.17 #> 3688 0.12 0.14 #> 3689 0.13 0.15 #> 3690 0.12 0.13 #> 3691 0.12 0.18 #> 3692 0.12 0.14 #> 3693 0.12 0.21 #> 3694 0.12 0.11 #> 3695 0.12 0.11 #> 3696 0.12 0.13 #> 3697 0.13 0.17 #> 3698 0.13 0.07 #> 3699 0.13 0.11 #> 3700 0.13 0.20 #> 3701 0.12 0.12 #> 3702 0.13 0.25 #> 3703 0.13 0.15 #> 3704 0.13 0.14 #> 3705 0.13 0.07 #> 3706 0.12 0.14 #> 3707 0.12 0.11 #> 3708 0.12 0.07 #> 3709 0.12 0.08 #> 3710 0.12 0.12 #> 3711 0.13 0.09 #> 3712 0.12 0.11 #> 3713 0.12 0.19 #> 3714 0.12 0.11 #> 3715 0.13 0.19 #> 3716 0.13 0.11 #> 3717 0.12 0.11 #> 3718 0.12 0.13 #> 3719 0.12 0.18 #> 3720 0.12 0.07 #> 3721 0.13 0.12 #> 3722 0.12 0.12 #> 3723 0.13 0.22 #> 3724 0.12 0.11 #> 3725 0.12 0.14 #> 3726 0.12 0.12 #> 3727 0.13 0.26 #> 3728 0.12 0.23 #> 3729 0.12 0.04 #> 3730 0.12 0.15 #> 3731 0.12 0.03 #> 3732 0.13 0.13 #> 3733 0.12 0.11 #> 3734 0.12 0.18 #> 3735 0.12 0.11 #> 3736 0.12 0.12 #> 3737 0.12 0.11 #> 3738 0.12 0.11 #> 3739 0.13 0.24 #> 3740 0.12 0.20 #> 3741 0.12 0.12 #> 3742 0.12 0.23 #> 3743 0.12 0.11 #> 3744 0.12 0.15 #> 3745 0.12 0.11 #> 3746 0.12 0.13 #> 3747 0.13 0.21 #> 3748 0.12 0.14 #> 3749 0.12 0.07 #> 3750 0.13 0.07 #> 3751 0.13 0.11 #> 3752 0.12 0.26 #> 3753 0.12 0.14 #> 3754 0.13 0.09 #> 3755 0.13 0.09 #> 3756 0.12 0.18 #> 3757 0.12 0.17 #> 3758 0.12 0.18 #> 3759 0.12 0.12 #> 3760 0.12 0.16 #> 3761 0.12 0.20 #> 3762 0.12 0.16 #> 3763 0.12 0.08 #> 3764 0.12 0.14 #> 3765 0.12 0.14 #> 3766 0.12 0.07 #> 3767 0.13 0.08 #> 3768 0.12 0.19 #> 3769 0.12 0.14 #> 3770 0.12 0.21 #> 3771 0.12 0.16 #> 3772 0.12 0.13 #> 3773 0.12 0.09 #> 3774 0.13 0.11 #> 3775 0.13 0.13 #> 3776 0.12 0.12 #> 3777 0.13 0.03 #> 3778 0.12 0.11 #> 3779 0.12 0.11 #> 3780 0.13 0.05 #> 3781 0.12 0.13 #> 3782 0.12 0.14 #> 3783 0.12 0.19 #> 3784 0.12 0.09 #> 3785 0.13 0.13 #> 3786 0.12 0.15 #> 3787 0.13 0.17 #> 3788 0.12 0.14 #> 3789 0.13 0.13 #> 3790 0.13 0.15 #> 3791 0.12 0.11 #> 3792 0.12 0.09 #> 3793 0.12 0.06 #> 3794 0.12 0.18 #> 3795 0.12 0.13 #> 3796 0.12 0.14 #> 3797 0.13 0.04 #> 3798 0.12 0.09 #> 3799 0.13 0.11 #> 3800 0.13 0.26 #> 3801 0.12 0.19 #> 3802 0.12 0.08 #> 3803 0.12 0.14 #> 3804 0.12 0.11 #> 3805 0.12 0.13 #> 3806 0.12 0.21 #> 3807 0.12 0.18 #> 3808 0.12 0.16 #> 3809 0.12 0.18 #> 3810 0.12 0.21 #> 3811 0.12 0.11 #> 3812 0.13 0.07 #> 3813 0.12 0.18 #> 3814 0.12 0.11 #> 3815 0.12 0.08 #> 3816 0.12 0.09 #> 3817 0.12 0.19 #> 3818 0.13 0.21 #> 3819 0.13 0.09 #> 3820 0.12 0.13 #> 3821 0.13 0.12 #> 3822 0.12 0.16 #> 3823 0.12 0.07 #> 3824 0.13 0.09 #> 3825 0.12 0.13 #> 3826 0.13 0.10 #> 3827 0.12 0.16 #> 3828 0.12 0.12 #> 3829 0.13 0.09 #> 3830 0.12 0.17 #> 3831 0.12 0.13 #> 3832 0.12 0.09 #> 3833 0.13 0.17 #> 3834 0.13 0.18 #> 3835 0.12 0.10 #> 3836 0.12 0.19 #> 3837 0.12 0.16 #> 3838 0.12 0.23 #> 3839 0.12 0.14 #> 3840 0.12 0.18 #> 3841 0.13 0.19 #> 3842 0.12 0.07 #> 3843 0.13 0.13 #> 3844 0.12 0.11 #> 3845 0.12 0.08 #> 3846 0.13 0.10 #> 3847 0.12 0.14 #> 3848 0.12 0.15 #> 3849 0.12 0.12 #> 3850 0.12 0.12 #> 3851 0.12 0.11 #> 3852 0.12 0.14 #> 3853 0.12 0.17 #> 3854 0.12 0.13 #> 3855 0.12 0.13 #> 3856 0.12 0.16 #> 3857 0.12 0.13 #> 3858 0.12 0.11 #> 3859 0.12 0.14 #> 3860 0.13 0.09 #> 3861 0.13 0.14 #> 3862 0.12 0.20 #> 3863 0.13 0.10 #> 3864 0.12 0.11 #> 3865 0.12 0.19 #> 3866 0.12 0.13 #> 3867 0.12 0.15 #> 3868 0.13 0.11 #> 3869 0.12 0.10 #> 3870 0.12 0.15 #> 3871 0.12 0.16 #> 3872 0.13 0.19 #> 3873 0.12 0.08 #> 3874 0.13 0.09 #> 3875 0.12 0.08 #> 3876 0.12 0.27 #> 3877 0.13 0.23 #> 3878 0.12 0.12 #> 3879 0.12 0.20 #> 3880 0.13 0.21 #> 3881 0.12 0.12 #> 3882 0.13 0.11 #> 3883 0.12 0.13 #> 3884 0.13 0.21 #> 3885 0.12 0.16 #> 3886 0.13 0.13 #> 3887 0.13 0.16 #> 3888 0.13 0.12 #> 3889 0.12 0.24 #> 3890 0.12 0.21 #> 3891 0.12 0.22 #> 3892 0.12 0.22 #> 3893 0.12 0.03 #> 3894 0.12 0.20 #> 3895 0.12 0.09 #> 3896 0.12 0.13 #> 3897 0.12 0.17 #> 3898 0.12 0.10 #> 3899 0.12 0.11 #> 3900 0.12 0.08 #> 3901 0.12 0.12 #> 3902 0.12 0.14 #> 3903 0.13 0.19 #> 3904 0.12 0.15 #> 3905 0.13 0.16 #> 3906 0.13 0.20 #> 3907 0.12 0.19 #> 3908 0.12 0.10 #> 3909 0.13 0.11 #> 3910 0.12 0.06 #> 3911 0.12 0.11 #> 3912 0.12 0.10 #> 3913 0.12 0.22 #> 3914 0.12 0.06 #> 3915 0.12 0.08 #> 3916 0.12 0.20 #> 3917 0.12 0.12 #> 3918 0.12 0.16 #> 3919 0.12 0.10 #> 3920 0.12 0.12 #> 3921 0.12 0.11 #> 3922 0.13 0.13 #> 3923 0.12 0.14 #> 3924 0.12 0.24 #> 3925 0.12 0.14 #> 3926 0.13 0.12 #> 3927 0.12 0.13 #> 3928 0.13 0.08 #> 3929 0.12 0.08 #> 3930 0.13 0.12 #> 3931 0.13 0.10 #> 3932 0.12 0.15 #> 3933 0.12 0.13 #> 3934 0.12 0.09 #> 3935 0.12 0.15 #> 3936 0.12 0.19 #> 3937 0.12 0.13 #> 3938 0.12 0.15 #> 3939 0.12 0.13 #> 3940 0.13 0.14 #> 3941 0.12 0.14 #> 3942 0.12 0.15 #> 3943 0.13 0.22 #> 3944 0.12 0.08 #> 3945 0.12 0.22 #> 3946 0.13 0.10 #> 3947 0.12 0.14 #> 3948 0.12 0.08 #> 3949 0.13 0.24 #> 3950 0.12 0.25 #> 3951 0.12 0.15 #> 3952 0.12 0.11 #> 3953 0.12 0.11 #> 3954 0.12 0.12 #> 3955 0.12 0.12 #> 3956 0.13 0.11 #> 3957 0.13 0.12 #> 3958 0.12 0.11 #> 3959 0.12 0.13 #> 3960 0.12 0.20 #> 3961 0.12 0.13 #> 3962 0.12 0.20 #> 3963 0.12 0.10 #> 3964 0.12 0.19 #> 3965 0.12 0.06 #> 3966 0.13 0.12 #> 3967 0.12 0.17 #> 3968 0.12 0.05 #> 3969 0.12 0.12 #> 3970 0.13 0.16 #> 3971 0.13 0.13 #> 3972 0.12 0.11 #> 3973 0.12 0.19 #> 3974 0.13 0.18 #> 3975 0.12 0.10 #> 3976 0.12 0.08 #> 3977 0.12 0.09 #> 3978 0.12 0.15 #> 3979 0.13 0.10 #> 3980 0.12 0.13 #> 3981 0.12 0.19 #> 3982 0.13 0.23 #> 3983 0.12 0.08 #> 3984 0.13 0.13 #> 3985 0.12 0.29 #> 3986 0.12 0.09 #> 3987 0.12 0.21 #> 3988 0.12 0.10 #> 3989 0.12 0.20 #> 3990 0.12 0.19 #> 3991 0.12 0.08 #> 3992 0.12 0.11 #> 3993 0.12 0.05 #> 3994 0.12 0.10 #> 3995 0.13 0.13 #> 3996 0.13 0.06 #> 3997 0.12 0.15 #> 3998 0.12 0.13 #> 3999 0.13 0.17 #> 4000 0.12 0.17 #>  #> $event_probabilities #>  #> Posterior draws of event probabilities (transformed parameters) #>  #> Dimensions: 4000 rows (draws) by 4 cols (data types) #>  #> Summary:  #>  #>       mean    sd #> X0Y0 0.250 0.197 #> X1Y0 0.254 0.199 #> X0Y1 0.245 0.192 #> X1Y1 0.250 0.195 #>  #> $stan_summary #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>             mean se_mean   sd   2.5%   25%   50%   75% 97.5% n_eff Rhat #> X.0         0.50    0.01 0.29   0.02  0.24  0.50  0.75  0.98  2775    1 #> X.1         0.50    0.01 0.29   0.02  0.25  0.50  0.76  0.98  2775    1 #> Y.00        0.25    0.00 0.20   0.01  0.09  0.21  0.37  0.72  1748    1 #> Y.10        0.25    0.00 0.20   0.01  0.09  0.20  0.37  0.71  4574    1 #> Y.01        0.25    0.00 0.20   0.01  0.09  0.20  0.36  0.73  4614    1 #> Y.11        0.25    0.00 0.20   0.01  0.09  0.20  0.38  0.71  4043    1 #> X0Y0        0.25    0.00 0.20   0.01  0.09  0.21  0.38  0.71  3130    1 #> X1Y0        0.25    0.00 0.20   0.01  0.09  0.21  0.38  0.72  2767    1 #> X0Y1        0.25    0.00 0.19   0.01  0.09  0.20  0.36  0.70  2894    1 #> X1Y1        0.25    0.00 0.19   0.01  0.09  0.21  0.37  0.72  2581    1 #> X0.Y00      0.13    0.00 0.14   0.00  0.03  0.08  0.19  0.50  2152    1 #> X1.Y00      0.13    0.00 0.13   0.00  0.03  0.08  0.18  0.50  1949    1 #> X0.Y10      0.12    0.00 0.13   0.00  0.02  0.08  0.17  0.47  3403    1 #> X1.Y10      0.13    0.00 0.14   0.00  0.02  0.08  0.19  0.49  3566    1 #> X0.Y01      0.12    0.00 0.13   0.00  0.03  0.08  0.18  0.49  3682    1 #> X1.Y01      0.13    0.00 0.14   0.00  0.03  0.08  0.18  0.51  3455    1 #> X0.Y11      0.13    0.00 0.14   0.00  0.02  0.08  0.18  0.50  3242    1 #> X1.Y11      0.12    0.00 0.13   0.00  0.03  0.08  0.17  0.48  3074    1 #> lp__       -7.59    0.05 1.72 -11.86 -8.43 -7.17 -6.34 -5.43  1148    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Mar 25 23:46:14 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #>  #> attr(,\"class\") #> [1] \"stan_objects\" \"list\"         grab(model, object = \"stan_fit\") #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>             mean se_mean   sd   2.5%   25%   50%   75% 97.5% n_eff Rhat #> lambdas[1]  0.50    0.01 0.29   0.02  0.24  0.50  0.75  0.98  2775    1 #> lambdas[2]  0.50    0.01 0.29   0.02  0.25  0.50  0.76  0.98  2775    1 #> lambdas[3]  0.25    0.00 0.20   0.01  0.09  0.21  0.37  0.72  1748    1 #> lambdas[4]  0.25    0.00 0.20   0.01  0.09  0.20  0.37  0.71  4574    1 #> lambdas[5]  0.25    0.00 0.20   0.01  0.09  0.20  0.36  0.73  4614    1 #> lambdas[6]  0.25    0.00 0.20   0.01  0.09  0.20  0.38  0.71  4043    1 #> w[1]        0.25    0.00 0.20   0.01  0.09  0.21  0.38  0.71  3130    1 #> w[2]        0.25    0.00 0.20   0.01  0.09  0.21  0.38  0.72  2767    1 #> w[3]        0.25    0.00 0.19   0.01  0.09  0.20  0.36  0.70  2894    1 #> w[4]        0.25    0.00 0.19   0.01  0.09  0.21  0.37  0.72  2581    1 #> types[1]    0.13    0.00 0.14   0.00  0.03  0.08  0.19  0.50  2152    1 #> types[2]    0.13    0.00 0.13   0.00  0.03  0.08  0.18  0.50  1949    1 #> types[3]    0.12    0.00 0.13   0.00  0.02  0.08  0.17  0.47  3403    1 #> types[4]    0.13    0.00 0.14   0.00  0.02  0.08  0.19  0.49  3566    1 #> types[5]    0.12    0.00 0.13   0.00  0.03  0.08  0.18  0.49  3682    1 #> types[6]    0.13    0.00 0.14   0.00  0.03  0.08  0.18  0.51  3455    1 #> types[7]    0.13    0.00 0.14   0.00  0.02  0.08  0.18  0.50  3242    1 #> types[8]    0.12    0.00 0.13   0.00  0.03  0.08  0.17  0.48  3074    1 #> lp__       -7.59    0.05 1.72 -11.86 -8.43 -7.17 -6.34 -5.43  1148    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Mar 25 23:46:14 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). grab(model, object = \"stan_summary\") #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>             mean se_mean   sd   2.5%   25%   50%   75% 97.5% n_eff Rhat #> X.0         0.50    0.01 0.29   0.02  0.24  0.50  0.75  0.98  2775    1 #> X.1         0.50    0.01 0.29   0.02  0.25  0.50  0.76  0.98  2775    1 #> Y.00        0.25    0.00 0.20   0.01  0.09  0.21  0.37  0.72  1748    1 #> Y.10        0.25    0.00 0.20   0.01  0.09  0.20  0.37  0.71  4574    1 #> Y.01        0.25    0.00 0.20   0.01  0.09  0.20  0.36  0.73  4614    1 #> Y.11        0.25    0.00 0.20   0.01  0.09  0.20  0.38  0.71  4043    1 #> X0Y0        0.25    0.00 0.20   0.01  0.09  0.21  0.38  0.71  3130    1 #> X1Y0        0.25    0.00 0.20   0.01  0.09  0.21  0.38  0.72  2767    1 #> X0Y1        0.25    0.00 0.19   0.01  0.09  0.20  0.36  0.70  2894    1 #> X1Y1        0.25    0.00 0.19   0.01  0.09  0.21  0.37  0.72  2581    1 #> X0.Y00      0.13    0.00 0.14   0.00  0.03  0.08  0.19  0.50  2152    1 #> X1.Y00      0.13    0.00 0.13   0.00  0.03  0.08  0.18  0.50  1949    1 #> X0.Y10      0.12    0.00 0.13   0.00  0.02  0.08  0.17  0.47  3403    1 #> X1.Y10      0.13    0.00 0.14   0.00  0.02  0.08  0.19  0.49  3566    1 #> X0.Y01      0.12    0.00 0.13   0.00  0.03  0.08  0.18  0.49  3682    1 #> X1.Y01      0.13    0.00 0.14   0.00  0.03  0.08  0.18  0.51  3455    1 #> X0.Y11      0.13    0.00 0.14   0.00  0.02  0.08  0.18  0.50  3242    1 #> X1.Y11      0.12    0.00 0.13   0.00  0.03  0.08  0.17  0.48  3074    1 #> lp__       -7.59    0.05 1.72 -11.86 -8.43 -7.17 -6.34 -5.43  1148    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Mar 25 23:46:14 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). grab(model, object = \"type_prior\") #> Prior distribution added to model #> Summary statistics of causal type prior distributions: #> Dimensions: 4000 rows (draws) by 8 cols (types)  #>  #> Summary:  #>  #>         mean    sd #> X0.Y00 0.126 0.133 #> X1.Y00 0.131 0.140 #> X0.Y10 0.122 0.128 #> X1.Y10 0.124 0.133 #> X0.Y01 0.125 0.134 #> X1.Y01 0.125 0.133 #> X0.Y11 0.124 0.133 #> X1.Y11 0.124 0.130 grab(model, object = \"type_posterior\") #> Posterior draws of causal types (transformed parameters) #> Dimensions: 4000 rows (draws) by 8 cols (types)  #>  #> Summary:  #>  #>         mean    sd #> X0.Y00 0.127 0.135 #> X1.Y00 0.126 0.134 #> X0.Y10 0.120 0.129 #> X1.Y10 0.128 0.138 #> X0.Y01 0.123 0.132 #> X1.Y01 0.126 0.136 #> X0.Y11 0.126 0.136 #> X1.Y11 0.125 0.134  # Example of arguments passed on to helpers grab(model,   object = \"event_probabilities\",   parameters = c(.6, .4, .1, .1, .7, .1)) #>  #> The probability of observing a given combination of data  #> realizations for a given set of parameter values. #>  #>      event_probs #> X0Y0        0.48 #> X1Y0        0.08 #> X0Y1        0.12 #> X1Y1        0.32  # }"},{"path":"/reference/gsub_many.html","id":null,"dir":"Reference","previous_headings":"","what":"Recursive substitution — gsub_many","title":"Recursive substitution — gsub_many","text":"Applies gsub() multiple patterns multiple replacements 1:1 mapping.","code":""},{"path":"/reference/gsub_many.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recursive substitution — gsub_many","text":"","code":"gsub_many(x, pattern_vector, replacement_vector, ...)"},{"path":"/reference/gsub_many.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recursive substitution — gsub_many","text":"x character vector. pattern_vector character vector. replacement_vector character vector. ... Options passed onto gsub() call.","code":""},{"path":"/reference/gsub_many.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Recursive substitution — gsub_many","text":"Returns multiple expression substituted elements","code":""},{"path":"/reference/increasing.html","id":null,"dir":"Reference","previous_headings":"","what":"Make monotonicity statement (positive) — increasing","title":"Make monotonicity statement (positive) — increasing","text":"Generate statement Y monotonic (increasing) X","code":""},{"path":"/reference/increasing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make monotonicity statement (positive) — increasing","text":"","code":"increasing(X, Y)"},{"path":"/reference/increasing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make monotonicity statement (positive) — increasing","text":"X character. quoted name input node Y character. quoted name outcome node","code":""},{"path":"/reference/increasing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make monotonicity statement (positive) — increasing","text":"character statement class statement","code":""},{"path":[]},{"path":"/reference/increasing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make monotonicity statement (positive) — increasing","text":"","code":"# \\donttest{ increasing('A', 'B') #>  #> Statement:  #> (B[A=1] > B[A=0]) # }"},{"path":"/reference/institutions_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Institutions and growth: Data for replication of analysis in\r\n*Integrated Inferences* — institutions_data","title":"Institutions and growth: Data for replication of analysis in\r\n*Integrated Inferences* — institutions_data","text":" dataset containing dichotomized versions variables Rodrik, Subramanian, Trebbi (2004).","code":""},{"path":"/reference/institutions_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Institutions and growth: Data for replication of analysis in\r\n*Integrated Inferences* — institutions_data","text":"","code":"institutions_data"},{"path":"/reference/institutions_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Institutions and growth: Data for replication of analysis in\r\n*Integrated Inferences* — institutions_data","text":"data frame 79 rows 5 columns: Y Income (GDP PPP 1995), dichotomized R Institutions, (based  Kaufmann, Kraay, Zoido-Lobaton (2002)) dichotomized D Distance equator (degrees), dichotomized M Settler mortality (Acemoglu, Johnson, Robinson), dichotomized country Country","code":""},{"path":"/reference/institutions_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Institutions and growth: Data for replication of analysis in\r\n*Integrated Inferences* — institutions_data","text":"https://drodrik.scholar.harvard.edu/publications/institutions-rule-primacy-institutions--geography--integration","code":""},{"path":"/reference/interacts.html","id":null,"dir":"Reference","previous_headings":"","what":"Make statement for any interaction — interacts","title":"Make statement for any interaction — interacts","text":"Generate statement X1, X1 interact production Y","code":""},{"path":"/reference/interacts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make statement for any interaction — interacts","text":"","code":"interacts(X1, X2, Y)"},{"path":"/reference/interacts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make statement for any interaction — interacts","text":"X1 character. quoted name input node 1. X2 character. quoted name input node 2. Y character. quoted name outcome node.","code":""},{"path":"/reference/interacts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make statement for any interaction — interacts","text":"character statement class statement","code":""},{"path":[]},{"path":"/reference/interacts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make statement for any interaction — interacts","text":"","code":"# \\donttest{ interacts('A', 'B', 'W') #>  #> Statement:  #> ((W[A =1, B = 1]) - (W[A = 0, B = 1])) != ((W[A =1, B = 0]) - (W[A = 0, B = 0])) get_query_types(model = make_model('X-> Y <- W'),          query = interacts('X', 'W', 'Y'), map = \"causal_type\") #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  ((Y[X=1,W=1])-(Y[X=0,W=1]))!=((Y[X=1,W=0])-(Y[X=0,W=0]))  #>  #> W0.X0.Y1000  W1.X0.Y1000 #> W0.X1.Y1000  W1.X1.Y1000 #> W0.X0.Y0100  W1.X0.Y0100 #> W0.X1.Y0100  W1.X1.Y0100 #> W0.X0.Y0010  W1.X0.Y0010 #> W0.X1.Y0010  W1.X1.Y0010 #> W0.X0.Y0110  W1.X0.Y0110 #> W0.X1.Y0110  W1.X1.Y0110 #> W0.X0.Y1110  W1.X0.Y1110 #> W0.X1.Y1110  W1.X1.Y1110 #> W0.X0.Y0001  W1.X0.Y0001 #> W0.X1.Y0001  W1.X1.Y0001 #> W0.X0.Y1001  W1.X0.Y1001 #> W0.X1.Y1001  W1.X1.Y1001 #> W0.X0.Y1101  W1.X0.Y1101 #> W0.X1.Y1101  W1.X1.Y1101 #> W0.X0.Y1011  W1.X0.Y1011 #> W0.X1.Y1011  W1.X1.Y1011 #> W0.X0.Y0111  W1.X0.Y0111 #> W0.X1.Y0111  W1.X1.Y0111 #>  #>  #>  Number of causal types that meet condition(s) =  40 #>  Total number of causal types in model =  64 # }"},{"path":"/reference/interpret_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Interpret or find position in nodal type — interpret_type","title":"Interpret or find position in nodal type — interpret_type","text":"Interprets position one digits (specified position) nodal type. Alternatively returns nodal type digit positions correspond one given condition.","code":""},{"path":"/reference/interpret_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interpret or find position in nodal type — interpret_type","text":"","code":"interpret_type(model, condition = NULL, position = NULL)"},{"path":"/reference/interpret_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interpret or find position in nodal type — interpret_type","text":"model causal_model. model object generated make_model. condition vector characters. Strings specifying child node, followed '|' (given) values parent nodes model. position named list integers. name name child node model, value vector digit positions node's nodal type interpreted. See `Details`.","code":""},{"path":"/reference/interpret_type.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interpret or find position in nodal type — interpret_type","text":"named list interpretation positions   digits nodal type","code":""},{"path":"/reference/interpret_type.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Interpret or find position in nodal type — interpret_type","text":"node child node X k parents nodal type   represented X followed 2^k digits. Argument position   allows user interpret meaning one digit positions   nodal type. example position = list(X = 1:3) return   interpretation first three digits causal types X.   Argument condition allows users query digit position   nodal type providing instead values parent nodes given   child. example, condition = 'X | Z=0 & R=1' returns digit   position corresponds values X takes Z = 0 R = 1.","code":""},{"path":"/reference/interpret_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interpret or find position in nodal type — interpret_type","text":"","code":"model <- make_model('R -> X; Z -> X; X -> Y') #Example using digit position interpret_type(model, position = list(X = c(3,4), Y = 1)) #> $X #>   node position display    interpretation #> 1    X        3 X**[*]* X | R = 0 & Z = 1 #> 2    X        4 X***[*] X | R = 1 & Z = 1 #>  #> $Y #>   node position display interpretation #> 1    Y        1   Y[*]*      Y | X = 0 #>  #Example using condition interpret_type(model, condition = c('X | Z=0 & R=1', 'X | Z=0 & R=0')) #> $X #>   node position display    interpretation #> 1    X        1 X[*]*** X | R = 0 & Z = 0 #> 2    X        2 X*[*]** X | R = 1 & Z = 0 #>  #Return interpretation of all digit positions of all nodes interpret_type(model) #> $R #>   node position display interpretation #> 1    R       NA      R0          R = 0 #> 2    R       NA      R1          R = 1 #>  #> $Z #>   node position display interpretation #> 1    Z       NA      Z0          Z = 0 #> 2    Z       NA      Z1          Z = 1 #>  #> $X #>   node position display    interpretation #> 1    X        1 X[*]*** X | R = 0 & Z = 0 #> 2    X        2 X*[*]** X | R = 1 & Z = 0 #> 3    X        3 X**[*]* X | R = 0 & Z = 1 #> 4    X        4 X***[*] X | R = 1 & Z = 1 #>  #> $Y #>   node position display interpretation #> 1    Y        1   Y[*]*      Y | X = 0 #> 2    Y        2   Y*[*]      Y | X = 1 #>"},{"path":"/reference/is_a_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Check whether argument is a model — is_a_model","title":"Check whether argument is a model — is_a_model","text":"Check whether argument model","code":""},{"path":"/reference/is_a_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check whether argument is a model — is_a_model","text":"","code":"is_a_model(model)"},{"path":"/reference/is_a_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check whether argument is a model — is_a_model","text":"model causal_model. model object generated make_model.","code":""},{"path":"/reference/is_a_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check whether argument is a model — is_a_model","text":"error message argument model.","code":""},{"path":"/reference/lipids_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Lipids: Data for Chickering and Pearl replication — lipids_data","title":"Lipids: Data for Chickering and Pearl replication — lipids_data","text":"compact dataset containing information encouragement, (Z, cholestyramine prescription), treatment (X, usage), outcome (Y, cholesterol). David Maxwell Chickering Judea Pearl: \"Clinician’s Tool Analyzing Non-compliance\", AAAI-96 Proceedings. Chickering Pearl turn draw data Efron, Bradley, David Feldman. \"Compliance explanatory variable clinical trials.\" Journal American Statistical Association 86.413 (1991): 9-17.","code":""},{"path":"/reference/lipids_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lipids: Data for Chickering and Pearl replication — lipids_data","text":"","code":"lipids_data"},{"path":"/reference/lipids_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Lipids: Data for Chickering and Pearl replication — lipids_data","text":"data frame 8 rows 3 columns: event data type strategy nodes data available count Number units data type","code":""},{"path":"/reference/lipids_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Lipids: Data for Chickering and Pearl replication — lipids_data","text":"https://cdn.aaai.org/AAAI/1996/AAAI96-188.pdf","code":""},{"path":"/reference/list_non_parents.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns a list with the nodes that are not directly pointing into a node — list_non_parents","title":"Returns a list with the nodes that are not directly pointing into a node — list_non_parents","text":"Returns list nodes directly pointing node","code":""},{"path":"/reference/list_non_parents.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns a list with the nodes that are not directly pointing into a node — list_non_parents","text":"","code":"list_non_parents(model, node)"},{"path":"/reference/list_non_parents.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns a list with the nodes that are not directly pointing into a node — list_non_parents","text":"model causal_model. model object generated make_model. node character string. quoted name node.","code":""},{"path":"/reference/list_non_parents.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns a list with the nodes that are not directly pointing into a node — list_non_parents","text":"Returns list nodes directly  pointing node","code":""},{"path":"/reference/make_ambiguities_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Make ambiguities matrix — make_ambiguities_matrix","title":"Make ambiguities matrix — make_ambiguities_matrix","text":"Make ambiguities matrix. ambiguities matrix maps causal types data types.","code":""},{"path":"/reference/make_ambiguities_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make ambiguities matrix — make_ambiguities_matrix","text":"","code":"make_ambiguities_matrix(model)"},{"path":"/reference/make_ambiguities_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make ambiguities matrix — make_ambiguities_matrix","text":"model causal_model. model object generated make_model.","code":""},{"path":"/reference/make_ambiguities_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make ambiguities matrix — make_ambiguities_matrix","text":"data.frame. Types (rows) corresponding possible   data realizations (columns).","code":""},{"path":"/reference/make_ambiguities_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make ambiguities matrix — make_ambiguities_matrix","text":"","code":"model <- make_model('X -> Y') CausalQueries:::make_ambiguities_matrix(model = model) #>       X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y00    1    0    0    0 #> X1Y00    0    1    0    0 #> X0Y10    0    0    1    0 #> X1Y10    0    1    0    0 #> X0Y01    1    0    0    0 #> X1Y01    0    0    0    1 #> X0Y11    0    0    1    0 #> X1Y11    0    0    0    1"},{"path":"/reference/make_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Make data — make_data","title":"Make data — make_data","text":"Make data","code":""},{"path":"/reference/make_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make data — make_data","text":"","code":"make_data(   model,   n = NULL,   parameters = NULL,   param_type = NULL,   nodes = NULL,   n_steps = NULL,   probs = NULL,   subsets = TRUE,   complete_data = NULL,   given = NULL,   verbose = TRUE,   ... )"},{"path":"/reference/make_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make data — make_data","text":"model causal_model. model object generated make_model. n Non negative integer. Number observations. provided inferred  largest n_step. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn model$parameters_df. param_type character. String specifying type parameters make (\"flat\", \"prior_mean\", \"posterior_mean\", \"prior_draw\", \"posterior_draw\", \"define\"). param_type set define use arguments passed make_priors; otherwise flat sets equal probabilities nodal type parameter set; prior_mean, prior_draw, posterior_mean, posterior_draw take parameters means draws prior posterior. nodes list. nodes observed step. NULL nodes observed. n_steps list. Number observations observed step probs list. Observation probabilities step subsets list. Strata within observations observed step. TRUE , otherwise expression evaluates logical condition. complete_data data.frame. Dataset complete observations. Optional. given string specifying known values nodes, e.g. \"X==1 & Y==1\" verbose Logical. TRUE prints step schedule. ... additional arguments can passed link{make_parameters}","code":""},{"path":"/reference/make_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make data — make_data","text":"data.frame simulated data.","code":""},{"path":"/reference/make_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make data — make_data","text":"Note default behavior take account whether node already observed determining whether select . One can however specifically request observation nodes previously observed.","code":""},{"path":"/reference/make_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make data — make_data","text":"","code":"# Simple draws model <- make_model(\"X -> M -> Y\") make_data(model) #>   X M Y #> 1 0 1 0 make_data(model, n = 3, nodes = c(\"X\",\"Y\")) #> # A tibble: 1 × 5 #>   node_names nodes     n_steps probs subsets #>   <chr>      <list>      <dbl> <dbl> <lgl>   #> 1 X, Y       <chr [2]>       3     1 TRUE    #>   X  M Y #> 1 0 NA 0 #> 2 0 NA 1 #> 3 1 NA 0 make_data(model, n = 3, param_type = \"prior_draw\") #>   X M Y #> 1 0 0 0 #> 2 1 1 1 #> 3 1 1 1 make_data(model, n = 10, param_type = \"define\", parameters =  0:9) #>    X M Y #> 1  1 0 0 #> 2  1 0 1 #> 3  1 0 1 #> 4  1 1 0 #> 5  1 1 0 #> 6  1 1 0 #> 7  1 1 1 #> 8  1 1 1 #> 9  1 1 1 #> 10 1 1 1  # Data Strategies # A strategy in which X, Y are observed for sure and M is observed # with 50% probability for X=1, Y=0 cases  model <- make_model(\"X -> M -> Y\") make_data(   model,   n = 8,   nodes = list(c(\"X\", \"Y\"), \"M\"),   probs = list(1, .5),   subsets = list(TRUE, \"X==1 & Y==0\")) #> # A tibble: 2 × 5 #>   node_names nodes     n_steps probs subsets     #>   <chr>      <list>    <lgl>   <dbl> <chr>       #> 1 X, Y       <chr [2]> NA        1   TRUE        #> 2 M          <chr [1]> NA        0.5 X==1 & Y==0 #> Empty subset #>   X  M Y #> 1 0 NA 1 #> 2 0 NA 0 #> 3 0 NA 0 #> 4 0 NA 1 #> 5 0 NA 1 #> 6 1 NA 1 #> 7 1 NA 1 #> 8 1 NA 1  # n not provided but inferred from largest n_step (not from sum of n_steps) make_data(   model,   nodes = list(c(\"X\", \"Y\"), \"M\"),   n_steps = list(5, 2)) #> # A tibble: 2 × 5 #>   node_names nodes     n_steps probs subsets #>   <chr>      <list>      <dbl> <dbl> <lgl>   #> 1 X, Y       <chr [2]>       5     1 TRUE    #> 2 M          <chr [1]>       2     1 TRUE    #>   X  M Y #> 1 0 NA 0 #> 2 0 NA 1 #> 3 1  0 0 #> 4 1 NA 0 #> 5 1  1 1  # Wide then deep   make_data(   model,   n = 8,   nodes = list(c(\"X\", \"Y\"), \"M\"),   subsets = list(TRUE, \"!is.na(X) & !is.na(Y)\"),   n_steps = list(6, 2)) #> # A tibble: 2 × 5 #>   node_names nodes     n_steps probs subsets               #>   <chr>      <list>      <dbl> <dbl> <chr>                 #> 1 X, Y       <chr [2]>       6     1 TRUE                  #> 2 M          <chr [1]>       2     1 !is.na(X) & !is.na(Y) #>    X  M  Y #> 1 NA NA NA #> 2  0 NA  1 #> 3  1 NA  0 #> 4 NA NA NA #> 5  1  0  1 #> 6  1  1  0 #> 7  1 NA  1 #> 8  1 NA  1   make_data(   model,   n = 8,   nodes = list(c(\"X\", \"Y\"), c(\"X\", \"M\")),   subsets = list(TRUE, \"is.na(X)\"),   n_steps = list(3, 2)) #> # A tibble: 2 × 5 #>   node_names nodes     n_steps probs subsets  #>   <chr>      <list>      <dbl> <dbl> <chr>    #> 1 X, Y       <chr [2]>       3     1 TRUE     #> 2 X, M       <chr [2]>       2     1 is.na(X) #>    X  M  Y #> 1  0 NA  0 #> 2 NA NA NA #> 3 NA NA NA #> 4  1  0 NA #> 5 NA NA NA #> 6  1 NA  0 #> 7  1  1 NA #> 8  1 NA  1  # Example with probabilities at each step  make_data(   model,   n = 8,   nodes = list(c(\"X\", \"Y\"), c(\"X\", \"M\")),   subsets = list(TRUE, \"is.na(X)\"),   probs = list(.5, .2)) #> # A tibble: 2 × 5 #>   node_names nodes     n_steps probs subsets  #>   <chr>      <list>    <lgl>   <dbl> <chr>    #> 1 X, Y       <chr [2]> NA        0.5 TRUE     #> 2 X, M       <chr [2]> NA        0.2 is.na(X) #>    X  M  Y #> 1  0 NA  0 #> 2  0  0 NA #> 3  0 NA  0 #> 4  0 NA  0 #> 5 NA NA NA #> 6  1 NA  0 #> 7 NA NA NA #> 8 NA NA NA  # Example with given data make_data(model, given = \"X==1 & Y==1\", n = 5) #>   X M Y #> 1 1 0 1 #> 2 1 0 1 #> 3 1 1 1 #> 4 1 1 1 #> 5 1 1 1"},{"path":"/reference/make_data_single.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate full dataset — make_data_single","title":"Generate full dataset — make_data_single","text":"Generate full dataset","code":""},{"path":"/reference/make_data_single.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate full dataset — make_data_single","text":"","code":"make_data_single(   model,   n = 1,   parameters = NULL,   param_type = NULL,   given = NULL,   w = NULL,   P = NULL,   A = NULL )"},{"path":"/reference/make_data_single.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate full dataset — make_data_single","text":"model causal_model. model object generated make_model. n integer. Number observations. parameters numeric vector. Values parameters may specified. default, parameters drawn priors. param_type character. String specifying type parameters make (\"flat\", \"prior_mean\", \"posterior_mean\", \"prior_draw\", \"posterior_draw\", \"define). param_type set define use arguments passed make_priors; otherwise flat sets equal probabilities nodal type parameter set; prior_mean, prior_draw, posterior_mean, posterior_draw take parameters means draws prior posterior. given string specifying known values nodes, e.g. \"X==1 & Y==1\" w Vector event probabilities can provided directly. useful speed repeated data draws. P matrix. Parameter matrix can used generate w w provided matrix. Ambiguity matrix can used generate w w provided","code":""},{"path":"/reference/make_data_single.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate full dataset — make_data_single","text":"data.frame simulated data.","code":""},{"path":"/reference/make_data_single.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate full dataset — make_data_single","text":"","code":"model <- make_model(\"X -> Y\")  # Simplest behavior uses by default the parameter vector contained in model CausalQueries:::make_data_single(model, n = 5) #>   X Y #> 1 0 0 #> 2 0 0 #> 3 0 1 #> 4 1 0 #> 5 1 1  CausalQueries:::make_data_single(model, n = 5, param_type = \"prior_draw\") #>   X Y #> 1 0 0 #> 2 0 0 #> 3 1 0 #> 4 1 1 #> 5 1 1  # Simulate multiple datasets. This is fastest if # event probabilities (w) are  provided w <- get_event_probabilities(model) replicate(5, CausalQueries:::make_data_single(model, n = 5, w = w)) #>   [,1]      [,2]      [,3]      [,4]      [,5]      #> X numeric,5 numeric,5 numeric,5 numeric,5 numeric,5 #> Y numeric,5 numeric,5 numeric,5 numeric,5 numeric,5"},{"path":"/reference/make_events.html","id":null,"dir":"Reference","previous_headings":"","what":"Make data in compact form — make_events","title":"Make data in compact form — make_events","text":"Draw n events given event probabilities. Draws full data . incomplete data see make_data.","code":""},{"path":"/reference/make_events.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make data in compact form — make_events","text":"","code":"make_events(   model,   n = 1,   w = NULL,   P = NULL,   A = NULL,   parameters = NULL,   param_type = NULL,   include_strategy = FALSE,   ... )"},{"path":"/reference/make_events.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make data in compact form — make_events","text":"model causal_model. model object generated make_model. n integer. Number observations. w numeric matrix. `n_parameters x 1` matrix event probabilities named rows. P data.frame. Parameter matrix. required may provided avoid repeated computation simulations. data.frame. Ambiguity matrix. required may provided avoid repeated computation simulations. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn model$parameters_df. param_type character. String specifying type parameters make 'flat', 'prior_mean', 'posterior_mean', 'prior_draw', 'posterior_draw', 'define. param_type set define use arguments passed make_priors; otherwise flat sets equal probabilities nodal type parameter set; prior_mean, prior_draw, posterior_mean, posterior_draw take parameters means draws prior posterior. include_strategy Logical. Whether include 'strategy' vector. Defaults FALSE. Strategy vector vary full data expected functions. ... Arguments passed make_priors param_type == define","code":""},{"path":"/reference/make_events.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make data in compact form — make_events","text":"data.frame events","code":""},{"path":"/reference/make_events.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make data in compact form — make_events","text":"","code":"# \\donttest{ model <- make_model('X -> Y') make_events(model = model) #>   event count #> 1  X0Y0     0 #> 2  X1Y0     1 #> 3  X0Y1     0 #> 4  X1Y1     0 make_events(model = model, param_type = 'prior_draw') #>   event count #> 1  X0Y0     0 #> 2  X1Y0     0 #> 3  X0Y1     0 #> 4  X1Y1     1 make_events(model = model, include_strategy = TRUE) #>   event strategy count #> 1  X0Y0       XY     0 #> 2  X1Y0       XY     0 #> 3  X0Y1       XY     1 #> 4  X1Y1       XY     0 # }"},{"path":"/reference/make_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a model — make_model","title":"Make a model — make_model","text":"make_model uses dagitty syntax functionality specify nodes edges graph. Implied causal types calculated default priors provided assumption confounding. Models can updated specification parameter matrix, P, providing restrictions causal types, /providing informative priors parameters. default setting causal model flat (uniform) priors parameters putting equal weight parameter within parameter set. can adjust set_priors set_parameters","code":""},{"path":"/reference/make_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a model — make_model","text":"","code":"make_model(statement, add_causal_types = TRUE, nodal_types = NULL)"},{"path":"/reference/make_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make a model — make_model","text":"statement character. Statement describing causal relations using dagitty syntax. directed relations permitted. instance \"X -> Y\"  \"X1 -> Y <- X2; X1 -> X2\". add_causal_types Logical. Whether create attach causal types model. Defaults `TRUE`. nodal_types List nodal types associated model nodes","code":""},{"path":"/reference/make_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make a model — make_model","text":"object class causal_model. object class \"causal_model\" list containing least following components: statement character vector statement defines model dag data.frame columns `parent``children`   indicating nodes relate . nodes named list nodes model parents_df data.frame listing nodes, whether   root nodes , number parents nodal_types Optional: named list nodal types   model. List ordered according causal ordering   nodes. NULL nodal types generated. FALSE, parameters data   frame generated. parameters_df data.frame descriptive information   parameters model causal_types data.frame listing causal types   nodal types produce ","code":""},{"path":[]},{"path":"/reference/make_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make a model — make_model","text":"","code":"make_model(statement = \"X -> Y\") #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>  modelXKY <- make_model(\"X -> K -> Y; X -> Y\")  # Example where cyclicaly dag attempted if (FALSE) {  modelXKX <- make_model(\"X -> K -> X\") }  # Examples with confounding model <- make_model(\"X->Y; X <-> Y\") model$P #>  #> Rows are parameters, grouped in parameter sets #>  #> Columns are causal types #>  #> Cell entries indicate whether a parameter probability isused #> in the calculation of causal type probability #>  #>          X0.Y00 X1.Y00 X0.Y10 X1.Y10 X0.Y01 X1.Y01 X0.Y11 X1.Y11 #> X.0           1      0      1      0      1      0      1      0 #> X.1           0      1      0      1      0      1      0      1 #> Y.00_X.0      1      0      0      0      0      0      0      0 #> Y.10_X.0      0      0      1      0      0      0      0      0 #> Y.01_X.0      0      0      0      0      1      0      0      0 #> Y.11_X.0      0      0      0      0      0      0      1      0 #> Y.00_X.1      0      1      0      0      0      0      0      0 #> Y.10_X.1      0      0      0      1      0      0      0      0 #> Y.01_X.1      0      0      0      0      0      1      0      0 #> Y.11_X.1      0      0      0      0      0      0      0      1 #>  #>   #>  param_set  (P) #>  X  Y.X.0  Y.X.1 model <- make_model(\"Y2 <- X -> Y1; X <-> Y1; X <-> Y2\") dim(model$P) #> [1] 18 32 model$P #>  #> Rows are parameters, grouped in parameter sets #>  #> Columns are causal types #>  #> Cell entries indicate whether a parameter probability isused #> in the calculation of causal type probability #>  #>           X0.Y100.Y200 X1.Y100.Y200 X0.Y110.Y200 X1.Y110.Y200 X0.Y101.Y200 #> X.0                  1            0            1            0            1 #> X.1                  0            1            0            1            0 #> Y1.00_X.0            1            0            0            0            0 #> Y1.10_X.0            0            0            1            0            0 #> Y1.01_X.0            0            0            0            0            1 #> Y1.11_X.0            0            0            0            0            0 #> Y1.00_X.1            0            1            0            0            0 #> Y1.10_X.1            0            0            0            1            0 #> Y1.01_X.1            0            0            0            0            0 #> Y1.11_X.1            0            0            0            0            0 #> Y2.00_X.0            1            0            1            0            1 #> Y2.10_X.0            0            0            0            0            0 #> Y2.01_X.0            0            0            0            0            0 #> Y2.11_X.0            0            0            0            0            0 #> Y2.00_X.1            0            1            0            1            0 #> Y2.10_X.1            0            0            0            0            0 #> Y2.01_X.1            0            0            0            0            0 #> Y2.11_X.1            0            0            0            0            0 #>           X1.Y101.Y200 X0.Y111.Y200 X1.Y111.Y200 X0.Y100.Y210 X1.Y100.Y210 #> X.0                  0            1            0            1            0 #> X.1                  1            0            1            0            1 #> Y1.00_X.0            0            0            0            1            0 #> Y1.10_X.0            0            0            0            0            0 #> Y1.01_X.0            0            0            0            0            0 #> Y1.11_X.0            0            1            0            0            0 #> Y1.00_X.1            0            0            0            0            1 #> Y1.10_X.1            0            0            0            0            0 #> Y1.01_X.1            1            0            0            0            0 #> Y1.11_X.1            0            0            1            0            0 #> Y2.00_X.0            0            1            0            0            0 #> Y2.10_X.0            0            0            0            1            0 #> Y2.01_X.0            0            0            0            0            0 #> Y2.11_X.0            0            0            0            0            0 #> Y2.00_X.1            1            0            1            0            0 #> Y2.10_X.1            0            0            0            0            1 #> Y2.01_X.1            0            0            0            0            0 #> Y2.11_X.1            0            0            0            0            0 #>           X0.Y110.Y210 X1.Y110.Y210 X0.Y101.Y210 X1.Y101.Y210 X0.Y111.Y210 #> X.0                  1            0            1            0            1 #> X.1                  0            1            0            1            0 #> Y1.00_X.0            0            0            0            0            0 #> Y1.10_X.0            1            0            0            0            0 #> Y1.01_X.0            0            0            1            0            0 #> Y1.11_X.0            0            0            0            0            1 #> Y1.00_X.1            0            0            0            0            0 #> Y1.10_X.1            0            1            0            0            0 #> Y1.01_X.1            0            0            0            1            0 #> Y1.11_X.1            0            0            0            0            0 #> Y2.00_X.0            0            0            0            0            0 #> Y2.10_X.0            1            0            1            0            1 #> Y2.01_X.0            0            0            0            0            0 #> Y2.11_X.0            0            0            0            0            0 #> Y2.00_X.1            0            0            0            0            0 #> Y2.10_X.1            0            1            0            1            0 #> Y2.01_X.1            0            0            0            0            0 #> Y2.11_X.1            0            0            0            0            0 #>           X1.Y111.Y210 X0.Y100.Y201 X1.Y100.Y201 X0.Y110.Y201 X1.Y110.Y201 #> X.0                  0            1            0            1            0 #> X.1                  1            0            1            0            1 #> Y1.00_X.0            0            1            0            0            0 #> Y1.10_X.0            0            0            0            1            0 #> Y1.01_X.0            0            0            0            0            0 #> Y1.11_X.0            0            0            0            0            0 #> Y1.00_X.1            0            0            1            0            0 #> Y1.10_X.1            0            0            0            0            1 #> Y1.01_X.1            0            0            0            0            0 #> Y1.11_X.1            1            0            0            0            0 #> Y2.00_X.0            0            0            0            0            0 #> Y2.10_X.0            0            0            0            0            0 #> Y2.01_X.0            0            1            0            1            0 #> Y2.11_X.0            0            0            0            0            0 #> Y2.00_X.1            0            0            0            0            0 #> Y2.10_X.1            1            0            0            0            0 #> Y2.01_X.1            0            0            1            0            1 #> Y2.11_X.1            0            0            0            0            0 #>           X0.Y101.Y201 X1.Y101.Y201 X0.Y111.Y201 X1.Y111.Y201 X0.Y100.Y211 #> X.0                  1            0            1            0            1 #> X.1                  0            1            0            1            0 #> Y1.00_X.0            0            0            0            0            1 #> Y1.10_X.0            0            0            0            0            0 #> Y1.01_X.0            1            0            0            0            0 #> Y1.11_X.0            0            0            1            0            0 #> Y1.00_X.1            0            0            0            0            0 #> Y1.10_X.1            0            0            0            0            0 #> Y1.01_X.1            0            1            0            0            0 #> Y1.11_X.1            0            0            0            1            0 #> Y2.00_X.0            0            0            0            0            0 #> Y2.10_X.0            0            0            0            0            0 #> Y2.01_X.0            1            0            1            0            0 #> Y2.11_X.0            0            0            0            0            1 #> Y2.00_X.1            0            0            0            0            0 #> Y2.10_X.1            0            0            0            0            0 #> Y2.01_X.1            0            1            0            1            0 #> Y2.11_X.1            0            0            0            0            0 #>           X1.Y100.Y211 X0.Y110.Y211 X1.Y110.Y211 X0.Y101.Y211 X1.Y101.Y211 #> X.0                  0            1            0            1            0 #> X.1                  1            0            1            0            1 #> Y1.00_X.0            0            0            0            0            0 #> Y1.10_X.0            0            1            0            0            0 #> Y1.01_X.0            0            0            0            1            0 #> Y1.11_X.0            0            0            0            0            0 #> Y1.00_X.1            1            0            0            0            0 #> Y1.10_X.1            0            0            1            0            0 #> Y1.01_X.1            0            0            0            0            1 #> Y1.11_X.1            0            0            0            0            0 #> Y2.00_X.0            0            0            0            0            0 #> Y2.10_X.0            0            0            0            0            0 #> Y2.01_X.0            0            0            0            0            0 #> Y2.11_X.0            0            1            0            1            0 #> Y2.00_X.1            0            0            0            0            0 #> Y2.10_X.1            0            0            0            0            0 #> Y2.01_X.1            0            0            0            0            0 #> Y2.11_X.1            1            0            1            0            1 #>           X0.Y111.Y211 X1.Y111.Y211 #> X.0                  1            0 #> X.1                  0            1 #> Y1.00_X.0            0            0 #> Y1.10_X.0            0            0 #> Y1.01_X.0            0            0 #> Y1.11_X.0            1            0 #> Y1.00_X.1            0            0 #> Y1.10_X.1            0            0 #> Y1.01_X.1            0            0 #> Y1.11_X.1            0            1 #> Y2.00_X.0            0            0 #> Y2.10_X.0            0            0 #> Y2.01_X.0            0            0 #> Y2.11_X.0            1            0 #> Y2.00_X.1            0            0 #> Y2.10_X.1            0            0 #> Y2.01_X.1            0            0 #> Y2.11_X.1            0            1 #>  #>   #>  param_set  (P) #>  X  Y1.X.0  Y1.X.1  Y2.X.0  Y2.X.1 model <- make_model(\"X1 -> Y <- X2; X1 <-> Y; X2 <-> Y\") dim(model$P) #> [1] 68 64 model$parameters_df #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>  #>  first 10 rows:  #>         param_names node gen   param_set nodal_type      given param_value #> 1              X1.0   X1   1          X1          0                 0.5000 #> 2              X1.1   X1   1          X1          1                 0.5000 #> 3              X2.0   X2   2          X2          0                 0.5000 #> 4              X2.1   X2   2          X2          1                 0.5000 #> 5  Y.0000_X1.0_X2.0    Y   3 Y.X1.0.X2.0       0000 X1.0, X2.0      0.0625 #> 6  Y.1000_X1.0_X2.0    Y   3 Y.X1.0.X2.0       1000 X1.0, X2.0      0.0625 #> 7  Y.0100_X1.0_X2.0    Y   3 Y.X1.0.X2.0       0100 X1.0, X2.0      0.0625 #> 8  Y.1100_X1.0_X2.0    Y   3 Y.X1.0.X2.0       1100 X1.0, X2.0      0.0625 #> 9  Y.0010_X1.0_X2.0    Y   3 Y.X1.0.X2.0       0010 X1.0, X2.0      0.0625 #> 10 Y.1010_X1.0_X2.0    Y   3 Y.X1.0.X2.0       1010 X1.0, X2.0      0.0625 #>    priors #> 1       1 #> 2       1 #> 3       1 #> 4       1 #> 5       1 #> 6       1 #> 7       1 #> 8       1 #> 9       1 #> 10      1  # A single node graph is also possible model <- make_model(\"X\")  # Unconnected nodes not allowed if (FALSE) {  model <- make_model(\"X <-> Y\") }  nodal_types <-   list(     A = c(\"0\",\"1\"),     B = c(\"0\",\"1\"),     C = c(\"0\",\"1\"),     D = c(\"0\",\"1\"),     E = c(\"0\",\"1\"),     Y = c(       \"00000000000000000000000000000000\",       \"01010101010101010101010101010101\",       \"00110011001100110011001100110011\",       \"00001111000011110000111100001111\",       \"00000000111111110000000011111111\",       \"00000000000000001111111111111111\",       \"11111111111111111111111111111111\" ))  make_model(\"A -> Y; B ->Y; C->Y; D->Y; E->Y\",           nodal_types = nodal_types)$parameters_df #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>  #>  first 10 rows:  #>    param_names node gen param_set nodal_type given param_value priors #> 1          A.0    A   1         A          0               0.5      1 #> 2          A.1    A   1         A          1               0.5      1 #> 3          B.0    B   2         B          0               0.5      1 #> 4          B.1    B   2         B          1               0.5      1 #> 5          C.0    C   3         C          0               0.5      1 #> 6          C.1    C   3         C          1               0.5      1 #> 7          D.0    D   4         D          0               0.5      1 #> 8          D.1    D   4         D          1               0.5      1 #> 9          E.0    E   5         E          0               0.5      1 #> 10         E.1    E   5         E          1               0.5      1  nodal_types = list(Y = c(\"01\", \"10\"), Z = c(\"0\", \"1\")) make_model(\"Z -> Y\", nodal_types = nodal_types)$parameters_df #> Ordering of provided nodal types is being altered to match generation #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>   param_names node gen param_set nodal_type given param_value priors #> 1         Z.0    Z   1         Z          0               0.5      1 #> 2         Z.1    Z   1         Z          1               0.5      1 #> 3        Y.01    Y   2         Y         01               0.5      1 #> 4        Y.10    Y   2         Y         10               0.5      1 make_model(\"Z -> Y\", nodal_types = FALSE)$parents_df #> Model not properly defined: nodal_types should be NULL or specified for all nodes in model:  Z, Y #>   node  root parents parent_nodes #> 1    Z  TRUE       0              #> 2    Y FALSE       1            Z"},{"path":"/reference/make_nodal_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Make nodal types — make_nodal_types","title":"Make nodal types — make_nodal_types","text":"Make nodal types","code":""},{"path":"/reference/make_nodal_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make nodal types — make_nodal_types","text":"","code":"make_nodal_types(model, include_node_names = FALSE)"},{"path":"/reference/make_nodal_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make nodal types — make_nodal_types","text":"model causal_model. model object generated make_model. include_node_names Logical. `TRUE` returns names form X0, X1; otherwise returns 0, 1. Defaults `FALSE`","code":""},{"path":"/reference/make_nodal_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make nodal types — make_nodal_types","text":"named list containing nodal types node","code":""},{"path":"/reference/make_nodal_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make nodal types — make_nodal_types","text":"","code":"# \\donttest{ model <- make_model('X -> K -> Y') CausalQueries:::make_nodal_types(model) #> Nodal types:  #> $X #> 0:1 #>  #> NULL #>  #> $K #> c(0, 1, 0, 1)  c(0, 0, 1, 1) #>  #> NULL #>  #> $Y #> c(0, 1, 0, 1)  c(0, 0, 1, 1) #>  #> NULL #>  #>  #> Number of types by node #> X K Y  #> 1 2 2  # }"},{"path":"/reference/make_parameters_df.html","id":null,"dir":"Reference","previous_headings":"","what":"function to make a parameters_df from nodal types — make_parameters_df","title":"function to make a parameters_df from nodal types — make_parameters_df","text":"function make parameters_df nodal types","code":""},{"path":"/reference/make_parameters_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"function to make a parameters_df from nodal types — make_parameters_df","text":"","code":"make_parameters_df(nodal_types)"},{"path":"/reference/make_parameters_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"function to make a parameters_df from nodal types — make_parameters_df","text":"nodal_types list nodal types","code":""},{"path":"/reference/make_parameters_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"function to make a parameters_df from nodal types — make_parameters_df","text":"","code":"make_parameters_df(list(X = \"1\", Y = c(\"01\", \"10\"))) #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>   param_names node gen param_set nodal_type given param_value priors #> 1         X.1    X   1         X          1               1.0      1 #> 2        Y.01    Y   2         Y         01               0.5      1 #> 3        Y.10    Y   2         Y         10               0.5      1"},{"path":"/reference/make_parameter_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Make parameter matrix — make_parameter_matrix","title":"Make parameter matrix — make_parameter_matrix","text":"Calculate parameter matrix assuming confounding. parameter matrix maps parameters causal types. models without confounding parameters correspond nodal types.","code":""},{"path":"/reference/make_parameter_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make parameter matrix — make_parameter_matrix","text":"","code":"make_parameter_matrix(model)"},{"path":"/reference/make_parameter_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make parameter matrix — make_parameter_matrix","text":"model causal_model. model object generated make_model.","code":""},{"path":"/reference/make_parameter_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make parameter matrix — make_parameter_matrix","text":"data.frame, parameter matrix, mapping parameters   causal types","code":""},{"path":"/reference/make_parameter_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make parameter matrix — make_parameter_matrix","text":"","code":"model <- make_model('X -> Y') make_parameter_matrix(model) #> Error in make_parameter_matrix(model): could not find function \"make_parameter_matrix\""},{"path":"/reference/make_parmap.html","id":null,"dir":"Reference","previous_headings":"","what":"Make parmap: a matrix mapping from parameters to data types — make_parmap","title":"Make parmap: a matrix mapping from parameters to data types — make_parmap","text":"Generates matrix row per parameter column per data type.","code":""},{"path":"/reference/make_parmap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make parmap: a matrix mapping from parameters to data types — make_parmap","text":"","code":"make_parmap(model, A = NULL, P = NULL)"},{"path":"/reference/make_parmap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make parmap: a matrix mapping from parameters to data types — make_parmap","text":"model causal_model. model object generated make_model. data.frame. Ambiguity matrix. required may provided avoid repeated computation simulations. P data.frame. Parameter matrix. required may provided avoid repeated computation simulations.","code":""},{"path":"/reference/make_parmap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make parmap: a matrix mapping from parameters to data types — make_parmap","text":"matrix","code":""},{"path":"/reference/make_parmap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make parmap: a matrix mapping from parameters to data types — make_parmap","text":"","code":"make_parmap(model = make_model('X->Y')) #> Error in make_parmap(model = make_model(\"X->Y\")): could not find function \"make_parmap\" make_parmap(model = make_model('X->Y; X<->Y')) #> Error in make_parmap(model = make_model(\"X->Y; X<->Y\")): could not find function \"make_parmap\" make_parmap(model = make_model('X->Y; X<->Y')) |> attr(\"map\") #> Error in make_parmap(model = make_model(\"X->Y; X<->Y\")): could not find function \"make_parmap\" make_parmap(model = make_model('X -> M -> Y; X <-> Y')) #> Error in make_parmap(model = make_model(\"X -> M -> Y; X <-> Y\")): could not find function \"make_parmap\" make_parmap(model = make_model('X -> M -> Y; M <-> Y')) #> Error in make_parmap(model = make_model(\"X -> M -> Y; M <-> Y\")): could not find function \"make_parmap\" model <- make_model('X -> M -> Y; M <-> Y; X <-> M') make_parmap(model) #> Error in make_parmap(model): could not find function \"make_parmap\" make_parmap(model) |> attr(\"map\") #> Error in make_parmap(model): could not find function \"make_parmap\" # Any ways (without paths splits) make_parmap(model) %*% (make_parmap(model) |> attr(\"map\")) #> Error in make_parmap(model): could not find function \"make_parmap\"  if (FALSE) { # X1 and X2 are confounded and jointly determine Y1, Y2. # For instance for models in which X and Y take on four values rather than 2. model <- make_model(\"Y2 <- X1 -> Y1; Y2 <- X2 ->Y1; X1 <-> X2; Y1 <-> Y2\") parmap <- make_parmap(model) parmap |> dim()  CausalQueries:::prep_stan_data(   model,   CausalQueries:::minimal_event_data(model))$n_params }"},{"path":"/reference/make_par_values.html","id":null,"dir":"Reference","previous_headings":"","what":"make_par_values — make_par_values","title":"make_par_values — make_par_values","text":"one step function make_priors make_parameters. See make_priors help.","code":""},{"path":"/reference/make_par_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_par_values — make_par_values","text":"","code":"make_par_values(   model,   alter = \"priors\",   x = NA,   alter_at = NA,   node = NA,   label = NA,   nodal_type = NA,   param_set = NA,   given = NA,   statement = NA,   join_by = \"|\",   param_names = NA,   distribution = NA,   normalize = FALSE )"},{"path":"/reference/make_par_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_par_values — make_par_values","text":"model model created make_model alter character vector one \"priors\" \"param_value\" specifying alter x vector real non negative values substituted \"priors\" \"param_value\" alter_at string specifying filtering operations applied parameters_df, yielding logical vector indicating parameters values altered. (see examples) node string indicating nodes altered label string. Label nodal type indicating nodal types values altered. Equivalent nodal_type. nodal_type string. Label nodal type indicating nodal types values altered param_set string indicating  name set parameters altered given string indicates node parameter altered depends statement causal query determines nodal types values altered join_by string specifying logical operator joining expanded types statement contains wildcards. Can take values '&' (logical ) '|' (logical ). param_names vector strings. name specific parameter form , example, 'X.1', 'Y.01' distribution string indicating common prior distribution (uniform, jeffreys certainty) normalize logical. TRUE normalizes param set probabilities sum 1.","code":""},{"path":"/reference/make_par_values.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"make_par_values — make_par_values","text":"","code":"# the below methods can be applied to either priors or # param_values by specifying the desired option in \\code{alter}  model <- CausalQueries::make_model(\"X -> M -> Y; X <-> Y\")  #altering values using \\code{alter_at} CausalQueries:::make_par_values(model = model,                                 x = c(0.5,0.25),                                 alter_at = paste(                                   \"node == 'Y' &\",                                   \"nodal_type %in% c('00','01') &\",                                   \"given == 'X.0'\")) #> Warning: You are altering parameters on confounded nodes. Alterations will be applied across all 'param_sets'. If this is not the alteration behavior you intended, try specifying the 'param_set' or 'given' option to more clearly indicate parameters whose values you wish to alter. #>  [1] 1.00 1.00 1.00 1.00 1.00 1.00 0.50 1.00 0.25 1.00 1.00 1.00 1.00 1.00  #altering values using \\code{param_names} CausalQueries:::make_par_values(model = model,                                 x = c(0.5,0.25),                                 param_names = c(\"Y.10_X.0\",\"Y.10_X.1\")) #> Warning: You are altering parameters on confounded nodes. Alterations will be applied across all 'param_sets'. If this is not the alteration behavior you intended, try specifying the 'param_set' or 'given' option to more clearly indicate parameters whose values you wish to alter. #>  [1] 1.00 1.00 1.00 1.00 1.00 1.00 1.00 0.50 1.00 1.00 1.00 0.25 1.00 1.00  #altering values using \\code{statement} CausalQueries:::make_par_values(model = model,                                 x = c(0.5,0.25),                                 statement = \"Y[M=1] > Y[M=0]\") #> Warning: A specified condition matches multiple parameters. In these cases it is unclear which parameter value should be assigned to which parameter. Assignment thus defaults to the order in which parameters appear in 'parameters_df'. We advise checking that parameter assignment was carried out as you intended.  #> Warning: You are altering parameters on confounded nodes. Alterations will be applied across all 'param_sets'. If this is not the alteration behavior you intended, try specifying the 'param_set' or 'given' option to more clearly indicate parameters whose values you wish to alter. #>  [1] 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 0.50 1.00 1.00 1.00 0.25 1.00  #altering values using a combination of other arguments CausalQueries:::make_par_values(model = model, x = c(0.5,0.25), node = \"Y\", nodal_type = c(\"00\",\"01\"), given = \"X.0\") #>  [1] 1.00 1.00 1.00 1.00 1.00 1.00 0.50 1.00 0.25 1.00 1.00 1.00 1.00 1.00"},{"path":"/reference/make_par_values_stops.html","id":null,"dir":"Reference","previous_headings":"","what":"make_par_values_stops — make_par_values_stops","title":"make_par_values_stops — make_par_values_stops","text":"helper remove stops reduce complexity make_par_values","code":""},{"path":"/reference/make_par_values_stops.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_par_values_stops — make_par_values_stops","text":"","code":"make_par_values_stops(   model,   alter = \"priors\",   x = NA,   alter_at = NA,   node = NA,   label = NA,   nodal_type = NA,   param_set = NA,   given = NA,   statement = NA,   join_by = \"|\",   param_names = NA,   distribution = NA,   normalize = FALSE )"},{"path":"/reference/make_par_values_stops.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_par_values_stops — make_par_values_stops","text":"model model created make_model alter character vector one \"priors\" \"param_value\" specifying alter x vector real non negative values substituted \"priors\" \"param_value\" alter_at string specifying filtering operations applied parameters_df, yielding logical vector indicating parameters values altered. (see examples) node string indicating nodes altered label string. Label nodal type indicating nodal types values altered. Equivalent nodal_type. nodal_type string. Label nodal type indicating nodal types values altered param_set string indicating  name set parameters altered given string indicates node parameter altered depends statement causal query determines nodal types values altered join_by string specifying logical operator joining expanded types statement contains wildcards. Can take values '&' (logical ) '|' (logical ). param_names vector strings. name specific parameter form , example, 'X.1', 'Y.01' distribution string indicating common prior distribution (uniform, jeffreys certainty) normalize logical. TRUE normalizes param set probabilities sum 1.","code":""},{"path":"/reference/make_prior_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a prior distribution from priors — make_prior_distribution","title":"Make a prior distribution from priors — make_prior_distribution","text":"Create `n_param`x `n_draws` database possible lambda draws attached model.","code":""},{"path":"/reference/make_prior_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a prior distribution from priors — make_prior_distribution","text":"","code":"make_prior_distribution(model, n_draws = 4000)"},{"path":"/reference/make_prior_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make a prior distribution from priors — make_prior_distribution","text":"model causal_model. model object generated make_model. n_draws scalar. Number draws.","code":""},{"path":"/reference/make_prior_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make a prior distribution from priors — make_prior_distribution","text":"`data.frame` dimension `n_param`x `n_draws` possible   lambda draws","code":""},{"path":[]},{"path":"/reference/make_prior_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make a prior distribution from priors — make_prior_distribution","text":"","code":"make_model('X -> Y') %>% make_prior_distribution(n_draws = 5) #> Summary statistics of model parameter prior distributions: #> Dimensions: 5 rows (draws) by 6 cols (parameters)  #>  #> Summary:  #>  #>      mean   sd #> X.0  0.46 0.24 #> X.1  0.54 0.24 #> Y.00 0.21 0.13 #> Y.10 0.23 0.23 #> Y.01 0.27 0.20 #> Y.11 0.30 0.16"},{"path":"/reference/minimal_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a data frame for case with no data — minimal_data","title":"Creates a data frame for case with no data — minimal_data","text":"Creates data frame case data","code":""},{"path":"/reference/minimal_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a data frame for case with no data — minimal_data","text":"","code":"minimal_data(model)"},{"path":"/reference/minimal_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a data frame for case with no data — minimal_data","text":"model causal_model. model object generated make_model.","code":""},{"path":"/reference/minimal_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a data frame for case with no data — minimal_data","text":"data.frame one row NAs columns named according   nodes model.","code":""},{"path":"/reference/minimal_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a data frame for case with no data — minimal_data","text":"","code":"# \\donttest{ model <- make_model('X -> K -> Y') CausalQueries:::minimal_data(model) #>    X  K  Y #> 1 NA NA NA # }"},{"path":"/reference/minimal_event_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a compact data frame for case with no data — minimal_event_data","title":"Creates a compact data frame for case with no data — minimal_event_data","text":"Creates compact data frame case data","code":""},{"path":"/reference/minimal_event_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a compact data frame for case with no data — minimal_event_data","text":"","code":"minimal_event_data(model)"},{"path":"/reference/minimal_event_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a compact data frame for case with no data — minimal_event_data","text":"model causal_model. model object generated make_model.","code":""},{"path":"/reference/minimal_event_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a compact data frame for case with no data — minimal_event_data","text":"compact data frame row represents element   exhaustive set events model. count event   set zero.","code":""},{"path":"/reference/minimal_event_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a compact data frame for case with no data — minimal_event_data","text":"","code":"# \\donttest{ model <- make_model('X -> K -> Y') CausalQueries:::minimal_event_data(model) #>    event strategy count #> 1 X0K0Y0      XKY     0 #> 2 X1K0Y0      XKY     0 #> 3 X0K1Y0      XKY     0 #> 4 X1K1Y0      XKY     0 #> 5 X0K0Y1      XKY     0 #> 6 X1K0Y1      XKY     0 #> 7 X0K1Y1      XKY     0 #> 8 X1K1Y1      XKY     0 # }"},{"path":"/reference/nodes_in_statement.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify nodes in a statement — nodes_in_statement","title":"Identify nodes in a statement — nodes_in_statement","text":"Identify nodes statement","code":""},{"path":"/reference/nodes_in_statement.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify nodes in a statement — nodes_in_statement","text":"","code":"nodes_in_statement(nodes, statement)"},{"path":"/reference/nodes_in_statement.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify nodes in a statement — nodes_in_statement","text":"nodes vector characters. contain quoted names nodes model statement character. quoted causal statement.","code":""},{"path":"/reference/nodes_in_statement.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify nodes in a statement — nodes_in_statement","text":"Returns name nodes present statement","code":""},{"path":"/reference/non_decreasing.html","id":null,"dir":"Reference","previous_headings":"","what":"Make monotonicity statement (non negative) — non_decreasing","title":"Make monotonicity statement (non negative) — non_decreasing","text":"Generate statement Y weakly monotonic (increasing) X","code":""},{"path":"/reference/non_decreasing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make monotonicity statement (non negative) — non_decreasing","text":"","code":"non_decreasing(X, Y)"},{"path":"/reference/non_decreasing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make monotonicity statement (non negative) — non_decreasing","text":"X character. quoted name input node Y character. quoted name outcome node","code":""},{"path":"/reference/non_decreasing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make monotonicity statement (non negative) — non_decreasing","text":"character statement class statement","code":""},{"path":[]},{"path":"/reference/non_decreasing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make monotonicity statement (non negative) — non_decreasing","text":"","code":"# \\donttest{ non_decreasing('A', 'B') #>  #> Statement:  #> (B[A=1] >= B[A=0]) # }"},{"path":"/reference/non_increasing.html","id":null,"dir":"Reference","previous_headings":"","what":"Make monotonicity statement (non positive) — non_increasing","title":"Make monotonicity statement (non positive) — non_increasing","text":"Generate statement Y weakly monotonic (increasing) X","code":""},{"path":"/reference/non_increasing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make monotonicity statement (non positive) — non_increasing","text":"","code":"non_increasing(X, Y)"},{"path":"/reference/non_increasing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make monotonicity statement (non positive) — non_increasing","text":"X character. quoted name input node Y character. quoted name outcome node","code":""},{"path":"/reference/non_increasing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make monotonicity statement (non positive) — non_increasing","text":"character statement class statement","code":""},{"path":[]},{"path":"/reference/non_increasing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make monotonicity statement (non positive) — non_increasing","text":"","code":"# \\donttest{ non_increasing('A', 'B') #>  #> Statement:  #> (B[A=1] <= B[A=0]) # }"},{"path":"/reference/n_check.html","id":null,"dir":"Reference","previous_headings":"","what":"n_check — n_check","title":"n_check — n_check","text":"n_check","code":""},{"path":"/reference/n_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"n_check — n_check","text":"","code":"n_check(n)"},{"path":"/reference/n_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"n_check — n_check","text":"n integer. Sample size argument.","code":""},{"path":"/reference/n_check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"n_check — n_check","text":"error message n integer less 0.","code":""},{"path":"/reference/n_check.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"n_check — n_check","text":"Checks whether input integer greater 0.","code":""},{"path":"/reference/observe_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Observe data, given a strategy — observe_data","title":"Observe data, given a strategy — observe_data","text":"Observe data, given strategy","code":""},{"path":"/reference/observe_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Observe data, given a strategy — observe_data","text":"","code":"observe_data(   complete_data,   observed = NULL,   nodes_to_observe = NULL,   prob = 1,   m = NULL,   subset = TRUE )"},{"path":"/reference/observe_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Observe data, given a strategy — observe_data","text":"complete_data data.frame. Data observed unobserved. observed data.frame. Data observed. nodes_to_observe list. Nodes observe. prob scalar. Observation probability. m integer. Number units observe; specified, m overrides prob. subset character.  Logical statement can applied rows complete data. instance observation nodes might depend observed values nodes; observation may sought data already observed!","code":""},{"path":"/reference/observe_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Observe data, given a strategy — observe_data","text":"data.frame logical values indicating nodes   observe row `complete_data`.","code":""},{"path":"/reference/observe_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Observe data, given a strategy — observe_data","text":"","code":"model <- make_model(\"X -> Y\") df <- make_data(model, n = 8) # Observe X values only observe_data(complete_data = df, nodes_to_observe = \"X\") #>      X     Y #> 1 TRUE FALSE #> 2 TRUE FALSE #> 3 TRUE FALSE #> 4 TRUE FALSE #> 5 TRUE FALSE #> 6 TRUE FALSE #> 7 TRUE FALSE #> 8 TRUE FALSE # Observe half the Y values for cases with observed X = 1 observe_data(complete_data = df,      observed = observe_data(complete_data = df, nodes_to_observe = \"X\"),      nodes_to_observe = \"Y\", prob = .5,      subset = \"X==1\") #>      X     Y #> 1 TRUE FALSE #> 2 TRUE FALSE #> 3 TRUE FALSE #> 4 TRUE FALSE #> 5 TRUE FALSE #> 6 TRUE FALSE #> 7 TRUE  TRUE #> 8 TRUE  TRUE"},{"path":"/reference/parameter_setting.html","id":null,"dir":"Reference","previous_headings":"","what":"Setting parameters — parameter_setting","title":"Setting parameters — parameter_setting","text":"Functionality altering parameters: vector 'true' parameters; possibly drawn prior posterior. Add true parameter vector model. Parameters can created using arguments passed make_parameters make_priors. Extracts parameters named vector","code":""},{"path":"/reference/parameter_setting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Setting parameters — parameter_setting","text":"","code":"make_parameters(   model,   parameters = NULL,   param_type = NULL,   warning = TRUE,   normalize = TRUE,   ... )  set_parameters(   model,   parameters = NULL,   param_type = NULL,   warning = FALSE,   ... )  get_parameters(model, param_type = NULL)"},{"path":"/reference/parameter_setting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Setting parameters — parameter_setting","text":"model causal_model. model object generated make_model. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn model$parameters_df. param_type character. String specifying type parameters make \"flat\", \"prior_mean\", \"posterior_mean\", \"prior_draw\", \"posterior_draw\", \"define\". param_type set define use arguments passed make_priors; otherwise flat sets equal probabilities nodal type parameter set; prior_mean, prior_draw, posterior_mean, posterior_draw take parameters means draws prior posterior. warning Logical. Whether warn parameter renormalization. normalize Logical. parameter given subset family residual elements normalized parameters param_set sum 1 provided params unaltered. ... Options passed onto make_priors.","code":""},{"path":"/reference/parameter_setting.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Setting parameters — parameter_setting","text":"vector draws prior distribution parameters object class causal_model. essentially returns   list containing elements comprising model   (e.g. 'statement', 'nodal_types' 'DAG') true vector   parameters attached . vector draws prior distribution parameters","code":""},{"path":"/reference/parameter_setting.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Setting parameters — parameter_setting","text":"","code":"# make_parameters examples:  # Simple examples model <- make_model('X -> Y') data  <- make_data(model, n = 2) model <- update_model(model, data) #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.1e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.176 seconds (Warm-up) #> Chain 1:                0.257 seconds (Sampling) #> Chain 1:                0.433 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 2.7e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.219 seconds (Warm-up) #> Chain 2:                0.2 seconds (Sampling) #> Chain 2:                0.419 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 4.5e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.45 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.233 seconds (Warm-up) #> Chain 3:                0.207 seconds (Sampling) #> Chain 3:                0.44 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 3.2e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.32 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.158 seconds (Warm-up) #> Chain 4:                0.169 seconds (Sampling) #> Chain 4:                0.327 seconds (Total) #> Chain 4:  make_parameters(model, parameters = c(.25, .75, 1.25,.25, .25, .25)) #> Model parameters with associated probabilities:  #>  #> X.0 X.1 Y.00 Y.10 Y.01 Y.11 #> 0.25 0.75 0.625 0.125 0.125 0.125 make_parameters(model, param_type = 'flat') #> No specific parameters to alter values for specified. Altering all parameters. #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #> 0.50 0.50 0.25 0.25 0.25 0.25  make_parameters(model, param_type = 'prior_draw') #>        X.0        X.1       Y.00       Y.10       Y.01       Y.11  #> 0.66831931 0.33168069 0.36621192 0.18754605 0.40954567 0.03669637  make_parameters(model, param_type = 'prior_mean') #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #> 0.50 0.50 0.25 0.25 0.25 0.25  make_parameters(model, param_type = 'posterior_draw') #>        X.0        X.1       Y.00       Y.10       Y.01       Y.11  #> 0.80563013 0.19436987 0.48015484 0.22781230 0.20157774 0.09045512  make_parameters(model, param_type = 'posterior_mean') #>       X.0       X.1      Y.00      Y.10      Y.01      Y.11  #> 0.4967758 0.5032242 0.3722884 0.2320339 0.2293647 0.1663129    # \\donttest{  #altering values using \\code{alter_at} make_model(\"X -> Y\") %>% make_parameters(parameters = c(0.5,0.25), alter_at = \"node == 'Y' & nodal_type %in% c('00','01')\") #>   X.0   X.1  Y.00  Y.10  Y.01  Y.11  #> 0.500 0.500 0.500 0.125 0.250 0.125   #altering values using \\code{param_names} make_model(\"X -> Y\") %>% make_parameters(parameters = c(0.5,0.25), param_names = c(\"Y.10\",\"Y.01\")) #>   X.0   X.1  Y.00  Y.10  Y.01  Y.11  #> 0.500 0.500 0.125 0.500 0.250 0.125   #altering values using \\code{statement} make_model(\"X -> Y\") %>% make_parameters(parameters = c(0.5), statement = \"Y[X=1] > Y[X=0]\") #>       X.0       X.1      Y.00      Y.10      Y.01      Y.11  #> 0.5000000 0.5000000 0.1666667 0.1666667 0.5000000 0.1666667   #altering values using a combination of other arguments make_model(\"X -> Y\") %>% make_parameters(parameters = c(0.5,0.25), node = \"Y\", nodal_type = c(\"00\",\"01\")) #>   X.0   X.1  Y.00  Y.10  Y.01  Y.11  #> 0.500 0.500 0.500 0.125 0.250 0.125   # Normalize renormalizes values not set so that value set is not renomalized make_parameters(make_model('X -> Y'),                statement = 'Y[X=1]>Y[X=0]', parameters = .5) #>       X.0       X.1      Y.00      Y.10      Y.01      Y.11  #> 0.5000000 0.5000000 0.1666667 0.1666667 0.5000000 0.1666667  make_parameters(make_model('X -> Y'),                statement = 'Y[X=1]>Y[X=0]', parameters = .5,                normalize = FALSE) #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #>  0.5  0.5  0.2  0.2  0.4  0.2     # }  # set_parameters examples:  make_model('X->Y') %>% set_parameters(1:6) %>% get_parameters() #> Error in get_parameters(.): could not find function \"get_parameters\"  # Simple examples model <- make_model('X -> Y') data  <- make_data(model, n = 2) model <- update_model(model, data) #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 1.8e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.135 seconds (Warm-up) #> Chain 1:                0.141 seconds (Sampling) #> Chain 1:                0.276 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 3.7e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.37 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.174 seconds (Warm-up) #> Chain 2:                0.185 seconds (Sampling) #> Chain 2:                0.359 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 2.9e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.29 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.264 seconds (Warm-up) #> Chain 3:                0.216 seconds (Sampling) #> Chain 3:                0.48 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 2.5e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.25 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.167 seconds (Warm-up) #> Chain 4:                0.12 seconds (Sampling) #> Chain 4:                0.287 seconds (Total) #> Chain 4:  set_parameters(model, parameters = c(.25, .75, 1.25,.25, .25, .25)) #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>  #>  #> Model has been updated and contains a posterior distribution with #> 4 chains, each with iter=2000; warmup=1000; thin=1;   #> Use grab(model, object = 'stan_summary') to inspect stan summary  #>  set_parameters(model, param_type = 'flat') #> No specific parameters to alter values for specified. Altering all parameters. #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>  #>  #> Model has been updated and contains a posterior distribution with #> 4 chains, each with iter=2000; warmup=1000; thin=1;   #> Use grab(model, object = 'stan_summary') to inspect stan summary  #>  set_parameters(model, param_type = 'prior_draw') #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>  #>  #> Model has been updated and contains a posterior distribution with #> 4 chains, each with iter=2000; warmup=1000; thin=1;   #> Use grab(model, object = 'stan_summary') to inspect stan summary  #>  set_parameters(model, param_type = 'prior_mean') #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>  #>  #> Model has been updated and contains a posterior distribution with #> 4 chains, each with iter=2000; warmup=1000; thin=1;   #> Use grab(model, object = 'stan_summary') to inspect stan summary  #>  set_parameters(model, param_type = 'posterior_draw') #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>  #>  #> Model has been updated and contains a posterior distribution with #> 4 chains, each with iter=2000; warmup=1000; thin=1;   #> Use grab(model, object = 'stan_summary') to inspect stan summary  #>  set_parameters(model, param_type = 'posterior_mean') #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>  #>  #> Model has been updated and contains a posterior distribution with #> 4 chains, each with iter=2000; warmup=1000; thin=1;   #> Use grab(model, object = 'stan_summary') to inspect stan summary  #>    # \\donttest{  #altering values using \\code{alter_at} make_model(\"X -> Y\") %>% set_parameters(parameters = c(0.5,0.25), alter_at = \"node == 'Y' & nodal_type %in% c('00','01')\") #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>   #altering values using \\code{param_names} make_model(\"X -> Y\") %>% set_parameters(parameters = c(0.5,0.25), param_names = c(\"Y.10\",\"Y.01\")) #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>   #altering values using \\code{statement} make_model(\"X -> Y\") %>% set_parameters(parameters = c(0.5), statement = \"Y[X=1] > Y[X=0]\") #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>   #altering values using a combination of other arguments make_model(\"X -> Y\") %>% set_parameters(parameters = c(0.5,0.25), node = \"Y\", nodal_type = c(\"00\",\"01\")) #>  #> Statement:  #> X -> Y #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>      # }  # get_parameters examples:  make_model('X -> Y') |> get_parameters() #> Error in get_parameters(make_model(\"X -> Y\")): could not find function \"get_parameters\""},{"path":"/reference/parents_to_int.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper to turn parents_list into a list of data_realizations column positions — parents_to_int","title":"Helper to turn parents_list into a list of data_realizations column positions — parents_to_int","text":"Helper turn parents_list list data_realizations column positions","code":""},{"path":"/reference/parents_to_int.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper to turn parents_list into a list of data_realizations column positions — parents_to_int","text":"","code":"parents_to_int(parents_list, position_set)"},{"path":"/reference/parents_to_int.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper to turn parents_list into a list of data_realizations column positions — parents_to_int","text":"parents_list named list character vectors specifying nodes DAG respective parents","code":""},{"path":"/reference/parents_to_int.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper to turn parents_list into a list of data_realizations column positions — parents_to_int","text":"list column positions","code":""},{"path":"/reference/perm.html","id":null,"dir":"Reference","previous_headings":"","what":"Produces the possible permutations of a set of nodes — perm","title":"Produces the possible permutations of a set of nodes — perm","text":"Produces possible permutations set nodes","code":""},{"path":"/reference/perm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produces the possible permutations of a set of nodes — perm","text":"","code":"perm(max = rep(1, 2))"},{"path":"/reference/perm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produces the possible permutations of a set of nodes — perm","text":"max vector integers. maximum value integer value starting 0. Defaults 1. number permutation defined max's length","code":""},{"path":"/reference/perm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produces the possible permutations of a set of nodes — perm","text":"matrix permutations","code":""},{"path":"/reference/perm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Produces the possible permutations of a set of nodes — perm","text":"","code":"# \\donttest{ CausalQueries:::perm(3) #>     #> 1 0 #> 2 1 #> 3 2 #> 4 3 # }"},{"path":"/reference/plot_dag.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots a DAG in ggplot style using a causal model input — plot_model","title":"Plots a DAG in ggplot style using a causal model input — plot_model","text":"confounds indicated (provided attr(model$P, 'confounds')), represented bidirectional arcs. Builds functionality ggdag dagitty.","code":""},{"path":"/reference/plot_dag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots a DAG in ggplot style using a causal model input — plot_model","text":"","code":"plot_model(   model = NULL,   x_coord = NULL,   y_coord = NULL,   title = \"\",   textcol = \"white\",   textsize = 3.88,   shape = 16,   nodecol = \"black\",   nodesize = 16 )"},{"path":"/reference/plot_dag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots a DAG in ggplot style using a causal model input — plot_model","text":"model causal_model object generated make_model x_coord vector x coordinates DAG nodes. left empty, coordinates randomly generated y_coord vector y coordinates DAG nodes. left empty, coordinates randomly generated title String specifying title graph textcol String specifying color text labels textsize Numeric, size text labels shape Indicates shape node. Defaults circular node. nodecol String indicating color node accepted ggplot's default palette nodesize Size node.","code":""},{"path":"/reference/plot_dag.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots a DAG in ggplot style using a causal model input — plot_model","text":"DAG plot ggplot style.","code":""},{"path":"/reference/plot_dag.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots a DAG in ggplot style using a causal model input — plot_model","text":"","code":"if (FALSE) { model <- make_model('X -> K -> Y; X <-> Y')  model |>   CausalQueries:::plot_model() model |>   CausalQueries:::plot_model(     x_coord = 1:3,     y_coord = 1:3,     title = \"Mixed text and math: $\\\\alpha^2 + \\\\Gamma$\") }"},{"path":"/reference/plot_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots a DAG in ggplot style using a causal model input — plot_model","title":"Plots a DAG in ggplot style using a causal model input — plot_model","text":"confounds indicated (provided attr(model$P, 'confounds')), represented bidirectional arcs. Builds functionality ggdag dagitty.","code":""},{"path":"/reference/plot_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots a DAG in ggplot style using a causal model input — plot_model","text":"","code":"plot_model(   model = NULL,   x_coord = NULL,   y_coord = NULL,   title = \"\",   textcol = \"white\",   textsize = 3.88,   shape = 16,   nodecol = \"black\",   nodesize = 16 )"},{"path":"/reference/plot_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots a DAG in ggplot style using a causal model input — plot_model","text":"model causal_model object generated make_model x_coord vector x coordinates DAG nodes. left empty, coordinates randomly generated y_coord vector y coordinates DAG nodes. left empty, coordinates randomly generated title String specifying title graph textcol String specifying color text labels textsize Numeric, size text labels shape Indicates shape node. Defaults circular node. nodecol String indicating color node accepted ggplot's default palette nodesize Size node.","code":""},{"path":"/reference/plot_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots a DAG in ggplot style using a causal model input — plot_model","text":"DAG plot ggplot style.","code":""},{"path":"/reference/plot_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots a DAG in ggplot style using a causal model input — plot_model","text":"","code":"if (FALSE) { model <- make_model('X -> K -> Y; X <-> Y')  model |>   CausalQueries:::plot_model() model |>   CausalQueries:::plot_model(     x_coord = 1:3,     y_coord = 1:3,     title = \"Mixed text and math: $\\\\alpha^2 + \\\\Gamma$\") }"},{"path":"/reference/prep_stan_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare data for 'stan' — prep_stan_data","title":"Prepare data for 'stan' — prep_stan_data","text":"Create list containing data passed 'stan","code":""},{"path":"/reference/prep_stan_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare data for 'stan' — prep_stan_data","text":"","code":"prep_stan_data(   model,   data,   keep_type_distribution = TRUE,   censored_types = NULL )"},{"path":"/reference/prep_stan_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare data for 'stan' — prep_stan_data","text":"model causal_model. model object generated make_model. data data.frame.  Data nodes can take three values: 0, 1, NA. long form generated make_events","code":""},{"path":"/reference/prep_stan_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare data for 'stan' — prep_stan_data","text":"list containing data passed 'stan'","code":""},{"path":"/reference/prep_stan_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare data for 'stan' — prep_stan_data","text":"","code":"# \\donttest{ model <- make_model('X->Y') data  <-  collapse_data(make_data(model, n = 6), model) CausalQueries:::prep_stan_data(model, data) #> $parmap #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X.0     1    0    1    0 #> X.1     0    1    0    1 #> Y.00    1    1    0    0 #> Y.10    0    1    1    0 #> Y.01    1    0    0    1 #> Y.11    0    0    1    1 #> attr(,\"map\") #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 #>  #> $map #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 #>  #> $n_paths #> [1] 4 #>  #> $n_params #> [1] 6 #>  #> $n_param_sets #> [1] 2 #>  #> $n_param_each #> X Y  #> 2 4  #>  #> $l_starts #> X Y  #> 1 3  #>  #> $l_ends #> X Y  #> 2 6  #>  #> $node_starts #> X Y  #> 1 3  #>  #> $node_ends #> X Y  #> 2 6  #>  #> $n_nodes #> [1] 2 #>  #> $lambdas_prior #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #>    1    1    1    1    1    1  #>  #> $n_data #> [1] 4 #>  #> $n_events #> [1] 4 #>  #> $n_strategies #> [1] 1 #>  #> $strategy_starts #> [1] 1 #>  #> $strategy_ends #> [1] 4 #>  #> $keep_type_distribution #> [1] 1 #>  #> $E #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 #>  #> $Y #> [1] 2 2 0 2 #>  #> $P #>  #> Rows are parameters, grouped in parameter sets #>  #> Columns are causal types #>  #> Cell entries indicate whether a parameter probability isused #> in the calculation of causal type probability #>  #>      X0.Y00 X1.Y00 X0.Y10 X1.Y10 X0.Y01 X1.Y01 X0.Y11 X1.Y11 #> X.0       1      0      1      0      1      0      1      0 #> X.1       0      1      0      1      0      1      0      1 #> Y.00      1      1      0      0      0      0      0      0 #> Y.10      0      0      1      1      0      0      0      0 #> Y.01      0      0      0      0      1      1      0      0 #> Y.11      0      0      0      0      0      0      1      1 #>  #>   #>  param_set  (P) #>   #> $n_types #> [1] 8 #>   model <- make_model('X->Y') |>   set_confound(list(X = 'Y[X=1]>Y[X=0]')) data  <-  collapse_data(make_data(model, n = 6), model) CausalQueries:::prep_stan_data(model, data) #> $parmap #>      X0Y0 X1Y0 X0Y1 X1Y1 #> Y.00    1    1    0    0 #> Y.10    0    1    1    0 #> Y.01    1    0    0    1 #> Y.11    0    0    1    1 #> attr(,\"map\") #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 #>  #> $map #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 #>  #> $n_paths #> [1] 4 #>  #> $n_params #> [1] 4 #>  #> $n_param_sets #> [1] 1 #>  #> $n_param_each #> Y  #> 4  #>  #> $l_starts #> Y  #> 1  #>  #> $l_ends #> Y  #> 4  #>  #> $node_starts #> Y  #> 1  #>  #> $node_ends #> Y  #> 4  #>  #> $n_nodes #> [1] 1 #>  #> $lambdas_prior #> Y.00 Y.10 Y.01 Y.11  #>    1    1    1    1  #>  #> $n_data #> [1] 4 #>  #> $n_events #> [1] 4 #>  #> $n_strategies #> [1] 1 #>  #> $strategy_starts #> [1] 1 #>  #> $strategy_ends #> [1] 4 #>  #> $keep_type_distribution #> [1] 1 #>  #> $E #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 #>  #> $Y #> [1] 0 1 2 3 #>  #> $P #>  #> Rows are parameters, grouped in parameter sets #>  #> Columns are causal types #>  #> Cell entries indicate whether a parameter probability isused #> in the calculation of causal type probability #>  #>      X0.Y00 X1.Y00 X0.Y10 X1.Y10 X0.Y01 X1.Y01 X0.Y11 X1.Y11 #> Y.00      1      1      0      0      0      0      0      0 #> Y.10      0      0      1      1      0      0      0      0 #> Y.01      0      0      0      0      1      1      0      0 #> Y.11      0      0      0      0      0      0      1      1 #>  #>   #>  param_set  (P) #>  Y #> $n_types #> [1] 8 #>  # }"},{"path":"/reference/print.causal_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for a causal model — print.causal_model","title":"Print a short summary for a causal model — print.causal_model","text":"print method class causal_model.","code":""},{"path":"/reference/print.causal_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for a causal model — print.causal_model","text":"","code":"# S3 method for causal_model print(x, ...)"},{"path":"/reference/print.causal_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for a causal model — print.causal_model","text":"x object causal_model class, usually result call make_model update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.causal_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print a short summary for a causal model — print.causal_model","text":"information regarding causal model includes statement describing causal relations using dagitty syntax, number nodal types per parent DAG, number causal types.","code":""},{"path":"/reference/print.causal_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for causal_model causal-types — print.causal_types","title":"Print a short summary for causal_model causal-types — print.causal_types","text":"print method class causal_types.","code":""},{"path":"/reference/print.causal_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for causal_model causal-types — print.causal_types","text":"","code":"# S3 method for causal_types print(x, ...)"},{"path":"/reference/print.causal_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for causal_model causal-types — print.causal_types","text":"x object causal_types class, sub-object object causal_model class produced using make_model update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.dag.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for a causal_model DAG — print.dag","title":"Print a short summary for a causal_model DAG — print.dag","text":"print method class dag.","code":""},{"path":"/reference/print.dag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for a causal_model DAG — print.dag","text":"","code":"# S3 method for dag print(x, ...)"},{"path":"/reference/print.dag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for a causal_model DAG — print.dag","text":"x object dag class, sub-object object causal_model class produced using make_model update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.event_probabilites.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for event probability distributions — print.event_probabilites","title":"Print a short summary for event probability distributions — print.event_probabilites","text":"print method class event_probabilities.","code":""},{"path":"/reference/print.event_probabilites.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for event probability distributions — print.event_probabilites","text":"","code":"# S3 method for event_probabilites print(x, ...)"},{"path":"/reference/print.event_probabilites.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for event probability distributions — print.event_probabilites","text":"x object event_probabilities class, sub-object object causal_model class produced using update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.event_probabilities.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for event probabilities — print.event_probabilities","title":"Print a short summary for event probabilities — print.event_probabilities","text":"print method class event_probabilities.","code":""},{"path":"/reference/print.event_probabilities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for event probabilities — print.event_probabilities","text":"","code":"# S3 method for event_probabilities print(x, ...)"},{"path":"/reference/print.event_probabilities.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for event probabilities — print.event_probabilities","text":"x object event_probabilities class, sub-object object causal_model class produced using update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.model_query.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a tightened summary of model queries — print.model_query","title":"Print a tightened summary of model queries — print.model_query","text":"print method class model_query.","code":""},{"path":"/reference/print.model_query.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a tightened summary of model queries — print.model_query","text":"","code":"# S3 method for model_query print(x)"},{"path":"/reference/print.model_query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a tightened summary of model queries — print.model_query","text":"x object model_query class. ... arguments passed methods.","code":""},{"path":"/reference/print.nodal_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for causal_model nodal-types — print.nodal_types","title":"Print a short summary for causal_model nodal-types — print.nodal_types","text":"print method class nodal_types.","code":""},{"path":"/reference/print.nodal_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for causal_model nodal-types — print.nodal_types","text":"","code":"# S3 method for nodal_types print(x, ...)"},{"path":"/reference/print.nodal_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for causal_model nodal-types — print.nodal_types","text":"x object nodal_types class, sub-object object causal_model class produced using make_model update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.nodes.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for a causal_model nodes — print.nodes","title":"Print a short summary for a causal_model nodes — print.nodes","text":"print method class nodes.","code":""},{"path":"/reference/print.nodes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for a causal_model nodes — print.nodes","text":"","code":"# S3 method for nodes print(x, ...)"},{"path":"/reference/print.nodes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for a causal_model nodes — print.nodes","text":"x object nodes class, sub-object object causal_model class produced using make_model update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for causal_model parameters — print.parameters","title":"Print a short summary for causal_model parameters — print.parameters","text":"print method class parameters.","code":""},{"path":"/reference/print.parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for causal_model parameters — print.parameters","text":"","code":"# S3 method for parameters print(x, ...)"},{"path":"/reference/print.parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for causal_model parameters — print.parameters","text":"x object parameters class, sub-object object causal_model class produced using make_model update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.parameters_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for a causal_model parameters data-frame — print.parameters_df","title":"Print a short summary for a causal_model parameters data-frame — print.parameters_df","text":"print method class parameters_df.","code":""},{"path":"/reference/print.parameters_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for a causal_model parameters data-frame — print.parameters_df","text":"","code":"# S3 method for parameters_df print(x, ...)"},{"path":"/reference/print.parameters_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for a causal_model parameters data-frame — print.parameters_df","text":"x object parameters_df class, sub-object object causal_model class produced using make_model update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.parameters_posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for causal_model parameter posterior distributions — print.parameters_posterior","title":"Print a short summary for causal_model parameter posterior distributions — print.parameters_posterior","text":"print method class parameters_posterior.","code":""},{"path":"/reference/print.parameters_posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for causal_model parameter posterior distributions — print.parameters_posterior","text":"","code":"# S3 method for parameters_posterior print(x, ...)"},{"path":"/reference/print.parameters_posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for causal_model parameter posterior distributions — print.parameters_posterior","text":"x object parameters_posterior class, sub-object object causal_model class produced using update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.parameters_prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for causal_model parameter prior distributions — print.parameters_prior","title":"Print a short summary for causal_model parameter prior distributions — print.parameters_prior","text":"print method class parameters_prior.","code":""},{"path":"/reference/print.parameters_prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for causal_model parameter prior distributions — print.parameters_prior","text":"","code":"# S3 method for parameters_prior print(x, ...)"},{"path":"/reference/print.parameters_prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for causal_model parameter prior distributions — print.parameters_prior","text":"x object parameters_prior class, sub-object object causal_model class produced using set_prior_distribution. ... arguments passed methods.","code":""},{"path":"/reference/print.parents_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for a causal_model parents data-frame — print.parents_df","title":"Print a short summary for a causal_model parents data-frame — print.parents_df","text":"print method class parents_df.","code":""},{"path":"/reference/print.parents_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for a causal_model parents data-frame — print.parents_df","text":"","code":"# S3 method for parents_df print(x, ...)"},{"path":"/reference/print.parents_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for a causal_model parents data-frame — print.parents_df","text":"x object parents_df class, sub-object object causal_model class produced using make_model update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.posterior_event_probabilities.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary of posterior_event_probabilities — print.posterior_event_probabilities","title":"Print a short summary of posterior_event_probabilities — print.posterior_event_probabilities","text":"print method class posterior_event_probabilities.","code":""},{"path":"/reference/print.posterior_event_probabilities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary of posterior_event_probabilities — print.posterior_event_probabilities","text":"","code":"# S3 method for posterior_event_probabilities print(x, ...)"},{"path":"/reference/print.posterior_event_probabilities.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary of posterior_event_probabilities — print.posterior_event_probabilities","text":"x object posterior_event_probabilities class. ... arguments passed methods.","code":""},{"path":"/reference/print.stan_fit_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for stan fit — print.stan_fit_summary","title":"Print a short summary for stan fit — print.stan_fit_summary","text":"print method class stan_summary.","code":""},{"path":"/reference/print.stan_fit_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for stan fit — print.stan_fit_summary","text":"","code":"# S3 method for stan_summary print(x, ...)"},{"path":"/reference/print.stan_fit_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for stan fit — print.stan_fit_summary","text":"x object stan_summary class, sub-object object causal_model class produced using update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.stan_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for stan fit — print.stan_summary","title":"Print a short summary for stan fit — print.stan_summary","text":"print method class stan_summary.","code":""},{"path":"/reference/print.stan_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for stan fit — print.stan_summary","text":"","code":"# S3 method for stan_summary print(x, ...)"},{"path":"/reference/print.stan_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for stan fit — print.stan_summary","text":"x object stan_summary class, sub-object object causal_model class produced using update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.statement.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for a causal_model statement — print.statement","title":"Print a short summary for a causal_model statement — print.statement","text":"print method class statement.","code":""},{"path":"/reference/print.statement.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for a causal_model statement — print.statement","text":"","code":"# S3 method for statement print(x, ...)"},{"path":"/reference/print.statement.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for a causal_model statement — print.statement","text":"x object statement class, sub-object object causal_model class produced using make_model update_model. ... arguments passed methods.","code":""},{"path":"/reference/print.type_posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for causal-type posterior distributions — print.type_posterior","title":"Print a short summary for causal-type posterior distributions — print.type_posterior","text":"print method class type_posterior.","code":""},{"path":"/reference/print.type_posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for causal-type posterior distributions — print.type_posterior","text":"","code":"# S3 method for type_posterior print(x, ...)"},{"path":"/reference/print.type_posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for causal-type posterior distributions — print.type_posterior","text":"x object type_posterior class, sub-object object causal_model class produced using get_type_prob_multiple. ... arguments passed methods.","code":""},{"path":"/reference/print.type_prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for causal-type prior distributions — print.type_prior","title":"Print a short summary for causal-type prior distributions — print.type_prior","text":"print method class type_prior.","code":""},{"path":"/reference/print.type_prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for causal-type prior distributions — print.type_prior","text":"","code":"# S3 method for type_prior print(x, ...)"},{"path":"/reference/print.type_prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for causal-type prior distributions — print.type_prior","text":"x object type_prior class, sub-object object causal_model class produced using make_model update_model. ... arguments passed methods.","code":""},{"path":"/reference/prior_setting.html","id":null,"dir":"Reference","previous_headings":"","what":"Setting priors — prior_setting","title":"Setting priors — prior_setting","text":"Functionality altering priors: make_priors Generates priors model. set_priors  Adds priors model. Extracts priors named vector","code":""},{"path":"/reference/prior_setting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Setting priors — prior_setting","text":"","code":"make_priors(   model,   alphas = NA,   distribution = NA,   alter_at = NA,   node = NA,   nodal_type = NA,   label = NA,   param_set = NA,   given = NA,   statement = NA,   join_by = \"|\",   param_names = NA )  set_priors(   model,   alphas = NA,   distribution = NA,   alter_at = NA,   node = NA,   nodal_type = NA,   label = NA,   param_set = NA,   given = NA,   statement = NA,   join_by = \"|\",   param_names = NA )  get_priors(model)"},{"path":"/reference/prior_setting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Setting priors — prior_setting","text":"model model object generated make_model(). alphas Real positive numbers giving hyperparameters Dirichlet distribution distribution string indicating common prior distribution (uniform, jeffreys certainty) alter_at string specifying filtering operations applied parameters_df, yielding logical vector indicating parameters values altered. (see examples) node string indicating nodes altered nodal_type string. Label nodal type indicating nodal types values altered label string. Label nodal type indicating nodal types values altered. Equivalent nodal_type. param_set string indicating  name set parameters altered given string indicates node parameter altered depends statement causal query determines nodal types values altered join_by string specifying logical operator joining expanded types statement contains wildcards. Can take values '&' (logical ) '|' (logical ). param_names vector strings. name specific parameter form , example, 'X.1', 'Y.01'","code":""},{"path":"/reference/prior_setting.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Setting priors — prior_setting","text":"vector indicating parameters prior distribution   nodal types (\"hyperparameters\"). object class causal_model. essentially returns   list containing elements comprising model   (e.g. 'statement', 'nodal_types' 'DAG') `priors` attached   . vector indicating hyperparameters prior distribution   nodal types.","code":""},{"path":"/reference/prior_setting.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Setting priors — prior_setting","text":"Seven arguments govern parameters altered. default '' can reduced specifying * alter_at String specifying filtering operations applied   parameters_df, yielding logical vector indicating parameters   values altered. \"node == 'X' & nodal_type * node, restricts example parameters associated node   'X' * label nodal_type label particular nodal type,   written either form Y0000 Y.Y0000 * param_set param_set parameter. * given Given parameter set parameter. * statement, restricts example nodal types satisfy   statement 'Y[X=1] > Y[X=0]' * param_set, given, useful setting confound   statements produce several sets parameters Two arguments govern values apply: * alphas one non-negative numbers * distribution indicates one common class: uniform, Jeffreys,   'certain' Forbidden statements include: Setting distribution values time. Setting distribution uniform, Jeffreys,     certainty. Setting negative values. specifying alter_at node,     nodal_type, param_set, given, statement,     param_names specifying param_names node,     nodal_type, param_set, given, statement,     alter_at specifying statement node     nodal_type","code":""},{"path":"/reference/prior_setting.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Setting priors — prior_setting","text":"","code":"# make_priors examples:  # Pass all nodal types model <- make_model(\"Y <- X\") make_priors(model, alphas = .4) #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #>  0.4  0.4  0.4  0.4  0.4  0.4  make_priors(model, distribution = \"jeffreys\") #> No specific parameters to alter values for specified. Altering all parameters. #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #>  0.5  0.5  0.5  0.5  0.5  0.5   model <- CausalQueries::make_model(\"X -> M -> Y; X <-> Y\")  #altering values using \\code{alter_at} make_priors(model = model, alphas = c(0.5,0.25), alter_at = \"node == 'Y' & nodal_type %in% c('00','01') & given == 'X.0'\") #> Warning: You are altering parameters on confounded nodes. Alterations will be applied across all 'param_sets'. If this is not the alteration behavior you intended, try specifying the 'param_set' or 'given' option to more clearly indicate parameters whose values you wish to alter. #>      X.0      X.1     M.00     M.10     M.01     M.11 Y.00_X.0 Y.10_X.0  #>     1.00     1.00     1.00     1.00     1.00     1.00     0.50     1.00  #> Y.01_X.0 Y.11_X.0 Y.00_X.1 Y.10_X.1 Y.01_X.1 Y.11_X.1  #>     0.25     1.00     1.00     1.00     1.00     1.00   #altering values using \\code{param_names} make_priors(model = model, alphas = c(0.5,0.25), param_names = c(\"Y.10_X.0\",\"Y.10_X.1\")) #> Warning: You are altering parameters on confounded nodes. Alterations will be applied across all 'param_sets'. If this is not the alteration behavior you intended, try specifying the 'param_set' or 'given' option to more clearly indicate parameters whose values you wish to alter. #>      X.0      X.1     M.00     M.10     M.01     M.11 Y.00_X.0 Y.10_X.0  #>     1.00     1.00     1.00     1.00     1.00     1.00     1.00     0.50  #> Y.01_X.0 Y.11_X.0 Y.00_X.1 Y.10_X.1 Y.01_X.1 Y.11_X.1  #>     1.00     1.00     1.00     0.25     1.00     1.00   #altering values using \\code{statement} make_priors(model = model, alphas = c(0.5,0.25), statement = \"Y[M=1] > Y[M=0]\") #> Warning: A specified condition matches multiple parameters. In these cases it is unclear which parameter value should be assigned to which parameter. Assignment thus defaults to the order in which parameters appear in 'parameters_df'. We advise checking that parameter assignment was carried out as you intended.  #> Warning: You are altering parameters on confounded nodes. Alterations will be applied across all 'param_sets'. If this is not the alteration behavior you intended, try specifying the 'param_set' or 'given' option to more clearly indicate parameters whose values you wish to alter. #>      X.0      X.1     M.00     M.10     M.01     M.11 Y.00_X.0 Y.10_X.0  #>     1.00     1.00     1.00     1.00     1.00     1.00     1.00     1.00  #> Y.01_X.0 Y.11_X.0 Y.00_X.1 Y.10_X.1 Y.01_X.1 Y.11_X.1  #>     0.50     1.00     1.00     1.00     0.25     1.00   #altering values using a combination of other arguments make_priors(model = model, alphas = c(0.5,0.25), node = \"Y\", nodal_type = c(\"00\",\"01\"), given = \"X.0\") #>      X.0      X.1     M.00     M.10     M.01     M.11 Y.00_X.0 Y.10_X.0  #>     1.00     1.00     1.00     1.00     1.00     1.00     0.50     1.00  #> Y.01_X.0 Y.11_X.0 Y.00_X.1 Y.10_X.1 Y.01_X.1 Y.11_X.1  #>     0.25     1.00     1.00     1.00     1.00     1.00   # set_priors examples:  # Pass all nodal types model <- make_model(\"Y <- X\") set_priors(model, alphas = .4) #>  #> Statement:  #> Y <- X #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>  set_priors(model, distribution = \"jeffreys\") #> No specific parameters to alter values for specified. Altering all parameters. #>  #> Statement:  #> Y <- X #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of unit types: 8 #>   model <- CausalQueries::make_model(\"X -> M -> Y; X <-> Y\")  #altering values using \\code{alter_at} set_priors(model = model, alphas = c(0.5,0.25), alter_at = \"node == 'Y' & nodal_type %in% c('00','01') & given == 'X.0'\") #> Warning: You are altering parameters on confounded nodes. Alterations will be applied across all 'param_sets'. If this is not the alteration behavior you intended, try specifying the 'param_set' or 'given' option to more clearly indicate parameters whose values you wish to alter. #>  #> Statement:  #> X -> M -> Y; X <-> Y; Y <-> X #>  #> Number of types by node: #> X M Y  #> 2 4 4  #>  #> Number of unit types: 32 #>   #altering values using \\code{param_names} set_priors(model = model, alphas = c(0.5,0.25), param_names = c(\"Y.10_X.0\",\"Y.10_X.1\")) #> Warning: You are altering parameters on confounded nodes. Alterations will be applied across all 'param_sets'. If this is not the alteration behavior you intended, try specifying the 'param_set' or 'given' option to more clearly indicate parameters whose values you wish to alter. #>  #> Statement:  #> X -> M -> Y; X <-> Y; Y <-> X #>  #> Number of types by node: #> X M Y  #> 2 4 4  #>  #> Number of unit types: 32 #>   #altering values using \\code{statement} set_priors(model = model, alphas = c(0.5,0.25), statement = \"Y[M=1] > Y[M=0]\") #> Warning: A specified condition matches multiple parameters. In these cases it is unclear which parameter value should be assigned to which parameter. Assignment thus defaults to the order in which parameters appear in 'parameters_df'. We advise checking that parameter assignment was carried out as you intended.  #> Warning: You are altering parameters on confounded nodes. Alterations will be applied across all 'param_sets'. If this is not the alteration behavior you intended, try specifying the 'param_set' or 'given' option to more clearly indicate parameters whose values you wish to alter. #>  #> Statement:  #> X -> M -> Y; X <-> Y; Y <-> X #>  #> Number of types by node: #> X M Y  #> 2 4 4  #>  #> Number of unit types: 32 #>   #altering values using a combination of other arguments set_priors(model = model, alphas = c(0.5,0.25), node = \"Y\", nodal_type = c(\"00\",\"01\"), given = \"X.0\") #>  #> Statement:  #> X -> M -> Y; X <-> Y; Y <-> X #>  #> Number of types by node: #> X M Y  #> 2 4 4  #>  #> Number of unit types: 32 #>   # get_priors examples:  get_priors(make_model('X -> Y')) #> Error in get_priors(make_model(\"X -> Y\")): could not find function \"get_priors\""},{"path":"/reference/queries_to_types.html","id":null,"dir":"Reference","previous_headings":"","what":"helper to get types from queries — queries_to_types","title":"helper to get types from queries — queries_to_types","text":"helper get types queries","code":""},{"path":"/reference/queries_to_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"helper to get types from queries — queries_to_types","text":"","code":"queries_to_types(jobs, model, query_col, realisations)"},{"path":"/reference/queries_to_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"helper to get types from queries — queries_to_types","text":"jobs DataFrame argument combinations model list models query_col string specifying name column jobs holding queries evaluated realisations list DataFrame outputs calls realise_outcomes","code":""},{"path":"/reference/queries_to_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"helper to get types from queries — queries_to_types","text":"jobs DataFrame nested column  map_query_to_nodal_type outputs","code":""},{"path":"/reference/query_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate query distribution — query_distribution","title":"Calculate query distribution — query_distribution","text":"Calculated distribution query prior posterior distribution parameters","code":""},{"path":"/reference/query_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate query distribution — query_distribution","text":"","code":"query_distribution(   model,   queries,   given = NULL,   using = \"parameters\",   parameters = NULL,   n_draws = 4000,   join_by = \"|\",   case_level = FALSE,   query = NULL )"},{"path":"/reference/query_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate query distribution — query_distribution","text":"model causal_model. model object generated make_model. queries character vector list character vectors specifying queries potential outcomes \"Y[X=1] - Y[X=0]\" given character vector specifying givens query. given quoted expression evaluates logical statement. given allows query conditioned *observational* distribution. value TRUE interpreted conditioning. using character. Whether use priors, posteriors parameters parameters vector list vectors real numbers [0,1]. true parameter vector used instead parameters attached model case  using specifies parameters n_draws integer. Number draws.rm join_by character. logical operator joining expanded types query contains wildcard (.). Can take values \"&\" (logical ) \"|\" (logical ). restriction contains wildcard (.) join_by specified, defaults \"|\", otherwise defaults NULL. case_level Logical. TRUE estimates probability query case. query alias queries","code":""},{"path":"/reference/query_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate query distribution — query_distribution","text":"DataFrame columns contain draws distribution   potential outcomes specified query","code":""},{"path":"/reference/query_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate query distribution — query_distribution","text":"","code":"model <- make_model(\"X -> Y\") %>%          set_parameters(c(.5, .5, .1, .2, .3, .4))  # \\donttest{  # simple  queries  query_distribution(model, query = \"(Y[X=1] > Y[X=0])\",                     using = \"priors\") |>    head() #>   (Y[X=1] > Y[X=0]) #> 1         0.4949833 #> 2         0.4073183 #> 3         0.0415724 #> 4         0.4344517 #> 5         0.8637861 #> 6         0.3049571   # multiple  queries  query_distribution(model,      query = list(\"(Y[X=1] > Y[X=0])\",                   \"(Y[X=1] < Y[X=0])\"),      using = \"priors\")|>    head() #>   (Y[X=1] > Y[X=0]) (Y[X=1] < Y[X=0]) #> 1        0.09241136         0.3060072 #> 2        0.52672044         0.2169082 #> 3        0.31044891         0.6252908 #> 4        0.31326378         0.3072935 #> 5        0.63320196         0.2024220 #> 6        0.10098846         0.7639153   # multiple queries and givens  query_distribution(model,    query = list(\"(Y[X=1] > Y[X=0])\", \"(Y[X=1] < Y[X=0])\"),    given = list(\"Y==1\", \"(Y[X=1] <= Y[X=0])\"),    using = \"priors\")|>    head() #>   (Y[X=1] > Y[X=0]) | Y==1 (Y[X=1] < Y[X=0]) | (Y[X=1] <= Y[X=0]) #> 1              0.230372777                             0.26931792 #> 2              0.046310742                             0.03116822 #> 3              0.755410299                             0.40469985 #> 4              0.423838008                             0.71253721 #> 5              0.002537272                             0.08124326 #> 6              0.079707704                             0.28529471   # linear queries  query_distribution(model, query = \"(Y[X=1] - Y[X=0])\") #>   (Y[X=1] - Y[X=0]) #> 1               0.1   # queries conditional on observables  query_distribution(model, query = \"(Y[X=1] > Y[X=0])\",                     given = \"X==1 & Y ==1\") #>   (Y[X=1] > Y[X=0]) #> 1         0.4285714   # Linear query conditional on potential outcomes  query_distribution(model, query = \"(Y[X=1] - Y[X=0])\",                     given = \"Y[X=1]==0\") #>   (Y[X=1] - Y[X=0]) #> 1        -0.6666667   # Use join_by to amend query interpretation  query_distribution(model, query = \"(Y[X=.] == 1)\", join_by = \"&\") #> Generated expanded expression: #> (Y[X=0] == 1 | Y[X=1] == 1) #>   (Y[X=.] == 1) #> 1           0.9   # Probability of causation query  query_distribution(model,     query = \"(Y[X=1] > Y[X=0])\",     given = \"X==1 & Y==1\",     using = \"priors\")  |> head() #>   (Y[X=1] > Y[X=0]) #> 1         0.3243476 #> 2         0.8100257 #> 3         0.0287984 #> 4         0.9486432 #> 5         0.2566036 #> 6         0.7279466   # Case level probability of causation query  query_distribution(model,     query = \"(Y[X=1] > Y[X=0])\",     given = \"X==1 & Y==1\",     case_level = TRUE,     using = \"priors\") #>   (Y[X=1] > Y[X=0]) #> 1         0.4930782   # Query posterior  update_model(model, make_data(model, n = 3)) |>  query_distribution(query = \"(Y[X=1] - Y[X=0])\", using = \"posteriors\") |>  head() #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.7e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.262 seconds (Warm-up) #> Chain 1:                0.222 seconds (Sampling) #> Chain 1:                0.484 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 4.5e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.45 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.231 seconds (Warm-up) #> Chain 2:                0.237 seconds (Sampling) #> Chain 2:                0.468 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 5.6e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.56 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.291 seconds (Warm-up) #> Chain 3:                0.204 seconds (Sampling) #> Chain 3:                0.495 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 2.3e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.184 seconds (Warm-up) #> Chain 4:                0.272 seconds (Sampling) #> Chain 4:                0.456 seconds (Total) #> Chain 4:  #>   (Y[X=1] - Y[X=0]) #> 1       -0.02255738 #> 2       -0.13757475 #> 3       -0.04571931 #> 4        0.46448376 #> 5       -0.17650957 #> 6       -0.17320323   # Case level queries provide the inference for a case, which is a scalar  # The case level query *updates* on the given information  # For instance, here we have a model for which we are quite sure that X  # causes Y but we do not know whether it works through two positive effects  # or two negative effects. Thus we do not know if M=0 would suggest an  # effect or no effect   set.seed(1)  model <-    make_model(\"X -> M -> Y\") |>    update_model(data.frame(X = rep(0:1, 8), Y = rep(0:1, 8)), iter = 10000) #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 3.5e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.35 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 10000 [  0%]  (Warmup) #> Chain 1: Iteration: 1000 / 10000 [ 10%]  (Warmup) #> Chain 1: Iteration: 2000 / 10000 [ 20%]  (Warmup) #> Chain 1: Iteration: 3000 / 10000 [ 30%]  (Warmup) #> Chain 1: Iteration: 4000 / 10000 [ 40%]  (Warmup) #> Chain 1: Iteration: 5000 / 10000 [ 50%]  (Warmup) #> Chain 1: Iteration: 5001 / 10000 [ 50%]  (Sampling) #> Chain 1: Iteration: 6000 / 10000 [ 60%]  (Sampling) #> Chain 1: Iteration: 7000 / 10000 [ 70%]  (Sampling) #> Chain 1: Iteration: 8000 / 10000 [ 80%]  (Sampling) #> Chain 1: Iteration: 9000 / 10000 [ 90%]  (Sampling) #> Chain 1: Iteration: 10000 / 10000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 2.171 seconds (Warm-up) #> Chain 1:                3.592 seconds (Sampling) #> Chain 1:                5.763 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 5.8e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.58 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 10000 [  0%]  (Warmup) #> Chain 2: Iteration: 1000 / 10000 [ 10%]  (Warmup) #> Chain 2: Iteration: 2000 / 10000 [ 20%]  (Warmup) #> Chain 2: Iteration: 3000 / 10000 [ 30%]  (Warmup) #> Chain 2: Iteration: 4000 / 10000 [ 40%]  (Warmup) #> Chain 2: Iteration: 5000 / 10000 [ 50%]  (Warmup) #> Chain 2: Iteration: 5001 / 10000 [ 50%]  (Sampling) #> Chain 2: Iteration: 6000 / 10000 [ 60%]  (Sampling) #> Chain 2: Iteration: 7000 / 10000 [ 70%]  (Sampling) #> Chain 2: Iteration: 8000 / 10000 [ 80%]  (Sampling) #> Chain 2: Iteration: 9000 / 10000 [ 90%]  (Sampling) #> Chain 2: Iteration: 10000 / 10000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 3.778 seconds (Warm-up) #> Chain 2:                5.321 seconds (Sampling) #> Chain 2:                9.099 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 3.7e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.37 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 10000 [  0%]  (Warmup) #> Chain 3: Iteration: 1000 / 10000 [ 10%]  (Warmup) #> Chain 3: Iteration: 2000 / 10000 [ 20%]  (Warmup) #> Chain 3: Iteration: 3000 / 10000 [ 30%]  (Warmup) #> Chain 3: Iteration: 4000 / 10000 [ 40%]  (Warmup) #> Chain 3: Iteration: 5000 / 10000 [ 50%]  (Warmup) #> Chain 3: Iteration: 5001 / 10000 [ 50%]  (Sampling) #> Chain 3: Iteration: 6000 / 10000 [ 60%]  (Sampling) #> Chain 3: Iteration: 7000 / 10000 [ 70%]  (Sampling) #> Chain 3: Iteration: 8000 / 10000 [ 80%]  (Sampling) #> Chain 3: Iteration: 9000 / 10000 [ 90%]  (Sampling) #> Chain 3: Iteration: 10000 / 10000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 3.241 seconds (Warm-up) #> Chain 3:                3.509 seconds (Sampling) #> Chain 3:                6.75 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 6.2e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.62 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 10000 [  0%]  (Warmup) #> Chain 4: Iteration: 1000 / 10000 [ 10%]  (Warmup) #> Chain 4: Iteration: 2000 / 10000 [ 20%]  (Warmup) #> Chain 4: Iteration: 3000 / 10000 [ 30%]  (Warmup) #> Chain 4: Iteration: 4000 / 10000 [ 40%]  (Warmup) #> Chain 4: Iteration: 5000 / 10000 [ 50%]  (Warmup) #> Chain 4: Iteration: 5001 / 10000 [ 50%]  (Sampling) #> Chain 4: Iteration: 6000 / 10000 [ 60%]  (Sampling) #> Chain 4: Iteration: 7000 / 10000 [ 70%]  (Sampling) #> Chain 4: Iteration: 8000 / 10000 [ 80%]  (Sampling) #> Chain 4: Iteration: 9000 / 10000 [ 90%]  (Sampling) #> Chain 4: Iteration: 10000 / 10000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 3.662 seconds (Warm-up) #> Chain 4:                4.158 seconds (Sampling) #> Chain 4:                7.82 seconds (Total) #> Chain 4:    Q <- \"Y[X=1] > Y[X=0]\"  G <- \"X==1 & Y==1 & M==1\"  QG <- \"(Y[X=1] > Y[X=0]) & (X==1 & Y==1 & M==1)\"   # In this case these are very different:  query_distribution(model, Q, given = G, using = \"posteriors\")[[1]] |> mean() #> [1] 0.4259119  query_distribution(model, Q, given = G, using = \"posteriors\",    case_level = TRUE) #>   Y[X=1] > Y[X=0] #> 1       0.6720842   # These are equivalent:  # 1. Case level query via function  query_distribution(model, Q, given = G,     using = \"posteriors\", case_level = TRUE) #>   Y[X=1] > Y[X=0] #> 1       0.6720842   # 2. Case level query by hand using Bayes  distribution <- query_distribution(     model, list(QG = QG, G = G), using = \"posteriors\")   mean(distribution$QG)/mean(distribution$G) #> [1] 0.6720842 # }"},{"path":"/reference/query_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate estimands dataframe — query_model","title":"Generate estimands dataframe — query_model","text":"Calculated parameter vector, prior posterior distribution.","code":""},{"path":"/reference/query_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate estimands dataframe — query_model","text":"","code":"query_model(   model,   queries = NULL,   given = NULL,   using = list(\"parameters\"),   parameters = NULL,   stats = NULL,   n_draws = 4000,   expand_grid = FALSE,   case_level = FALSE,   query = NULL,   cred = 95 )"},{"path":"/reference/query_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate estimands dataframe — query_model","text":"model causal_model. model object generated make_model. queries vector strings list strings specifying queries potential outcomes \"Y[X=1] - Y[X=0]\". given vector list strings specifying givens. given quoted expression evaluates logical statement. Allows estimand conditioned *observational* (counterfactual) distribution. using vector list strings. Whether use priors, posteriors parameters. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn model$parameters_df. stats Functions applied estimand distribution. NULL, defaults mean, standard deviation, 95% confidence interval. Functions return single numeric value. n_draws integer. Number draws. expand_grid Logical. TRUE combinations provided lists examined. list cycled separately. Defaults FALSE. case_level Logical. TRUE estimates probability query case. query alias queries cred size credible interval ranging 0 100","code":""},{"path":"/reference/query_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate estimands dataframe — query_model","text":"DataFrame columns Model, Query, Given Using   defined corresponding input values. columns generated   specified stats.","code":""},{"path":"/reference/query_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate estimands dataframe — query_model","text":"Queries can condition observed counterfactual quantities. Nested \"complex\" counterfactual queries form Y[X=1, M[X=0]] allowed.","code":""},{"path":"/reference/query_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate estimands dataframe — query_model","text":"","code":"model <- make_model(\"X -> Y\") query_model(model, \"Y[X=1] - Y[X = 0]\", using = \"priors\") #>  #> Causal queries generated by query_model (all at population level) #>  #> |query             |using  |   mean|   sd| cred.low| cred.high| #> |:-----------------|:------|------:|----:|--------:|---------:| #> |Y[X=1] - Y[X = 0] |priors | -0.004| 0.32|   -0.653|      0.63| #>  query_model(model, \"Y[X=1] > Y[X = 0]\", using = \"parameters\") #>  #> Causal queries generated by query_model (all at population level) #>  #> |query             |using      | mean| #> |:-----------------|:----------|----:| #> |Y[X=1] > Y[X = 0] |parameters | 0.25| #>  query_model(model, \"Y[X=1] > Y[X = 0]\", using = c(\"priors\", \"parameters\")) #>  #> Causal queries generated by query_model (all at population level) #>  #> |query             |using      |  mean|    sd| cred.low| cred.high| #> |:-----------------|:----------|-----:|-----:|--------:|---------:| #> |Y[X=1] > Y[X = 0] |priors     | 0.243| 0.192|    0.008|     0.695| #> |Y[X=1] > Y[X = 0] |parameters | 0.250|    NA|    0.250|     0.250| #>  # \\donttest{  # `expand_grid= TRUE` requests the Cartesian product of arguments  models <- list(  M1 = make_model(\"X -> Y\"),  M2 = make_model(\"X -> Y\") |>    set_restrictions(\"Y[X=1] < Y[X=0]\")  )   query_model(   models,   query = list(ATE = \"Y[X=1] - Y[X=0]\",                Share_positive = \"Y[X=1] > Y[X=0]\"),   given = c(TRUE,  \"Y==1 & X==1\"),   using = c(\"parameters\", \"priors\"),   expand_grid = FALSE) #>  #> Causal queries generated by query_model (all at population level) #>  #> |model |query          |given       |using      |  mean|    sd| cred.low| cred.high| #> |:-----|:--------------|:-----------|:----------|-----:|-----:|--------:|---------:| #> |M1    |ATE            |-           |parameters | 0.000|    NA|    0.000|     0.000| #> |M1    |Share_positive |Y==1 & X==1 |priors     | 0.495| 0.291|    0.024|     0.976| #> |M2    |ATE            |-           |parameters | 0.333|    NA|    0.333|     0.333| #> |M2    |Share_positive |Y==1 & X==1 |priors     | 0.501| 0.286|    0.026|     0.974| #>   query_model(   models,   query = list(ATE = \"Y[X=1] - Y[X=0]\",                Share_positive = \"Y[X=1] > Y[X=0]\"),   given = c(TRUE,  \"Y==1 & X==1\"),   using = c(\"parameters\", \"priors\"),   expand_grid = TRUE) #>  #> Causal queries generated by query_model (all at population level) #>  #> |model |query          |given       |using      |  mean|    sd| cred.low| cred.high| #> |:-----|:--------------|:-----------|:----------|-----:|-----:|--------:|---------:| #> |M1    |ATE            |-           |parameters | 0.000|    NA|    0.000|     0.000| #> |M2    |ATE            |-           |parameters | 0.333|    NA|    0.333|     0.333| #> |M1    |ATE            |-           |priors     | 0.005| 0.321|   -0.637|     0.636| #> |M2    |ATE            |-           |priors     | 0.337| 0.241|    0.012|     0.855| #> |M1    |ATE            |Y==1 & X==1 |parameters | 0.500|    NA|    0.500|     0.500| #> |M2    |ATE            |Y==1 & X==1 |parameters | 0.500|    NA|    0.500|     0.500| #> |M1    |ATE            |Y==1 & X==1 |priors     | 0.509| 0.291|    0.026|     0.971| #> |M2    |ATE            |Y==1 & X==1 |priors     | 0.498| 0.290|    0.024|     0.974| #> |M1    |Share_positive |-           |parameters | 0.250|    NA|    0.250|     0.250| #> |M2    |Share_positive |-           |parameters | 0.333|    NA|    0.333|     0.333| #> |M1    |Share_positive |-           |priors     | 0.256| 0.197|    0.008|     0.712| #> |M2    |Share_positive |-           |priors     | 0.337| 0.241|    0.012|     0.855| #> |M1    |Share_positive |Y==1 & X==1 |parameters | 0.500|    NA|    0.500|     0.500| #> |M2    |Share_positive |Y==1 & X==1 |parameters | 0.500|    NA|    0.500|     0.500| #> |M1    |Share_positive |Y==1 & X==1 |priors     | 0.509| 0.291|    0.026|     0.971| #> |M2    |Share_positive |Y==1 & X==1 |priors     | 0.498| 0.290|    0.024|     0.974| #>   # An example of a custom statistic: uncertainty of token causation f <- function(x) mean(x)*(1-mean(x))  query_model(   model,   using = list( \"parameters\", \"priors\"),   query = \"Y[X=1] > Y[X=0]\",   stats = c(mean = mean, sd = sd, token_variance = f)) #>  #> Causal queries generated by query_model (all at population level) #>  #> |query           |using      |  mean|    sd| token_variance| #> |:---------------|:----------|-----:|-----:|--------------:| #> |Y[X=1] > Y[X=0] |parameters | 0.250|    NA|          0.188| #> |Y[X=1] > Y[X=0] |priors     | 0.254| 0.195|          0.189| #>  # }"},{"path":"/reference/query_to_expression.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper to turn query into a data expression — query_to_expression","title":"Helper to turn query into a data expression — query_to_expression","text":"Helper turn query data expression","code":""},{"path":"/reference/query_to_expression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper to turn query into a data expression — query_to_expression","text":"","code":"query_to_expression(query, node)"},{"path":"/reference/query_to_expression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper to turn query into a data expression — query_to_expression","text":"query character string. expression defining nodal types interrogate realise_outcomes. expression form \"Y[X=1]\" asks value Y X set 1 node character string. quoted name node.","code":""},{"path":"/reference/query_to_expression.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper to turn query into a data expression — query_to_expression","text":"cleaned query expression","code":""},{"path":"/reference/realise_outcomes.html","id":null,"dir":"Reference","previous_headings":"","what":"Realise outcomes — realise_outcomes","title":"Realise outcomes — realise_outcomes","text":"Realise outcomes causal types. Calculated sequentially calculating endogenous nodes. operator applied node takes given value descendants generated accordingly.","code":""},{"path":"/reference/realise_outcomes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Realise outcomes — realise_outcomes","text":"","code":"realise_outcomes(model, dos = NULL, node = NULL, add_rownames = TRUE)"},{"path":"/reference/realise_outcomes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Realise outcomes — realise_outcomes","text":"model causal_model. model object generated make_model. dos named list. actions defining node values, e.g., list(X = 0, M = 1). node character. optional quoted name node whose outcome revealed. specified values parents need specified via dos. add_rownames logical indicating whether add causal types rownames output","code":""},{"path":"/reference/realise_outcomes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Realise outcomes — realise_outcomes","text":"data.frame object revealed data node (columns)   given causal / nodal type (rows) .","code":""},{"path":"/reference/realise_outcomes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Realise outcomes — realise_outcomes","text":"node specified outcomes realised possible causal types consistent model. node specified outcomes Y returned conditional different values parents, whether values parents obtain given restrictions model. realise_outcomes starts creating types   (via get_nodal_types). takes types endogenous   reveals outcome based value parents took.   Exogenous nodes outcomes correspond type.","code":""},{"path":"/reference/realise_outcomes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Realise outcomes — realise_outcomes","text":"","code":"# \\donttest{ make_model(\"X -> Y\") |>   realise_outcomes() #>      X Y #> 0.00 0 0 #> 1.00 1 0 #> 0.10 0 1 #> 1.10 1 0 #> 0.01 0 0 #> 1.01 1 1 #> 0.11 0 1 #> 1.11 1 1  make_model(\"X -> Y <- W\") |> set_restrictions(labels = list(X = \"1\", Y=\"0010\"), keep = TRUE) |>  realise_outcomes() #>          W X Y #> 0.1.0010 0 1 1 #> 1.1.0010 1 1 0  make_model(\"X1->Y; X2->M; M->Y\") |> realise_outcomes(dos = list(X1 = 1, M = 0)) #>             X1 X2 M Y #> 0.0.00.0000  1  0 0 0 #> 1.0.00.0000  1  0 0 0 #> 0.1.00.0000  1  1 0 0 #> 1.1.00.0000  1  1 0 0 #> 0.0.10.0000  1  0 0 0 #> 1.0.10.0000  1  0 0 0 #> 0.1.10.0000  1  1 0 0 #> 1.1.10.0000  1  1 0 0 #> 0.0.01.0000  1  0 0 0 #> 1.0.01.0000  1  0 0 0 #> 0.1.01.0000  1  1 0 0 #> 1.1.01.0000  1  1 0 0 #> 0.0.11.0000  1  0 0 0 #> 1.0.11.0000  1  0 0 0 #> 0.1.11.0000  1  1 0 0 #> 1.1.11.0000  1  1 0 0 #> 0.0.00.1000  1  0 0 0 #> 1.0.00.1000  1  0 0 0 #> 0.1.00.1000  1  1 0 0 #> 1.1.00.1000  1  1 0 0 #> 0.0.10.1000  1  0 0 0 #> 1.0.10.1000  1  0 0 0 #> 0.1.10.1000  1  1 0 0 #> 1.1.10.1000  1  1 0 0 #> 0.0.01.1000  1  0 0 0 #> 1.0.01.1000  1  0 0 0 #> 0.1.01.1000  1  1 0 0 #> 1.1.01.1000  1  1 0 0 #> 0.0.11.1000  1  0 0 0 #> 1.0.11.1000  1  0 0 0 #> 0.1.11.1000  1  1 0 0 #> 1.1.11.1000  1  1 0 0 #> 0.0.00.0100  1  0 0 1 #> 1.0.00.0100  1  0 0 1 #> 0.1.00.0100  1  1 0 1 #> 1.1.00.0100  1  1 0 1 #> 0.0.10.0100  1  0 0 1 #> 1.0.10.0100  1  0 0 1 #> 0.1.10.0100  1  1 0 1 #> 1.1.10.0100  1  1 0 1 #> 0.0.01.0100  1  0 0 1 #> 1.0.01.0100  1  0 0 1 #> 0.1.01.0100  1  1 0 1 #> 1.1.01.0100  1  1 0 1 #> 0.0.11.0100  1  0 0 1 #> 1.0.11.0100  1  0 0 1 #> 0.1.11.0100  1  1 0 1 #> 1.1.11.0100  1  1 0 1 #> 0.0.00.1100  1  0 0 1 #> 1.0.00.1100  1  0 0 1 #> 0.1.00.1100  1  1 0 1 #> 1.1.00.1100  1  1 0 1 #> 0.0.10.1100  1  0 0 1 #> 1.0.10.1100  1  0 0 1 #> 0.1.10.1100  1  1 0 1 #> 1.1.10.1100  1  1 0 1 #> 0.0.01.1100  1  0 0 1 #> 1.0.01.1100  1  0 0 1 #> 0.1.01.1100  1  1 0 1 #> 1.1.01.1100  1  1 0 1 #> 0.0.11.1100  1  0 0 1 #> 1.0.11.1100  1  0 0 1 #> 0.1.11.1100  1  1 0 1 #> 1.1.11.1100  1  1 0 1 #> 0.0.00.0010  1  0 0 0 #> 1.0.00.0010  1  0 0 0 #> 0.1.00.0010  1  1 0 0 #> 1.1.00.0010  1  1 0 0 #> 0.0.10.0010  1  0 0 0 #> 1.0.10.0010  1  0 0 0 #> 0.1.10.0010  1  1 0 0 #> 1.1.10.0010  1  1 0 0 #> 0.0.01.0010  1  0 0 0 #> 1.0.01.0010  1  0 0 0 #> 0.1.01.0010  1  1 0 0 #> 1.1.01.0010  1  1 0 0 #> 0.0.11.0010  1  0 0 0 #> 1.0.11.0010  1  0 0 0 #> 0.1.11.0010  1  1 0 0 #> 1.1.11.0010  1  1 0 0 #> 0.0.00.1010  1  0 0 0 #> 1.0.00.1010  1  0 0 0 #> 0.1.00.1010  1  1 0 0 #> 1.1.00.1010  1  1 0 0 #> 0.0.10.1010  1  0 0 0 #> 1.0.10.1010  1  0 0 0 #> 0.1.10.1010  1  1 0 0 #> 1.1.10.1010  1  1 0 0 #> 0.0.01.1010  1  0 0 0 #> 1.0.01.1010  1  0 0 0 #> 0.1.01.1010  1  1 0 0 #> 1.1.01.1010  1  1 0 0 #> 0.0.11.1010  1  0 0 0 #> 1.0.11.1010  1  0 0 0 #> 0.1.11.1010  1  1 0 0 #> 1.1.11.1010  1  1 0 0 #> 0.0.00.0110  1  0 0 1 #> 1.0.00.0110  1  0 0 1 #> 0.1.00.0110  1  1 0 1 #> 1.1.00.0110  1  1 0 1 #> 0.0.10.0110  1  0 0 1 #> 1.0.10.0110  1  0 0 1 #> 0.1.10.0110  1  1 0 1 #> 1.1.10.0110  1  1 0 1 #> 0.0.01.0110  1  0 0 1 #> 1.0.01.0110  1  0 0 1 #> 0.1.01.0110  1  1 0 1 #> 1.1.01.0110  1  1 0 1 #> 0.0.11.0110  1  0 0 1 #> 1.0.11.0110  1  0 0 1 #> 0.1.11.0110  1  1 0 1 #> 1.1.11.0110  1  1 0 1 #> 0.0.00.1110  1  0 0 1 #> 1.0.00.1110  1  0 0 1 #> 0.1.00.1110  1  1 0 1 #> 1.1.00.1110  1  1 0 1 #> 0.0.10.1110  1  0 0 1 #> 1.0.10.1110  1  0 0 1 #> 0.1.10.1110  1  1 0 1 #> 1.1.10.1110  1  1 0 1 #> 0.0.01.1110  1  0 0 1 #> 1.0.01.1110  1  0 0 1 #> 0.1.01.1110  1  1 0 1 #> 1.1.01.1110  1  1 0 1 #> 0.0.11.1110  1  0 0 1 #> 1.0.11.1110  1  0 0 1 #> 0.1.11.1110  1  1 0 1 #> 1.1.11.1110  1  1 0 1 #> 0.0.00.0001  1  0 0 0 #> 1.0.00.0001  1  0 0 0 #> 0.1.00.0001  1  1 0 0 #> 1.1.00.0001  1  1 0 0 #> 0.0.10.0001  1  0 0 0 #> 1.0.10.0001  1  0 0 0 #> 0.1.10.0001  1  1 0 0 #> 1.1.10.0001  1  1 0 0 #> 0.0.01.0001  1  0 0 0 #> 1.0.01.0001  1  0 0 0 #> 0.1.01.0001  1  1 0 0 #> 1.1.01.0001  1  1 0 0 #> 0.0.11.0001  1  0 0 0 #> 1.0.11.0001  1  0 0 0 #> 0.1.11.0001  1  1 0 0 #> 1.1.11.0001  1  1 0 0 #> 0.0.00.1001  1  0 0 0 #> 1.0.00.1001  1  0 0 0 #> 0.1.00.1001  1  1 0 0 #> 1.1.00.1001  1  1 0 0 #> 0.0.10.1001  1  0 0 0 #> 1.0.10.1001  1  0 0 0 #> 0.1.10.1001  1  1 0 0 #> 1.1.10.1001  1  1 0 0 #> 0.0.01.1001  1  0 0 0 #> 1.0.01.1001  1  0 0 0 #> 0.1.01.1001  1  1 0 0 #> 1.1.01.1001  1  1 0 0 #> 0.0.11.1001  1  0 0 0 #> 1.0.11.1001  1  0 0 0 #> 0.1.11.1001  1  1 0 0 #> 1.1.11.1001  1  1 0 0 #> 0.0.00.0101  1  0 0 1 #> 1.0.00.0101  1  0 0 1 #> 0.1.00.0101  1  1 0 1 #> 1.1.00.0101  1  1 0 1 #> 0.0.10.0101  1  0 0 1 #> 1.0.10.0101  1  0 0 1 #> 0.1.10.0101  1  1 0 1 #> 1.1.10.0101  1  1 0 1 #> 0.0.01.0101  1  0 0 1 #> 1.0.01.0101  1  0 0 1 #> 0.1.01.0101  1  1 0 1 #> 1.1.01.0101  1  1 0 1 #> 0.0.11.0101  1  0 0 1 #> 1.0.11.0101  1  0 0 1 #> 0.1.11.0101  1  1 0 1 #> 1.1.11.0101  1  1 0 1 #> 0.0.00.1101  1  0 0 1 #> 1.0.00.1101  1  0 0 1 #> 0.1.00.1101  1  1 0 1 #> 1.1.00.1101  1  1 0 1 #> 0.0.10.1101  1  0 0 1 #> 1.0.10.1101  1  0 0 1 #> 0.1.10.1101  1  1 0 1 #> 1.1.10.1101  1  1 0 1 #> 0.0.01.1101  1  0 0 1 #> 1.0.01.1101  1  0 0 1 #> 0.1.01.1101  1  1 0 1 #> 1.1.01.1101  1  1 0 1 #> 0.0.11.1101  1  0 0 1 #> 1.0.11.1101  1  0 0 1 #> 0.1.11.1101  1  1 0 1 #> 1.1.11.1101  1  1 0 1 #> 0.0.00.0011  1  0 0 0 #> 1.0.00.0011  1  0 0 0 #> 0.1.00.0011  1  1 0 0 #> 1.1.00.0011  1  1 0 0 #> 0.0.10.0011  1  0 0 0 #> 1.0.10.0011  1  0 0 0 #> 0.1.10.0011  1  1 0 0 #> 1.1.10.0011  1  1 0 0 #> 0.0.01.0011  1  0 0 0 #> 1.0.01.0011  1  0 0 0 #> 0.1.01.0011  1  1 0 0 #> 1.1.01.0011  1  1 0 0 #> 0.0.11.0011  1  0 0 0 #> 1.0.11.0011  1  0 0 0 #> 0.1.11.0011  1  1 0 0 #> 1.1.11.0011  1  1 0 0 #> 0.0.00.1011  1  0 0 0 #> 1.0.00.1011  1  0 0 0 #> 0.1.00.1011  1  1 0 0 #> 1.1.00.1011  1  1 0 0 #> 0.0.10.1011  1  0 0 0 #> 1.0.10.1011  1  0 0 0 #> 0.1.10.1011  1  1 0 0 #> 1.1.10.1011  1  1 0 0 #> 0.0.01.1011  1  0 0 0 #> 1.0.01.1011  1  0 0 0 #> 0.1.01.1011  1  1 0 0 #> 1.1.01.1011  1  1 0 0 #> 0.0.11.1011  1  0 0 0 #> 1.0.11.1011  1  0 0 0 #> 0.1.11.1011  1  1 0 0 #> 1.1.11.1011  1  1 0 0 #> 0.0.00.0111  1  0 0 1 #> 1.0.00.0111  1  0 0 1 #> 0.1.00.0111  1  1 0 1 #> 1.1.00.0111  1  1 0 1 #> 0.0.10.0111  1  0 0 1 #> 1.0.10.0111  1  0 0 1 #> 0.1.10.0111  1  1 0 1 #> 1.1.10.0111  1  1 0 1 #> 0.0.01.0111  1  0 0 1 #> 1.0.01.0111  1  0 0 1 #> 0.1.01.0111  1  1 0 1 #> 1.1.01.0111  1  1 0 1 #> 0.0.11.0111  1  0 0 1 #> 1.0.11.0111  1  0 0 1 #> 0.1.11.0111  1  1 0 1 #> 1.1.11.0111  1  1 0 1 #> 0.0.00.1111  1  0 0 1 #> 1.0.00.1111  1  0 0 1 #> 0.1.00.1111  1  1 0 1 #> 1.1.00.1111  1  1 0 1 #> 0.0.10.1111  1  0 0 1 #> 1.0.10.1111  1  0 0 1 #> 0.1.10.1111  1  1 0 1 #> 1.1.10.1111  1  1 0 1 #> 0.0.01.1111  1  0 0 1 #> 1.0.01.1111  1  0 0 1 #> 0.1.01.1111  1  1 0 1 #> 1.1.01.1111  1  1 0 1 #> 0.0.11.1111  1  0 0 1 #> 1.0.11.1111  1  0 0 1 #> 0.1.11.1111  1  1 0 1 #> 1.1.11.1111  1  1 0 1  # With node specified make_model(\"X->M->Y\") |> realise_outcomes(node = \"Y\") #>      M Y #> 0.00 0 0 #> 1.00 1 0 #> 0.10 0 1 #> 1.10 1 0 #> 0.01 0 0 #> 1.01 1 1 #> 0.11 0 1 #> 1.11 1 1  make_model(\"X->M->Y\") |> realise_outcomes(dos = list(M = 1), node = \"Y\") #>      M Y #> 1.00 1 0 #> 1.10 1 0 #> 1.01 1 1 #> 1.11 1 1 # }"},{"path":"/reference/restrict_by_labels.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduce nodal types using labels — restrict_by_labels","title":"Reduce nodal types using labels — restrict_by_labels","text":"Reduce nodal types using labels","code":""},{"path":"/reference/restrict_by_labels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduce nodal types using labels — restrict_by_labels","text":"","code":"restrict_by_labels(model, labels, given = NULL, keep = FALSE)"},{"path":"/reference/restrict_by_labels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduce nodal types using labels — restrict_by_labels","text":"model causal_model. model object generated make_model. labels list character vectors specifying nodal types kept removed model. given character vector list character vectors specifying nodes parameter set restricted depends. mixing labels restricted given ones , labels without given restrictions given specified one NULL, NA, \"\" \" \". keep Logical. `FALSE`, removes `TRUE` keeps causal types specified restriction.","code":""},{"path":"/reference/restrict_by_labels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reduce nodal types using labels — restrict_by_labels","text":"list two components: 1. vector parameters names   parameters implicated restrictions, 2. vector subsetting   instructions used identify implicated causal types","code":""},{"path":[]},{"path":"/reference/restrict_by_query.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduce nodal types using statement — restrict_by_query","title":"Reduce nodal types using statement — restrict_by_query","text":"Reduce nodal types using statement","code":""},{"path":"/reference/restrict_by_query.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduce nodal types using statement — restrict_by_query","text":"","code":"restrict_by_query(model, statement, join_by = \"|\", given = NULL, keep = FALSE)"},{"path":"/reference/restrict_by_query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduce nodal types using statement — restrict_by_query","text":"model model created make_model() statement list character vectors specifying nodal types removed model. Use get_nodal_types see syntax. join_by string list strings. logical operator joining expanded types statement contains wildcard (.). Can take values '&' (logical ) '|' (logical ). restriction contains wildcard (.) join_by specified, defaults '|', otherwise defaults NULL. given character vector list character vectors specifying nodes parameter set restricted depends. given must either NULL length statement. mixing statements restricted given ones , statements without given restrictions given specified one NULL, NA, \"\" \" \". keep Logical. `FALSE`, removes `TRUE` keeps causal types specified restriction.","code":""},{"path":"/reference/restrict_by_query.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reduce nodal types using statement — restrict_by_query","text":"list two components: 1. vector parameters names   parameters implicated restrictions, 2. vector subsetting   instructions used identify implicated causal types","code":""},{"path":[]},{"path":"/reference/reveal_outcomes.html","id":null,"dir":"Reference","previous_headings":"","what":"Reveal outcomes — reveal_outcomes","title":"Reveal outcomes — reveal_outcomes","text":"`r lifecycle::badge(\"deprecated\")` function deprecated name causes clashes DeclareDesign. Use realise_outcomes instead.","code":""},{"path":"/reference/reveal_outcomes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reveal outcomes — reveal_outcomes","text":"","code":"reveal_outcomes(model, dos = NULL, node = NULL)"},{"path":"/reference/set_ambiguities_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Set ambiguity matrix — set_ambiguities_matrix","title":"Set ambiguity matrix — set_ambiguities_matrix","text":"Add ambiguities matrix model","code":""},{"path":"/reference/set_ambiguities_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set ambiguity matrix — set_ambiguities_matrix","text":"","code":"set_ambiguities_matrix(model, A = NULL)"},{"path":"/reference/set_ambiguities_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set ambiguity matrix — set_ambiguities_matrix","text":"model causal_model. model object generated make_model. data.frame. Ambiguity matrix. required may provided avoid repeated computation simulations.","code":""},{"path":"/reference/set_ambiguities_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set ambiguity matrix — set_ambiguities_matrix","text":"object type causal_model   ambiguities matrix attached","code":""},{"path":"/reference/set_ambiguities_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set ambiguity matrix — set_ambiguities_matrix","text":"","code":"model <- make_model('X -> Y') %>%          set_ambiguities_matrix() #> Error in set_ambiguities_matrix(.): could not find function \"set_ambiguities_matrix\" model$A #> Error in eval(expr, envir, enclos): object 'model' not found"},{"path":"/reference/set_confound.html","id":null,"dir":"Reference","previous_headings":"","what":"Set confound — set_confound","title":"Set confound — set_confound","text":"Adjust parameter matrix allow confounding.","code":""},{"path":"/reference/set_confound.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set confound — set_confound","text":"","code":"set_confound(model, confound = NULL)"},{"path":"/reference/set_confound.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set confound — set_confound","text":"model causal_model. model object generated make_model. confound list statements indicating pairs nodes whose types jointly distributed (e.g. list(\"<-> B\", \"C <-> D\")).","code":""},{"path":"/reference/set_confound.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set confound — set_confound","text":"object class causal_model updated parameters_df   parameter matrix.","code":""},{"path":"/reference/set_confound.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set confound — set_confound","text":"Confounding X Y arises nodal types X Y independently distributed. X -> Y graph, instance, 2 nodal types X 4 Y. thus 8 joint nodal types: table 8 interior elements unconstrained joint distribution 7 degrees freedom. confounding assumption means Pr(t^X | t^Y) = Pr(t^X),  Pr(t^X, t^Y) = Pr(t^X)Pr(t^Y). case 3 degrees freedom Y 1 X, totaling 4 rather 7. set_confound lets relax assumption increasing number parameters characterizing joint distribution. Using fact P(,B) = P()P(B|) new parameters introduced capture P(B|=) rather simply P(B). instance two parameters (one degree freedom) govern distribution types X  four parameters (3 degrees freedom) govern  types Y given type X total 1+3+3 = 7 degrees freedom.","code":"|          | t^X                |                    |           | |-----|----|--------------------|--------------------|-----------| |     |    | 0                  | 1                  | Sum       | |-----|----|--------------------|--------------------|-----------| | t^Y | 00 | Pr(t^X=0 & t^Y=00) | Pr(t^X=1 & t^Y=00) | Pr(t^Y=00)| |     | 10 | .                  | .                  | .         | |     | 01 | .                  | .                  | .         | |     | 11 | .                  | .                  | .         | |-----|----|--------------------|--------------------|-----------| |     |Sum | Pr(t^X=0)          | Pr(t^X=1)          | 1         |"},{"path":"/reference/set_confound.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set confound — set_confound","text":"","code":"make_model('X -> Y; X <-> Y') |> get_parameters() #> Error in get_parameters(make_model(\"X -> Y; X <-> Y\")): could not find function \"get_parameters\"  make_model('X -> M -> Y; X <-> Y') |> get_parameters() #> Error in get_parameters(make_model(\"X -> M -> Y; X <-> Y\")): could not find function \"get_parameters\"  model <- make_model('X -> M -> Y; X <-> Y; M <-> Y') model$parameters_df #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>  #>  first 10 rows:  #>      param_names node gen  param_set nodal_type     given param_value priors #> 1            X.0    X   1          X          0                  0.50      1 #> 2            X.1    X   1          X          1                  0.50      1 #> 3           M.00    M   2          M         00                  0.25      1 #> 4           M.10    M   2          M         10                  0.25      1 #> 5           M.01    M   2          M         01                  0.25      1 #> 6           M.11    M   2          M         11                  0.25      1 #> 7  Y.00_M.00_X.0    Y   3 Y.M.00.X.0         00 M.00, X.0        0.25      1 #> 8  Y.10_M.00_X.0    Y   3 Y.M.00.X.0         10 M.00, X.0        0.25      1 #> 9  Y.01_M.00_X.0    Y   3 Y.M.00.X.0         01 M.00, X.0        0.25      1 #> 10 Y.11_M.00_X.0    Y   3 Y.M.00.X.0         11 M.00, X.0        0.25      1  # Example where set_confound is implemented after restrictions make_model(\"A -> B -> C\") |> set_restrictions(increasing(\"A\", \"B\")) |> set_confound(\"B <-> C\") |> get_parameters() #> Error in get_parameters(set_confound(set_restrictions(make_model(\"A -> B -> C\"),     increasing(\"A\", \"B\")), \"B <-> C\")): could not find function \"get_parameters\"  # Example where two parents are confounded make_model('A -> B <- C; A <-> C') |>   set_parameters(node = \"C\", c(0.05, .95, .95, 0.05)) |>   make_data(n = 50) |>   cor() #> Warning: A specified condition matches multiple parameters. In these cases it is unclear which parameter value should be assigned to which parameter. Assignment thus defaults to the order in which parameters appear in 'parameters_df'. We advise checking that parameter assignment was carried out as you intended.  #> Warning: You are altering parameters on confounded nodes. Alterations will be applied across all 'param_sets'. If this is not the alteration behavior you intended, try specifying the 'param_set' or 'given' option to more clearly indicate parameters whose values you wish to alter. #>             A           C           B #> A  1.00000000 -0.91987179 -0.08353438 #> C -0.91987179  1.00000000  0.08353438 #> B -0.08353438  0.08353438  1.00000000   # Example with two confounds, added sequentially model <- make_model('A -> B -> C') |>   set_confound(list(\"A <-> B\", \"B <-> C\")) model$statement #> [1] \"A -> B -> C; B <-> A; C <-> B\" # plot(model)"},{"path":"/reference/set_parameter_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Set parameter matrix — set_parameter_matrix","title":"Set parameter matrix — set_parameter_matrix","text":"Add parameter matrix model","code":""},{"path":"/reference/set_parameter_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set parameter matrix — set_parameter_matrix","text":"","code":"set_parameter_matrix(model, P = NULL)"},{"path":"/reference/set_parameter_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set parameter matrix — set_parameter_matrix","text":"model causal_model. model object generated make_model. P data.frame. Parameter matrix. required may provided avoid repeated computation simulations.","code":""},{"path":"/reference/set_parameter_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set parameter matrix — set_parameter_matrix","text":"object class causal_model. essentially returns   list containing elements comprising model   (e.g. 'statement', 'nodal_types' 'DAG') parameter matrix   attached .","code":""},{"path":"/reference/set_parameter_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set parameter matrix — set_parameter_matrix","text":"","code":"model <- make_model('X -> Y') P <- diag(8) colnames(P) <- rownames(model$causal_types) model <- set_parameter_matrix(model, P = P)"},{"path":"/reference/set_parmap.html","id":null,"dir":"Reference","previous_headings":"","what":"Set parmap: a matrix mapping from parameters to data types — set_parmap","title":"Set parmap: a matrix mapping from parameters to data types — set_parmap","text":"Generates adds parmap model","code":""},{"path":"/reference/set_parmap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set parmap: a matrix mapping from parameters to data types — set_parmap","text":"","code":"set_parmap(model)"},{"path":"/reference/set_parmap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set parmap: a matrix mapping from parameters to data types — set_parmap","text":"model causal_model. model object generated make_model.","code":""},{"path":"/reference/set_parmap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set parmap: a matrix mapping from parameters to data types — set_parmap","text":"matrix","code":""},{"path":"/reference/set_parmap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set parmap: a matrix mapping from parameters to data types — set_parmap","text":"","code":"set_parmap(model = make_model('X->Y')) #> Error in set_parmap(model = make_model(\"X->Y\")): could not find function \"set_parmap\""},{"path":"/reference/set_prior_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Add prior distribution draws — set_prior_distribution","title":"Add prior distribution draws — set_prior_distribution","text":"Add `n_param x n_draws` database possible parameter draws model.","code":""},{"path":"/reference/set_prior_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add prior distribution draws — set_prior_distribution","text":"","code":"set_prior_distribution(model, n_draws = 4000)"},{"path":"/reference/set_prior_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add prior distribution draws — set_prior_distribution","text":"model causal_model. model object generated make_model. n_draws scalar. Number draws.","code":""},{"path":"/reference/set_prior_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add prior distribution draws — set_prior_distribution","text":"object class causal_model `prior_distribution`   attached .","code":""},{"path":[]},{"path":"/reference/set_prior_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add prior distribution draws — set_prior_distribution","text":"","code":"make_model('X -> Y') %>%   set_prior_distribution(n_draws = 5) %>%   get_prior_distribution() #> Error in get_prior_distribution(.): could not find function \"get_prior_distribution\""},{"path":"/reference/set_restrictions.html","id":null,"dir":"Reference","previous_headings":"","what":"Restrict a model — set_restrictions","title":"Restrict a model — set_restrictions","text":"Restrict model's parameter space. reduces number nodal types consequence number unit causal types.","code":""},{"path":"/reference/set_restrictions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Restrict a model — set_restrictions","text":"","code":"set_restrictions(   model,   statement = NULL,   join_by = \"|\",   labels = NULL,   param_names = NULL,   given = NULL,   keep = FALSE )"},{"path":"/reference/set_restrictions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Restrict a model — set_restrictions","text":"model causal_model. model object generated make_model. statement quoted expressions defining restriction. values parents specified, statements surrounded parentheses, instance (Y[= 1] > Y[=0]) interpreted combinations parents Y set possible levels might take. join_by string. logical operator joining expanded types statement contains wildcard (.). Can take values '&' (logical ) '|' (logical ). restriction contains wildcard (.) join_by specified, defaults '|', otherwise defaults NULL. Note join_by joins within statements, across statements. labels list character vectors specifying nodal types kept removed model. Use get_nodal_types see syntax. Note labels gets overwritten statement statement NULL. param_names character vector names parameters restrict . given character vector list character vectors specifying nodes parameter set restricted depends. restricting statement, given must either NULL length statement. mixing statements restricted given ones , statements without given restrictions given specified one NULL, NA, \"\" \" \". keep Logical. `FALSE`, removes `TRUE` keeps causal types specified statement labels.","code":""},{"path":"/reference/set_restrictions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Restrict a model — set_restrictions","text":"object class model. causal types nodal types   model reduced according stated restriction.","code":""},{"path":"/reference/set_restrictions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Restrict a model — set_restrictions","text":"Restrictions made nodal types, unit causal types. Thus instance model X -> M -> Y, one apply simple restriction Y nondecreasing  X, however one can restrict M nondecreasing X Y nondecreasing M. restriction Y nondecreasing X otherwise require restrictions causal types, nodal types, implies form undeclared confounding (.e. cases M decreasing X, Y decreasing M). Since restrictions nodal types, parents node implicitly fixed.  Thus model make_model(`X -> Y <- W`) request set_restrictions(`(Y[X=1] == 0)`) interpreted set_restrictions(`(Y[X=1, W=0] == 0 | Y[X=1, W=1] == 0)`). Statements implicitly controlled nodes surrounded parentheses, examples. Note prior probabilities redistributed remaining types.","code":""},{"path":[]},{"path":"/reference/set_restrictions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Restrict a model — set_restrictions","text":"","code":"# 1. Restrict parameter space using statements model <- make_model('X->Y') %>%   set_restrictions(statement = c('X[] == 0'))  model <- make_model('X->Y') %>%   set_restrictions(non_increasing('X', 'Y'))  model <- make_model('X -> Y <- W') %>%   set_restrictions(c(decreasing('X', 'Y'), substitutes('X', 'W', 'Y')))  model$parameters_df #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>  #>  first 10 rows:  #>    param_names node gen param_set nodal_type given param_value priors #> 1          W.0    W   1         W          0         0.5000000      1 #> 2          W.1    W   1         W          1         0.5000000      1 #> 3          X.0    X   2         X          0         0.5000000      1 #> 4          X.1    X   2         X          1         0.5000000      1 #> 5       Y.0000    Y   3         Y       0000         0.1428571      1 #> 10      Y.1010    Y   3         Y       1010         0.1428571      1 #> 13      Y.0001    Y   3         Y       0001         0.1428571      1 #> 15      Y.0101    Y   3         Y       0101         0.1428571      1 #> 17      Y.0011    Y   3         Y       0011         0.1428571      1 #> 18      Y.1011    Y   3         Y       1011         0.1428571      1  model <- make_model('X-> Y <- W') %>%   set_restrictions(statement = decreasing('X', 'Y')) model$parameters_df #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>  #>  first 10 rows:  #>    param_names node gen param_set nodal_type given param_value priors #> 1          W.0    W   1         W          0         0.5000000      1 #> 2          W.1    W   1         W          1         0.5000000      1 #> 3          X.0    X   2         X          0         0.5000000      1 #> 4          X.1    X   2         X          1         0.5000000      1 #> 5       Y.0000    Y   3         Y       0000         0.1111111      1 #> 9       Y.0010    Y   3         Y       0010         0.1111111      1 #> 10      Y.1010    Y   3         Y       1010         0.1111111      1 #> 13      Y.0001    Y   3         Y       0001         0.1111111      1 #> 15      Y.0101    Y   3         Y       0101         0.1111111      1 #> 17      Y.0011    Y   3         Y       0011         0.1111111      1  model <- make_model('X->Y') %>%   set_restrictions(decreasing('X', 'Y')) model$parameters_df #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>   param_names node gen param_set nodal_type given param_value priors #> 1         X.0    X   1         X          0         0.5000000      1 #> 2         X.1    X   1         X          1         0.5000000      1 #> 3        Y.00    Y   2         Y         00         0.3333333      1 #> 5        Y.01    Y   2         Y         01         0.3333333      1 #> 6        Y.11    Y   2         Y         11         0.3333333      1  model <- make_model('X->Y') %>%   set_restrictions(c(increasing('X', 'Y'), decreasing('X', 'Y'))) model$parameters_df #> Mapping of model parameters to nodal types:  #>  #> ---------------------------------------------------------------- #>  #>  param_names: name of parameter #>  node: name of endogeneous node associated with the parameter #>  gen: partial causal ordering of the parameter's node #>  param_set: parameter groupings forming a simplex #>  given: if model has confounding gives conditioning nodal type #>  param_value: parameter values #>  priors: hyperparameters of the prior Dirichlet distribution  #>  #> ---------------------------------------------------------------- #>  #>   param_names node gen param_set nodal_type given param_value priors #> 1         X.0    X   1         X          0               0.5      1 #> 2         X.1    X   1         X          1               0.5      1 #> 3        Y.00    Y   2         Y         00               0.5      1 #> 6        Y.11    Y   2         Y         11               0.5      1 # \\donttest{ # Restrict to define a model with monotonicity model <- make_model('X->Y') %>% set_restrictions(statement = c('Y[X=1] < Y[X=0]')) get_parameter_matrix(model) #> Error in get_parameter_matrix(model): could not find function \"get_parameter_matrix\"  # Restrict to a single type in endogenous node model <- make_model('X->Y') %>% set_restrictions(statement =  '(Y[X = 1] == 1)', join_by = '&', keep = TRUE) get_parameter_matrix(model) #> Error in get_parameter_matrix(model): could not find function \"get_parameter_matrix\"  #  Use of | and & # Keep node if *for some value of B* Y[A = 1] == 1 model <- make_model('A->Y<-B') %>% set_restrictions(statement =  '(Y[A = 1] == 1)', join_by = '|', keep = TRUE) dim(get_parameter_matrix(model)) #> Error in get_parameter_matrix(model): could not find function \"get_parameter_matrix\"   # Keep node if *for all values of B* Y[A = 1] == 1 model <- make_model('A->Y<-B') %>% set_restrictions(statement =  '(Y[A = 1] == 1)', join_by = '&', keep = TRUE) dim(get_parameter_matrix(model)) #> Error in get_parameter_matrix(model): could not find function \"get_parameter_matrix\"  # Restrict multiple nodes model <- make_model('X->Y<-M; X -> M' ) %>% set_restrictions(statement =  c('(Y[X = 1] == 1)', '(M[X = 1] == 1)'),                  join_by = '&', keep = TRUE) get_parameter_matrix(model) #> Error in get_parameter_matrix(model): could not find function \"get_parameter_matrix\"  # Restrict using statements and given: model <- make_model(\"X -> Y -> Z; X <-> Z\") %>%  set_restrictions(list(decreasing('X','Y'), decreasing('Y','Z')),                   given = c(NA,'X.0')) get_parameter_matrix(model) #> Error in get_parameter_matrix(model): could not find function \"get_parameter_matrix\"  # Restrictions on levels for endogenous nodes aren't allowed if (FALSE) { model <- make_model('X->Y') %>% set_restrictions(statement =  '(Y == 1)') }  # 2. Restrict parameter space Using labels: model <- make_model('X->Y') %>% set_restrictions(labels = list(X = '0', Y = '00'))  # Restrictions can be  with wildcards model <- make_model('X->Y') %>% set_restrictions(labels = list(Y = '?0')) get_parameter_matrix(model) #> Error in get_parameter_matrix(model): could not find function \"get_parameter_matrix\"  # Deterministic model model <- make_model('S -> C -> Y <- R <- X; X -> C -> R') %>% set_restrictions(labels = list(C = '1000', R = '0001', Y = '0001'),                  keep = TRUE) get_parameter_matrix(model) #> Error in get_parameter_matrix(model): could not find function \"get_parameter_matrix\"  # Restrict using labels and given: model <- make_model(\"X -> Y -> Z; X <-> Z\") %>%  set_restrictions(labels = list(X = '0', Z = '00'), given = c(NA,'X.0')) get_parameter_matrix(model) #> Error in get_parameter_matrix(model): could not find function \"get_parameter_matrix\" # }"},{"path":"/reference/set_sampling_args.html","id":null,"dir":"Reference","previous_headings":"","what":"set_sampling_args\r\nFrom 'rstanarm' (November 1st, 2019) — set_sampling_args","title":"set_sampling_args\r\nFrom 'rstanarm' (November 1st, 2019) — set_sampling_args","text":"set_sampling_args 'rstanarm' (November 1st, 2019)","code":""},{"path":"/reference/set_sampling_args.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"set_sampling_args\r\nFrom 'rstanarm' (November 1st, 2019) — set_sampling_args","text":"","code":"set_sampling_args(object, user_dots = list(), user_adapt_delta = NULL, ...)"},{"path":"/reference/set_sampling_args.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"set_sampling_args\r\nFrom 'rstanarm' (November 1st, 2019) — set_sampling_args","text":"object stanfit object. user_dots list. User commands. user_adapt_delta double 0 1. Adapt delta passed user ... arguments passed 'stan'","code":""},{"path":"/reference/set_sampling_args.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"set_sampling_args\r\nFrom 'rstanarm' (November 1st, 2019) — set_sampling_args","text":"list arguments passed stan","code":""},{"path":"/reference/set_sampling_args.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"set_sampling_args\r\nFrom 'rstanarm' (November 1st, 2019) — set_sampling_args","text":"Set sampling arguments","code":""},{"path":"/reference/simulate_data.html","id":null,"dir":"Reference","previous_headings":"","what":"simulate_data is an alias for make_data — simulate_data","title":"simulate_data is an alias for make_data — simulate_data","text":"simulate_data alias make_data","code":""},{"path":"/reference/simulate_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"simulate_data is an alias for make_data — simulate_data","text":"","code":"simulate_data(...)"},{"path":"/reference/simulate_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"simulate_data is an alias for make_data — simulate_data","text":"... arguments make_model","code":""},{"path":"/reference/simulate_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"simulate_data is an alias for make_data — simulate_data","text":"data.frame simulated data.","code":""},{"path":"/reference/simulate_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"simulate_data is an alias for make_data — simulate_data","text":"","code":"simulate_data(make_model(\"X->Y\")) #>   X Y #> 1 0 1"},{"path":"/reference/st_within.html","id":null,"dir":"Reference","previous_headings":"","what":"Get string between two regular expression patterns — st_within","title":"Get string between two regular expression patterns — st_within","text":"Returns substring enclosed two regular expression patterns. default returns name arguments indexed squared brackets ([]) string containing expression.","code":""},{"path":"/reference/st_within.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get string between two regular expression patterns — st_within","text":"","code":"st_within(   x,   left = \"[^_[:^punct:]]|\\\\b\",   right = \"\\\\[\",   rm_left = 0,   rm_right = -1 )"},{"path":"/reference/st_within.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get string between two regular expression patterns — st_within","text":"x character string. left character string. Regular expression serve look ahead. right character string. Regular expression serve look behind. rm_left integer. Number bites left-side match remove result. Defaults -1. rm_right integer. Number bites right-side match remove result. Defaults 0.","code":""},{"path":"/reference/st_within.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get string between two regular expression patterns — st_within","text":"character vector.","code":""},{"path":"/reference/st_within.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get string between two regular expression patterns — st_within","text":"","code":"a <- '(XX[Y=0] == 1) > (XX[Y=1] == 0)' CausalQueries:::st_within(a) #> [1] \"XX\" \"XX\" b <- '(XXX[[Y=0]] == 1 + XXX[[Y=1]] == 0)' CausalQueries:::st_within(b) #> [1] \"XXX\" \"XXX\""},{"path":"/reference/substitutes.html","id":null,"dir":"Reference","previous_headings":"","what":"Make statement for substitutes — substitutes","title":"Make statement for substitutes — substitutes","text":"Generate statement X1, X1 substitute production Y","code":""},{"path":"/reference/substitutes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make statement for substitutes — substitutes","text":"","code":"substitutes(X1, X2, Y)"},{"path":"/reference/substitutes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make statement for substitutes — substitutes","text":"X1 character. quoted name input node 1. X2 character. quoted name input node 2. Y character. quoted name outcome node.","code":""},{"path":"/reference/substitutes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make statement for substitutes — substitutes","text":"character statement class statement","code":""},{"path":[]},{"path":"/reference/substitutes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make statement for substitutes — substitutes","text":"","code":"# \\donttest{ get_query_types(model = make_model('A -> B <- C'),          query = substitutes('A', 'C', 'B'),map = \"causal_type\") #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  ((B[A=1,C=1])-(B[A=0,C=1]))<((B[A=1,C=0])-(B[A=0,C=0]))  #>  #> A0.C0.B0100  A1.C0.B0100 #> A0.C1.B0100  A1.C1.B0100 #> A0.C0.B0010  A1.C0.B0010 #> A0.C1.B0010  A1.C1.B0010 #> A0.C0.B0110  A1.C0.B0110 #> A0.C1.B0110  A1.C1.B0110 #> A0.C0.B1110  A1.C0.B1110 #> A0.C1.B1110  A1.C1.B1110 #> A0.C0.B0111  A1.C0.B0111 #> A0.C1.B0111  A1.C1.B0111 #>  #>  #>  Number of causal types that meet condition(s) =  20 #>  Total number of causal types in model =  64  query_model(model = make_model('A -> B <- C'),          queries = substitutes('A', 'C', 'B'),          using = 'parameters') #>  #> Causal queries generated by query_model (all at population level) #>  #> |query                                                                             |using      |  mean| #> |:---------------------------------------------------------------------------------|:----------|-----:| #> |((B[A = 1, C = 1]) - (B[A = 0, C = 1])) < ((B[A = 1, C = 0]) - (B[A = 0, C = 0])) |parameters | 0.312| #>  # }"},{"path":"/reference/summarise_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"helper to compute mean and sd of a distribution data.frame — summarise_distribution","title":"helper to compute mean and sd of a distribution data.frame — summarise_distribution","text":"helper compute mean sd distribution data.frame","code":""},{"path":"/reference/summarise_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"helper to compute mean and sd of a distribution data.frame — summarise_distribution","text":"","code":"summarise_distribution(x)"},{"path":"/reference/summarise_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"helper to compute mean and sd of a distribution data.frame — summarise_distribution","text":"x object summarizing","code":""},{"path":"/reference/summary.causal_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing causal models — summary.causal_model","title":"Summarizing causal models — summary.causal_model","text":"summary method class causal_model.","code":""},{"path":"/reference/summary.causal_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing causal models — summary.causal_model","text":"","code":"# S3 method for causal_model summary(object, ...)  # S3 method for summary.causal_model print(x, stanfit = FALSE, ...)"},{"path":"/reference/summary.causal_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing causal models — summary.causal_model","text":"object object causal_model class produced using make_model update_model. ... arguments passed methods. x object summary.causal_model class, usually result call summary.causal_model. stanfit Logical. Whether include readable summary stanfit produced updating model via update_model. Defaults `FALSE`.","code":""},{"path":"/reference/summary.causal_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarizing causal models — summary.causal_model","text":"print.summary.causal_model reports DAG data frame, full specification nodal types summary model restrictions addition standard print.causal_model output.","code":""},{"path":"/reference/te.html","id":null,"dir":"Reference","previous_headings":"","what":"Make treatment effect statement (positive) — te","title":"Make treatment effect statement (positive) — te","text":"Generate statement (Y(1) - Y(0)). statement applied model returns element (1,0,-1) set cases. useful purposes querying model, uses require list types, set_restrictions.","code":""},{"path":"/reference/te.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make treatment effect statement (positive) — te","text":"","code":"te(X, Y)"},{"path":"/reference/te.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make treatment effect statement (positive) — te","text":"X character. quoted name input node Y character. quoted name outcome node","code":""},{"path":"/reference/te.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make treatment effect statement (positive) — te","text":"character statement class statement","code":""},{"path":[]},{"path":"/reference/te.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make treatment effect statement (positive) — te","text":"","code":"# \\donttest{ te('A', 'B') #>  #> Statement:  #> (B[A=1] - B[A=0])  model <- make_model('X->Y') %>% set_restrictions(increasing('X', 'Y')) query_model(model, list(ate = te('X', 'Y')),  using = 'parameters') #>  #> Causal queries generated by query_model (all at population level) #>  #> |query |using      |   mean| #> |:-----|:----------|------:| #> |ate   |parameters | -0.333| #>   # set_restrictions  breaks with te because it requires a listing # of causal types, not numeric output. # } if (FALSE) { model <- make_model('X->Y') %>% set_restrictions(te('X', 'Y')) }"},{"path":"/reference/type_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate type matrix — type_matrix","title":"Generate type matrix — type_matrix","text":"Generate type matrix","code":""},{"path":"/reference/type_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate type matrix — type_matrix","text":"","code":"type_matrix(parent_n)"},{"path":"/reference/type_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate type matrix — type_matrix","text":"parent_n integer. Number parents given child.","code":""},{"path":"/reference/type_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate type matrix — type_matrix","text":"data.frame whose rows contain digits   causal types model","code":""},{"path":"/reference/type_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate type matrix — type_matrix","text":"","code":"# \\donttest{ CausalQueries:::type_matrix(2) #>    00 10 01 11 #> 1   0  0  0  0 #> 2   1  0  0  0 #> 3   0  1  0  0 #> 4   1  1  0  0 #> 5   0  0  1  0 #> 6   1  0  1  0 #> 7   0  1  1  0 #> 8   1  1  1  0 #> 9   0  0  0  1 #> 10  1  0  0  1 #> 11  0  1  0  1 #> 12  1  1  0  1 #> 13  0  0  1  1 #> 14  1  0  1  1 #> 15  0  1  1  1 #> 16  1  1  1  1 # }"},{"path":"/reference/uncollapse_nodal_types.html","id":null,"dir":"Reference","previous_headings":"","what":"uncollapse nodal types — uncollapse_nodal_types","title":"uncollapse nodal types — uncollapse_nodal_types","text":"uncollapse nodal types","code":""},{"path":"/reference/uncollapse_nodal_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"uncollapse nodal types — uncollapse_nodal_types","text":"","code":"uncollapse_nodal_types(nodal_types)"},{"path":"/reference/uncollapse_nodal_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"uncollapse nodal types — uncollapse_nodal_types","text":"nodal_types list nodal types collapsed form ('01', '11') etc..","code":""},{"path":"/reference/uncollapse_nodal_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"uncollapse nodal types — uncollapse_nodal_types","text":"list containing nodes nodal types data.frame form","code":""},{"path":"/reference/uncollapse_nodal_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"uncollapse nodal types — uncollapse_nodal_types","text":"","code":"model <- make_model('X -> K -> Y') (nodal_types <- get_nodal_types(model , collapse = TRUE)) #> Error in get_nodal_types(model, collapse = TRUE): could not find function \"get_nodal_types\" CausalQueries:::uncollapse_nodal_types(nodal_types) #> Error in lapply(nodal_types, stringr::str_split, \"\"): object 'nodal_types' not found"},{"path":"/reference/unpack_wildcard.html","id":null,"dir":"Reference","previous_headings":"","what":"Unpack a wild card — unpack_wildcard","title":"Unpack a wild card — unpack_wildcard","text":"Unpack wild card","code":""},{"path":"/reference/unpack_wildcard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unpack a wild card — unpack_wildcard","text":"","code":"unpack_wildcard(x)"},{"path":"/reference/unpack_wildcard.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unpack a wild card — unpack_wildcard","text":"x character. nodal type containing one wildcard characters '?' unpacked.","code":""},{"path":"/reference/unpack_wildcard.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unpack a wild card — unpack_wildcard","text":"type label wildcard characters '?' substituted 0 1.","code":""},{"path":"/reference/update_causal_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Update causal types based on nodal types — update_causal_types","title":"Update causal types based on nodal types — update_causal_types","text":"Update causal types based nodal types","code":""},{"path":"/reference/update_causal_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update causal types based on nodal types — update_causal_types","text":"","code":"update_causal_types(model, restrict_given = NULL)"},{"path":"/reference/update_causal_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update causal types based on nodal types — update_causal_types","text":"model causal_model. model object generated make_model. restrict_given character vector subsetting instructions rows dropped causal types data.frame.","code":""},{"path":"/reference/update_causal_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update causal types based on nodal types — update_causal_types","text":"data.frame containing updated causal types model","code":""},{"path":"/reference/update_causal_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update causal types based on nodal types — update_causal_types","text":"","code":"CausalQueries:::update_causal_types(make_model('X->Y')) #>  #> Causal Types:  #> cartesian product of nodal types #>  #>        X  Y #> X0.Y00 0 00 #> X1.Y00 1 00 #> X0.Y10 0 10 #> X1.Y10 1 10 #> X0.Y01 0 01 #> X1.Y01 1 01 #> X0.Y11 0 11 #> X1.Y11 1 11"},{"path":"/reference/update_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit causal model using 'stan' — update_model","title":"Fit causal model using 'stan' — update_model","text":"Takes model data returns model object data attached posterior model","code":""},{"path":"/reference/update_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit causal model using 'stan' — update_model","text":"","code":"update_model(   model,   data = NULL,   data_type = NULL,   keep_type_distribution = TRUE,   keep_event_probabilities = FALSE,   keep_fit = FALSE,   censored_types = NULL,   ... )"},{"path":"/reference/update_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit causal model using 'stan' — update_model","text":"model causal_model. model object generated make_model. data data.frame.  Data nodes can take three values: 0, 1, NA. long form generated make_events data_type Either 'long' (made make_data) 'compact' (made collapse_data). Compact data must entries member strategy family produce valid simplex. long form data provided missingness, missing data assumed missing random. keep_type_distribution Logical. Whether keep (transformed) distribution causal types.  Defaults `TRUE` keep_event_probabilities Logical. Whether keep (transformed) distribution event probabilities. Defaults `FALSE` keep_fit Logical. Whether keep stanfit object produced rstan::sampling inspection. See ?stanfit details. Defaults `FALSE`. Note  stanfit object internal names parameters (lambda), event probabilities (w), type distribution (types) censored_types vector data types selected data, e.g. c(\"X0Y0\") ... Options passed onto sampling call. details see ?rstan::sampling","code":""},{"path":"/reference/update_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit causal model using 'stan' — update_model","text":"object class causal_model. returned model   list containing elements comprising model   (e.g. 'statement', 'nodal_types' 'DAG')  posterior_distribution returned stan attached .","code":""},{"path":[]},{"path":"/reference/update_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit causal model using 'stan' — update_model","text":"","code":"model <- make_model('X->Y')  data_long   <- simulate_data(model, n = 4)  data_short  <- collapse_data(data_long, model)  # \\donttest{  model <-  update_model(model, data_long) #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.5e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.25 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.203 seconds (Warm-up) #> Chain 1:                0.162 seconds (Sampling) #> Chain 1:                0.365 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 4.7e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.47 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.182 seconds (Warm-up) #> Chain 2:                0.168 seconds (Sampling) #> Chain 2:                0.35 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 1.7e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.212 seconds (Warm-up) #> Chain 3:                0.215 seconds (Sampling) #> Chain 3:                0.427 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 1.6e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.156 seconds (Warm-up) #> Chain 4:                0.148 seconds (Sampling) #> Chain 4:                0.304 seconds (Total) #> Chain 4:   model <-  update_model(model, data_short) #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 1.9e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.198 seconds (Warm-up) #> Chain 1:                0.177 seconds (Sampling) #> Chain 1:                0.375 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 5.6e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.56 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.163 seconds (Warm-up) #> Chain 2:                0.106 seconds (Sampling) #> Chain 2:                0.269 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 1.8e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.144 seconds (Warm-up) #> Chain 3:                0.131 seconds (Sampling) #> Chain 3:                0.275 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 1.5e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.108 seconds (Warm-up) #> Chain 4:                0.218 seconds (Sampling) #> Chain 4:                0.326 seconds (Total) #> Chain 4:   # }  if (FALSE) {    # It is possible to implement updating without data, in which    # case the posterior is a stan object that reflects the prior    update_model(model)     data <- data.frame(X=rep(0:1, 10), Y=rep(0:1,10))     # Censored data types    # We update less than we might because we are aware of filtered data    uncensored <-      make_model(\"X->Y\") |>      update_model(data) |>      query_model(te(\"X\", \"Y\"), using = \"posteriors\")     censored <-      make_model(\"X->Y\") |>      update_model(        data,        censored_types = c(\"X1Y0\")) |>      query_model(te(\"X\", \"Y\"), using = \"posteriors\")      # Censored data: We learn nothing because the data    # we see is the only data we could ever see    make_model(\"X->Y\") |>      update_model(        data,        censored_types = c(\"X1Y0\", \"X0Y0\", \"X0Y1\")) |>      query_model(te(\"X\", \"Y\"), using = \"posteriors\")  }"},{"path":"/news/index.html","id":"causalqueries-102","dir":"Changelog","previous_headings":"","what":"CausalQueries 1.0.2","title":"CausalQueries 1.0.2","text":"CRAN release: 2024-01-15","code":""},{"path":[]},{"path":"/news/index.html","id":"id_1-passing-nodal_types-to-make_model-now-implements-correct-error-handling-1-0-2","dir":"Changelog","previous_headings":"Bug Fixes","what":"1. passing nodal_types to make_model() now implements correct error handling","title":"CausalQueries 1.0.2","text":"Previously make_model(\"X -> Y\" , nodal_types = list(Y = c(\"0\", \"1\"))) permissible leading setting nodal_types: led undefined behavior unhelpful downstream error messages. passing nodal_types make_model() users now forced specify set nodal_types node.","code":"$X NULL  $Y [1] \"0\" \"1\""},{"path":[]},{"path":"/news/index.html","id":"id_3-node-naming-checks-are-operational-in-make_model-1-0-2","dir":"Changelog","previous_headings":"Bug Fixes","what":"3. node naming checks are operational in make_model()","title":"CausalQueries 1.0.2","text":"Previously hyphenated names throw error corrupted silently conversion model definition strings dagitty objects. Checks correct variable naming now reinstated.","code":"make_model(\"institutions -> political-inequality\")  Statement:  [1] \"institutions -> political-inequality\"  DAG:          parent  children 1 institutions political"},{"path":[]},{"path":"/news/index.html","id":"id_1-type-safety-1-0-2","dir":"Changelog","previous_headings":"Improvements","what":"1. type safety","title":"CausalQueries 1.0.2","text":"Calls sapply() ben replaced vapply() wherever possible enforce type safety.","code":""},{"path":"/news/index.html","id":"id_2-range-based-looping-1-0-2","dir":"Changelog","previous_headings":"Improvements","what":"2. range based looping","title":"CausalQueries 1.0.2","text":"Looping via index replaced range based looping wherever possible guard 0 length exceptions.","code":""},{"path":"/news/index.html","id":"id_3-goodpracticegp-1-0-2","dir":"Changelog","previous_headings":"Improvements","what":"3. goodpractice::gp()","title":"CausalQueries 1.0.2","text":"goodpractice code improvements implemented.","code":""},{"path":"/news/index.html","id":"causalqueries-100","dir":"Changelog","previous_headings":"","what":"CausalQueries 1.0.0","title":"CausalQueries 1.0.0","text":"CRAN release: 2023-10-13","code":""},{"path":"/news/index.html","id":"non-backwards-compatible-changes-1-0-0","dir":"Changelog","previous_headings":"","what":"Non Backwards Compatible Changes","title":"CausalQueries 1.0.0","text":"query_distribution() now supports use multiple queries one function call thus returns DataFrame distribution draws instead single numeric vector.","code":""},{"path":[]},{"path":"/news/index.html","id":"querying-1-0-0","dir":"Changelog","previous_headings":"New Functionality","what":"Querying","title":"CausalQueries 1.0.0","text":"query_distribution(): now supports specification multiple queries givens evaluated single model one function call. query_model(): now supports specification multiple models evaluate set queries one function call. eliminates need redundant function calls querying models substantially improves computation time computationally expensive function calls produce data structures required querying now reduced minimum via redundancy elimination caching.","code":"model <- make_model(\"X -> Y\")    query_distribution(model,    query = list(\"(Y[X=1] > Y[X=0])\", \"(Y[X=1] < Y[X=0])\"),    given = list(\"Y==1\", \"(Y[X=1] <= Y[X=0])\"),    using = \"priors\")|>  head() models <- list(   M1 = make_model(\"X -> Y\"),   M2 = make_model(\"X -> Y\") |> set_restrictions(\"Y[X=1] < Y[X=0]\")   )     query_model(   models,   query = list(ATE = \"Y[X=1] - Y[X=0]\", Share_positive = \"Y[X=1] > Y[X=0]\"),   given = c(TRUE,  \"Y==1 & X==1\"),   using = c(\"parameters\", \"priors\"),   expand_grid = FALSE)   query_model(   models,   query = list(ATE = \"Y[X=1] - Y[X=0]\", Share_positive = \"Y[X=1] > Y[X=0]\"),   given = c(TRUE,  \"Y==1 & X==1\"),   using = c(\"parameters\", \"priors\"),   expand_grid = TRUE)"},{"path":"/news/index.html","id":"realising-outcomes-and-interpreting-nodal-causal-types-1-0-0","dir":"Changelog","previous_headings":"New Functionality","what":"Realising Outcomes and Interpreting Nodal-/Causal-Types","title":"CausalQueries 1.0.0","text":"realise_outcomes(): specifying node option now produces DataFrame detailing specified node responds parents presence absence operations. produces reduced form usual realise_outcomes() output detailing causal-types; aids interpretation nodal- causal-types. update resolves previous bugs errors relating specification nodes multiple parents node option.","code":"model <- make_model(\"X1 -> M -> Y -> Z; X2 -> Y\") |>   realise_outcomes(dos = list(M = 1), node = \"Y\")"},{"path":[]},{"path":"/news/index.html","id":"id_1-setting-parameters-and-priors-1-0-0","dir":"Changelog","previous_headings":"Bug Fixes","what":"1. Setting Parameters and Priors","title":"CausalQueries 1.0.0","text":"Previously set_parameters() set_priors() default applying changes order parameters appeared parameters_df DataFrame; regardless order changes specified aforementioned functions. Calling: results following parameters_df. Now changes parameters values get applied order specified function call; resulting following parameters_df example: Additionally implemented helpful warnings instructions identifying parameters updated specified. particularly useful setting priors parameters models confounding changes may inadvertently applied across param_sets.","code":"model <- make_model(\"X -> Y\")  set_priors(model, alphas = c(3,4), nodal_type = c(\"10\",00)) param_names node    gen param_set nodal_type given param_value priors   <chr>       <chr> <int> <chr>     <chr>      <chr>       <dbl>  <dbl> 1 X.0         X         1 X         0          \"\"           0.5       1 2 X.1         X         1 X         1          \"\"           0.5       1 3 Y.00        Y         2 Y         00         \"\"           0.25      3 4 Y.10        Y         2 Y         10         \"\"           0.25      4 5 Y.01        Y         2 Y         01         \"\"           0.25      1 6 Y.11        Y         2 Y         11         \"\"           0.25      1 param_names node    gen param_set nodal_type given param_value priors   <chr>       <chr> <int> <chr>     <chr>      <chr>       <dbl>  <dbl> 1 X.0         X         1 X         0          \"\"           0.5       1 2 X.1         X         1 X         1          \"\"           0.5       1 3 Y.00        Y         2 Y         00         \"\"           0.25      4 4 Y.10        Y         2 Y         10         \"\"           0.25      3 5 Y.01        Y         2 Y         01         \"\"           0.25      1 6 Y.11        Y         2 Y         11         \"\"           0.25      1"},{"path":"/news/index.html","id":"id_2-updating-with-censored-types-1-0-0","dir":"Changelog","previous_headings":"Bug Fixes","what":"2. Updating with Censored Types","title":"CausalQueries 1.0.0","text":"Previously updating models censored types fail 0s w vector induced censoring evaluate -Inf Stan MCMC algorithm began sampling posterior multinational distribution. resolved issue pruning w vector multinomial run. preserves true w vector (event probabilities without censoring) still updating censored data-","code":""},{"path":"/news/index.html","id":"id_3-setting-restrictions-with-wild-cards-1-0-0","dir":"Changelog","previous_headings":"Bug Fixes","what":"3. Setting Restrictions with Wild Cards","title":"CausalQueries 1.0.0","text":"Previously wildcards set_restrictions() erroneously interpreted valid nodal types, leading errors undefined behavior. Proper unpacking mapping wildcards existing nodal types restored.","code":""},{"path":"/news/index.html","id":"id_4-checks-for-misspecified-queries-1-0-0","dir":"Changelog","previous_headings":"Bug Fixes","what":"4. Checks for Misspecified Queries","title":"CausalQueries 1.0.0","text":"Previously misspecifications queries like Y[X==1]=1 lead undefined behavior mapping queries nodal causal types. now correct misspecified queries internally warn misspecification. example; running: now produces","code":"model <- CausalQueries::make_model(\"X -> Y\") get_query_types(model, \"Y[X=1]=1\") Causal types satisfying query's condition(s)     query =  Y[X=1]==1   X0.Y01  X1.Y01 X0.Y11  X1.Y11    Number of causal types that meet condition(s) =  4  Total number of causal types in model =  8 Warning message: In check_query(query) :   statements to the effect that the realization of a node should equal some value should be specified with `==` not `=`.    The query has been changed accordingly: Y[X=1]==1"},{"path":"/news/index.html","id":"id_5-allowing-overwriting-of-a-parameter-matrix-1-0-0","dir":"Changelog","previous_headings":"Bug Fixes","what":"5. Allowing overwriting of a Parameter Matrix","title":"CausalQueries 1.0.0","text":"Previously parameter matrix P attached causal_model object overwritten. Overwrites now possible.","code":""},{"path":[]},{"path":"/news/index.html","id":"id_1-fast-realise_outcomes-1-0-0","dir":"Changelog","previous_headings":"Improvements","what":"1. Fast realise_outcomes()","title":"CausalQueries 1.0.0","text":"achieved ~100 fold speed gain realise_outcomes() functionality. Nodal types given node generated Cartesian product parent realizations. Consider meaning nodal types node Y 3 parents [X1,X2,X3]: row DataFrame corresponds digit Y's nodal types. first digit nodal type Y (see first row ), corresponds realization Y X1 = 0, X2 = 0, X3 = 0. fourth digit nodal type Y (see fourth row ), corresponds realization Y X1 = 1, X2 = 1, X3 = 0. Finding position realization value Y nodal type given parent realizations equivalent finding row number Cartesian product DataFrame. definition Cartesian product, number consecutive 0 1 elements given column 2columnindex, indexing columns 0. Given set parent realizations R indexed 0, corresponding row number DataFrame indexed 0 can thus computed via: $$row = (\\sum_{= 0}^{|R| - 1} (2^{} \\times R_i))$$. implement fast C++ version computing powers 2 via bit shifting.","code":""},{"path":"/news/index.html","id":"id_2-stan-update-1-0-0","dir":"Changelog","previous_headings":"Improvements","what":"2. Stan update","title":"CausalQueries 1.0.0","text":"updated new array syntax introduced Stan v2.33.0","code":""}]
