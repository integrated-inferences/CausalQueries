[{"path":"https://integrated-inferences.github.io/CausalQueries/articles/a-getting-started.html","id":"make-a-model","dir":"Articles","previous_headings":"","what":"Make a model","title":"Getting Started","text":"Generating: make model need provide DAG statement make_model. instance \"X->Y\" \"X -> M -> Y <- X\" \"Z -> X -> Y <-> X\". Graphing: made model can inspect DAG:  Simple summaries: can access simple summary using summary() can examine model details using inspect(). Inspecting: model set parameters default distribution . Tailoring: features can edited using set_restrictions, set_priors set_parameters. example setting monotonicity restriction (see ?set_restrictions ): example setting priors (see ?set_priors ): Simulation: Data can drawn model like :","code":"# examples of models xy_model <- make_model(\"X -> Y\") iv_model <- make_model(\"Z -> X -> Y <-> X\") plot(xy_model) summary(xy_model) #>  #> Causal statement:  #> X -> Y #>  #> Nodal types:  #> $X #> 0  1 #>  #>   node position display interpretation #> 1    X       NA      X0          X = 0 #> 2    X       NA      X1          X = 1 #>  #> $Y #> 00  10  01  11 #>  #>   node position display interpretation #> 1    Y        1   Y[*]*      Y | X = 0 #> 2    Y        2   Y*[*]      Y | X = 1 #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of causal types:  8 #>  #> Note: Model does not contain: posterior_distribution, stan_objects; #> to include these objects use update_model() #>  #> Note: To pose causal queries of this model use query_model() xy_model |> inspect(\"parameters_df\")  #>  #> parameters_df #> Mapping of model parameters to nodal types:  #>  #>   param_names: name of parameter #>   node:        name of endogeneous node associated #>                with the parameter #>   gen:         partial causal ordering of the #>                parameter's node #>   param_set:   parameter groupings forming a simplex #>   given:       if model has confounding gives #>                conditioning nodal type #>   param_value: parameter values #>   priors:      hyperparameters of the prior #>                Dirichlet distribution  #>  #>   param_names node gen param_set nodal_type given param_value priors #> 1         X.0    X   1         X          0              0.50      1 #> 2         X.1    X   1         X          1              0.50      1 #> 3        Y.00    Y   2         Y         00              0.25      1 #> 4        Y.10    Y   2         Y         10              0.25      1 #> 5        Y.01    Y   2         Y         01              0.25      1 #> 6        Y.11    Y   2         Y         11              0.25      1 iv_model <-    iv_model |> set_restrictions(decreasing('Z', 'X')) iv_model <-    iv_model |> set_priors(distribution = \"jeffreys\") #> Altering all parameters. data <- make_data(iv_model, n = 4)   data |> kable()"},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/a-getting-started.html","id":"update-the-model","dir":"Articles","previous_headings":"","what":"Update the model","title":"Getting Started","text":"Updating: Update using update_model. can pass rstan arguments update_model. Inspecting: can access posterior distribution model parameters directly thus: row draw parameters.","code":"df <-    data.frame(X = rbinom(100, 1, .5)) |>   mutate(Y = rbinom(100, 1, .25 + X*.5))  xy_model <-    xy_model |>    update_model(df, refresh = 0) xy_model |> grab(\"posterior_distribution\") |>    head() |> kable()"},{"path":[]},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/a-getting-started.html","id":"arbitrary-queries","dir":"Articles","previous_headings":"Query the model","what":"Arbitrary queries","title":"Getting Started","text":"Querying: ask arbitrary causal queries model. Examples unconditional queries: Examples conditional queries: Queries can even conditional counterfactual quantities. probability positive effect given effect: Note use ‚Äú:‚Äù separate base query condition rather ‚Äú|‚Äù avoid confusion logical operators.","code":"xy_model |>    query_model(\"Y[X=1] > Y[X=0]\",                using = c(\"priors\", \"posteriors\"))  #>  #> Causal queries generated by query_model (all at population level) #>  #> |query           |using      |  mean|    sd| cred.low| cred.high| #> |:---------------|:----------|-----:|-----:|--------:|---------:| #> |Y[X=1] > Y[X=0] |priors     | 0.254| 0.196|    0.007|     0.722| #> |Y[X=1] > Y[X=0] |posteriors | 0.446| 0.119|    0.196|     0.649| xy_model |>    query_model(\"Y[X=1] > Y[X=0] : X == 1 & Y == 1\", using = c(\"priors\", \"posteriors\"))  #>  #> Causal queries generated by query_model (all at population level) #>  #> |label                             |using      |  mean|    sd| cred.low| cred.high| #> |:---------------------------------|:----------|-----:|-----:|--------:|---------:| #> |Y[X=1] > Y[X=0] : X == 1 & Y == 1 |priors     | 0.499| 0.287|    0.023|     0.978| #> |Y[X=1] > Y[X=0] : X == 1 & Y == 1 |posteriors | 0.677| 0.173|    0.335|     0.972| xy_model |>    query_model(\"Y[X=1] > Y[X=0] : Y[X=1] != Y[X=0]\",               using = c(\"priors\", \"posteriors\"))  #>  #> Causal queries generated by query_model (all at population level) #>  #> |label                              |using      |  mean|    sd| cred.low| cred.high| #> |:----------------------------------|:----------|-----:|-----:|--------:|---------:| #> |Y[X=1] > Y[X=0] : Y[X=1] != Y[X=0] |priors     | 0.503| 0.290|    0.024|     0.975| #> |Y[X=1] > Y[X=0] : Y[X=1] != Y[X=0] |posteriors | 0.748| 0.106|    0.574|     0.971|"},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/a-getting-started.html","id":"output","dir":"Articles","previous_headings":"Query the model","what":"Output","title":"Getting Started","text":"Query output ready printing tables, can also plotted, especially useful batch requests: tabular output","code":"batch_queries <- xy_model |>    query_model(queries = list(ATE = \"Y[X=1] - Y[X=0]\",                               `Positive effect given any effect` = \"Y[X=1] > Y[X=0] : Y[X=1] != Y[X=0]\"),                using = c(\"priors\", \"posteriors\"),                expand_grid = TRUE)   batch_queries |> kable(digits = 2, caption = \"tabular output\") batch_queries |> plot()"},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/b-plotting.html","id":"a-basic-plot","dir":"Articles","previous_headings":"","what":"A basic plot:","title":"Plotting models","text":"","code":"model <- make_model(\"X -> Y\")  model |> plot_model()"},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/b-plotting.html","id":"ggplot-layers","dir":"Articles","previous_headings":"","what":"ggplot layers","title":"Plotting models","text":"model produced ggplot object additional layers can added usual way.","code":"model |>    plot_model()  +    annotate(\"text\", x = c(1, -1) , y = c(1.5, 1.5), label = c(\"Some text\", \"Some more text\")) +    coord_flip()"},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/b-plotting.html","id":"adding-labels","dir":"Articles","previous_headings":"","what":"Adding labels","title":"Plotting models","text":"Provide labels order model nodes.","code":"model <- make_model(\"A -> B -> C <- A\")    # Check node ordering inspect(model, \"nodes\") #>  #> Nodes:  #> A, B, C  # Provide labels model |>    plot_model(      labels = c(\"This is A\", \"Here is B\", \"And C\"),      nodecol = \"white\", textcol = \"black\")"},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/b-plotting.html","id":"controlling-positions","dir":"Articles","previous_headings":"","what":"Controlling positions","title":"Plotting models","text":"can manually set positions using x_coord y_coord arguments. can manually set positions using x_coord y_coord arguments.","code":"model |>    plot(x_coord = 0:2,  y_coord = c(0, 2, 1))"},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/b-plotting.html","id":"controlling-color","dir":"Articles","previous_headings":"","what":"Controlling color","title":"Plotting models","text":"can manually control node color text color nodes together separately.","code":"model |>    plot(x_coord = 0:2,  y_coord = c(0, 2, 1),         nodecol = c(\"blue\", \"orange\", \"red\"),        textcol = c(\"white\", \"red\", \"blue\"))"},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/b-plotting.html","id":"models-with-unobserved-confounding","dir":"Articles","previous_headings":"","what":"Models with unobserved confounding","title":"Plotting models","text":"Unobserved confounding represented using dashed curves.","code":"make_model('X -> K -> Y <- X; X <-> Y; K <-> Y') |>   plot()"},{"path":[]},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/b-plotting.html","id":"effective-node-placement","dir":"Articles","previous_headings":"More complex models","what":"Effective node placement","title":"Plotting models","text":"","code":"make_model(\"I -> V -> G <- N; C -> I <- A -> G; G -> Z\",            add_causal_types = FALSE) |>    plot()"},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/b-plotting.html","id":"requires-manual-coordinates","dir":"Articles","previous_headings":"More complex models","what":"Requires manual coordinates","title":"Plotting models","text":"graph bad node placement.  Better:","code":"make_model(\"D <- A -> B -> C -> D -> E; B -> E\",            add_causal_types = FALSE) |>    plot() make_model(\"D <- A -> B -> C -> D -> E; B -> E\",            add_causal_types = FALSE) |>     plot(x_coord = c(0, -.1, 0, .1, 0), y_coord = 5:1)"},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/c-canonical-models.html","id":"simple-experiment","dir":"Articles","previous_headings":"","what":"Simple experiment","title":"Canonical causal models","text":"model justified randomized control trial. lot data can get tight estimates effect XX YY whether given outcome YY due XX. ‚Äúeffects causes‚Äù estimand identified, ‚Äúcauses effects‚Äù estimand . illustration generate data parameterized model try recover average treatment effect ‚Äúprobability causation‚Äù (POC) X=1, Y=1 cases. former tight credibility interval, latter .","code":"model <- make_model(\"X -> Y\") model |> plot() data <- model |>    set_parameters(nodal_type = c(\"10\", \"01\"), parameters = c(.1, .6)) |>    make_data(n = 5000)  model |>   update_model(data, refresh = 0, iter = 10000) |>      query_model(queries =                  list(ATE = \"Y[X=1] - Y[X=0]\",                      POC = \"Y[X=1] - Y[X=0] : X==1 & Y==1\"),               using = \"posteriors\" ) |>      plot() +   xlim(-1,1)"},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/c-canonical-models.html","id":"confounded","dir":"Articles","previous_headings":"","what":"Confounded","title":"Canonical causal models","text":"appropriate model XX randomized possible unknown factors affect assignment XX outcome YY. illustration use data, drawn model X fact randomized (though know ) true treatment effect 0.5. see lost identification ATE also uncertainty POC much greater.","code":"model <- make_model(\"X -> Y; X <-> Y\")  model |> plot() model |>   update_model(data, refresh = 0, iter = 10000) |>      query_model(queries =                  list(ATE = \"Y[X=1] - Y[X=0]\",                      POC = \"Y[X=1] - Y[X=0] : X==1 & Y==1\"),               using = \"posteriors\") |>      plot() +   xlim(-1,1)"},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/c-canonical-models.html","id":"chain-model","dir":"Articles","previous_headings":"","what":"Chain model","title":"Canonical causal models","text":"chain model. model hard justify experimentation since randomization ZZ guarantee third features influence XX YY, ZZ operates YY though XX. Even still, good model illustrate limits learning effects observation values mediators. imagine data produced model ZZ 0.8 average effect XX XX 0.8 average effect YY. see positive evidence causal chain (XX) modest effect belief Z=1Z=1 caused Y=1Y=1. Negative evidence much stronger effect, albeit considerable posterior uncertainty.","code":"model <- make_model(\"Z -> X -> Y\") model |> plot() data <- model |>    set_parameters(param_names = c(\"X.10\", \"X.01\", \"Y.10\", \"Y.01\"),                   parameters = c(0.05, .85, .05, .85)) |>    make_data(n = 5000)  model |>   update_model(data, refresh = 0, iter = 10000) |>      query_model(query = list(\"Y[Z=1] - Y[Z=0]\"),               given = c(TRUE, \"Z==1 & Y==1\", \"Z==1 & Y==1 & X==0\", \"Z==1 & Y==1 & X==1\"),               using = \"posteriors\") |>      plot() +   xlim(-1,1)"},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/c-canonical-models.html","id":"iv-model","dir":"Articles","previous_headings":"","what":"IV model","title":"Canonical causal models","text":"classic ‚Äúinstrumental variables‚Äù model. model sometimes justified randomization ZZ assumption ZZ operates YY though XX (exclusion restriction). Researchers also often assume ZZ monotonic effect XX, impose . analyse using data focusing attention effects XX YY population also specifically units XX responds positively YY, compliers. IV inferences Note relatively tight posterior complier average effect wide posterior average effect probability causation.","code":"model <- make_model(\"Z -> X -> Y; X <-> Y\") model |> plot() model |>   update_model(data, refresh = 0, iter = 10000) |>      query_model(query = list(\"Y[X=1] - Y[X=0]\"),               given = c(TRUE, \"X[Z=1] > X[Z=0]\", \"X==1 & Y==1\"),               using = \"posteriors\") |>      plot() +   xlim(-1,1)"},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/c-canonical-models.html","id":"mediation-model-with-sequential-ignorability","dir":"Articles","previous_headings":"","what":"Mediation model with sequential ignorability","title":"Canonical causal models","text":"typical mediation type problem might want understand effects ZZ YY operate directly operate via XX. assumed third features cause XX YY. strong assumption key part ‚Äúsequential ignorability‚Äù (see Forastiere et al (2018) extensive treatment relationship sequential ignorability ‚Äústrong principal ignorability‚Äù impose ). one might ask queries different types direct indirect effect ZZ YY well average effects ZZ XX YY XX YY. example data drawn world common type Y=1Y=1 Z=1Z=1 X=1X=1 ZZ exerts negative effect XX; positive direct effects negative indirect effects. Mediation model estimate quantities well.","code":"model <- make_model(\"Z -> X -> Y <- Z\") model |> plot() model <-     make_model(\"Z -> X -> Y <- Z\") |>    set_parameters(nodal_type = c(\"00\", \"10\"), parameters = c(0, .5)) |>    set_parameters(nodal_type = \"0001\", parameters = .5)   data <- model |> make_data(n = 2000)  queries <- list(   `ATE Z -> X` = \"X[Z=1] - X[Z=0]\",   `ATE Z -> Y` = \"Y[Z=1] - Y[Z=0]\",   `ATE X -> Y` = \"Y[X=1] - Y[X=0]\",   `Direct (Z=1)` = \"Y[Z = 1, X = X[Z=1]] - Y[Z = 0, X = X[Z=1]]\",   `Direct (Z=0)` = \"Y[Z = 1, X = X[Z=0]] - Y[Z = 0, X = X[Z=0]]\",   `Indirect (Z=1)` = \"Y[Z = 1, X = X[Z=1]] - Y[Z = 1, X = X[Z=0]]\",   `Indirect (Z=0)` = \"Y[Z = 0, X = X[Z=1]] - Y[Z = 0, X = X[Z=0]]\" )  model |>   update_model(data, refresh = 0, iter = 5000)  |>      query_model(     query = queries,     cred = 99,     using = c(\"parameters\", \"posteriors\"),     expand_grid = TRUE) |>      plot() +   xlim(-1,1)"},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/c-canonical-models.html","id":"mediation-model-without-sequential-ignorability","dir":"Articles","previous_headings":"","what":"Mediation model without sequential ignorability","title":"Canonical causal models","text":"now allow may third features cause XX YY. Thus assume ‚Äúsequential ignorability.‚Äù model might justified random assignment ZZ. example data drawn way means data generating model potential outcomes YY independent XX, though researcher know . true (unknown) values queries also . Mediation model see nearly well. ensure stable estimates ran large number iterations. non-identified quantities credibility intervals tight (!) one case true value lies outside (). highlights extreme difficulty problem. Nevertheless gains relative priors considerable.","code":"make_model(\"Z -> X -> Y <- Z; X <-> Y\")  |>   set_parameters(nodal_type = c(\"00\", \"10\"), parameters = c(0, .5)) |>    set_parameters(nodal_type = \"0001\", parameters = .5)   |>      update_model(data, iter = 10000) |>         query_model(     query = queries,     cred = 99,     using = c(\"parameters\", \"posteriors\"),     expand_grid = TRUE) |>      plot()  +   xlim(-1,1)"},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/c-canonical-models.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Canonical causal models","text":"Forastiere, Laura, Alessandra Mattei, Peng Ding. ‚ÄúPrincipal ignorability mediation analysis: beyond sequential ignorability.‚Äù Biometrika 105.4 (2018): 979-986.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/d-front-door.html","id":"try-it","dir":"Articles","previous_headings":"","what":"Try it","title":"Through the front door","text":"Say X, M, Y perfectly correlated. average treatment effect identified?","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/e-posteriors.html","id":"accessing-the-posterior","dir":"Articles","previous_headings":"","what":"Accessing the posterior","title":"Inspecting posteriors","text":"update model using CausalQueries, CausalQueries generates updates stan model saves posterior distribution parameters model. basic usage : posterior parameters can accessed thus: querying model can request use posterior distribution using argument:","code":"data <- data.frame(X = rep(c(0:1), 10), Y = rep(c(0:1), 10))  model <- make_model(\"X -> Y\") |>    update_model(data) inspect(model, \"posterior_distribution\") #>  #> posterior_distribution #> Summary statistics of model parameters posterior distributions: #>  #>   Distributions matrix dimensions are  #>   4000 rows (draws) by 6 cols (parameters) #>  #>      mean   sd #> X.0  0.50 0.11 #> X.1  0.50 0.11 #> Y.00 0.08 0.07 #> Y.10 0.04 0.04 #> Y.01 0.80 0.11 #> Y.11 0.08 0.07 model |>    query_model(     query = \"Y[X=1] > Y[X=0]\",     using = c(\"priors\", \"posteriors\")) |>   kable(digits = 2)"},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/e-posteriors.html","id":"summary-of-stan-performance","dir":"Articles","previous_headings":"","what":"Summary of stan performance","title":"Inspecting posteriors","text":"can access summary parameter values convergence information produced stan thus: summary provides information distribution parameters well convergence diagnostics, summarized Rhat column. printout first six rows show distribution model parameters; next eight rows show distribution transformed parameters, causal types. last row shows unnormalized log density Stan‚Äôs unconstrained space , described Stan documentation intended diagnose sampling efficiency evaluate approximations. See stan documentation details.","code":"inspect(model, \"stan_summary\") #>  #> stan_summary #> Stan model summary: #>  #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>              mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> X.0          0.50    0.00 0.11   0.30   0.42   0.50   0.57   0.72  2017    1 #> X.1          0.50    0.00 0.11   0.28   0.43   0.50   0.58   0.70  2017    1 #> Y.00         0.08    0.00 0.07   0.00   0.03   0.06   0.11   0.27  2159    1 #> Y.10         0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  4189    1 #> Y.01         0.80    0.00 0.11   0.55   0.74   0.82   0.88   0.95  4365    1 #> Y.11         0.08    0.00 0.07   0.00   0.02   0.06   0.11   0.26  4005    1 #> X0.Y00       0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  2103    1 #> X1.Y00       0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  2172    1 #> X0.Y10       0.02    0.00 0.02   0.00   0.01   0.01   0.03   0.07  3589    1 #> X1.Y10       0.02    0.00 0.02   0.00   0.01   0.02   0.03   0.07  4177    1 #> X0.Y01       0.40    0.00 0.10   0.21   0.33   0.40   0.47   0.61  2417    1 #> X1.Y01       0.40    0.00 0.10   0.21   0.33   0.40   0.47   0.60  2407    1 #> X0.Y11       0.04    0.00 0.04   0.00   0.01   0.03   0.05   0.14  3899    1 #> X1.Y11       0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  3652    1 #> lp__       -14.60    0.04 1.53 -18.42 -15.31 -14.26 -13.52 -12.66  1214    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Nov 27 14:53:01 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1)."},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/e-posteriors.html","id":"warnings","dir":"Articles","previous_headings":"","what":"Warnings!","title":"Inspecting posteriors","text":"pass summary warnings generated stan indications updating gone well. produces warnings executed. (iterations also difficult model data entirely missing mediator data pattern consistent two opposite models: one combining positive effects one combining negative effects.) can access warnings like : also remind use print summary methods: also query model:  warnings always important safest aware arise investigate . warnings see stan post warnings.","code":"model <-    make_model(\"X -> M -> Y; M <-> Y\") |>   update_model(data = data.frame(X = rep(0:1, 10000), Y = rep(0:1, 10000)),                 iter = 500,                refresh = 0) #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess inspect(model, \"stan_warnings\") #>  #> stan_warnings #> Stan warnings generated during updating: #> Bulk Effective Samples Size (ESS) is too low #> Tail Effective Samples Size (ESS) is too low model #>  #> Causal statement:  #> M -> Y; M <-> Y; X -> M #>  #> Number of nodal types by node: #> X M Y  #> 2 4 4  #>  #> Number of causal types: 32 #>  #> Model has been updated and contains a posterior distribution with #> 4 chains, each with iter=500; warmup=250; thin=1;   #> Use inspect(model, 'stan_objects') to inspect stan summary #>  #> Warnings passed from rstan during updating: #> Bulk Effective Samples Size (ESS) is too low #> Tail Effective Samples Size (ESS) is too low query_model(model, \"X==1\", using = \"posteriors\") #> Note: warnings passed from rstan during updating: #>  #> Model 1 warnings: #> Bulk Effective Samples Size (ESS) is too low #> Tail Effective Samples Size (ESS) is too low #>  #>  #> Causal queries generated by query_model (all at population level) #>  #> |query |using      | mean|    sd| cred.low| cred.high| #> |:-----|:----------|----:|-----:|--------:|---------:| #> |X==1  |posteriors |  0.5| 0.003|    0.493|     0.507| query_model(model, \"X==1\", using = \"posteriors\") |> plot() #> Note: warnings passed from rstan during updating: #>  #> Model 1 warnings: #> Bulk Effective Samples Size (ESS) is too low #> Tail Effective Samples Size (ESS) is too low"},{"path":"https://integrated-inferences.github.io/CausalQueries/articles/e-posteriors.html","id":"advanced-diagnostics","dir":"Articles","previous_headings":"","what":"Advanced diagnostics","title":"Inspecting posteriors","text":"interested advanced diagnostics performance can save access raw stan output. Note summary raw output shows labels used generic stan model: lambda vector parameters, corresponding parameters parameters dataframe (inspect(model, \"parameters_df\")), , saved, vector types causal types (see inspect(model, \"causal_types\")) w event probabilities (inspect(model, \"prior_event_probabilities\")). can use diagnostic packages bayesplot.","code":"model <- make_model(\"X -> Y\") |>    update_model(data, keep_fit = TRUE) model |> inspect(\"stanfit\") #>  #> stanfit #> Stan model summary: #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>              mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> lambdas[1]   0.50    0.00 0.10   0.29   0.42   0.50   0.57   0.70  2139    1 #> lambdas[2]   0.50    0.00 0.10   0.30   0.43   0.50   0.58   0.71  2139    1 #> lambdas[3]   0.08    0.00 0.07   0.00   0.03   0.06   0.11   0.26  2048    1 #> lambdas[4]   0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  4175    1 #> lambdas[5]   0.80    0.00 0.11   0.55   0.74   0.81   0.88   0.96  4528    1 #> lambdas[6]   0.08    0.00 0.07   0.00   0.02   0.06   0.11   0.27  4225    1 #> types[1]     0.04    0.00 0.04   0.00   0.01   0.03   0.05   0.14  1999    1 #> types[2]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  2107    1 #> types[3]     0.02    0.00 0.02   0.00   0.01   0.01   0.03   0.08  4059    1 #> types[4]     0.02    0.00 0.02   0.00   0.01   0.02   0.03   0.07  3872    1 #> types[5]     0.40    0.00 0.10   0.21   0.33   0.39   0.47   0.60  2567    1 #> types[6]     0.40    0.00 0.10   0.22   0.34   0.40   0.47   0.60  2481    1 #> types[7]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  3943    1 #> types[8]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  4067    1 #> lp__       -14.55    0.04 1.52 -18.45 -15.30 -14.24 -13.42 -12.63  1348    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Nov 27 14:53:10 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). model |> inspect(\"stanfit\") |>   bayesplot::mcmc_pairs(pars = c(\"lambdas[3]\", \"lambdas[4]\", \"lambdas[5]\", \"lambdas[6]\")) #>  #> stanfit #> Stan model summary: #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>              mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> lambdas[1]   0.50    0.00 0.10   0.29   0.42   0.50   0.57   0.70  2139    1 #> lambdas[2]   0.50    0.00 0.10   0.30   0.43   0.50   0.58   0.71  2139    1 #> lambdas[3]   0.08    0.00 0.07   0.00   0.03   0.06   0.11   0.26  2048    1 #> lambdas[4]   0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  4175    1 #> lambdas[5]   0.80    0.00 0.11   0.55   0.74   0.81   0.88   0.96  4528    1 #> lambdas[6]   0.08    0.00 0.07   0.00   0.02   0.06   0.11   0.27  4225    1 #> types[1]     0.04    0.00 0.04   0.00   0.01   0.03   0.05   0.14  1999    1 #> types[2]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  2107    1 #> types[3]     0.02    0.00 0.02   0.00   0.01   0.01   0.03   0.08  4059    1 #> types[4]     0.02    0.00 0.02   0.00   0.01   0.02   0.03   0.07  3872    1 #> types[5]     0.40    0.00 0.10   0.21   0.33   0.39   0.47   0.60  2567    1 #> types[6]     0.40    0.00 0.10   0.22   0.34   0.40   0.47   0.60  2481    1 #> types[7]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  3943    1 #> types[8]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  4067    1 #> lp__       -14.55    0.04 1.52 -18.45 -15.30 -14.24 -13.42 -12.63  1348    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Nov 27 14:53:10 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). np <- model |> inspect(\"stanfit\") |> bayesplot::nuts_params() #>  #> stanfit #> Stan model summary: #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>              mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> lambdas[1]   0.50    0.00 0.10   0.29   0.42   0.50   0.57   0.70  2139    1 #> lambdas[2]   0.50    0.00 0.10   0.30   0.43   0.50   0.58   0.71  2139    1 #> lambdas[3]   0.08    0.00 0.07   0.00   0.03   0.06   0.11   0.26  2048    1 #> lambdas[4]   0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  4175    1 #> lambdas[5]   0.80    0.00 0.11   0.55   0.74   0.81   0.88   0.96  4528    1 #> lambdas[6]   0.08    0.00 0.07   0.00   0.02   0.06   0.11   0.27  4225    1 #> types[1]     0.04    0.00 0.04   0.00   0.01   0.03   0.05   0.14  1999    1 #> types[2]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  2107    1 #> types[3]     0.02    0.00 0.02   0.00   0.01   0.01   0.03   0.08  4059    1 #> types[4]     0.02    0.00 0.02   0.00   0.01   0.02   0.03   0.07  3872    1 #> types[5]     0.40    0.00 0.10   0.21   0.33   0.39   0.47   0.60  2567    1 #> types[6]     0.40    0.00 0.10   0.22   0.34   0.40   0.47   0.60  2481    1 #> types[7]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  3943    1 #> types[8]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  4067    1 #> lp__       -14.55    0.04 1.52 -18.45 -15.30 -14.24 -13.42 -12.63  1348    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Nov 27 14:53:10 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). head(np) |> kable() model |>    inspect(\"stanfit\") |>   bayesplot::mcmc_trace(pars = \"lambdas[5]\", np = np)  #>  #> stanfit #> Stan model summary: #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>              mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> lambdas[1]   0.50    0.00 0.10   0.29   0.42   0.50   0.57   0.70  2139    1 #> lambdas[2]   0.50    0.00 0.10   0.30   0.43   0.50   0.58   0.71  2139    1 #> lambdas[3]   0.08    0.00 0.07   0.00   0.03   0.06   0.11   0.26  2048    1 #> lambdas[4]   0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.15  4175    1 #> lambdas[5]   0.80    0.00 0.11   0.55   0.74   0.81   0.88   0.96  4528    1 #> lambdas[6]   0.08    0.00 0.07   0.00   0.02   0.06   0.11   0.27  4225    1 #> types[1]     0.04    0.00 0.04   0.00   0.01   0.03   0.05   0.14  1999    1 #> types[2]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  2107    1 #> types[3]     0.02    0.00 0.02   0.00   0.01   0.01   0.03   0.08  4059    1 #> types[4]     0.02    0.00 0.02   0.00   0.01   0.02   0.03   0.07  3872    1 #> types[5]     0.40    0.00 0.10   0.21   0.33   0.39   0.47   0.60  2567    1 #> types[6]     0.40    0.00 0.10   0.22   0.34   0.40   0.47   0.60  2481    1 #> types[7]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  3943    1 #> types[8]     0.04    0.00 0.04   0.00   0.01   0.03   0.06   0.14  4067    1 #> lp__       -14.55    0.04 1.52 -18.45 -15.30 -14.24 -13.42 -12.63  1348    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Nov 27 14:53:10 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #> No divergences to plot."},{"path":"https://integrated-inferences.github.io/CausalQueries/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Clara Bicalho. Contributor. Jasper Cooper. Contributor. Macartan Humphreys. Author. Till Tietz. Author, maintainer. Alan Jacobs. Author. Merlin Heidemanns. Contributor. Lily Medina. Author. Julio Solis. Contributor. Georgiy Syunyaev. Author.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Humphreys M, Tietz T, Jacobs , Medina L, Syunyaev G (2024). CausalQueries: Make, Update, Query Binary Causal Models. R package version 1.2.1, https://integrated-inferences.github.io/CausalQueries/.","code":"@Manual{,   title = {CausalQueries: Make, Update, and Query Binary Causal Models},   author = {Macartan Humphreys and Till Tietz and Alan Jacobs and Lily Medina and Georgiy Syunyaev},   year = {2024},   note = {R package version 1.2.1},   url = {https://integrated-inferences.github.io/CausalQueries/}, }"},{"path":"https://integrated-inferences.github.io/CausalQueries/CONTRIBUTING.html","id":"contributing-to-causalqueries","dir":"","previous_headings":"","what":"Contributing to CausalQueries","title":"NA","text":"üéâ Welcome contribution guidelines thank interest contributing! ### Reporting bug report bug make sure bug hasn‚Äôt reported . track bugs issues GitHub. related issue opened, create issue keeping mind following guidelines: Use informative title Write minimal working example allows us reproduce bug found bug ‚Äôre reporting crashes R session, please mention title ### Contributing code look issues GitHub like solve one ? like develop feature? ‚Äôs great gladly welcome . just like suggest follow simple guidelines: Fork CausalQueries repository Clone fork locally Always date master branch Add edits Run pass devtools::check() Reach 100% coverage covr::package_coverage() Add contributor DESCRIPTION file Open pull request Note: members CausalQueries dev team can skip first two bullet points branch instead.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/index.html","id":"causalqueries","dir":"","previous_headings":"","what":"Make, Update, and Query Binary Causal Models","title":"Make, Update, and Query Binary Causal Models","text":"CausalQueries package lets declare binary causal models, update beliefs causal types given data calculate arbitrary estimands. Model definition implemented via dagitty style syntax. Updating implemented stan. See vignettes guide getting started. See guide using CausalQueries along many examples causal models See website comprehensive overview CausalQueries","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Make, Update, and Query Binary Causal Models","text":"install latest stable release CausalQueries: install latest development release :","code":"install.packages(\"CausalQueries\") install.packages(\"devtools\") devtools::install_github(\"integrated-inferences/CausalQueries\")"},{"path":"https://integrated-inferences.github.io/CausalQueries/index.html","id":"helping-out--contributing","dir":"","previous_headings":"","what":"Helping Out & Contributing","title":"Make, Update, and Query Binary Causal Models","text":"CausalQueries open active developer community. welcome contributions excited keen get involved. Please refer CONTRIBUTING.md get started.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/index.html","id":"causal-models","dir":"","previous_headings":"","what":"Causal Models","title":"Make, Update, and Query Binary Causal Models","text":"Causal models defined : directed acyclic graph (DAG), provides set variables, causal ordering , set assumptions regarding conditional independence. arrow B change never induces change B. Functional forms. Functional forms describe causal relationships nodes. often make strong assumptions specify functional form; fortunately however variables categorical need functional forms usual sense. DAG implies set ‚Äúcausal types.‚Äù Units can classed together causal type respond way variables. instance, type might set units X=1 Y=1 X=1. set causal types grows rapidly number nodes number nodes pointing given node. setting imposing functional forms placing restrictions causal types: restrictions reduce complexity require substantive assumptions. example restriction might ‚ÄúY monotonic X.‚Äù Priors. standard case, DAG plus restrictions imply set parameters combine form causal types. parameters want learn . learn first provide priors parameters. priors specified causal model complete (‚Äúprobabilistic causal model‚Äù) ready inference. Setting priors done using set_priors function many examples can seen typing ? set_priors.R. wrinkle: possible nodes related ways captured DAG. cases dotted curves sometimes placed nodes graph. possible specify possible unobservable confounding causal model. implications parameter space.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/index.html","id":"inference","dir":"","previous_headings":"","what":"Inference","title":"Make, Update, and Query Binary Causal Models","text":"goal form beliefs parameters also substantive estimands: causal model hand data available nodes, possible make use generic stan model generates posteriors parameter vector. Given updated (prior) beliefs parameters possible calculate causal estimands inference causal model. example ‚Äúprobability X cause Y given X=1, Y=1 Z=1.‚Äù","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/index.html","id":"credits-etc","dir":"","previous_headings":"","what":"Credits etc","title":"Make, Update, and Query Binary Causal Models","text":"approach used CausalQueries developed Humphreys Jacobs 2023 drawing work probabilistic causal models described Pearl‚Äôs Causality (Pearl, 2009). thank Ben Goodrich provided generous insights using stan project. thank Alan M Jacobs key work developing framework underlying package. thanks Jasper Cooper contributions generating generic function create Stan code, Clara Bicalho helped figure syntax causal statements, Julio S. Sol√≠s Arce made many key contributions figuring simplify specification priors, Merlin Heidemanns figured rstantools integration made myriad code improvements.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/add_dots.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper to fill in missing do operators in causal expression ‚Äî add_dots","title":"Helper to fill in missing do operators in causal expression ‚Äî add_dots","text":"Helper fill missing operators causal expression","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/add_dots.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper to fill in missing do operators in causal expression ‚Äî add_dots","text":"","code":"add_dots(q, model)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/add_dots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper to fill in missing do operators in causal expression ‚Äî add_dots","text":"q character string. Causal query least one parent node missing operator. model causal_model. model object generated make_model.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/add_dots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper to fill in missing do operators in causal expression ‚Äî add_dots","text":"causal query expression parents nodes set   either 0, 1 wildcard '.'.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/add_dots.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helper to fill in missing do operators in causal expression ‚Äî add_dots","text":"","code":"# \\donttest{ model <- make_model('X -> Y <- M') CausalQueries:::add_dots('Y[X=1]', model) #> [1] \"Y[X=1, M = . ]\" CausalQueries:::add_dots('Y[]', model) #> [1] \"Y[M = . , X = . ]\" # }"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/CausalQueries-package.html","id":null,"dir":"Reference","previous_headings":"","what":"'CausalQueries' ‚Äî CausalQueries-package","title":"'CausalQueries' ‚Äî CausalQueries-package","text":"'CausalQueries' package lets generate binary causal models, update models given data calculate arbitrary causal queries. Model definition makes use dagitty syntax. Updating implemented 'stan'.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/CausalQueries.html","id":null,"dir":"Reference","previous_headings":"","what":"'CausalQueries' ‚Äî CausalQueries","title":"'CausalQueries' ‚Äî CausalQueries","text":"'CausalQueries' package lets users generate binary causal models, update models given data, calculate arbitrary causal queries. Model definition makes use dagitty type syntax. Updating implemented 'stan'.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/CausalQueries_internal_inherit_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Create parameter documentation to inherit ‚Äî CausalQueries_internal_inherit_params","title":"Create parameter documentation to inherit ‚Äî CausalQueries_internal_inherit_params","text":"Create parameter documentation inherit","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/CausalQueries_internal_inherit_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create parameter documentation to inherit ‚Äî CausalQueries_internal_inherit_params","text":"","code":"CausalQueries_internal_inherit_params(   model,   query,   join_by,   parameters,   P,   A,   data,   data_events,   node,   statement,   using,   n_draws )"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/CausalQueries_internal_inherit_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create parameter documentation to inherit ‚Äî CausalQueries_internal_inherit_params","text":"model causal_model. model object generated make_model. query character string. expression defining nodal types interrogate. expression form \"Y[X=1]\" asks value Y X set 1 join_by logical operator. Used connect causal statements: ('&') ('|'). Defaults '|'. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn parameters dataframe. See inspect(model, \"parameters_df\"). P data.frame. Parameter matrix. required may provided avoid repeated computation simulations. See inspect(model, \"parameter_matrix\"). data.frame. Ambiguities matrix. required may provided avoid repeated computation simulations. inspect(model, \"ambiguities_matrix\") data data.frame.  Data nodes can take three values: 0, 1, NA. long form generated make_events data_events 'compact' data.frame one row per data type. Must compatible nodes model. default columns event, strategy count. node character string. quoted name node. statement character string. quoted causal statement. using character string. Indicates whether use `priors`, `posteriors` `parameters`. n_draws integer. prior distribution provided, generate prior distribution n_draws number draws.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/CausalQueries_internal_inherit_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create parameter documentation to inherit ‚Äî CausalQueries_internal_inherit_params","text":"function return anything. used   inherit roxygen documentation","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/check_args.html","id":null,"dir":"Reference","previous_headings":"","what":"helper to check arguments ‚Äî check_args","title":"helper to check arguments ‚Äî check_args","text":"helper check arguments","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/check_args.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"helper to check arguments ‚Äî check_args","text":"","code":"check_args(model, using, given, queries, case_level, fun)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/check_args.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"helper to check arguments ‚Äî check_args","text":"model passed parent function using passed parent function given passed parent function queries passed parent function fun string specifying name parent function","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/check_args.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"helper to check arguments ‚Äî check_args","text":"list altered arguments","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/clean_statement.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper to clean and check the validity of causal statements specifying a DAG. This function isolates nodes and edges specified in a causal statements and makes them processable by make_dag ‚Äî clean_statement","title":"Helper to clean and check the validity of causal statements specifying a DAG. This function isolates nodes and edges specified in a causal statements and makes them processable by make_dag ‚Äî clean_statement","text":"Helper clean check validity causal statements specifying DAG. function isolates nodes edges specified causal statements makes processable make_dag","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/clean_statement.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper to clean and check the validity of causal statements specifying a DAG. This function isolates nodes and edges specified in a causal statements and makes them processable by make_dag ‚Äî clean_statement","text":"","code":"clean_statement(statement)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/clean_statement.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper to clean and check the validity of causal statements specifying a DAG. This function isolates nodes and edges specified in a causal statements and makes them processable by make_dag ‚Äî clean_statement","text":"statement character string. Statement describing causal relations nodes.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/clean_statement.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper to clean and check the validity of causal statements specifying a DAG. This function isolates nodes and edges specified in a causal statements and makes them processable by make_dag ‚Äî clean_statement","text":"list nodes edges specified input statement","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/construct_commands_alter_at.html","id":null,"dir":"Reference","previous_headings":"","what":"make_par_values ‚Äî construct_commands_alter_at","title":"make_par_values ‚Äî construct_commands_alter_at","text":"helper generate filter commands specifying rows parameters_df altered given alter_at statement","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/construct_commands_alter_at.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_par_values ‚Äî construct_commands_alter_at","text":"","code":"construct_commands_alter_at(alter_at)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/construct_commands_alter_at.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_par_values ‚Äî construct_commands_alter_at","text":"alter_at string specifying filtering operations applied parameters_df, yielding logical vector indicating parameters values altered.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/construct_commands_alter_at.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"make_par_values ‚Äî construct_commands_alter_at","text":"string specifying filter command","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/construct_commands_other_args.html","id":null,"dir":"Reference","previous_headings":"","what":"make_par_values ‚Äî construct_commands_other_args","title":"make_par_values ‚Äî construct_commands_other_args","text":"helper generate filter commands specifying rows parameters_df altered given combinations nodes, nodal_types, param_sets, givens statements","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/construct_commands_other_args.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_par_values ‚Äî construct_commands_other_args","text":"","code":"construct_commands_other_args(   node,   nodal_type,   param_set,   given,   statement,   model,   join_by )"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/construct_commands_other_args.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_par_values ‚Äî construct_commands_other_args","text":"node string indicating nodes altered nodal_type string. Label nodal type indicating nodal types values altered param_set string indicating  name set parameters altered given string indicates node parameter altered depends statement causal query determines nodal types values altered model model created make_model join_by string specifying logical operator joining expanded types statement contains wildcards. Can take values '&' (logical ) '|' (logical ).","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/construct_commands_other_args.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"make_par_values ‚Äî construct_commands_other_args","text":"string specifying filter command","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/construct_commands_param_names.html","id":null,"dir":"Reference","previous_headings":"","what":"make_par_values ‚Äî construct_commands_param_names","title":"make_par_values ‚Äî construct_commands_param_names","text":"helper generate filter commands specifying rows parameters_df altered given vector parameter names","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/construct_commands_param_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_par_values ‚Äî construct_commands_param_names","text":"","code":"construct_commands_param_names(param_names, model_param_names)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/construct_commands_param_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_par_values ‚Äî construct_commands_param_names","text":"param_names vector strings. name specific parameter form , example, 'X.1', 'Y.01' model_param_names vector strings. Parameter names found model.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/construct_commands_param_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"make_par_values ‚Äî construct_commands_param_names","text":"string specifying filter command","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/data_helpers.html","id":null,"dir":"Reference","previous_headings":"","what":"Data helpers ‚Äî data_helpers","title":"Data helpers ‚Äî data_helpers","text":"Various helpers simulate data manipulate data types compact long forms. collapse_data can used convert long form data compact form data, expand_data can used convert compact form data (one row per data type) long form data (one row per observation). make_data generates dataset one row per observation. make_events generates dataset one row data type. Draws full data . generate various types incomplete data see make_data.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/data_helpers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data helpers ‚Äî data_helpers","text":"","code":"collapse_data(   data,   model,   drop_NA = TRUE,   drop_family = FALSE,   summary = FALSE )  expand_data(data_events = NULL, model)  make_data(   model,   n = NULL,   parameters = NULL,   param_type = NULL,   nodes = NULL,   n_steps = NULL,   probs = NULL,   subsets = TRUE,   complete_data = NULL,   given = NULL,   verbose = FALSE,   ... )  make_events(   model,   n = 1,   w = NULL,   P = NULL,   A = NULL,   parameters = NULL,   param_type = NULL,   include_strategy = FALSE,   ... )"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/data_helpers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data helpers ‚Äî data_helpers","text":"data data.frame.  Data nodes can take three values: 0, 1, NA. long form generated make_events model causal_model. model object generated make_model. drop_NA Logical. Whether exclude strategy families contain observed data. Exceptionally data provided, minimal data data first node returned. Defaults `TRUE` drop_family Logical. Whether remove column strategy output. Defaults `FALSE`. summary Logical. Whether return summary data. See details. Defaults `FALSE`. data_events 'compact' data.frame one row per data type. Must compatible nodes model. default columns event, strategy count. n integer. Number observations. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn parameters dataframe. See inspect(model, \"parameters_df\"). param_type character. String specifying type parameters make 'flat', 'prior_mean', 'posterior_mean', 'prior_draw', 'posterior_draw', 'define. param_type set define use arguments passed make_priors; otherwise flat sets equal probabilities nodal type parameter set; prior_mean, prior_draw, posterior_mean, posterior_draw take parameters means draws prior posterior. nodes list. nodes observed step. NULL nodes observed. n_steps list. Number observations observed step probs list. Observation probabilities step subsets list. Strata within observations observed step. TRUE , otherwise expression evaluates logical condition. complete_data data.frame. Dataset complete observations. Optional. given string specifying known values nodes, e.g. \"X==1 & Y==1\" verbose Logical. TRUE prints step schedule. ... Arguments passed make_priors param_type == define w numeric matrix. `n_parameters x 1` matrix event probabilities named rows. P data.frame. Parameter matrix. required may provided avoid repeated computation simulations. See inspect(model, \"parameter_matrix\"). data.frame. Ambiguities matrix. required may provided avoid repeated computation simulations. inspect(model, \"ambiguities_matrix\") include_strategy Logical. Whether include 'strategy' vector. Defaults FALSE. Strategy vector vary full data expected functions.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/data_helpers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data helpers ‚Äî data_helpers","text":"vector data events summary = TRUE `collapse_data` returns list containing   following components: data_events compact data.frame event types strategies. observed_events vector character strings specifying events      observed data unobserved_events vector character strings specifying      events observed data data.frame rows data observation data.frame simulated data. data.frame events","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/data_helpers.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data helpers ‚Äî data_helpers","text":"Note default behavior take account whether node already observed determining whether select . One can however specifically request observation nodes previously observed.","code":""},{"path":[]},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/data_helpers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data helpers ‚Äî data_helpers","text":"","code":"# \\donttest{  model <- make_model('X -> Y')  df <- data.frame(X = c(0,1,NA), Y = c(0,0,1))  df |> collapse_data(model) #>   event strategy count #> 1  X0Y0       XY     1 #> 2  X1Y0       XY     1 #> 3  X0Y1       XY     0 #> 4  X1Y1       XY     0 #> 5    Y0        Y     0 #> 6    Y1        Y     1  # Illustrating options  df |> collapse_data(model, drop_NA = FALSE) #>   event strategy count #> 1  X0Y0       XY     1 #> 2  X1Y0       XY     1 #> 3  X0Y1       XY     0 #> 4  X1Y1       XY     0 #> 5    Y0        Y     0 #> 6    Y1        Y     1 #> 7    X0        X     0 #> 8    X1        X     0  df |> collapse_data(model, drop_family = TRUE) #>   event count #> 1  X0Y0     1 #> 2  X1Y0     1 #> 3  X0Y1     0 #> 4  X1Y1     0 #> 5    Y0     0 #> 6    Y1     1  df |> collapse_data(model, summary = TRUE) #> $data_events #>   event strategy count #> 1  X0Y0       XY     1 #> 2  X1Y0       XY     1 #> 3  X0Y1       XY     0 #> 4  X1Y1       XY     0 #> 5    Y0        Y     0 #> 6    Y1        Y     1 #>  #> $observed_events #> [1] \"X0Y0\" \"X1Y0\" \"Y1\"   #>  #> $unobserved_events #> [1] \"X0Y1\" \"X1Y1\" \"Y0\"   #>   # Appropriate behavior given restricted models  model <- make_model('X -> Y') |>   set_restrictions('X[]==1') df <- make_data(model, n = 10) df[1,1] <- '' df |> collapse_data(model) #>   event strategy count #> 1  X0Y0       XY     2 #> 2  X0Y1       XY     7 #> 3    Y0        Y     1 #> 4    Y1        Y     0  df <- data.frame(X = 0:1) df |> collapse_data(model) #> X1 data is inconsistent with model and ignored #>   event strategy count #> 1    X0        X     1  # }  # \\donttest{ model <- make_model('X->M->Y') make_events(model, n = 5) |>   expand_data(model) #>   X M Y #> 1 0 0 0 #> 2 0 0 1 #> 3 1 0 0 #> 4 1 0 1 #> 5 1 1 1 make_events(model, n = 0) |>   expand_data(model) #>    X  M  Y #> 1 NA NA NA  # }   # Simple draws model <- make_model(\"X -> M -> Y\") make_data(model) #>   X M Y #> 1 0 1 0 make_data(model, n = 3, nodes = c(\"X\",\"Y\")) #>   X  M Y #> 1 1 NA 1 #> 2 1 NA 1 #> 3 1 NA 1 make_data(model, n = 3, param_type = \"prior_draw\") #>   X M Y #> 1 0 0 0 #> 2 0 0 1 #> 3 1 1 0 make_data(model, n = 10, param_type = \"define\", parameters =  0:9) #>    X M Y #> 1  1 0 0 #> 2  1 0 0 #> 3  1 0 1 #> 4  1 0 1 #> 5  1 1 0 #> 6  1 1 0 #> 7  1 1 1 #> 8  1 1 1 #> 9  1 1 1 #> 10 1 1 1  # Data Strategies # A strategy in which X, Y are observed for sure and M is observed # with 50% probability for X=1, Y=0 cases  model <- make_model(\"X -> M -> Y\") make_data(   model,   n = 8,   nodes = list(c(\"X\", \"Y\"), \"M\"),   probs = list(1, .5),   subsets = list(TRUE, \"X==1 & Y==0\")) #>   X  M Y #> 1 0 NA 0 #> 2 0 NA 1 #> 3 1  0 0 #> 4 1  0 0 #> 5 1 NA 0 #> 6 1 NA 1 #> 7 1 NA 0 #> 8 1 NA 1  # n not provided but inferred from largest n_step (not from sum of n_steps) make_data(   model,   nodes = list(c(\"X\", \"Y\"), \"M\"),   n_steps = list(5, 2)) #>   X  M Y #> 1 0  0 1 #> 2 0  1 1 #> 3 0 NA 1 #> 4 1 NA 0 #> 5 1 NA 0  # Wide then deep   make_data(   model,   n = 8,   nodes = list(c(\"X\", \"Y\"), \"M\"),   subsets = list(TRUE, \"!is.na(X) & !is.na(Y)\"),   n_steps = list(6, 2)) #>    X  M  Y #> 1  0  0  0 #> 2 NA NA NA #> 3  0 NA  1 #> 4  0 NA  1 #> 5  1 NA  0 #> 6  1  0  0 #> 7  1 NA  1 #> 8 NA NA NA   make_data(   model,   n = 8,   nodes = list(c(\"X\", \"Y\"), c(\"X\", \"M\")),   subsets = list(TRUE, \"is.na(X)\"),   n_steps = list(3, 2)) #>    X  M  Y #> 1  0 NA  0 #> 2 NA NA NA #> 3  0 NA  1 #> 4 NA NA NA #> 5  1  0 NA #> 6  1  0 NA #> 7  1 NA  0 #> 8 NA NA NA  # Example with probabilities at each step  make_data(   model,   n = 8,   nodes = list(c(\"X\", \"Y\"), c(\"X\", \"M\")),   subsets = list(TRUE, \"is.na(X)\"),   probs = list(.5, .2)) #>    X  M  Y #> 1  0  0 NA #> 2 NA NA NA #> 3 NA NA NA #> 4 NA NA NA #> 5  1 NA  1 #> 6  1 NA  1 #> 7  1 NA  0 #> 8  1 NA  0  # Example with given data make_data(model, given = \"X==1 & Y==1\", n = 5) #>   X M Y #> 1 1 0 1 #> 2 1 0 1 #> 3 1 0 1 #> 4 1 1 1 #> 5 1 1 1 # \\donttest{ model <- make_model('X -> Y') make_events(model = model) #>   event count #> 1  X0Y0     0 #> 2  X1Y0     1 #> 3  X0Y1     0 #> 4  X1Y1     0 make_events(model = model, param_type = 'prior_draw') #>   event count #> 1  X0Y0     0 #> 2  X1Y0     0 #> 3  X0Y1     0 #> 4  X1Y1     1 make_events(model = model, include_strategy = TRUE) #>   event strategy count #> 1  X0Y0       XY     1 #> 2  X1Y0       XY     0 #> 3  X0Y1       XY     0 #> 4  X1Y1       XY     0 # }"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/data_type_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Data type names ‚Äî data_type_names","title":"Data type names ‚Äî data_type_names","text":"Provides names data types","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/data_type_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data type names ‚Äî data_type_names","text":"","code":"data_type_names(model, data)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/data_type_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data type names ‚Äî data_type_names","text":"model causal_model. model object generated make_model. data data.frame.  Data nodes can take three values: 0, 1, NA. long form generated make_events","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/data_type_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data type names ‚Äî data_type_names","text":"vector strings data types","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/data_type_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data type names ‚Äî data_type_names","text":"","code":"model <- make_model('X -> Y') data <- make_data(model, n = 2) data_type_names(model, data) #> Error in data_type_names(model, data): could not find function \"data_type_names\""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/democracy_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Development and Democratization: Data for replication of analysis in *Integrated Inferences* ‚Äî democracy_data","title":"Development and Democratization: Data for replication of analysis in *Integrated Inferences* ‚Äî democracy_data","text":"dataset containing information inequality, democracy, mobilization, international pressure. Made devtools::use_data(democracy_data, CausalQueries)","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/democracy_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Development and Democratization: Data for replication of analysis in *Integrated Inferences* ‚Äî democracy_data","text":"","code":"democracy_data"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/democracy_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Development and Democratization: Data for replication of analysis in *Integrated Inferences* ‚Äî democracy_data","text":"data frame 84 rows 5 nodes: Case Case D Democracy Inequality P International Pressure M Mobilization","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/democracy_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Development and Democratization: Data for replication of analysis in *Integrated Inferences* ‚Äî democracy_data","text":"https://www.cambridge.org/core/journals/american-political-science-review/article/inequality--regime-change-democratic-transitions---stability--democratic-rule/C39AAF4CF274445555FF41F7CC896AE3#fndtn-supplementary-materials/","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/deparse_given.html","id":null,"dir":"Reference","previous_headings":"","what":"helper to separate query and givens in query statement ‚Äî deparse_given","title":"helper to separate query and givens in query statement ‚Äî deparse_given","text":"helper separate query givens query statement","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/deparse_given.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"helper to separate query and givens in query statement ‚Äî deparse_given","text":"","code":"deparse_given(query)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/draw_causal_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw a single causal type given a parameter vector ‚Äî draw_causal_type","title":"Draw a single causal type given a parameter vector ‚Äî draw_causal_type","text":"Output parameter data frame recording parameters (case level priors) case level causal type.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/draw_causal_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw a single causal type given a parameter vector ‚Äî draw_causal_type","text":"","code":"draw_causal_type(model, ...)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/draw_causal_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw a single causal type given a parameter vector ‚Äî draw_causal_type","text":"model causal_model. model object generated make_model. ... Arguments passed  `set_parameters`","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/draw_causal_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw a single causal type given a parameter vector ‚Äî draw_causal_type","text":"","code":"# Simple draw using model's parameter vector make_model(\"X -> M -> Y\") |> draw_causal_type() #> # A tibble: 10 √ó 9 #>    param_names node    gen param_set nodal_type given param_value priors #>    <chr>       <chr> <int> <chr>     <chr>      <chr>       <dbl>  <dbl> #>  1 X.0         X         1 X         0          \"\"           0.5       1 #>  2 X.1         X         1 X         1          \"\"           0.5       1 #>  3 M.00        M         2 M         00         \"\"           0.25      1 #>  4 M.10        M         2 M         10         \"\"           0.25      1 #>  5 M.01        M         2 M         01         \"\"           0.25      1 #>  6 M.11        M         2 M         11         \"\"           0.25      1 #>  7 Y.00        Y         3 Y         00         \"\"           0.25      1 #>  8 Y.10        Y         3 Y         10         \"\"           0.25      1 #>  9 Y.01        Y         3 Y         01         \"\"           0.25      1 #> 10 Y.11        Y         3 Y         11         \"\"           0.25      1 #> # ‚Ñπ 1 more variable: causal_type <int>  # Draw parameters from priors and draw type from parameters make_model(\"X -> M -> Y\") |> draw_causal_type(, param_type = \"prior_draw\") #> # A tibble: 10 √ó 9 #>    param_names node    gen param_set nodal_type given param_value priors #>    <chr>       <chr> <int> <chr>     <chr>      <chr>       <dbl>  <dbl> #>  1 X.0         X         1 X         0          \"\"       0.355         1 #>  2 X.1         X         1 X         1          \"\"       0.645         1 #>  3 M.00        M         2 M         00         \"\"       0.654         1 #>  4 M.10        M         2 M         10         \"\"       0.204         1 #>  5 M.01        M         2 M         01         \"\"       0.0204        1 #>  6 M.11        M         2 M         11         \"\"       0.121         1 #>  7 Y.00        Y         3 Y         00         \"\"       0.000978      1 #>  8 Y.10        Y         3 Y         10         \"\"       0.0656        1 #>  9 Y.01        Y         3 Y         01         \"\"       0.484         1 #> 10 Y.11        Y         3 Y         11         \"\"       0.450         1 #> # ‚Ñπ 1 more variable: causal_type <int>  # Draw type given specified parameters make_model(\"X -> M -> Y\") |> draw_causal_type(parameters = 1:10) #> # A tibble: 10 √ó 9 #>    param_names node    gen param_set nodal_type given param_value priors #>    <chr>       <chr> <int> <chr>     <chr>      <chr>       <dbl>  <dbl> #>  1 X.0         X         1 X         0          \"\"          0.333      1 #>  2 X.1         X         1 X         1          \"\"          0.667      1 #>  3 M.00        M         2 M         00         \"\"          0.167      1 #>  4 M.10        M         2 M         10         \"\"          0.222      1 #>  5 M.01        M         2 M         01         \"\"          0.278      1 #>  6 M.11        M         2 M         11         \"\"          0.333      1 #>  7 Y.00        Y         3 Y         00         \"\"          0.206      1 #>  8 Y.10        Y         3 Y         10         \"\"          0.235      1 #>  9 Y.01        Y         3 Y         01         \"\"          0.265      1 #> 10 Y.11        Y         3 Y         11         \"\"          0.294      1 #> # ‚Ñπ 1 more variable: causal_type <int>"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/drop_empty_families.html","id":null,"dir":"Reference","previous_headings":"","what":"Drop empty families ‚Äî drop_empty_families","title":"Drop empty families ‚Äî drop_empty_families","text":"Drop empty families","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/drop_empty_families.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Drop empty families ‚Äî drop_empty_families","text":"","code":"drop_empty_families(data_events)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/drop_empty_families.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Drop empty families ‚Äî drop_empty_families","text":"data_events data.frame. must compatible nodes model. default columns event, strategy count.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/drop_empty_families.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Drop empty families ‚Äî drop_empty_families","text":"Returns data events strategies (excluding  strategy families   contain observed data)","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/drop_empty_families.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Drop empty families ‚Äî drop_empty_families","text":"","code":"# \\donttest{ data_events <- data.frame(event = c('X0Y0', 'Y0'),                           strategy = c('XY', 'Y'),                           count = 1:0) CausalQueries:::drop_empty_families(data_events) #>   event strategy count #> 1  X0Y0       XY     1 # }"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/expand_nodal_expression.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper to expand nodal expression ‚Äî expand_nodal_expression","title":"Helper to expand nodal expression ‚Äî expand_nodal_expression","text":"Helper expand nodal expression","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/expand_nodal_expression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper to expand nodal expression ‚Äî expand_nodal_expression","text":"","code":"expand_nodal_expression(model, query, node, join_by = \"|\")"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/expand_nodal_expression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper to expand nodal expression ‚Äî expand_nodal_expression","text":"model causal_model. model object generated make_model. query character string. expression defining nodal types interrogate. expression form \"Y[X=1]\" asks value Y X set 1 node character string. quoted name node. join_by logical operator. Used connect causal statements: ('&') ('|'). Defaults '|'.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/expand_nodal_expression.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper to expand nodal expression ‚Äî expand_nodal_expression","text":"nodal expression missing parents","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_all_data_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Get all data types ‚Äî get_all_data_types","title":"Get all data types ‚Äî get_all_data_types","text":"Creates data frame data types (including NA types) possible model.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_all_data_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get all data types ‚Äî get_all_data_types","text":"","code":"get_all_data_types(   model,   complete_data = FALSE,   possible_data = FALSE,   given = NULL )"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_all_data_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get all data types ‚Äî get_all_data_types","text":"model causal_model. model object generated make_model. complete_data Logical. `TRUE` returns complete data types (NAs). Defaults `FALSE`. possible_data Logical. `TRUE` returns complete data types (NAs) *possible* given model restrictions. Note principle intervention make observationally impossible data types arise. Defaults `FALSE`. given character.  quoted statement evaluates logical. Data conditional specific values.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_all_data_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get all data types ‚Äî get_all_data_types","text":"data.frame data types (including NA types)   possible model.","code":""},{"path":[]},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_all_data_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get all data types ‚Äî get_all_data_types","text":"","code":"# \\donttest{ make_model('X -> Y') |> get_all_data_types() #>      event  X  Y #> X0Y0  X0Y0  0  0 #> X1Y0  X1Y0  1  0 #> X0Y1  X0Y1  0  1 #> X1Y1  X1Y1  1  1 #> Y0      Y0 NA  0 #> Y1      Y1 NA  1 #> X0      X0  0 NA #> X1      X1  1 NA #> None  None NA NA model <- make_model('X -> Y') |>   set_restrictions(labels = list(Y = '00'), keep = TRUE)   get_all_data_types(model) #>      event  X  Y #> X0Y0  X0Y0  0  0 #> X1Y0  X1Y0  1  0 #> X0Y1  X0Y1  0  1 #> X1Y1  X1Y1  1  1 #> Y0      Y0 NA  0 #> Y1      Y1 NA  1 #> X0      X0  0 NA #> X1      X1  1 NA #> None  None NA NA   get_all_data_types(model, complete_data = TRUE) #>      event X Y #> X0Y0  X0Y0 0 0 #> X1Y0  X1Y0 1 0 #> X0Y1  X0Y1 0 1 #> X1Y1  X1Y1 1 1   get_all_data_types(model, possible_data = TRUE) #>      event X Y #> X0Y0  X0Y0 0 0 #> X1Y0  X1Y0 1 0   get_all_data_types(model, given  = 'X==1') #>      event X  Y #> X1Y0  X1Y0 1  0 #> X1Y1  X1Y1 1  1 #> X1      X1 1 NA   get_all_data_types(model, given  = 'X==1 & Y==1') #>      event X Y #> X1Y1  X1Y1 1 1 # }"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_estimands.html","id":null,"dir":"Reference","previous_headings":"","what":"helper to get estimands ‚Äî get_estimands","title":"helper to get estimands ‚Äî get_estimands","text":"helper get estimands","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_estimands.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"helper to get estimands ‚Äî get_estimands","text":"","code":"get_estimands(jobs, given_types, query_types, type_distributions)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_estimands.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"helper to get estimands ‚Äî get_estimands","text":"jobs data frame argument combinations given_types output queries_to_types query_types output queries_to_types type_distributions output get_type_distributions","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_estimands.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"helper to get estimands ‚Äî get_estimands","text":"list estimands","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_event_probabilities.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw event probabilities ‚Äî get_event_probabilities","title":"Draw event probabilities ‚Äî get_event_probabilities","text":"`get_event_probabilities` draws event probability vector `w` given single realization parameters","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_event_probabilities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw event probabilities ‚Äî get_event_probabilities","text":"","code":"get_event_probabilities(   model,   parameters = NULL,   A = NULL,   P = NULL,   given = NULL )"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_event_probabilities.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw event probabilities ‚Äî get_event_probabilities","text":"model causal_model. model object generated make_model. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn parameters dataframe. See inspect(model, \"parameters_df\"). data.frame. Ambiguities matrix. required may provided avoid repeated computation simulations. inspect(model, \"ambiguities_matrix\") P data.frame. Parameter matrix. required may provided avoid repeated computation simulations. See inspect(model, \"parameter_matrix\"). given string specifying known values nodes, e.g. \"X==1 & Y==1\"","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_event_probabilities.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw event probabilities ‚Äî get_event_probabilities","text":"array event probabilities","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_event_probabilities.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw event probabilities ‚Äî get_event_probabilities","text":"","code":"# \\donttest{ model <- make_model('X -> Y') get_event_probabilities(model = model) #>      event_probs #> X0Y0        0.25 #> X1Y0        0.25 #> X0Y1        0.25 #> X1Y1        0.25 get_event_probabilities(model = model, given = \"X==1\") #>      event_probs #> X0Y0         0.0 #> X1Y0         0.5 #> X0Y1         0.0 #> X1Y1         0.5 get_event_probabilities(model = model, parameters = rep(1, 6)) #>      event_probs #> X0Y0        0.25 #> X1Y0        0.25 #> X0Y1        0.25 #> X1Y1        0.25 get_event_probabilities(model = model, parameters = 1:6) #>      event_probs #> X0Y0   0.1481481 #> X1Y0   0.2592593 #> X0Y1   0.1851852 #> X1Y1   0.4074074 # }"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_parameter_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Get parameter matrix ‚Äî get_parameter_matrix","title":"Get parameter matrix ‚Äî get_parameter_matrix","text":"Return parameter matrix exists; otherwise calculate assuming confounding. parameter matrix  maps parameters causal types. models without confounding parameters correspond nodal types.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_parameter_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get parameter matrix ‚Äî get_parameter_matrix","text":"","code":"get_parameter_matrix(model)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_parameter_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get parameter matrix ‚Äî get_parameter_matrix","text":"model model created make_model()","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_parameter_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get parameter matrix ‚Äî get_parameter_matrix","text":"data.frame, parameter matrix, mapping   parameters causal types","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_query_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Look up query types ‚Äî get_query_types","title":"Look up query types ‚Äî get_query_types","text":"Find nodal causal types satisfied query.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_query_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Look up query types ‚Äî get_query_types","text":"","code":"get_query_types(model, query, map = \"causal_type\", join_by = \"|\")"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_query_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Look up query types ‚Äî get_query_types","text":"model causal_model. model object generated make_model. query character string. expression defining nodal types interrogate. expression form \"Y[X=1]\" asks value Y X set 1 map Types query. Either nodal_type causal_type. Default causal_type. join_by logical operator. Used connect causal statements: ('&') ('|'). Defaults '|'.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_query_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Look up query types ‚Äî get_query_types","text":"list containing following elements types named vector logical values indicating whether   nodal_type causal_type satisfy `query` query character string specified user expanded_query character string expanded query.   differs `query` contains wildcard '.' evaluated_nodes Value nodes take given query node character string node whose   nodal types queried type_list List causal types satisfied query","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_query_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Look up query types ‚Äî get_query_types","text":"","code":"model <- make_model('X -> M -> Y; X->Y') query <- '(Y[X=0] > Y[X=1])' # \\donttest{ get_query_types(model, query, map=\"nodal_type\") #>  #> Nodal types adding weight to query #>  #>  query :  (Y[X=0,M=0]>Y[X=1,M=0] | Y[X=0,M=1]>Y[X=1,M=1])  #>  #>  1000   0010 #>  1010   0110 #>  1110   1001 #>  1011    #>  #>  #>  Number of nodal types that add weight to query = 7 #>  Total number of nodal types related to Y = 16 get_query_types(model, query, map=\"causal_type\") #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  (Y[X=0]>Y[X=1])  #>  #> X0.M00.Y1000  X1.M00.Y1000 #> X0.M01.Y1000  X1.M01.Y1000 #> X0.M01.Y1100  X1.M01.Y1100 #> X0.M10.Y0010  X1.M10.Y0010 #> X0.M11.Y0010  X1.M11.Y0010 #> X0.M00.Y1010  X1.M00.Y1010 #> X0.M10.Y1010  X1.M10.Y1010 #> X0.M01.Y1010  X1.M01.Y1010 #> X0.M11.Y1010  X1.M11.Y1010 #> X0.M11.Y0110  X1.M11.Y0110 #> X0.M01.Y1110  X1.M01.Y1110 #> X0.M11.Y1110  X1.M11.Y1110 #> X0.M00.Y1001  X1.M00.Y1001 #> X0.M10.Y0011  X1.M10.Y0011 #> X0.M00.Y1011  X1.M00.Y1011 #> X0.M10.Y1011  X1.M10.Y1011 #>  #>  #>  Number of causal types that meet condition(s) =  32 #>  Total number of causal types in model =  128 get_query_types(model, query) #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  (Y[X=0]>Y[X=1])  #>  #> X0.M00.Y1000  X1.M00.Y1000 #> X0.M01.Y1000  X1.M01.Y1000 #> X0.M01.Y1100  X1.M01.Y1100 #> X0.M10.Y0010  X1.M10.Y0010 #> X0.M11.Y0010  X1.M11.Y0010 #> X0.M00.Y1010  X1.M00.Y1010 #> X0.M10.Y1010  X1.M10.Y1010 #> X0.M01.Y1010  X1.M01.Y1010 #> X0.M11.Y1010  X1.M11.Y1010 #> X0.M11.Y0110  X1.M11.Y0110 #> X0.M01.Y1110  X1.M01.Y1110 #> X0.M11.Y1110  X1.M11.Y1110 #> X0.M00.Y1001  X1.M00.Y1001 #> X0.M10.Y0011  X1.M10.Y0011 #> X0.M00.Y1011  X1.M00.Y1011 #> X0.M10.Y1011  X1.M10.Y1011 #>  #>  #>  Number of causal types that meet condition(s) =  32 #>  Total number of causal types in model =  128  # Examples with map = \"nodal_type\"  query <- '(Y[X=0, M = .] > Y[X=1, M = 0])' get_query_types(model, query, map=\"nodal_type\") #>  #> Nodal types adding weight to query #>  #>  query :  (Y[X=0,M=0]>Y[X=1,M=0] | Y[X=0,M=1]>Y[X=1,M=0])  #>  #>  1000   0010 #>  1010   1001 #>  0011   1011 #>  #>  #>  Number of nodal types that add weight to query = 6 #>  Total number of nodal types related to Y = 16  query <- '(Y[] == 1)' get_query_types(model, query, map=\"nodal_type\") #>  #> Nodal types adding weight to query #>  #>  query :  (Y[X=0,M=0]==1 | Y[X=1,M=0]==1 | Y[X=0,M=1]==1 | Y[X=1,M=1]==1)  #>  #>  1000   0100 #>  1100   0010 #>  1010   0110 #>  1110   0001 #>  1001   0101 #>  1101   0011 #>  1011   0111 #>  1111    #>  #>  #>  Number of nodal types that add weight to query = 15 #>  Total number of nodal types related to Y = 16 get_query_types(model, query, map=\"nodal_type\", join_by = '&') #>  #> Nodal types adding weight to query #>  #>  query :  (Y[X=0,M=0]==1 & Y[X=1,M=0]==1 & Y[X=0,M=1]==1 & Y[X=1,M=1]==1)  #>  #>  1111    #>  #>  #>  Number of nodal types that add weight to query = 1 #>  Total number of nodal types related to Y = 16  # Root nodes specified with [] get_query_types(model, '(X[] == 1)', map=\"nodal_type\") #>  #> Nodal types adding weight to query #>  #>  query :  (X[]==1)  #>  #>  1    #>  #>  #>  Number of nodal types that add weight to query = 1 #>  Total number of nodal types related to X = 2  query <- '(M[X=1] == M[X=0])' get_query_types(model, query, map=\"nodal_type\") #>  #> Nodal types adding weight to query #>  #>  query :  (M[X=1]==M[X=0])  #>  #>  00   11 #>  #>  #>  Number of nodal types that add weight to query = 2 #>  Total number of nodal types related to M = 4  # Nested do operations get_query_types(  model = make_model('A -> B -> C -> D'),  query = '(D[C=C[B=B[A=1]], A=0] > D[C=C[B=B[A=0]], A=0])') #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  (D[C=C[B=B[A=1]],A=0]>D[C=C[B=B[A=0]],A=0])  #>  #> A0.B01.C10.D10  A1.B01.C10.D10 #> A0.B10.C01.D10  A1.B10.C01.D10 #> A0.B10.C10.D01  A1.B10.C10.D01 #> A0.B01.C01.D01  A1.B01.C01.D01 #>  #>  #>  Number of causal types that meet condition(s) =  8 #>  Total number of causal types in model =  128  # Helpers model <- make_model('M->Y; X->Y') query <- complements('X', 'M', 'Y') get_query_types(model, query, map=\"nodal_type\") #>  #> Nodal types adding weight to query #>  #>  query :  ((Y[X=1,M=1])-(Y[X=0,M=1]))>((Y[X=1,M=0])-(Y[X=0,M=0]))  #>  #>  1000   0001 #>  1001   1101 #>  1011    #>  #>  #>  Number of nodal types that add weight to query = 5 #>  Total number of nodal types related to Y = 16  # Examples with map = \"causal_type\"  model <- make_model('X -> M -> Y; X->Y') query <- 'Y[M=M[X=0], X=1]==1' get_query_types(model, query, map= \"causal_type\") #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  Y[M=M[X=0],X=1]==1  #>  #> X0.M00.Y0100  X1.M00.Y0100 #> X0.M01.Y0100  X1.M01.Y0100 #> X0.M00.Y1100  X1.M00.Y1100 #> X0.M01.Y1100  X1.M01.Y1100 #> X0.M00.Y0110  X1.M00.Y0110 #> X0.M01.Y0110  X1.M01.Y0110 #> X0.M00.Y1110  X1.M00.Y1110 #> X0.M01.Y1110  X1.M01.Y1110 #> X0.M10.Y0001  X1.M10.Y0001 #> X0.M11.Y0001  X1.M11.Y0001 #> X0.M10.Y1001  X1.M10.Y1001 #> X0.M11.Y1001  X1.M11.Y1001 #> X0.M00.Y0101  X1.M00.Y0101 #> X0.M10.Y0101  X1.M10.Y0101 #> X0.M01.Y0101  X1.M01.Y0101 #> X0.M11.Y0101  X1.M11.Y0101 #> X0.M00.Y1101  X1.M00.Y1101 #> X0.M10.Y1101  X1.M10.Y1101 #> X0.M01.Y1101  X1.M01.Y1101 #> X0.M11.Y1101  X1.M11.Y1101 #> X0.M10.Y0011  X1.M10.Y0011 #> X0.M11.Y0011  X1.M11.Y0011 #> X0.M10.Y1011  X1.M10.Y1011 #> X0.M11.Y1011  X1.M11.Y1011 #> X0.M00.Y0111  X1.M00.Y0111 #> X0.M10.Y0111  X1.M10.Y0111 #> X0.M01.Y0111  X1.M01.Y0111 #> X0.M11.Y0111  X1.M11.Y0111 #> X0.M00.Y1111  X1.M00.Y1111 #> X0.M10.Y1111  X1.M10.Y1111 #> X0.M01.Y1111  X1.M01.Y1111 #> X0.M11.Y1111  X1.M11.Y1111 #>  #>  #>  Number of causal types that meet condition(s) =  64 #>  Total number of causal types in model =  128  query <- '(Y[X = 1, M = 1] >  Y[X = 0, M = 1]) &           (Y[X = 1, M = 0] >  Y[X = 0, M = 0])' get_query_types(model, query, \"causal_type\") #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  (Y[X=1,M=1]>Y[X=0,M=1])& #> (Y[X=1,M=0]>Y[X=0,M=0])  #>  #> X0.M00.Y0101  X1.M00.Y0101 #> X0.M10.Y0101  X1.M10.Y0101 #> X0.M01.Y0101  X1.M01.Y0101 #> X0.M11.Y0101  X1.M11.Y0101 #>  #>  #>  Number of causal types that meet condition(s) =  8 #>  Total number of causal types in model =  128  query <- 'Y[X=1] == Y[X=0]' get_query_types(model, query, \"causal_type\") #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  Y[X=1]==Y[X=0]  #>  #> X0.M00.Y0000  X1.M00.Y0000 #> X0.M10.Y0000  X1.M10.Y0000 #> X0.M01.Y0000  X1.M01.Y0000 #> X0.M11.Y0000  X1.M11.Y0000 #> X0.M10.Y1000  X1.M10.Y1000 #> X0.M11.Y1000  X1.M11.Y1000 #> X0.M01.Y0100  X1.M01.Y0100 #> X0.M11.Y0100  X1.M11.Y0100 #> X0.M00.Y1100  X1.M00.Y1100 #> X0.M11.Y1100  X1.M11.Y1100 #> X0.M00.Y0010  X1.M00.Y0010 #> X0.M01.Y0010  X1.M01.Y0010 #> X0.M10.Y0110  X1.M10.Y0110 #> X0.M01.Y0110  X1.M01.Y0110 #> X0.M00.Y1110  X1.M00.Y1110 #> X0.M10.Y1110  X1.M10.Y1110 #> X0.M00.Y0001  X1.M00.Y0001 #> X0.M10.Y0001  X1.M10.Y0001 #> X0.M10.Y1001  X1.M10.Y1001 #> X0.M01.Y1001  X1.M01.Y1001 #> X0.M00.Y1101  X1.M00.Y1101 #> X0.M01.Y1101  X1.M01.Y1101 #> X0.M00.Y0011  X1.M00.Y0011 #> X0.M11.Y0011  X1.M11.Y0011 #> X0.M01.Y1011  X1.M01.Y1011 #> X0.M11.Y1011  X1.M11.Y1011 #> X0.M10.Y0111  X1.M10.Y0111 #> X0.M11.Y0111  X1.M11.Y0111 #> X0.M00.Y1111  X1.M00.Y1111 #> X0.M10.Y1111  X1.M10.Y1111 #> X0.M01.Y1111  X1.M01.Y1111 #> X0.M11.Y1111  X1.M11.Y1111 #>  #>  #>  Number of causal types that meet condition(s) =  64 #>  Total number of causal types in model =  128  query <- '(X == 1) & (M==1) & (Y ==1) & (Y[X=0] ==1)' get_query_types(model, query, \"causal_type\") #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  (X==1)&(M==1)&(Y==1)&(Y[X=0]==1)  #>  #> X1.M01.Y1001  X1.M01.Y1101 #> X1.M11.Y0011  X1.M01.Y1011 #> X1.M11.Y1011  X1.M11.Y0111 #> X1.M01.Y1111  X1.M11.Y1111 #>  #>  #>  Number of causal types that meet condition(s) =  8 #>  Total number of causal types in model =  128  query <- '(Y[X = .]==1)' get_query_types(model, query, \"causal_type\") #> Generated expanded expression: #> (Y[X=0]==1 | Y[X=1]==1) #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  (Y[X=0]==1|Y[X=1]==1)  #>  #> X0.M00.Y1000  X1.M00.Y1000 #> X0.M01.Y1000  X1.M01.Y1000 #> X0.M00.Y0100  X1.M00.Y0100 #> X0.M10.Y0100  X1.M10.Y0100 #> X0.M00.Y1100  X1.M00.Y1100 #> X0.M10.Y1100  X1.M10.Y1100 #> X0.M01.Y1100  X1.M01.Y1100 #> X0.M10.Y0010  X1.M10.Y0010 #> X0.M11.Y0010  X1.M11.Y0010 #> X0.M00.Y1010  X1.M00.Y1010 #> X0.M10.Y1010  X1.M10.Y1010 #> X0.M01.Y1010  X1.M01.Y1010 #> X0.M11.Y1010  X1.M11.Y1010 #> X0.M00.Y0110  X1.M00.Y0110 #> X0.M10.Y0110  X1.M10.Y0110 #> X0.M11.Y0110  X1.M11.Y0110 #> X0.M00.Y1110  X1.M00.Y1110 #> X0.M10.Y1110  X1.M10.Y1110 #> X0.M01.Y1110  X1.M01.Y1110 #> X0.M11.Y1110  X1.M11.Y1110 #> X0.M01.Y0001  X1.M01.Y0001 #> X0.M11.Y0001  X1.M11.Y0001 #> X0.M00.Y1001  X1.M00.Y1001 #> X0.M01.Y1001  X1.M01.Y1001 #> X0.M11.Y1001  X1.M11.Y1001 #> X0.M00.Y0101  X1.M00.Y0101 #> X0.M10.Y0101  X1.M10.Y0101 #> X0.M01.Y0101  X1.M01.Y0101 #> X0.M11.Y0101  X1.M11.Y0101 #> X0.M00.Y1101  X1.M00.Y1101 #> X0.M10.Y1101  X1.M10.Y1101 #> X0.M01.Y1101  X1.M01.Y1101 #> X0.M11.Y1101  X1.M11.Y1101 #> X0.M10.Y0011  X1.M10.Y0011 #> X0.M01.Y0011  X1.M01.Y0011 #> X0.M11.Y0011  X1.M11.Y0011 #> X0.M00.Y1011  X1.M00.Y1011 #> X0.M10.Y1011  X1.M10.Y1011 #> X0.M01.Y1011  X1.M01.Y1011 #> X0.M11.Y1011  X1.M11.Y1011 #> X0.M00.Y0111  X1.M00.Y0111 #> X0.M10.Y0111  X1.M10.Y0111 #> X0.M01.Y0111  X1.M01.Y0111 #> X0.M11.Y0111  X1.M11.Y0111 #> X0.M00.Y1111  X1.M00.Y1111 #> X0.M10.Y1111  X1.M10.Y1111 #> X0.M01.Y1111  X1.M01.Y1111 #> X0.M11.Y1111  X1.M11.Y1111 #>  #>  #>  Number of causal types that meet condition(s) =  96 #>  Total number of causal types in model =  128 # }"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_type_distributions.html","id":null,"dir":"Reference","previous_headings":"","what":"helper to get type distributions ‚Äî get_type_distributions","title":"helper to get type distributions ‚Äî get_type_distributions","text":"helper get type distributions","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_type_distributions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"helper to get type distributions ‚Äî get_type_distributions","text":"","code":"get_type_distributions(jobs, model, n_draws, parameters = NULL)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_type_distributions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"helper to get type distributions ‚Äî get_type_distributions","text":"jobs data frame argument combinations model list models n_draws integer specifying number draws prior distribution parameters optional list parameter vectors","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_type_distributions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"helper to get type distributions ‚Äî get_type_distributions","text":"jobs data frame nested column type distributions","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_type_prob_c.html","id":null,"dir":"Reference","previous_headings":"","what":"generates one draw from type probability distribution for each type in P ‚Äî get_type_prob_c","title":"generates one draw from type probability distribution for each type in P ‚Äî get_type_prob_c","text":"generates one draw type probability distribution type P","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_type_prob_c.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"generates one draw from type probability distribution for each type in P ‚Äî get_type_prob_c","text":"","code":"get_type_prob_c(P, parameters)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_type_prob_c.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"generates one draw from type probability distribution for each type in P ‚Äî get_type_prob_c","text":"P parameter_matrix parameters causal types parameters, priors posteriors","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_type_prob_c.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"generates one draw from type probability distribution for each type in P ‚Äî get_type_prob_c","text":"draw type distribution type P","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_type_prob_multiple_c.html","id":null,"dir":"Reference","previous_headings":"","what":"generates n draws from type probability distribution for each type in P ‚Äî get_type_prob_multiple_c","title":"generates n draws from type probability distribution for each type in P ‚Äî get_type_prob_multiple_c","text":"generates n draws type probability distribution type P","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_type_prob_multiple_c.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"generates n draws from type probability distribution for each type in P ‚Äî get_type_prob_multiple_c","text":"","code":"get_type_prob_multiple_c(params, P)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_type_prob_multiple_c.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"generates n draws from type probability distribution for each type in P ‚Äî get_type_prob_multiple_c","text":"params parameters, priors posteriors P parameter_matrix parameters causal types","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/get_type_prob_multiple_c.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"generates n draws from type probability distribution for each type in P ‚Äî get_type_prob_multiple_c","text":"draws type distribution type P","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/inspection.html","id":null,"dir":"Reference","previous_headings":"","what":"Helpers for inspecting causal models ‚Äî inspection","title":"Helpers for inspecting causal models ‚Äî inspection","text":"Various helpers inspect access internal objects generated used Causal Models Returns specified elements causal_model prints summary. Users can use inspect extract model's components objects implied model structure including nodal types, causal types, parameter priors, parameter posteriors, type priors, type posteriors, relevant elements. See argument options. Returns specified elements causal_model. Users can use inspect extract model's components objects implied model structure including nodal types, causal types, parameter priors, parameter posteriors, type priors, type posteriors, relevant elements. See argument options.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/inspection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helpers for inspecting causal models ‚Äî inspection","text":"","code":"inspect(model, what = NULL, ...)  grab(model, what = NULL, ...)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/inspection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helpers for inspecting causal models ‚Äî inspection","text":"model causal_model. model object generated make_model. character string specifying component retrieve. Available options : \"statement\" character string describing causal relations using dagitty syntax, \"nodes\" list containing nodes model, \"parents_df\" table listing nodes, whether root nodes , number names parents , \"parameters\" vector 'true' parameters, \"parameter_names\" vector names parameters, \"parameter_mapping\" matrix mapping parameters data types, \"parameter_matrix\" matrix mapping parameters causal types, \"parameters_df\" data frame containing parameter information, \"causal_types\" data frame listing causal types nodal types produce , \"nodal_types\" list nodal types model, \"data_types\" list data types consistent model; options see ?get_all_data_types, \"ambiguities_matrix\" matrix mapping causal types data types, \"type_prior\" matrix type probabilities using priors, \"prior_hyperparameters\" vector alpha values used parameterize Dirichlet prior distributions; optionally provide node names reduce output, e.g., inspect(prior_hyperparameters, nodes = c('M', 'Y')), \"prior_event_probabilities\" vector data (event) probabilities given single realization parameters; options see ?get_event_probabilities, \"prior_distribution\" data frame parameter prior distribution, \"posterior_distribution\" data frame parameter posterior distribution, \"posterior_event_probabilities\" sample data (event) probabilities posterior, \"type_distribution\" matrix type probabilities using posteriors, \"data\" data frame data provided update model, \"stanfit\" stanfit object generated Stan; prints stanfit summary updated parameter names, \"stan_warnings\" Messages generated generation stanfitobject. \"stan_summary\" list Stan outputs includes stanfit, data, , requested updating model, posterior event_probabilities type_distribution; prints stanfit summary updated parameter names. ... arguments passed helper \"get_*\" functions: get_all_data_types, get_event_probabilities,  get_priors, Anys additional arguments must named.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/inspection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helpers for inspecting causal models ‚Äî inspection","text":"Objects  can derived causal_model, summary. Quiet return objects can derived causal_model.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/inspection.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helpers for inspecting causal models ‚Äî inspection","text":"","code":"# \\donttest{  model <- make_model(\"X -> Y\") data <- make_data(model, n = 4)  inspect(model, what = \"statement\") #>  #> Causal statement:  #> X -> Y inspect(model, what = \"parameters\") #>  #> parameters #> Model parameters with associated probabilities:  #>  #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #> 0.50 0.50 0.25 0.25 0.25 0.25  inspect(model, what = \"nodes\") #>  #> Nodes:  #> X, Y inspect(model, what = \"parents_df\") #>  #> Root vs Non-Root status with number and names of parents for each node:  #>  #>   node  root parents parent_nodes #> 1    X  TRUE       0              #> 2    Y FALSE       1            X inspect(model, what = \"parameters_df\") #>  #> parameters_df #> Mapping of model parameters to nodal types:  #>  #>   param_names: name of parameter #>   node:        name of endogeneous node associated #>                with the parameter #>   gen:         partial causal ordering of the #>                parameter's node #>   param_set:   parameter groupings forming a simplex #>   given:       if model has confounding gives #>                conditioning nodal type #>   param_value: parameter values #>   priors:      hyperparameters of the prior #>                Dirichlet distribution  #>  #>   param_names node gen param_set nodal_type given param_value priors #> 1         X.0    X   1         X          0              0.50      1 #> 2         X.1    X   1         X          1              0.50      1 #> 3        Y.00    Y   2         Y         00              0.25      1 #> 4        Y.10    Y   2         Y         10              0.25      1 #> 5        Y.01    Y   2         Y         01              0.25      1 #> 6        Y.11    Y   2         Y         11              0.25      1 inspect(model, what = \"causal_types\") #>  #> causal_types (Causal Types) #>  #> Cartesian product of nodal types #>        X  Y #> X0.Y00 0 00 #> X1.Y00 1 00 #> X0.Y10 0 10 #> X1.Y10 1 10 #> X0.Y01 0 01 #> X1.Y01 1 01 #> X0.Y11 0 11 #> X1.Y11 1 11 inspect(model, what = \"prior_distribution\") #>  #> prior_distribution #> Summary statistics of model parameters prior distributions: #>  #>   Distributions matrix dimensions are  #>   4000 rows (draws) by 6 cols (parameters) #>  #>      mean   sd #> X.0  0.51 0.29 #> X.1  0.49 0.29 #> Y.00 0.25 0.20 #> Y.10 0.25 0.19 #> Y.01 0.25 0.20 #> Y.11 0.25 0.19 inspect(model, what = \"prior_hyperparameters\", nodes = \"Y\") #>  #> prior_hyperparameters #> Alpha parameter values used for Dirichlet prior distributions: #>  #> Y.00 Y.10 Y.01 Y.11  #>    1    1    1    1  inspect(model, what = \"prior_event_probabilities\", parameters = c(.1, .9, .25, .25, 0, .5)) #>  #> prior_event_probabilities #> Probabilities of observing data (events) #> for a specified set of parameter values: #>  #> data frame with 0 columns and 0 rows #> Error in .inspect.grab(model, what = what, print = TRUE, ...): The following requested object is not supported: prior_event_probabilities inspect(model, what = \"prior_event_probabilities\", given = \"Y==1\") #>  #> prior_event_probabilities #> Probabilities of observing data (events) #> for a specified set of parameter values: #>  #> data frame with 0 columns and 0 rows #> Error in .inspect.grab(model, what = what, print = TRUE, ...): The following requested object is not supported: prior_event_probabilities inspect(model, what = \"data_types\", complete_data = TRUE) #>  #> data_types (Data types): #> Data frame of all possible data (events) given the model: #>  #>      event X Y #> X0Y0  X0Y0 0 0 #> X1Y0  X1Y0 1 0 #> X0Y1  X0Y1 0 1 #> X1Y1  X1Y1 1 1 inspect(model, what = \"data_types\", complete_data = FALSE) #>  #> data_types (Data types): #> Data frame of all possible data (events) given the model: #>  #>      event  X  Y #> X0Y0  X0Y0  0  0 #> X1Y0  X1Y0  1  0 #> X0Y1  X0Y1  0  1 #> X1Y1  X1Y1  1  1 #> Y0      Y0 NA  0 #> Y1      Y1 NA  1 #> X0      X0  0 NA #> X1      X1  1 NA #> None  None NA NA   model <- update_model(model,   data = data,   keep_fit = TRUE,   keep_event_probabilities = TRUE) #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.1e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.138 seconds (Warm-up) #> Chain 1:                0.113 seconds (Sampling) #> Chain 1:                0.251 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1.7e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.133 seconds (Warm-up) #> Chain 2:                0.14 seconds (Sampling) #> Chain 2:                0.273 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 1.7e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.137 seconds (Warm-up) #> Chain 3:                0.13 seconds (Sampling) #> Chain 3:                0.267 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 1.7e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.14 seconds (Warm-up) #> Chain 4:                0.12 seconds (Sampling) #> Chain 4:                0.26 seconds (Total) #> Chain 4:   inspect(model, what = \"posterior_distribution\") #>  #> posterior_distribution #> Summary statistics of model parameters posterior distributions: #>  #>   Distributions matrix dimensions are  #>   4000 rows (draws) by 6 cols (parameters) #>  #>      mean   sd #> X.0  0.50 0.19 #> X.1  0.50 0.19 #> Y.00 0.21 0.16 #> Y.10 0.46 0.22 #> Y.01 0.13 0.11 #> Y.11 0.20 0.16 inspect(model, what = \"posterior_event_probabilities\") #>  #> posterior_event_probabilities #> Posterior draws of event probabilities (transformed parameters): #>  #>   Distributions matrix dimensions are  #>   4000 rows (draws) by 4 cols (events) #>  #>      mean   sd #> X0Y0 0.16 0.11 #> X1Y0 0.34 0.16 #> X0Y1 0.33 0.16 #> X1Y1 0.16 0.11 inspect(model, what = \"type_distribution\") #>  #> type_distribution #> Posterior draws of causal types (transformed parameters): #>  #>   Distributions matrix dimensions are  #>   4000 rows (draws) by 8 cols (causal types) #>  #>        mean   sd #> X0.Y00 0.10 0.09 #> X1.Y00 0.10 0.10 #> X0.Y10 0.23 0.15 #> X1.Y10 0.23 0.15 #> X0.Y01 0.06 0.06 #> X1.Y01 0.06 0.06 #> X0.Y11 0.10 0.09 #> X1.Y11 0.10 0.09 inspect(model, what = \"data\") #>  #> Data used to update the model: #>  #> data #>   Data frame dimensions are  #>   4 rows by 2 cols #>  #>   X Y #> 1 0 1 #> 2 0 1 #> 3 1 0 #> 4 1 0 inspect(model, what = \"stan_warnings\") #>  #> stan_warnings #> Stan warnings generated during updating: inspect(model, what = \"stanfit\") #>  #> stanfit #> Stan model summary: #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>              mean se_mean   sd   2.5%    25%    50%   75% 97.5% n_eff Rhat #> lambdas[1]   0.50    0.00 0.19   0.15   0.36   0.50  0.64  0.85  2618    1 #> lambdas[2]   0.50    0.00 0.19   0.15   0.36   0.50  0.64  0.85  2618    1 #> lambdas[3]   0.21    0.00 0.16   0.01   0.08   0.17  0.30  0.60  1955    1 #> lambdas[4]   0.46    0.00 0.22   0.05   0.30   0.47  0.63  0.85  3385    1 #> lambdas[5]   0.13    0.00 0.11   0.00   0.04   0.10  0.18  0.40  5006    1 #> lambdas[6]   0.20    0.00 0.16   0.01   0.08   0.17  0.30  0.59  4210    1 #> w[1]         0.16    0.00 0.11   0.02   0.08   0.14  0.23  0.44  2552    1 #> w[2]         0.34    0.00 0.16   0.07   0.22   0.32  0.44  0.69  3049    1 #> w[3]         0.33    0.00 0.16   0.08   0.21   0.32  0.44  0.68  2648    1 #> w[4]         0.16    0.00 0.11   0.02   0.08   0.14  0.22  0.45  3550    1 #> types[1]     0.10    0.00 0.09   0.00   0.03   0.08  0.14  0.34  1956    1 #> types[2]     0.10    0.00 0.10   0.00   0.03   0.08  0.15  0.36  2316    1 #> types[3]     0.23    0.00 0.15   0.02   0.12   0.21  0.32  0.56  3131    1 #> types[4]     0.23    0.00 0.15   0.02   0.12   0.21  0.32  0.56  3062    1 #> types[5]     0.06    0.00 0.06   0.00   0.02   0.04  0.09  0.23  4043    1 #> types[6]     0.06    0.00 0.06   0.00   0.02   0.04  0.09  0.23  4041    1 #> types[7]     0.10    0.00 0.09   0.00   0.03   0.08  0.15  0.34  3171    1 #> types[8]     0.10    0.00 0.09   0.00   0.03   0.08  0.14  0.35  3711    1 #> lp__       -10.49    0.04 1.62 -14.61 -11.26 -10.15 -9.29 -8.48  1306    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Nov 27 14:45:35 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  model <- make_model(\"X -> Y\")  x <- grab(model, what = \"statement\") x #> [1] \"X -> Y\""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/institutions_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Institutions and growth: Data for replication of analysis in *Integrated Inferences* ‚Äî institutions_data","title":"Institutions and growth: Data for replication of analysis in *Integrated Inferences* ‚Äî institutions_data","text":" dataset containing dichotomized versions variables Rodrik, Subramanian, Trebbi (2004).","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/institutions_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Institutions and growth: Data for replication of analysis in *Integrated Inferences* ‚Äî institutions_data","text":"","code":"institutions_data"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/institutions_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Institutions and growth: Data for replication of analysis in *Integrated Inferences* ‚Äî institutions_data","text":"data frame 79 rows 5 columns: Y Income (GDP PPP 1995), dichotomized R Institutions, (based  Kaufmann, Kraay, Zoido-Lobaton (2002)) dichotomized D Distance equator (degrees), dichotomized M Settler mortality (Acemoglu, Johnson, Robinson), dichotomized country Country","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/institutions_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Institutions and growth: Data for replication of analysis in *Integrated Inferences* ‚Äî institutions_data","text":"https://drodrik.scholar.harvard.edu/publications/institutions-rule-primacy-institutions--geography--integration","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/interpret_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Interpret or find position in nodal type ‚Äî interpret_type","title":"Interpret or find position in nodal type ‚Äî interpret_type","text":"Interprets position one digits (specified position) nodal type. Alternatively returns nodal type digit positions correspond one given condition.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/interpret_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interpret or find position in nodal type ‚Äî interpret_type","text":"","code":"interpret_type(model, condition = NULL, position = NULL, nodes = NULL)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/interpret_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interpret or find position in nodal type ‚Äî interpret_type","text":"model causal_model. model object generated make_model. condition vector characters. Strings specifying child node, followed '|' (given) values parent nodes model. position named list integers. name name child node model, value vector digit positions node's nodal type interpreted. See `Details`. nodes vector names nodes. Can used limit interpretation selected nodes.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/interpret_type.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interpret or find position in nodal type ‚Äî interpret_type","text":"named list interpretation positions   digits nodal type","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/interpret_type.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Interpret or find position in nodal type ‚Äî interpret_type","text":"node child node X k parents nodal type   represented X followed 2^k digits. Argument position   allows user interpret meaning one digit positions   nodal type. example position = list(X = 1:3) return   interpretation first three digits causal types X.   Argument condition allows users query digit position   nodal type providing instead values parent nodes given   child. example, condition = 'X | Z=0 & R=1' returns digit   position corresponds values X takes Z = 0 R = 1.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/interpret_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interpret or find position in nodal type ‚Äî interpret_type","text":"","code":"model <- make_model('R -> X; Z -> X; X -> Y') #Return interpretation of all digit positions of all nodes interpret_type(model) #> $R #>   node position display interpretation #> 1    R       NA      R0          R = 0 #> 2    R       NA      R1          R = 1 #>  #> $Z #>   node position display interpretation #> 1    Z       NA      Z0          Z = 0 #> 2    Z       NA      Z1          Z = 1 #>  #> $X #>   node position display    interpretation #> 1    X        1 X[*]*** X | R = 0 & Z = 0 #> 2    X        2 X*[*]** X | R = 1 & Z = 0 #> 3    X        3 X**[*]* X | R = 0 & Z = 1 #> 4    X        4 X***[*] X | R = 1 & Z = 1 #>  #> $Y #>   node position display interpretation #> 1    Y        1   Y[*]*      Y | X = 0 #> 2    Y        2   Y*[*]      Y | X = 1 #>  #Example using digit position interpret_type(model, position = list(X = c(3,4), Y = 1)) #> $<NA> #> NULL #>  #> $<NA> #> NULL #>  #> $X #>   node position display    interpretation #> 1    X        3 X**[*]* X | R = 0 & Z = 1 #> 2    X        4 X***[*] X | R = 1 & Z = 1 #>  #> $Y #>   node position display interpretation #> 1    Y        1   Y[*]*      Y | X = 0 #>  interpret_type(model, position = list(R = 1)) #> $R #>   node position display interpretation #> 1    R        1  RNA[*]        R |  =  #>  #> $<NA> #> NULL #>  #> $<NA> #> NULL #>  #> $<NA> #> NULL #>  #Example using condition interpret_type(model, condition = c('X | Z=0 & R=1', 'X | Z=0 & R=0')) #> $<NA> #> NULL #>  #> $<NA> #> NULL #>  #> $X #>   node position display    interpretation #> 1    X        1 X[*]*** X | R = 0 & Z = 0 #> 2    X        2 X*[*]** X | R = 1 & Z = 0 #>  #> $<NA> #> NULL #>  # Example using node names interpret_type(model, nodes = c(\"Y\", \"R\")) #> $Y #>   node position display interpretation #> 1    Y        1   Y[*]*      Y | X = 0 #> 2    Y        2   Y*[*]      Y | X = 1 #>  #> $R #>   node position display interpretation #> 1    R       NA      R0          R = 0 #> 2    R       NA      R1          R = 1 #>"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/lipids_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Lipids: Data for Chickering and Pearl replication ‚Äî lipids_data","title":"Lipids: Data for Chickering and Pearl replication ‚Äî lipids_data","text":"compact dataset containing information encouragement, (Z, cholestyramine prescription), treatment (X, usage), outcome (Y, cholesterol). David Maxwell Chickering Judea Pearl: \"Clinician‚Äôs Tool Analyzing Non-compliance\", AAAI-96 Proceedings. Chickering Pearl turn draw data Efron, Bradley, David Feldman. \"Compliance explanatory variable clinical trials.\" Journal American Statistical Association 86.413 (1991): 9-17.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/lipids_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lipids: Data for Chickering and Pearl replication ‚Äî lipids_data","text":"","code":"lipids_data"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/lipids_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Lipids: Data for Chickering and Pearl replication ‚Äî lipids_data","text":"data frame 8 rows 3 columns: event data type strategy nodes data available count Number units data type","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/lipids_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Lipids: Data for Chickering and Pearl replication ‚Äî lipids_data","text":"https://cdn.aaai.org/AAAI/1996/AAAI96-188.pdf","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/list_non_parents.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns a list with the nodes that are not directly pointing into a node ‚Äî list_non_parents","title":"Returns a list with the nodes that are not directly pointing into a node ‚Äî list_non_parents","text":"Returns list nodes directly pointing node","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/list_non_parents.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns a list with the nodes that are not directly pointing into a node ‚Äî list_non_parents","text":"","code":"list_non_parents(model, node)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/list_non_parents.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns a list with the nodes that are not directly pointing into a node ‚Äî list_non_parents","text":"model causal_model. model object generated make_model. node character string. quoted name node.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/list_non_parents.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns a list with the nodes that are not directly pointing into a node ‚Äî list_non_parents","text":"Returns list nodes directly  pointing node","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_dag.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper to run a causal statement specifying a DAG into a data.frame of pairwise parent child relations between nodes specified by a respective edge. ‚Äî make_dag","title":"Helper to run a causal statement specifying a DAG into a data.frame of pairwise parent child relations between nodes specified by a respective edge. ‚Äî make_dag","text":"Helper run causal statement specifying DAG data.frame pairwise parent child relations nodes specified respective edge.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_dag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper to run a causal statement specifying a DAG into a data.frame of pairwise parent child relations between nodes specified by a respective edge. ‚Äî make_dag","text":"","code":"make_dag(statement)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_dag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper to run a causal statement specifying a DAG into a data.frame of pairwise parent child relations between nodes specified by a respective edge. ‚Äî make_dag","text":"statement character string. Statement describing causal relations nodes. directed relations permitted. instance \"X -> Y\"  \"X1 -> Y <- X2; X1 -> X2\"","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_dag.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper to run a causal statement specifying a DAG into a data.frame of pairwise parent child relations between nodes specified by a respective edge. ‚Äî make_dag","text":"data.frame columns v, w, e specifying parent, child   edge respectively","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_data_single.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate full dataset ‚Äî make_data_single","title":"Generate full dataset ‚Äî make_data_single","text":"Generate full dataset","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_data_single.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate full dataset ‚Äî make_data_single","text":"","code":"make_data_single(   model,   n = 1,   parameters = NULL,   param_type = NULL,   given = NULL,   w = NULL,   P = NULL,   A = NULL )"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_data_single.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate full dataset ‚Äî make_data_single","text":"model causal_model. model object generated make_model. n integer. Number observations. parameters numeric vector. Values parameters may specified. default, parameters drawn priors. param_type character. String specifying type parameters make (\"flat\", \"prior_mean\", \"posterior_mean\", \"prior_draw\", \"posterior_draw\", \"define). param_type set define use arguments passed make_priors; otherwise flat sets equal probabilities nodal type parameter set; prior_mean, prior_draw, posterior_mean, posterior_draw take parameters means draws prior posterior. given string specifying known values nodes, e.g. \"X==1 & Y==1\" w Vector event probabilities can provided directly. useful speed repeated data draws. P matrix. Parameter matrix can used generate w w provided matrix. Ambiguity matrix can used generate w w provided","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_data_single.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate full dataset ‚Äî make_data_single","text":"data.frame simulated data.","code":""},{"path":[]},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_data_single.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate full dataset ‚Äî make_data_single","text":"","code":"model <- make_model(\"X -> Y\")  # Simplest behavior uses by default the parameter vector contained in model CausalQueries:::make_data_single(model, n = 5) #>   X Y #> 1 0 1 #> 2 0 1 #> 3 0 1 #> 4 1 0 #> 5 1 0  CausalQueries:::make_data_single(model, n = 5, param_type = \"prior_draw\") #>   X Y #> 1 0 0 #> 2 0 0 #> 3 0 1 #> 4 1 0 #> 5 1 0  # Simulate multiple datasets. This is fastest if # event probabilities (w) are  provided w <- get_event_probabilities(model) replicate(5, CausalQueries:::make_data_single(model, n = 5, w = w)) #>   [,1]      [,2]      [,3]      [,4]      [,5]      #> X numeric,5 numeric,5 numeric,5 numeric,5 numeric,5 #> Y numeric,5 numeric,5 numeric,5 numeric,5 numeric,5"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a model ‚Äî make_model","title":"Make a model ‚Äî make_model","text":"make_model uses causal statements encoded strings specify nodes edges graph. Implied causal types calculated default priors provided assumption confounding. Models can updated specification parameter matrix, P, providing restrictions causal types, /providing informative priors parameters. default setting causal model flat (uniform) priors parameters putting equal weight parameter within parameter set. can adjust set_priors set_parameters","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a model ‚Äî make_model","text":"","code":"make_model(statement, add_causal_types = TRUE, nodal_types = NULL)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make a model ‚Äî make_model","text":"statement character string. Statement describing causal relations nodes. directed relations permitted. instance \"X -> Y\"  \"X1 -> Y <- X2; X1 -> X2\". add_causal_types Logical. Whether create attach causal types model. Defaults `TRUE`. nodal_types List nodal types associated model nodes","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make a model ‚Äî make_model","text":"object class causal_model. object class \"causal_model\" list containing least following components: statement character vector statement defines model dag data.frame columns `parent``children`   indicating nodes relate . nodes named list nodes model parents_df data.frame listing nodes, whether   root nodes , number parents nodal_types Optional: named list nodal types   model. List ordered according causal ordering   nodes. NULL nodal types generated. FALSE, parameters data   frame generated. parameters_df data.frame descriptive information   parameters model causal_types data.frame listing causal types   nodal types produce ","code":""},{"path":[]},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make a model ‚Äî make_model","text":"","code":"make_model(statement = \"X -> Y\") #>  #> Causal statement:  #> X -> Y #>  #> Number of nodal types by node: #> X Y  #> 2 4  #>  #> Number of causal types: 8 modelXKY <- make_model(\"X -> K -> Y; X -> Y\")  # Example where cyclicaly dag attempted if (FALSE) { # \\dontrun{  modelXKX <- make_model(\"X -> K -> X\") } # }  # Examples with confounding model <- make_model(\"X->Y; X <-> Y\") inspect(model, \"parameter_matrix\") #>  #> parameter_matrix: #>  #>   rows:   parameters #>   cols:   causal types #>   cells:  whether a parameter probability is used #>           in the calculation of causal type probability #>  #>          X0.Y00 X1.Y00 X0.Y10 X1.Y10 X0.Y01 X1.Y01 X0.Y11 X1.Y11 #> X.0           1      0      1      0      1      0      1      0 #> X.1           0      1      0      1      0      1      0      1 #> Y.00_X.0      1      0      0      0      0      0      0      0 #> Y.10_X.0      0      0      1      0      0      0      0      0 #> Y.01_X.0      0      0      0      0      1      0      0      0 #> Y.11_X.0      0      0      0      0      0      0      1      0 #> Y.00_X.1      0      1      0      0      0      0      0      0 #> Y.10_X.1      0      0      0      1      0      0      0      0 #> Y.01_X.1      0      0      0      0      0      1      0      0 #> Y.11_X.1      0      0      0      0      0      0      0      1 model <- make_model(\"Y2 <- X -> Y1; X <-> Y1; X <-> Y2\") dim(inspect(model, \"parameter_matrix\")) #>  #> parameter_matrix: #>  #>   rows:   parameters #>   cols:   causal types #>   cells:  whether a parameter probability is used #>           in the calculation of causal type probability #>  #>           X0.Y100.Y200 X1.Y100.Y200 X0.Y110.Y200 X1.Y110.Y200 X0.Y101.Y200 #> X.0                  1            0            1            0            1 #> X.1                  0            1            0            1            0 #> Y1.00_X.0            1            0            0            0            0 #> Y1.10_X.0            0            0            1            0            0 #> Y1.01_X.0            0            0            0            0            1 #> Y1.11_X.0            0            0            0            0            0 #> Y1.00_X.1            0            1            0            0            0 #> Y1.10_X.1            0            0            0            1            0 #> Y1.01_X.1            0            0            0            0            0 #> Y1.11_X.1            0            0            0            0            0 #> Y2.00_X.0            1            0            1            0            1 #> Y2.10_X.0            0            0            0            0            0 #> Y2.01_X.0            0            0            0            0            0 #> Y2.11_X.0            0            0            0            0            0 #> Y2.00_X.1            0            1            0            1            0 #> Y2.10_X.1            0            0            0            0            0 #> Y2.01_X.1            0            0            0            0            0 #> Y2.11_X.1            0            0            0            0            0 #>           X1.Y101.Y200 X0.Y111.Y200 X1.Y111.Y200 X0.Y100.Y210 X1.Y100.Y210 #> X.0                  0            1            0            1            0 #> X.1                  1            0            1            0            1 #> Y1.00_X.0            0            0            0            1            0 #> Y1.10_X.0            0            0            0            0            0 #> Y1.01_X.0            0            0            0            0            0 #> Y1.11_X.0            0            1            0            0            0 #> Y1.00_X.1            0            0            0            0            1 #> Y1.10_X.1            0            0            0            0            0 #> Y1.01_X.1            1            0            0            0            0 #> Y1.11_X.1            0            0            1            0            0 #> Y2.00_X.0            0            1            0            0            0 #> Y2.10_X.0            0            0            0            1            0 #> Y2.01_X.0            0            0            0            0            0 #> Y2.11_X.0            0            0            0            0            0 #> Y2.00_X.1            1            0            1            0            0 #> Y2.10_X.1            0            0            0            0            1 #> Y2.01_X.1            0            0            0            0            0 #> Y2.11_X.1            0            0            0            0            0 #>           X0.Y110.Y210 X1.Y110.Y210 X0.Y101.Y210 X1.Y101.Y210 X0.Y111.Y210 #> X.0                  1            0            1            0            1 #> X.1                  0            1            0            1            0 #> Y1.00_X.0            0            0            0            0            0 #> Y1.10_X.0            1            0            0            0            0 #> Y1.01_X.0            0            0            1            0            0 #> Y1.11_X.0            0            0            0            0            1 #> Y1.00_X.1            0            0            0            0            0 #> Y1.10_X.1            0            1            0            0            0 #> Y1.01_X.1            0            0            0            1            0 #> Y1.11_X.1            0            0            0            0            0 #> Y2.00_X.0            0            0            0            0            0 #> Y2.10_X.0            1            0            1            0            1 #> Y2.01_X.0            0            0            0            0            0 #> Y2.11_X.0            0            0            0            0            0 #> Y2.00_X.1            0            0            0            0            0 #> Y2.10_X.1            0            1            0            1            0 #> Y2.01_X.1            0            0            0            0            0 #> Y2.11_X.1            0            0            0            0            0 #>           X1.Y111.Y210 X0.Y100.Y201 X1.Y100.Y201 X0.Y110.Y201 X1.Y110.Y201 #> X.0                  0            1            0            1            0 #> X.1                  1            0            1            0            1 #> Y1.00_X.0            0            1            0            0            0 #> Y1.10_X.0            0            0            0            1            0 #> Y1.01_X.0            0            0            0            0            0 #> Y1.11_X.0            0            0            0            0            0 #> Y1.00_X.1            0            0            1            0            0 #> Y1.10_X.1            0            0            0            0            1 #> Y1.01_X.1            0            0            0            0            0 #> Y1.11_X.1            1            0            0            0            0 #> Y2.00_X.0            0            0            0            0            0 #> Y2.10_X.0            0            0            0            0            0 #> Y2.01_X.0            0            1            0            1            0 #> Y2.11_X.0            0            0            0            0            0 #> Y2.00_X.1            0            0            0            0            0 #> Y2.10_X.1            1            0            0            0            0 #> Y2.01_X.1            0            0            1            0            1 #> Y2.11_X.1            0            0            0            0            0 #>           X0.Y101.Y201 X1.Y101.Y201 X0.Y111.Y201 X1.Y111.Y201 X0.Y100.Y211 #> X.0                  1            0            1            0            1 #> X.1                  0            1            0            1            0 #> Y1.00_X.0            0            0            0            0            1 #> Y1.10_X.0            0            0            0            0            0 #> Y1.01_X.0            1            0            0            0            0 #> Y1.11_X.0            0            0            1            0            0 #> Y1.00_X.1            0            0            0            0            0 #> Y1.10_X.1            0            0            0            0            0 #> Y1.01_X.1            0            1            0            0            0 #> Y1.11_X.1            0            0            0            1            0 #> Y2.00_X.0            0            0            0            0            0 #> Y2.10_X.0            0            0            0            0            0 #> Y2.01_X.0            1            0            1            0            0 #> Y2.11_X.0            0            0            0            0            1 #> Y2.00_X.1            0            0            0            0            0 #> Y2.10_X.1            0            0            0            0            0 #> Y2.01_X.1            0            1            0            1            0 #> Y2.11_X.1            0            0            0            0            0 #>           X1.Y100.Y211 X0.Y110.Y211 X1.Y110.Y211 X0.Y101.Y211 X1.Y101.Y211 #> X.0                  0            1            0            1            0 #> X.1                  1            0            1            0            1 #> Y1.00_X.0            0            0            0            0            0 #> Y1.10_X.0            0            1            0            0            0 #> Y1.01_X.0            0            0            0            1            0 #> Y1.11_X.0            0            0            0            0            0 #> Y1.00_X.1            1            0            0            0            0 #> Y1.10_X.1            0            0            1            0            0 #> Y1.01_X.1            0            0            0            0            1 #> Y1.11_X.1            0            0            0            0            0 #> Y2.00_X.0            0            0            0            0            0 #> Y2.10_X.0            0            0            0            0            0 #> Y2.01_X.0            0            0            0            0            0 #> Y2.11_X.0            0            1            0            1            0 #> Y2.00_X.1            0            0            0            0            0 #> Y2.10_X.1            0            0            0            0            0 #> Y2.01_X.1            0            0            0            0            0 #> Y2.11_X.1            1            0            1            0            1 #>           X0.Y111.Y211 X1.Y111.Y211 #> X.0                  1            0 #> X.1                  0            1 #> Y1.00_X.0            0            0 #> Y1.10_X.0            0            0 #> Y1.01_X.0            0            0 #> Y1.11_X.0            1            0 #> Y1.00_X.1            0            0 #> Y1.10_X.1            0            0 #> Y1.01_X.1            0            0 #> Y1.11_X.1            0            1 #> Y2.00_X.0            0            0 #> Y2.10_X.0            0            0 #> Y2.01_X.0            0            0 #> Y2.11_X.0            1            0 #> Y2.00_X.1            0            0 #> Y2.10_X.1            0            0 #> Y2.01_X.1            0            0 #> Y2.11_X.1            0            1 #> [1] 18 32 inspect(model, \"parameter_matrix\") #>  #> parameter_matrix: #>  #>   rows:   parameters #>   cols:   causal types #>   cells:  whether a parameter probability is used #>           in the calculation of causal type probability #>  #>           X0.Y100.Y200 X1.Y100.Y200 X0.Y110.Y200 X1.Y110.Y200 X0.Y101.Y200 #> X.0                  1            0            1            0            1 #> X.1                  0            1            0            1            0 #> Y1.00_X.0            1            0            0            0            0 #> Y1.10_X.0            0            0            1            0            0 #> Y1.01_X.0            0            0            0            0            1 #> Y1.11_X.0            0            0            0            0            0 #> Y1.00_X.1            0            1            0            0            0 #> Y1.10_X.1            0            0            0            1            0 #> Y1.01_X.1            0            0            0            0            0 #> Y1.11_X.1            0            0            0            0            0 #> Y2.00_X.0            1            0            1            0            1 #> Y2.10_X.0            0            0            0            0            0 #> Y2.01_X.0            0            0            0            0            0 #> Y2.11_X.0            0            0            0            0            0 #> Y2.00_X.1            0            1            0            1            0 #> Y2.10_X.1            0            0            0            0            0 #> Y2.01_X.1            0            0            0            0            0 #> Y2.11_X.1            0            0            0            0            0 #>           X1.Y101.Y200 X0.Y111.Y200 X1.Y111.Y200 X0.Y100.Y210 X1.Y100.Y210 #> X.0                  0            1            0            1            0 #> X.1                  1            0            1            0            1 #> Y1.00_X.0            0            0            0            1            0 #> Y1.10_X.0            0            0            0            0            0 #> Y1.01_X.0            0            0            0            0            0 #> Y1.11_X.0            0            1            0            0            0 #> Y1.00_X.1            0            0            0            0            1 #> Y1.10_X.1            0            0            0            0            0 #> Y1.01_X.1            1            0            0            0            0 #> Y1.11_X.1            0            0            1            0            0 #> Y2.00_X.0            0            1            0            0            0 #> Y2.10_X.0            0            0            0            1            0 #> Y2.01_X.0            0            0            0            0            0 #> Y2.11_X.0            0            0            0            0            0 #> Y2.00_X.1            1            0            1            0            0 #> Y2.10_X.1            0            0            0            0            1 #> Y2.01_X.1            0            0            0            0            0 #> Y2.11_X.1            0            0            0            0            0 #>           X0.Y110.Y210 X1.Y110.Y210 X0.Y101.Y210 X1.Y101.Y210 X0.Y111.Y210 #> X.0                  1            0            1            0            1 #> X.1                  0            1            0            1            0 #> Y1.00_X.0            0            0            0            0            0 #> Y1.10_X.0            1            0            0            0            0 #> Y1.01_X.0            0            0            1            0            0 #> Y1.11_X.0            0            0            0            0            1 #> Y1.00_X.1            0            0            0            0            0 #> Y1.10_X.1            0            1            0            0            0 #> Y1.01_X.1            0            0            0            1            0 #> Y1.11_X.1            0            0            0            0            0 #> Y2.00_X.0            0            0            0            0            0 #> Y2.10_X.0            1            0            1            0            1 #> Y2.01_X.0            0            0            0            0            0 #> Y2.11_X.0            0            0            0            0            0 #> Y2.00_X.1            0            0            0            0            0 #> Y2.10_X.1            0            1            0            1            0 #> Y2.01_X.1            0            0            0            0            0 #> Y2.11_X.1            0            0            0            0            0 #>           X1.Y111.Y210 X0.Y100.Y201 X1.Y100.Y201 X0.Y110.Y201 X1.Y110.Y201 #> X.0                  0            1            0            1            0 #> X.1                  1            0            1            0            1 #> Y1.00_X.0            0            1            0            0            0 #> Y1.10_X.0            0            0            0            1            0 #> Y1.01_X.0            0            0            0            0            0 #> Y1.11_X.0            0            0            0            0            0 #> Y1.00_X.1            0            0            1            0            0 #> Y1.10_X.1            0            0            0            0            1 #> Y1.01_X.1            0            0            0            0            0 #> Y1.11_X.1            1            0            0            0            0 #> Y2.00_X.0            0            0            0            0            0 #> Y2.10_X.0            0            0            0            0            0 #> Y2.01_X.0            0            1            0            1            0 #> Y2.11_X.0            0            0            0            0            0 #> Y2.00_X.1            0            0            0            0            0 #> Y2.10_X.1            1            0            0            0            0 #> Y2.01_X.1            0            0            1            0            1 #> Y2.11_X.1            0            0            0            0            0 #>           X0.Y101.Y201 X1.Y101.Y201 X0.Y111.Y201 X1.Y111.Y201 X0.Y100.Y211 #> X.0                  1            0            1            0            1 #> X.1                  0            1            0            1            0 #> Y1.00_X.0            0            0            0            0            1 #> Y1.10_X.0            0            0            0            0            0 #> Y1.01_X.0            1            0            0            0            0 #> Y1.11_X.0            0            0            1            0            0 #> Y1.00_X.1            0            0            0            0            0 #> Y1.10_X.1            0            0            0            0            0 #> Y1.01_X.1            0            1            0            0            0 #> Y1.11_X.1            0            0            0            1            0 #> Y2.00_X.0            0            0            0            0            0 #> Y2.10_X.0            0            0            0            0            0 #> Y2.01_X.0            1            0            1            0            0 #> Y2.11_X.0            0            0            0            0            1 #> Y2.00_X.1            0            0            0            0            0 #> Y2.10_X.1            0            0            0            0            0 #> Y2.01_X.1            0            1            0            1            0 #> Y2.11_X.1            0            0            0            0            0 #>           X1.Y100.Y211 X0.Y110.Y211 X1.Y110.Y211 X0.Y101.Y211 X1.Y101.Y211 #> X.0                  0            1            0            1            0 #> X.1                  1            0            1            0            1 #> Y1.00_X.0            0            0            0            0            0 #> Y1.10_X.0            0            1            0            0            0 #> Y1.01_X.0            0            0            0            1            0 #> Y1.11_X.0            0            0            0            0            0 #> Y1.00_X.1            1            0            0            0            0 #> Y1.10_X.1            0            0            1            0            0 #> Y1.01_X.1            0            0            0            0            1 #> Y1.11_X.1            0            0            0            0            0 #> Y2.00_X.0            0            0            0            0            0 #> Y2.10_X.0            0            0            0            0            0 #> Y2.01_X.0            0            0            0            0            0 #> Y2.11_X.0            0            1            0            1            0 #> Y2.00_X.1            0            0            0            0            0 #> Y2.10_X.1            0            0            0            0            0 #> Y2.01_X.1            0            0            0            0            0 #> Y2.11_X.1            1            0            1            0            1 #>           X0.Y111.Y211 X1.Y111.Y211 #> X.0                  1            0 #> X.1                  0            1 #> Y1.00_X.0            0            0 #> Y1.10_X.0            0            0 #> Y1.01_X.0            0            0 #> Y1.11_X.0            1            0 #> Y1.00_X.1            0            0 #> Y1.10_X.1            0            0 #> Y1.01_X.1            0            0 #> Y1.11_X.1            0            1 #> Y2.00_X.0            0            0 #> Y2.10_X.0            0            0 #> Y2.01_X.0            0            0 #> Y2.11_X.0            1            0 #> Y2.00_X.1            0            0 #> Y2.10_X.1            0            0 #> Y2.01_X.1            0            0 #> Y2.11_X.1            0            1 model <- make_model(\"X1 -> Y <- X2; X1 <-> Y; X2 <-> Y\") dim(inspect(model, \"parameter_matrix\")) #>  #> parameter_matrix: #>  #>   rows:   parameters #>   cols:   causal types #>   cells:  whether a parameter probability is used #>           in the calculation of causal type probability #>  #>                  X10.X20.Y0000 X11.X20.Y0000 X10.X21.Y0000 X11.X21.Y0000 #> X1.0                         1             0             1             0 #> X1.1                         0             1             0             1 #> X2.0                         1             1             0             0 #> X2.1                         0             0             1             1 #> Y.0000_X1.0_X2.0             1             0             0             0 #> Y.1000_X1.0_X2.0             0             0             0             0 #> Y.0100_X1.0_X2.0             0             0             0             0 #> Y.1100_X1.0_X2.0             0             0             0             0 #> Y.0010_X1.0_X2.0             0             0             0             0 #> Y.1010_X1.0_X2.0             0             0             0             0 #> Y.0110_X1.0_X2.0             0             0             0             0 #> Y.1110_X1.0_X2.0             0             0             0             0 #> Y.0001_X1.0_X2.0             0             0             0             0 #> Y.1001_X1.0_X2.0             0             0             0             0 #> Y.0101_X1.0_X2.0             0             0             0             0 #> Y.1101_X1.0_X2.0             0             0             0             0 #> Y.0011_X1.0_X2.0             0             0             0             0 #> Y.1011_X1.0_X2.0             0             0             0             0 #> Y.0111_X1.0_X2.0             0             0             0             0 #> Y.1111_X1.0_X2.0             0             0             0             0 #> Y.0000_X1.0_X2.1             0             0             1             0 #> Y.1000_X1.0_X2.1             0             0             0             0 #> Y.0100_X1.0_X2.1             0             0             0             0 #> Y.1100_X1.0_X2.1             0             0             0             0 #> Y.0010_X1.0_X2.1             0             0             0             0 #> Y.1010_X1.0_X2.1             0             0             0             0 #> Y.0110_X1.0_X2.1             0             0             0             0 #> Y.1110_X1.0_X2.1             0             0             0             0 #> Y.0001_X1.0_X2.1             0             0             0             0 #> Y.1001_X1.0_X2.1             0             0             0             0 #> Y.0101_X1.0_X2.1             0             0             0             0 #> Y.1101_X1.0_X2.1             0             0             0             0 #> Y.0011_X1.0_X2.1             0             0             0             0 #> Y.1011_X1.0_X2.1             0             0             0             0 #> Y.0111_X1.0_X2.1             0             0             0             0 #> Y.1111_X1.0_X2.1             0             0             0             0 #> Y.0000_X1.1_X2.0             0             1             0             0 #> Y.1000_X1.1_X2.0             0             0             0             0 #> Y.0100_X1.1_X2.0             0             0             0             0 #> Y.1100_X1.1_X2.0             0             0             0             0 #> Y.0010_X1.1_X2.0             0             0             0             0 #> Y.1010_X1.1_X2.0             0             0             0             0 #> Y.0110_X1.1_X2.0             0             0             0             0 #> Y.1110_X1.1_X2.0             0             0             0             0 #> Y.0001_X1.1_X2.0             0             0             0             0 #> Y.1001_X1.1_X2.0             0             0             0             0 #> Y.0101_X1.1_X2.0             0             0             0             0 #> Y.1101_X1.1_X2.0             0             0             0             0 #> Y.0011_X1.1_X2.0             0             0             0             0 #> Y.1011_X1.1_X2.0             0             0             0             0 #> Y.0111_X1.1_X2.0             0             0             0             0 #> Y.1111_X1.1_X2.0             0             0             0             0 #> Y.0000_X1.1_X2.1             0             0             0             1 #> Y.1000_X1.1_X2.1             0             0             0             0 #> Y.0100_X1.1_X2.1             0             0             0             0 #> Y.1100_X1.1_X2.1             0             0             0             0 #> Y.0010_X1.1_X2.1             0             0             0             0 #> Y.1010_X1.1_X2.1             0             0             0             0 #> Y.0110_X1.1_X2.1             0             0             0             0 #> Y.1110_X1.1_X2.1             0             0             0             0 #> Y.0001_X1.1_X2.1             0             0             0             0 #> Y.1001_X1.1_X2.1             0             0             0             0 #> Y.0101_X1.1_X2.1             0             0             0             0 #> Y.1101_X1.1_X2.1             0             0             0             0 #> Y.0011_X1.1_X2.1             0             0             0             0 #> Y.1011_X1.1_X2.1             0             0             0             0 #> Y.0111_X1.1_X2.1             0             0             0             0 #> Y.1111_X1.1_X2.1             0             0             0             0 #>                  X10.X20.Y1000 X11.X20.Y1000 X10.X21.Y1000 X11.X21.Y1000 #> X1.0                         1             0             1             0 #> X1.1                         0             1             0             1 #> X2.0                         1             1             0             0 #> X2.1                         0             0             1             1 #> Y.0000_X1.0_X2.0             0             0             0             0 #> Y.1000_X1.0_X2.0             1             0             0             0 #> Y.0100_X1.0_X2.0             0             0             0             0 #> Y.1100_X1.0_X2.0             0             0             0             0 #> Y.0010_X1.0_X2.0             0             0             0             0 #> Y.1010_X1.0_X2.0             0             0             0             0 #> Y.0110_X1.0_X2.0             0             0             0             0 #> Y.1110_X1.0_X2.0             0             0             0             0 #> Y.0001_X1.0_X2.0             0             0             0             0 #> Y.1001_X1.0_X2.0             0             0             0             0 #> Y.0101_X1.0_X2.0             0             0             0             0 #> Y.1101_X1.0_X2.0             0             0             0             0 #> Y.0011_X1.0_X2.0             0             0             0             0 #> Y.1011_X1.0_X2.0             0             0             0             0 #> Y.0111_X1.0_X2.0             0             0             0             0 #> Y.1111_X1.0_X2.0             0             0             0             0 #> Y.0000_X1.0_X2.1             0             0             0             0 #> Y.1000_X1.0_X2.1             0             0             1             0 #> Y.0100_X1.0_X2.1             0             0             0             0 #> Y.1100_X1.0_X2.1             0             0             0             0 #> Y.0010_X1.0_X2.1             0             0             0             0 #> Y.1010_X1.0_X2.1             0             0             0             0 #> Y.0110_X1.0_X2.1             0             0             0             0 #> Y.1110_X1.0_X2.1             0             0             0             0 #> Y.0001_X1.0_X2.1             0             0             0             0 #> Y.1001_X1.0_X2.1             0             0             0             0 #> Y.0101_X1.0_X2.1             0             0             0             0 #> Y.1101_X1.0_X2.1             0             0             0             0 #> Y.0011_X1.0_X2.1             0             0             0             0 #> Y.1011_X1.0_X2.1             0             0             0             0 #> Y.0111_X1.0_X2.1             0             0             0             0 #> Y.1111_X1.0_X2.1             0             0             0             0 #> Y.0000_X1.1_X2.0             0             0             0             0 #> Y.1000_X1.1_X2.0             0             1             0             0 #> Y.0100_X1.1_X2.0             0             0             0             0 #> Y.1100_X1.1_X2.0             0             0             0             0 #> Y.0010_X1.1_X2.0             0             0             0             0 #> Y.1010_X1.1_X2.0             0             0             0             0 #> Y.0110_X1.1_X2.0             0             0             0             0 #> Y.1110_X1.1_X2.0             0             0             0             0 #> Y.0001_X1.1_X2.0             0             0             0             0 #> Y.1001_X1.1_X2.0             0             0             0             0 #> Y.0101_X1.1_X2.0             0             0             0             0 #> Y.1101_X1.1_X2.0             0             0             0             0 #> Y.0011_X1.1_X2.0             0             0             0             0 #> Y.1011_X1.1_X2.0             0             0             0             0 #> Y.0111_X1.1_X2.0             0             0             0             0 #> Y.1111_X1.1_X2.0             0             0             0             0 #> Y.0000_X1.1_X2.1             0             0             0             0 #> Y.1000_X1.1_X2.1             0             0             0             1 #> Y.0100_X1.1_X2.1             0             0             0             0 #> Y.1100_X1.1_X2.1             0             0             0             0 #> Y.0010_X1.1_X2.1             0             0             0             0 #> Y.1010_X1.1_X2.1             0             0             0             0 #> Y.0110_X1.1_X2.1             0             0             0             0 #> Y.1110_X1.1_X2.1             0             0             0             0 #> Y.0001_X1.1_X2.1             0             0             0             0 #> Y.1001_X1.1_X2.1             0             0             0             0 #> Y.0101_X1.1_X2.1             0             0             0             0 #> Y.1101_X1.1_X2.1             0             0             0             0 #> Y.0011_X1.1_X2.1             0             0             0             0 #> Y.1011_X1.1_X2.1             0             0             0             0 #> Y.0111_X1.1_X2.1             0             0             0             0 #> Y.1111_X1.1_X2.1             0             0             0             0 #>                  X10.X20.Y0100 X11.X20.Y0100 X10.X21.Y0100 X11.X21.Y0100 #> X1.0                         1             0             1             0 #> X1.1                         0             1             0             1 #> X2.0                         1             1             0             0 #> X2.1                         0             0             1             1 #> Y.0000_X1.0_X2.0             0             0             0             0 #> Y.1000_X1.0_X2.0             0             0             0             0 #> Y.0100_X1.0_X2.0             1             0             0             0 #> Y.1100_X1.0_X2.0             0             0             0             0 #> Y.0010_X1.0_X2.0             0             0             0             0 #> Y.1010_X1.0_X2.0             0             0             0             0 #> Y.0110_X1.0_X2.0             0             0             0             0 #> Y.1110_X1.0_X2.0             0             0             0             0 #> Y.0001_X1.0_X2.0             0             0             0             0 #> Y.1001_X1.0_X2.0             0             0             0             0 #> Y.0101_X1.0_X2.0             0             0             0             0 #> Y.1101_X1.0_X2.0             0             0             0             0 #> Y.0011_X1.0_X2.0             0             0             0             0 #> Y.1011_X1.0_X2.0             0             0             0             0 #> Y.0111_X1.0_X2.0             0             0             0             0 #> Y.1111_X1.0_X2.0             0             0             0             0 #> Y.0000_X1.0_X2.1             0             0             0             0 #> Y.1000_X1.0_X2.1             0             0             0             0 #> Y.0100_X1.0_X2.1             0             0             1             0 #> Y.1100_X1.0_X2.1             0             0             0             0 #> Y.0010_X1.0_X2.1             0             0             0             0 #> Y.1010_X1.0_X2.1             0             0             0             0 #> Y.0110_X1.0_X2.1             0             0             0             0 #> Y.1110_X1.0_X2.1             0             0             0             0 #> Y.0001_X1.0_X2.1             0             0             0             0 #> Y.1001_X1.0_X2.1             0             0             0             0 #> Y.0101_X1.0_X2.1             0             0             0             0 #> Y.1101_X1.0_X2.1             0             0             0             0 #> Y.0011_X1.0_X2.1             0             0             0             0 #> Y.1011_X1.0_X2.1             0             0             0             0 #> Y.0111_X1.0_X2.1             0             0             0             0 #> Y.1111_X1.0_X2.1             0             0             0             0 #> Y.0000_X1.1_X2.0             0             0             0             0 #> Y.1000_X1.1_X2.0             0             0             0             0 #> Y.0100_X1.1_X2.0             0             1             0             0 #> Y.1100_X1.1_X2.0             0             0             0             0 #> Y.0010_X1.1_X2.0             0             0             0             0 #> Y.1010_X1.1_X2.0             0             0             0             0 #> Y.0110_X1.1_X2.0             0             0             0             0 #> Y.1110_X1.1_X2.0             0             0             0             0 #> Y.0001_X1.1_X2.0             0             0             0             0 #> Y.1001_X1.1_X2.0             0             0             0             0 #> Y.0101_X1.1_X2.0             0             0             0             0 #> Y.1101_X1.1_X2.0             0             0             0             0 #> Y.0011_X1.1_X2.0             0             0             0             0 #> Y.1011_X1.1_X2.0             0             0             0             0 #> Y.0111_X1.1_X2.0             0             0             0             0 #> Y.1111_X1.1_X2.0             0             0             0             0 #> Y.0000_X1.1_X2.1             0             0             0             0 #> Y.1000_X1.1_X2.1             0             0             0             0 #> Y.0100_X1.1_X2.1             0             0             0             1 #> Y.1100_X1.1_X2.1             0             0             0             0 #> Y.0010_X1.1_X2.1             0             0             0             0 #> Y.1010_X1.1_X2.1             0             0             0             0 #> Y.0110_X1.1_X2.1             0             0             0             0 #> Y.1110_X1.1_X2.1             0             0             0             0 #> Y.0001_X1.1_X2.1             0             0             0             0 #> Y.1001_X1.1_X2.1             0             0             0             0 #> Y.0101_X1.1_X2.1             0             0             0             0 #> Y.1101_X1.1_X2.1             0             0             0             0 #> Y.0011_X1.1_X2.1             0             0             0             0 #> Y.1011_X1.1_X2.1             0             0             0             0 #> Y.0111_X1.1_X2.1             0             0             0             0 #> Y.1111_X1.1_X2.1             0             0             0             0 #>                  X10.X20.Y1100 X11.X20.Y1100 X10.X21.Y1100 X11.X21.Y1100 #> X1.0                         1             0             1             0 #> X1.1                         0             1             0             1 #> X2.0                         1             1             0             0 #> X2.1                         0             0             1             1 #> Y.0000_X1.0_X2.0             0             0             0             0 #> Y.1000_X1.0_X2.0             0             0             0             0 #> Y.0100_X1.0_X2.0             0             0             0             0 #> Y.1100_X1.0_X2.0             1             0             0             0 #> Y.0010_X1.0_X2.0             0             0             0             0 #> Y.1010_X1.0_X2.0             0             0             0             0 #> Y.0110_X1.0_X2.0             0             0             0             0 #> Y.1110_X1.0_X2.0             0             0             0             0 #> Y.0001_X1.0_X2.0             0             0             0             0 #> Y.1001_X1.0_X2.0             0             0             0             0 #> Y.0101_X1.0_X2.0             0             0             0             0 #> Y.1101_X1.0_X2.0             0             0             0             0 #> Y.0011_X1.0_X2.0             0             0             0             0 #> Y.1011_X1.0_X2.0             0             0             0             0 #> Y.0111_X1.0_X2.0             0             0             0             0 #> Y.1111_X1.0_X2.0             0             0             0             0 #> Y.0000_X1.0_X2.1             0             0             0             0 #> Y.1000_X1.0_X2.1             0             0             0             0 #> Y.0100_X1.0_X2.1             0             0             0             0 #> Y.1100_X1.0_X2.1             0             0             1             0 #> Y.0010_X1.0_X2.1             0             0             0             0 #> Y.1010_X1.0_X2.1             0             0             0             0 #> Y.0110_X1.0_X2.1             0             0             0             0 #> Y.1110_X1.0_X2.1             0             0             0             0 #> Y.0001_X1.0_X2.1             0             0             0             0 #> Y.1001_X1.0_X2.1             0             0             0             0 #> Y.0101_X1.0_X2.1             0             0             0             0 #> Y.1101_X1.0_X2.1             0             0             0             0 #> Y.0011_X1.0_X2.1             0             0             0             0 #> Y.1011_X1.0_X2.1             0             0             0             0 #> Y.0111_X1.0_X2.1             0             0             0             0 #> Y.1111_X1.0_X2.1             0             0             0             0 #> Y.0000_X1.1_X2.0             0             0             0             0 #> Y.1000_X1.1_X2.0             0             0             0             0 #> Y.0100_X1.1_X2.0             0             0             0             0 #> Y.1100_X1.1_X2.0             0             1             0             0 #> Y.0010_X1.1_X2.0             0             0             0             0 #> Y.1010_X1.1_X2.0             0             0             0             0 #> Y.0110_X1.1_X2.0             0             0             0             0 #> Y.1110_X1.1_X2.0             0             0             0             0 #> Y.0001_X1.1_X2.0             0             0             0             0 #> Y.1001_X1.1_X2.0             0             0             0             0 #> Y.0101_X1.1_X2.0             0             0             0             0 #> Y.1101_X1.1_X2.0             0             0             0             0 #> Y.0011_X1.1_X2.0             0             0             0             0 #> Y.1011_X1.1_X2.0             0             0             0             0 #> Y.0111_X1.1_X2.0             0             0             0             0 #> Y.1111_X1.1_X2.0             0             0             0             0 #> Y.0000_X1.1_X2.1             0             0             0             0 #> Y.1000_X1.1_X2.1             0             0             0             0 #> Y.0100_X1.1_X2.1             0             0             0             0 #> Y.1100_X1.1_X2.1             0             0             0             1 #> Y.0010_X1.1_X2.1             0             0             0             0 #> Y.1010_X1.1_X2.1             0             0             0             0 #> Y.0110_X1.1_X2.1             0             0             0             0 #> Y.1110_X1.1_X2.1             0             0             0             0 #> Y.0001_X1.1_X2.1             0             0             0             0 #> Y.1001_X1.1_X2.1             0             0             0             0 #> Y.0101_X1.1_X2.1             0             0             0             0 #> Y.1101_X1.1_X2.1             0             0             0             0 #> Y.0011_X1.1_X2.1             0             0             0             0 #> Y.1011_X1.1_X2.1             0             0             0             0 #> Y.0111_X1.1_X2.1             0             0             0             0 #> Y.1111_X1.1_X2.1             0             0             0             0 #>                  X10.X20.Y0010 X11.X20.Y0010 X10.X21.Y0010 X11.X21.Y0010 #> X1.0                         1             0             1             0 #> X1.1                         0             1             0             1 #> X2.0                         1             1             0             0 #> X2.1                         0             0             1             1 #> Y.0000_X1.0_X2.0             0             0             0             0 #> Y.1000_X1.0_X2.0             0             0             0             0 #> Y.0100_X1.0_X2.0             0             0             0             0 #> Y.1100_X1.0_X2.0             0             0             0             0 #> Y.0010_X1.0_X2.0             1             0             0             0 #> Y.1010_X1.0_X2.0             0             0             0             0 #> Y.0110_X1.0_X2.0             0             0             0             0 #> Y.1110_X1.0_X2.0             0             0             0             0 #> Y.0001_X1.0_X2.0             0             0             0             0 #> Y.1001_X1.0_X2.0             0             0             0             0 #> Y.0101_X1.0_X2.0             0             0             0             0 #> Y.1101_X1.0_X2.0             0             0             0             0 #> Y.0011_X1.0_X2.0             0             0             0             0 #> Y.1011_X1.0_X2.0             0             0             0             0 #> Y.0111_X1.0_X2.0             0             0             0             0 #> Y.1111_X1.0_X2.0             0             0             0             0 #> Y.0000_X1.0_X2.1             0             0             0             0 #> Y.1000_X1.0_X2.1             0             0             0             0 #> Y.0100_X1.0_X2.1             0             0             0             0 #> Y.1100_X1.0_X2.1             0             0             0             0 #> Y.0010_X1.0_X2.1             0             0             1             0 #> Y.1010_X1.0_X2.1             0             0             0             0 #> Y.0110_X1.0_X2.1             0             0             0             0 #> Y.1110_X1.0_X2.1             0             0             0             0 #> Y.0001_X1.0_X2.1             0             0             0             0 #> Y.1001_X1.0_X2.1             0             0             0             0 #> Y.0101_X1.0_X2.1             0             0             0             0 #> Y.1101_X1.0_X2.1             0             0             0             0 #> Y.0011_X1.0_X2.1             0             0             0             0 #> Y.1011_X1.0_X2.1             0             0             0             0 #> Y.0111_X1.0_X2.1             0             0             0             0 #> Y.1111_X1.0_X2.1             0             0             0             0 #> Y.0000_X1.1_X2.0             0             0             0             0 #> Y.1000_X1.1_X2.0             0             0             0             0 #> Y.0100_X1.1_X2.0             0             0             0             0 #> Y.1100_X1.1_X2.0             0             0             0             0 #> Y.0010_X1.1_X2.0             0             1             0             0 #> Y.1010_X1.1_X2.0             0             0             0             0 #> Y.0110_X1.1_X2.0             0             0             0             0 #> Y.1110_X1.1_X2.0             0             0             0             0 #> Y.0001_X1.1_X2.0             0             0             0             0 #> Y.1001_X1.1_X2.0             0             0             0             0 #> Y.0101_X1.1_X2.0             0             0             0             0 #> Y.1101_X1.1_X2.0             0             0             0             0 #> Y.0011_X1.1_X2.0             0             0             0             0 #> Y.1011_X1.1_X2.0             0             0             0             0 #> Y.0111_X1.1_X2.0             0             0             0             0 #> Y.1111_X1.1_X2.0             0             0             0             0 #> Y.0000_X1.1_X2.1             0             0             0             0 #> Y.1000_X1.1_X2.1             0             0             0             0 #> Y.0100_X1.1_X2.1             0             0             0             0 #> Y.1100_X1.1_X2.1             0             0             0             0 #> Y.0010_X1.1_X2.1             0             0             0             1 #> Y.1010_X1.1_X2.1             0             0             0             0 #> Y.0110_X1.1_X2.1             0             0             0             0 #> Y.1110_X1.1_X2.1             0             0             0             0 #> Y.0001_X1.1_X2.1             0             0             0             0 #> Y.1001_X1.1_X2.1             0             0             0             0 #> Y.0101_X1.1_X2.1             0             0             0             0 #> Y.1101_X1.1_X2.1             0             0             0             0 #> Y.0011_X1.1_X2.1             0             0             0             0 #> Y.1011_X1.1_X2.1             0             0             0             0 #> Y.0111_X1.1_X2.1             0             0             0             0 #> Y.1111_X1.1_X2.1             0             0             0             0 #>                  X10.X20.Y1010 X11.X20.Y1010 X10.X21.Y1010 X11.X21.Y1010 #> X1.0                         1             0             1             0 #> X1.1                         0             1             0             1 #> X2.0                         1             1             0             0 #> X2.1                         0             0             1             1 #> Y.0000_X1.0_X2.0             0             0             0             0 #> Y.1000_X1.0_X2.0             0             0             0             0 #> Y.0100_X1.0_X2.0             0             0             0             0 #> Y.1100_X1.0_X2.0             0             0             0             0 #> Y.0010_X1.0_X2.0             0             0             0             0 #> Y.1010_X1.0_X2.0             1             0             0             0 #> Y.0110_X1.0_X2.0             0             0             0             0 #> Y.1110_X1.0_X2.0             0             0             0             0 #> Y.0001_X1.0_X2.0             0             0             0             0 #> Y.1001_X1.0_X2.0             0             0             0             0 #> Y.0101_X1.0_X2.0             0             0             0             0 #> Y.1101_X1.0_X2.0             0             0             0             0 #> Y.0011_X1.0_X2.0             0             0             0             0 #> Y.1011_X1.0_X2.0             0             0             0             0 #> Y.0111_X1.0_X2.0             0             0             0             0 #> Y.1111_X1.0_X2.0             0             0             0             0 #> Y.0000_X1.0_X2.1             0             0             0             0 #> Y.1000_X1.0_X2.1             0             0             0             0 #> Y.0100_X1.0_X2.1             0             0             0             0 #> Y.1100_X1.0_X2.1             0             0             0             0 #> Y.0010_X1.0_X2.1             0             0             0             0 #> Y.1010_X1.0_X2.1             0             0             1             0 #> Y.0110_X1.0_X2.1             0             0             0             0 #> Y.1110_X1.0_X2.1             0             0             0             0 #> Y.0001_X1.0_X2.1             0             0             0             0 #> Y.1001_X1.0_X2.1             0             0             0             0 #> Y.0101_X1.0_X2.1             0             0             0             0 #> Y.1101_X1.0_X2.1             0             0             0             0 #> Y.0011_X1.0_X2.1             0             0             0             0 #> Y.1011_X1.0_X2.1             0             0             0             0 #> Y.0111_X1.0_X2.1             0             0             0             0 #> Y.1111_X1.0_X2.1             0             0             0             0 #> Y.0000_X1.1_X2.0             0             0             0             0 #> Y.1000_X1.1_X2.0             0             0             0             0 #> Y.0100_X1.1_X2.0             0             0             0             0 #> Y.1100_X1.1_X2.0             0             0             0             0 #> Y.0010_X1.1_X2.0             0             0             0             0 #> Y.1010_X1.1_X2.0             0             1             0             0 #> Y.0110_X1.1_X2.0             0             0             0             0 #> Y.1110_X1.1_X2.0             0             0             0             0 #> Y.0001_X1.1_X2.0             0             0             0             0 #> Y.1001_X1.1_X2.0             0             0             0             0 #> Y.0101_X1.1_X2.0             0             0             0             0 #> Y.1101_X1.1_X2.0             0             0             0             0 #> Y.0011_X1.1_X2.0             0             0             0             0 #> Y.1011_X1.1_X2.0             0             0             0             0 #> Y.0111_X1.1_X2.0             0             0             0             0 #> Y.1111_X1.1_X2.0             0             0             0             0 #> Y.0000_X1.1_X2.1             0             0             0             0 #> Y.1000_X1.1_X2.1             0             0             0             0 #> Y.0100_X1.1_X2.1             0             0             0             0 #> Y.1100_X1.1_X2.1             0             0             0             0 #> Y.0010_X1.1_X2.1             0             0             0             0 #> Y.1010_X1.1_X2.1             0             0             0             1 #> Y.0110_X1.1_X2.1             0             0             0             0 #> Y.1110_X1.1_X2.1             0             0             0             0 #> Y.0001_X1.1_X2.1             0             0             0             0 #> Y.1001_X1.1_X2.1             0             0             0             0 #> Y.0101_X1.1_X2.1             0             0             0             0 #> Y.1101_X1.1_X2.1             0             0             0             0 #> Y.0011_X1.1_X2.1             0             0             0             0 #> Y.1011_X1.1_X2.1             0             0             0             0 #> Y.0111_X1.1_X2.1             0             0             0             0 #> Y.1111_X1.1_X2.1             0             0             0             0 #>                  X10.X20.Y0110 X11.X20.Y0110 X10.X21.Y0110 X11.X21.Y0110 #> X1.0                         1             0             1             0 #> X1.1                         0             1             0             1 #> X2.0                         1             1             0             0 #> X2.1                         0             0             1             1 #> Y.0000_X1.0_X2.0             0             0             0             0 #> Y.1000_X1.0_X2.0             0             0             0             0 #> Y.0100_X1.0_X2.0             0             0             0             0 #> Y.1100_X1.0_X2.0             0             0             0             0 #> Y.0010_X1.0_X2.0             0             0             0             0 #> Y.1010_X1.0_X2.0             0             0             0             0 #> Y.0110_X1.0_X2.0             1             0             0             0 #> Y.1110_X1.0_X2.0             0             0             0             0 #> Y.0001_X1.0_X2.0             0             0             0             0 #> Y.1001_X1.0_X2.0             0             0             0             0 #> Y.0101_X1.0_X2.0             0             0             0             0 #> Y.1101_X1.0_X2.0             0             0             0             0 #> Y.0011_X1.0_X2.0             0             0             0             0 #> Y.1011_X1.0_X2.0             0             0             0             0 #> Y.0111_X1.0_X2.0             0             0             0             0 #> Y.1111_X1.0_X2.0             0             0             0             0 #> Y.0000_X1.0_X2.1             0             0             0             0 #> Y.1000_X1.0_X2.1             0             0             0             0 #> Y.0100_X1.0_X2.1             0             0             0             0 #> Y.1100_X1.0_X2.1             0             0             0             0 #> Y.0010_X1.0_X2.1             0             0             0             0 #> Y.1010_X1.0_X2.1             0             0             0             0 #> Y.0110_X1.0_X2.1             0             0             1             0 #> Y.1110_X1.0_X2.1             0             0             0             0 #> Y.0001_X1.0_X2.1             0             0             0             0 #> Y.1001_X1.0_X2.1             0             0             0             0 #> Y.0101_X1.0_X2.1             0             0             0             0 #> Y.1101_X1.0_X2.1             0             0             0             0 #> Y.0011_X1.0_X2.1             0             0             0             0 #> Y.1011_X1.0_X2.1             0             0             0             0 #> Y.0111_X1.0_X2.1             0             0             0             0 #> Y.1111_X1.0_X2.1             0             0             0             0 #> Y.0000_X1.1_X2.0             0             0             0             0 #> Y.1000_X1.1_X2.0             0             0             0             0 #> Y.0100_X1.1_X2.0             0             0             0             0 #> Y.1100_X1.1_X2.0             0             0             0             0 #> Y.0010_X1.1_X2.0             0             0             0             0 #> Y.1010_X1.1_X2.0             0             0             0             0 #> Y.0110_X1.1_X2.0             0             1             0             0 #> Y.1110_X1.1_X2.0             0             0             0             0 #> Y.0001_X1.1_X2.0             0             0             0             0 #> Y.1001_X1.1_X2.0             0             0             0             0 #> Y.0101_X1.1_X2.0             0             0             0             0 #> Y.1101_X1.1_X2.0             0             0             0             0 #> Y.0011_X1.1_X2.0             0             0             0             0 #> Y.1011_X1.1_X2.0             0             0             0             0 #> Y.0111_X1.1_X2.0             0             0             0             0 #> Y.1111_X1.1_X2.0             0             0             0             0 #> Y.0000_X1.1_X2.1             0             0             0             0 #> Y.1000_X1.1_X2.1             0             0             0             0 #> Y.0100_X1.1_X2.1             0             0             0             0 #> Y.1100_X1.1_X2.1             0             0             0             0 #> Y.0010_X1.1_X2.1             0             0             0             0 #> Y.1010_X1.1_X2.1             0             0             0             0 #> Y.0110_X1.1_X2.1             0             0             0             1 #> Y.1110_X1.1_X2.1             0             0             0             0 #> Y.0001_X1.1_X2.1             0             0             0             0 #> Y.1001_X1.1_X2.1             0             0             0             0 #> Y.0101_X1.1_X2.1             0             0             0             0 #> Y.1101_X1.1_X2.1             0             0             0             0 #> Y.0011_X1.1_X2.1             0             0             0             0 #> Y.1011_X1.1_X2.1             0             0             0             0 #> Y.0111_X1.1_X2.1             0             0             0             0 #> Y.1111_X1.1_X2.1             0             0             0             0 #>                  X10.X20.Y1110 X11.X20.Y1110 X10.X21.Y1110 X11.X21.Y1110 #> X1.0                         1             0             1             0 #> X1.1                         0             1             0             1 #> X2.0                         1             1             0             0 #> X2.1                         0             0             1             1 #> Y.0000_X1.0_X2.0             0             0             0             0 #> Y.1000_X1.0_X2.0             0             0             0             0 #> Y.0100_X1.0_X2.0             0             0             0             0 #> Y.1100_X1.0_X2.0             0             0             0             0 #> Y.0010_X1.0_X2.0             0             0             0             0 #> Y.1010_X1.0_X2.0             0             0             0             0 #> Y.0110_X1.0_X2.0             0             0             0             0 #> Y.1110_X1.0_X2.0             1             0             0             0 #> Y.0001_X1.0_X2.0             0             0             0             0 #> Y.1001_X1.0_X2.0             0             0             0             0 #> Y.0101_X1.0_X2.0             0             0             0             0 #> Y.1101_X1.0_X2.0             0             0             0             0 #> Y.0011_X1.0_X2.0             0             0             0             0 #> Y.1011_X1.0_X2.0             0             0             0             0 #> Y.0111_X1.0_X2.0             0             0             0             0 #> Y.1111_X1.0_X2.0             0             0             0             0 #> Y.0000_X1.0_X2.1             0             0             0             0 #> Y.1000_X1.0_X2.1             0             0             0             0 #> Y.0100_X1.0_X2.1             0             0             0             0 #> Y.1100_X1.0_X2.1             0             0             0             0 #> Y.0010_X1.0_X2.1             0             0             0             0 #> Y.1010_X1.0_X2.1             0             0             0             0 #> Y.0110_X1.0_X2.1             0             0             0             0 #> Y.1110_X1.0_X2.1             0             0             1             0 #> Y.0001_X1.0_X2.1             0             0             0             0 #> Y.1001_X1.0_X2.1             0             0             0             0 #> Y.0101_X1.0_X2.1             0             0             0             0 #> Y.1101_X1.0_X2.1             0             0             0             0 #> Y.0011_X1.0_X2.1             0             0             0             0 #> Y.1011_X1.0_X2.1             0             0             0             0 #> Y.0111_X1.0_X2.1             0             0             0             0 #> Y.1111_X1.0_X2.1             0             0             0             0 #> Y.0000_X1.1_X2.0             0             0             0             0 #> Y.1000_X1.1_X2.0             0             0             0             0 #> Y.0100_X1.1_X2.0             0             0             0             0 #> Y.1100_X1.1_X2.0             0             0             0             0 #> Y.0010_X1.1_X2.0             0             0             0             0 #> Y.1010_X1.1_X2.0             0             0             0             0 #> Y.0110_X1.1_X2.0             0             0             0             0 #> Y.1110_X1.1_X2.0             0             1             0             0 #> Y.0001_X1.1_X2.0             0             0             0             0 #> Y.1001_X1.1_X2.0             0             0             0             0 #> Y.0101_X1.1_X2.0             0             0             0             0 #> Y.1101_X1.1_X2.0             0             0             0             0 #> Y.0011_X1.1_X2.0             0             0             0             0 #> Y.1011_X1.1_X2.0             0             0             0             0 #> Y.0111_X1.1_X2.0             0             0             0             0 #> Y.1111_X1.1_X2.0             0             0             0             0 #> Y.0000_X1.1_X2.1             0             0             0             0 #> Y.1000_X1.1_X2.1             0             0             0             0 #> Y.0100_X1.1_X2.1             0             0             0             0 #> Y.1100_X1.1_X2.1             0             0             0             0 #> Y.0010_X1.1_X2.1             0             0             0             0 #> Y.1010_X1.1_X2.1             0             0             0             0 #> Y.0110_X1.1_X2.1             0             0             0             0 #> Y.1110_X1.1_X2.1             0             0             0             1 #> Y.0001_X1.1_X2.1             0             0             0             0 #> Y.1001_X1.1_X2.1             0             0             0             0 #> Y.0101_X1.1_X2.1             0             0             0             0 #> Y.1101_X1.1_X2.1             0             0             0             0 #> Y.0011_X1.1_X2.1             0             0             0             0 #> Y.1011_X1.1_X2.1             0             0             0             0 #> Y.0111_X1.1_X2.1             0             0             0             0 #> Y.1111_X1.1_X2.1             0             0             0             0 #>                  X10.X20.Y0001 X11.X20.Y0001 X10.X21.Y0001 X11.X21.Y0001 #> X1.0                         1             0             1             0 #> X1.1                         0             1             0             1 #> X2.0                         1             1             0             0 #> X2.1                         0             0             1             1 #> Y.0000_X1.0_X2.0             0             0             0             0 #> Y.1000_X1.0_X2.0             0             0             0             0 #> Y.0100_X1.0_X2.0             0             0             0             0 #> Y.1100_X1.0_X2.0             0             0             0             0 #> Y.0010_X1.0_X2.0             0             0             0             0 #> Y.1010_X1.0_X2.0             0             0             0             0 #> Y.0110_X1.0_X2.0             0             0             0             0 #> Y.1110_X1.0_X2.0             0             0             0             0 #> Y.0001_X1.0_X2.0             1             0             0             0 #> Y.1001_X1.0_X2.0             0             0             0             0 #> Y.0101_X1.0_X2.0             0             0             0             0 #> Y.1101_X1.0_X2.0             0             0             0             0 #> Y.0011_X1.0_X2.0             0             0             0             0 #> Y.1011_X1.0_X2.0             0             0             0             0 #> Y.0111_X1.0_X2.0             0             0             0             0 #> Y.1111_X1.0_X2.0             0             0             0             0 #> Y.0000_X1.0_X2.1             0             0             0             0 #> Y.1000_X1.0_X2.1             0             0             0             0 #> Y.0100_X1.0_X2.1             0             0             0             0 #> Y.1100_X1.0_X2.1             0             0             0             0 #> Y.0010_X1.0_X2.1             0             0             0             0 #> Y.1010_X1.0_X2.1             0             0             0             0 #> Y.0110_X1.0_X2.1             0             0             0             0 #> Y.1110_X1.0_X2.1             0             0             0             0 #> Y.0001_X1.0_X2.1             0             0             1             0 #> Y.1001_X1.0_X2.1             0             0             0             0 #> Y.0101_X1.0_X2.1             0             0             0             0 #> Y.1101_X1.0_X2.1             0             0             0             0 #> Y.0011_X1.0_X2.1             0             0             0             0 #> Y.1011_X1.0_X2.1             0             0             0             0 #> Y.0111_X1.0_X2.1             0             0             0             0 #> Y.1111_X1.0_X2.1             0             0             0             0 #> Y.0000_X1.1_X2.0             0             0             0             0 #> Y.1000_X1.1_X2.0             0             0             0             0 #> Y.0100_X1.1_X2.0             0             0             0             0 #> Y.1100_X1.1_X2.0             0             0             0             0 #> Y.0010_X1.1_X2.0             0             0             0             0 #> Y.1010_X1.1_X2.0             0             0             0             0 #> Y.0110_X1.1_X2.0             0             0             0             0 #> Y.1110_X1.1_X2.0             0             0             0             0 #> Y.0001_X1.1_X2.0             0             1             0             0 #> Y.1001_X1.1_X2.0             0             0             0             0 #> Y.0101_X1.1_X2.0             0             0             0             0 #> Y.1101_X1.1_X2.0             0             0             0             0 #> Y.0011_X1.1_X2.0             0             0             0             0 #> Y.1011_X1.1_X2.0             0             0             0             0 #> Y.0111_X1.1_X2.0             0             0             0             0 #> Y.1111_X1.1_X2.0             0             0             0             0 #> Y.0000_X1.1_X2.1             0             0             0             0 #> Y.1000_X1.1_X2.1             0             0             0             0 #> Y.0100_X1.1_X2.1             0             0             0             0 #> Y.1100_X1.1_X2.1             0             0             0             0 #> Y.0010_X1.1_X2.1             0             0             0             0 #> Y.1010_X1.1_X2.1             0             0             0             0 #> Y.0110_X1.1_X2.1             0             0             0             0 #> Y.1110_X1.1_X2.1             0             0             0             0 #> Y.0001_X1.1_X2.1             0             0             0             1 #> Y.1001_X1.1_X2.1             0             0             0             0 #> Y.0101_X1.1_X2.1             0             0             0             0 #> Y.1101_X1.1_X2.1             0             0             0             0 #> Y.0011_X1.1_X2.1             0             0             0             0 #> Y.1011_X1.1_X2.1             0             0             0             0 #> Y.0111_X1.1_X2.1             0             0             0             0 #> Y.1111_X1.1_X2.1             0             0             0             0 #>                  X10.X20.Y1001 X11.X20.Y1001 X10.X21.Y1001 X11.X21.Y1001 #> X1.0                         1             0             1             0 #> X1.1                         0             1             0             1 #> X2.0                         1             1             0             0 #> X2.1                         0             0             1             1 #> Y.0000_X1.0_X2.0             0             0             0             0 #> Y.1000_X1.0_X2.0             0             0             0             0 #> Y.0100_X1.0_X2.0             0             0             0             0 #> Y.1100_X1.0_X2.0             0             0             0             0 #> Y.0010_X1.0_X2.0             0             0             0             0 #> Y.1010_X1.0_X2.0             0             0             0             0 #> Y.0110_X1.0_X2.0             0             0             0             0 #> Y.1110_X1.0_X2.0             0             0             0             0 #> Y.0001_X1.0_X2.0             0             0             0             0 #> Y.1001_X1.0_X2.0             1             0             0             0 #> Y.0101_X1.0_X2.0             0             0             0             0 #> Y.1101_X1.0_X2.0             0             0             0             0 #> Y.0011_X1.0_X2.0             0             0             0             0 #> Y.1011_X1.0_X2.0             0             0             0             0 #> Y.0111_X1.0_X2.0             0             0             0             0 #> Y.1111_X1.0_X2.0             0             0             0             0 #> Y.0000_X1.0_X2.1             0             0             0             0 #> Y.1000_X1.0_X2.1             0             0             0             0 #> Y.0100_X1.0_X2.1             0             0             0             0 #> Y.1100_X1.0_X2.1             0             0             0             0 #> Y.0010_X1.0_X2.1             0             0             0             0 #> Y.1010_X1.0_X2.1             0             0             0             0 #> Y.0110_X1.0_X2.1             0             0             0             0 #> Y.1110_X1.0_X2.1             0             0             0             0 #> Y.0001_X1.0_X2.1             0             0             0             0 #> Y.1001_X1.0_X2.1             0             0             1             0 #> Y.0101_X1.0_X2.1             0             0             0             0 #> Y.1101_X1.0_X2.1             0             0             0             0 #> Y.0011_X1.0_X2.1             0             0             0             0 #> Y.1011_X1.0_X2.1             0             0             0             0 #> Y.0111_X1.0_X2.1             0             0             0             0 #> Y.1111_X1.0_X2.1             0             0             0             0 #> Y.0000_X1.1_X2.0             0             0             0             0 #> Y.1000_X1.1_X2.0             0             0             0             0 #> Y.0100_X1.1_X2.0             0             0             0             0 #> Y.1100_X1.1_X2.0             0             0             0             0 #> Y.0010_X1.1_X2.0             0             0             0             0 #> Y.1010_X1.1_X2.0             0             0             0             0 #> Y.0110_X1.1_X2.0             0             0             0             0 #> Y.1110_X1.1_X2.0             0             0             0             0 #> Y.0001_X1.1_X2.0             0             0             0             0 #> Y.1001_X1.1_X2.0             0             1             0             0 #> Y.0101_X1.1_X2.0             0             0             0             0 #> Y.1101_X1.1_X2.0             0             0             0             0 #> Y.0011_X1.1_X2.0             0             0             0             0 #> Y.1011_X1.1_X2.0             0             0             0             0 #> Y.0111_X1.1_X2.0             0             0             0             0 #> Y.1111_X1.1_X2.0             0             0             0             0 #> Y.0000_X1.1_X2.1             0             0             0             0 #> Y.1000_X1.1_X2.1             0             0             0             0 #> Y.0100_X1.1_X2.1             0             0             0             0 #> Y.1100_X1.1_X2.1             0             0             0             0 #> Y.0010_X1.1_X2.1             0             0             0             0 #> Y.1010_X1.1_X2.1             0             0             0             0 #> Y.0110_X1.1_X2.1             0             0             0             0 #> Y.1110_X1.1_X2.1             0             0             0             0 #> Y.0001_X1.1_X2.1             0             0             0             0 #> Y.1001_X1.1_X2.1             0             0             0             1 #> Y.0101_X1.1_X2.1             0             0             0             0 #> Y.1101_X1.1_X2.1             0             0             0             0 #> Y.0011_X1.1_X2.1             0             0             0             0 #> Y.1011_X1.1_X2.1             0             0             0             0 #> Y.0111_X1.1_X2.1             0             0             0             0 #> Y.1111_X1.1_X2.1             0             0             0             0 #>                  X10.X20.Y0101 X11.X20.Y0101 X10.X21.Y0101 X11.X21.Y0101 #> X1.0                         1             0             1             0 #> X1.1                         0             1             0             1 #> X2.0                         1             1             0             0 #> X2.1                         0             0             1             1 #> Y.0000_X1.0_X2.0             0             0             0             0 #> Y.1000_X1.0_X2.0             0             0             0             0 #> Y.0100_X1.0_X2.0             0             0             0             0 #> Y.1100_X1.0_X2.0             0             0             0             0 #> Y.0010_X1.0_X2.0             0             0             0             0 #> Y.1010_X1.0_X2.0             0             0             0             0 #> Y.0110_X1.0_X2.0             0             0             0             0 #> Y.1110_X1.0_X2.0             0             0             0             0 #> Y.0001_X1.0_X2.0             0             0             0             0 #> Y.1001_X1.0_X2.0             0             0             0             0 #> Y.0101_X1.0_X2.0             1             0             0             0 #> Y.1101_X1.0_X2.0             0             0             0             0 #> Y.0011_X1.0_X2.0             0             0             0             0 #> Y.1011_X1.0_X2.0             0             0             0             0 #> Y.0111_X1.0_X2.0             0             0             0             0 #> Y.1111_X1.0_X2.0             0             0             0             0 #> Y.0000_X1.0_X2.1             0             0             0             0 #> Y.1000_X1.0_X2.1             0             0             0             0 #> Y.0100_X1.0_X2.1             0             0             0             0 #> Y.1100_X1.0_X2.1             0             0             0             0 #> Y.0010_X1.0_X2.1             0             0             0             0 #> Y.1010_X1.0_X2.1             0             0             0             0 #> Y.0110_X1.0_X2.1             0             0             0             0 #> Y.1110_X1.0_X2.1             0             0             0             0 #> Y.0001_X1.0_X2.1             0             0             0             0 #> Y.1001_X1.0_X2.1             0             0             0             0 #> Y.0101_X1.0_X2.1             0             0             1             0 #> Y.1101_X1.0_X2.1             0             0             0             0 #> Y.0011_X1.0_X2.1             0             0             0             0 #> Y.1011_X1.0_X2.1             0             0             0             0 #> Y.0111_X1.0_X2.1             0             0             0             0 #> Y.1111_X1.0_X2.1             0             0             0             0 #> Y.0000_X1.1_X2.0             0             0             0             0 #> Y.1000_X1.1_X2.0             0             0             0             0 #> Y.0100_X1.1_X2.0             0             0             0             0 #> Y.1100_X1.1_X2.0             0             0             0             0 #> Y.0010_X1.1_X2.0             0             0             0             0 #> Y.1010_X1.1_X2.0             0             0             0             0 #> Y.0110_X1.1_X2.0             0             0             0             0 #> Y.1110_X1.1_X2.0             0             0             0             0 #> Y.0001_X1.1_X2.0             0             0             0             0 #> Y.1001_X1.1_X2.0             0             0             0             0 #> Y.0101_X1.1_X2.0             0             1             0             0 #> Y.1101_X1.1_X2.0             0             0             0             0 #> Y.0011_X1.1_X2.0             0             0             0             0 #> Y.1011_X1.1_X2.0             0             0             0             0 #> Y.0111_X1.1_X2.0             0             0             0             0 #> Y.1111_X1.1_X2.0             0             0             0             0 #> Y.0000_X1.1_X2.1             0             0             0             0 #> Y.1000_X1.1_X2.1             0             0             0             0 #> Y.0100_X1.1_X2.1             0             0             0             0 #> Y.1100_X1.1_X2.1             0             0             0             0 #> Y.0010_X1.1_X2.1             0             0             0             0 #> Y.1010_X1.1_X2.1             0             0             0             0 #> Y.0110_X1.1_X2.1             0             0             0             0 #> Y.1110_X1.1_X2.1             0             0             0             0 #> Y.0001_X1.1_X2.1             0             0             0             0 #> Y.1001_X1.1_X2.1             0             0             0             0 #> Y.0101_X1.1_X2.1             0             0             0             1 #> Y.1101_X1.1_X2.1             0             0             0             0 #> Y.0011_X1.1_X2.1             0             0             0             0 #> Y.1011_X1.1_X2.1             0             0             0             0 #> Y.0111_X1.1_X2.1             0             0             0             0 #> Y.1111_X1.1_X2.1             0             0             0             0 #>                  X10.X20.Y1101 X11.X20.Y1101 X10.X21.Y1101 X11.X21.Y1101 #> X1.0                         1             0             1             0 #> X1.1                         0             1             0             1 #> X2.0                         1             1             0             0 #> X2.1                         0             0             1             1 #> Y.0000_X1.0_X2.0             0             0             0             0 #> Y.1000_X1.0_X2.0             0             0             0             0 #> Y.0100_X1.0_X2.0             0             0             0             0 #> Y.1100_X1.0_X2.0             0             0             0             0 #> Y.0010_X1.0_X2.0             0             0             0             0 #> Y.1010_X1.0_X2.0             0             0             0             0 #> Y.0110_X1.0_X2.0             0             0             0             0 #> Y.1110_X1.0_X2.0             0             0             0             0 #> Y.0001_X1.0_X2.0             0             0             0             0 #> Y.1001_X1.0_X2.0             0             0             0             0 #> Y.0101_X1.0_X2.0             0             0             0             0 #> Y.1101_X1.0_X2.0             1             0             0             0 #> Y.0011_X1.0_X2.0             0             0             0             0 #> Y.1011_X1.0_X2.0             0             0             0             0 #> Y.0111_X1.0_X2.0             0             0             0             0 #> Y.1111_X1.0_X2.0             0             0             0             0 #> Y.0000_X1.0_X2.1             0             0             0             0 #> Y.1000_X1.0_X2.1             0             0             0             0 #> Y.0100_X1.0_X2.1             0             0             0             0 #> Y.1100_X1.0_X2.1             0             0             0             0 #> Y.0010_X1.0_X2.1             0             0             0             0 #> Y.1010_X1.0_X2.1             0             0             0             0 #> Y.0110_X1.0_X2.1             0             0             0             0 #> Y.1110_X1.0_X2.1             0             0             0             0 #> Y.0001_X1.0_X2.1             0             0             0             0 #> Y.1001_X1.0_X2.1             0             0             0             0 #> Y.0101_X1.0_X2.1             0             0             0             0 #> Y.1101_X1.0_X2.1             0             0             1             0 #> Y.0011_X1.0_X2.1             0             0             0             0 #> Y.1011_X1.0_X2.1             0             0             0             0 #> Y.0111_X1.0_X2.1             0             0             0             0 #> Y.1111_X1.0_X2.1             0             0             0             0 #> Y.0000_X1.1_X2.0             0             0             0             0 #> Y.1000_X1.1_X2.0             0             0             0             0 #> Y.0100_X1.1_X2.0             0             0             0             0 #> Y.1100_X1.1_X2.0             0             0             0             0 #> Y.0010_X1.1_X2.0             0             0             0             0 #> Y.1010_X1.1_X2.0             0             0             0             0 #> Y.0110_X1.1_X2.0             0             0             0             0 #> Y.1110_X1.1_X2.0             0             0             0             0 #> Y.0001_X1.1_X2.0             0             0             0             0 #> Y.1001_X1.1_X2.0             0             0             0             0 #> Y.0101_X1.1_X2.0             0             0             0             0 #> Y.1101_X1.1_X2.0             0             1             0             0 #> Y.0011_X1.1_X2.0             0             0             0             0 #> Y.1011_X1.1_X2.0             0             0             0             0 #> Y.0111_X1.1_X2.0             0             0             0             0 #> Y.1111_X1.1_X2.0             0             0             0             0 #> Y.0000_X1.1_X2.1             0             0             0             0 #> Y.1000_X1.1_X2.1             0             0             0             0 #> Y.0100_X1.1_X2.1             0             0             0             0 #> Y.1100_X1.1_X2.1             0             0             0             0 #> Y.0010_X1.1_X2.1             0             0             0             0 #> Y.1010_X1.1_X2.1             0             0             0             0 #> Y.0110_X1.1_X2.1             0             0             0             0 #> Y.1110_X1.1_X2.1             0             0             0             0 #> Y.0001_X1.1_X2.1             0             0             0             0 #> Y.1001_X1.1_X2.1             0             0             0             0 #> Y.0101_X1.1_X2.1             0             0             0             0 #> Y.1101_X1.1_X2.1             0             0             0             1 #> Y.0011_X1.1_X2.1             0             0             0             0 #> Y.1011_X1.1_X2.1             0             0             0             0 #> Y.0111_X1.1_X2.1             0             0             0             0 #> Y.1111_X1.1_X2.1             0             0             0             0 #>                  X10.X20.Y0011 X11.X20.Y0011 X10.X21.Y0011 X11.X21.Y0011 #> X1.0                         1             0             1             0 #> X1.1                         0             1             0             1 #> X2.0                         1             1             0             0 #> X2.1                         0             0             1             1 #> Y.0000_X1.0_X2.0             0             0             0             0 #> Y.1000_X1.0_X2.0             0             0             0             0 #> Y.0100_X1.0_X2.0             0             0             0             0 #> Y.1100_X1.0_X2.0             0             0             0             0 #> Y.0010_X1.0_X2.0             0             0             0             0 #> Y.1010_X1.0_X2.0             0             0             0             0 #> Y.0110_X1.0_X2.0             0             0             0             0 #> Y.1110_X1.0_X2.0             0             0             0             0 #> Y.0001_X1.0_X2.0             0             0             0             0 #> Y.1001_X1.0_X2.0             0             0             0             0 #> Y.0101_X1.0_X2.0             0             0             0             0 #> Y.1101_X1.0_X2.0             0             0             0             0 #> Y.0011_X1.0_X2.0             1             0             0             0 #> Y.1011_X1.0_X2.0             0             0             0             0 #> Y.0111_X1.0_X2.0             0             0             0             0 #> Y.1111_X1.0_X2.0             0             0             0             0 #> Y.0000_X1.0_X2.1             0             0             0             0 #> Y.1000_X1.0_X2.1             0             0             0             0 #> Y.0100_X1.0_X2.1             0             0             0             0 #> Y.1100_X1.0_X2.1             0             0             0             0 #> Y.0010_X1.0_X2.1             0             0             0             0 #> Y.1010_X1.0_X2.1             0             0             0             0 #> Y.0110_X1.0_X2.1             0             0             0             0 #> Y.1110_X1.0_X2.1             0             0             0             0 #> Y.0001_X1.0_X2.1             0             0             0             0 #> Y.1001_X1.0_X2.1             0             0             0             0 #> Y.0101_X1.0_X2.1             0             0             0             0 #> Y.1101_X1.0_X2.1             0             0             0             0 #> Y.0011_X1.0_X2.1             0             0             1             0 #> Y.1011_X1.0_X2.1             0             0             0             0 #> Y.0111_X1.0_X2.1             0             0             0             0 #> Y.1111_X1.0_X2.1             0             0             0             0 #> Y.0000_X1.1_X2.0             0             0             0             0 #> Y.1000_X1.1_X2.0             0             0             0             0 #> Y.0100_X1.1_X2.0             0             0             0             0 #> Y.1100_X1.1_X2.0             0             0             0             0 #> Y.0010_X1.1_X2.0             0             0             0             0 #> Y.1010_X1.1_X2.0             0             0             0             0 #> Y.0110_X1.1_X2.0             0             0             0             0 #> Y.1110_X1.1_X2.0             0             0             0             0 #> Y.0001_X1.1_X2.0             0             0             0             0 #> Y.1001_X1.1_X2.0             0             0             0             0 #> Y.0101_X1.1_X2.0             0             0             0             0 #> Y.1101_X1.1_X2.0             0             0             0             0 #> Y.0011_X1.1_X2.0             0             1             0             0 #> Y.1011_X1.1_X2.0             0             0             0             0 #> Y.0111_X1.1_X2.0             0             0             0             0 #> Y.1111_X1.1_X2.0             0             0             0             0 #> Y.0000_X1.1_X2.1             0             0             0             0 #> Y.1000_X1.1_X2.1             0             0             0             0 #> Y.0100_X1.1_X2.1             0             0             0             0 #> Y.1100_X1.1_X2.1             0             0             0             0 #> Y.0010_X1.1_X2.1             0             0             0             0 #> Y.1010_X1.1_X2.1             0             0             0             0 #> Y.0110_X1.1_X2.1             0             0             0             0 #> Y.1110_X1.1_X2.1             0             0             0             0 #> Y.0001_X1.1_X2.1             0             0             0             0 #> Y.1001_X1.1_X2.1             0             0             0             0 #> Y.0101_X1.1_X2.1             0             0             0             0 #> Y.1101_X1.1_X2.1             0             0             0             0 #> Y.0011_X1.1_X2.1             0             0             0             1 #> Y.1011_X1.1_X2.1             0             0             0             0 #> Y.0111_X1.1_X2.1             0             0             0             0 #> Y.1111_X1.1_X2.1             0             0             0             0 #>                  X10.X20.Y1011 X11.X20.Y1011 X10.X21.Y1011 X11.X21.Y1011 #> X1.0                         1             0             1             0 #> X1.1                         0             1             0             1 #> X2.0                         1             1             0             0 #> X2.1                         0             0             1             1 #> Y.0000_X1.0_X2.0             0             0             0             0 #> Y.1000_X1.0_X2.0             0             0             0             0 #> Y.0100_X1.0_X2.0             0             0             0             0 #> Y.1100_X1.0_X2.0             0             0             0             0 #> Y.0010_X1.0_X2.0             0             0             0             0 #> Y.1010_X1.0_X2.0             0             0             0             0 #> Y.0110_X1.0_X2.0             0             0             0             0 #> Y.1110_X1.0_X2.0             0             0             0             0 #> Y.0001_X1.0_X2.0             0             0             0             0 #> Y.1001_X1.0_X2.0             0             0             0             0 #> Y.0101_X1.0_X2.0             0             0             0             0 #> Y.1101_X1.0_X2.0             0             0             0             0 #> Y.0011_X1.0_X2.0             0             0             0             0 #> Y.1011_X1.0_X2.0             1             0             0             0 #> Y.0111_X1.0_X2.0             0             0             0             0 #> Y.1111_X1.0_X2.0             0             0             0             0 #> Y.0000_X1.0_X2.1             0             0             0             0 #> Y.1000_X1.0_X2.1             0             0             0             0 #> Y.0100_X1.0_X2.1             0             0             0             0 #> Y.1100_X1.0_X2.1             0             0             0             0 #> Y.0010_X1.0_X2.1             0             0             0             0 #> Y.1010_X1.0_X2.1             0             0             0             0 #> Y.0110_X1.0_X2.1             0             0             0             0 #> Y.1110_X1.0_X2.1             0             0             0             0 #> Y.0001_X1.0_X2.1             0             0             0             0 #> Y.1001_X1.0_X2.1             0             0             0             0 #> Y.0101_X1.0_X2.1             0             0             0             0 #> Y.1101_X1.0_X2.1             0             0             0             0 #> Y.0011_X1.0_X2.1             0             0             0             0 #> Y.1011_X1.0_X2.1             0             0             1             0 #> Y.0111_X1.0_X2.1             0             0             0             0 #> Y.1111_X1.0_X2.1             0             0             0             0 #> Y.0000_X1.1_X2.0             0             0             0             0 #> Y.1000_X1.1_X2.0             0             0             0             0 #> Y.0100_X1.1_X2.0             0             0             0             0 #> Y.1100_X1.1_X2.0             0             0             0             0 #> Y.0010_X1.1_X2.0             0             0             0             0 #> Y.1010_X1.1_X2.0             0             0             0             0 #> Y.0110_X1.1_X2.0             0             0             0             0 #> Y.1110_X1.1_X2.0             0             0             0             0 #> Y.0001_X1.1_X2.0             0             0             0             0 #> Y.1001_X1.1_X2.0             0             0             0             0 #> Y.0101_X1.1_X2.0             0             0             0             0 #> Y.1101_X1.1_X2.0             0             0             0             0 #> Y.0011_X1.1_X2.0             0             0             0             0 #> Y.1011_X1.1_X2.0             0             1             0             0 #> Y.0111_X1.1_X2.0             0             0             0             0 #> Y.1111_X1.1_X2.0             0             0             0             0 #> Y.0000_X1.1_X2.1             0             0             0             0 #> Y.1000_X1.1_X2.1             0             0             0             0 #> Y.0100_X1.1_X2.1             0             0             0             0 #> Y.1100_X1.1_X2.1             0             0             0             0 #> Y.0010_X1.1_X2.1             0             0             0             0 #> Y.1010_X1.1_X2.1             0             0             0             0 #> Y.0110_X1.1_X2.1             0             0             0             0 #> Y.1110_X1.1_X2.1             0             0             0             0 #> Y.0001_X1.1_X2.1             0             0             0             0 #> Y.1001_X1.1_X2.1             0             0             0             0 #> Y.0101_X1.1_X2.1             0             0             0             0 #> Y.1101_X1.1_X2.1             0             0             0             0 #> Y.0011_X1.1_X2.1             0             0             0             0 #> Y.1011_X1.1_X2.1             0             0             0             1 #> Y.0111_X1.1_X2.1             0             0             0             0 #> Y.1111_X1.1_X2.1             0             0             0             0 #>                  X10.X20.Y0111 X11.X20.Y0111 X10.X21.Y0111 X11.X21.Y0111 #> X1.0                         1             0             1             0 #> X1.1                         0             1             0             1 #> X2.0                         1             1             0             0 #> X2.1                         0             0             1             1 #> Y.0000_X1.0_X2.0             0             0             0             0 #> Y.1000_X1.0_X2.0             0             0             0             0 #> Y.0100_X1.0_X2.0             0             0             0             0 #> Y.1100_X1.0_X2.0             0             0             0             0 #> Y.0010_X1.0_X2.0             0             0             0             0 #> Y.1010_X1.0_X2.0             0             0             0             0 #> Y.0110_X1.0_X2.0             0             0             0             0 #> Y.1110_X1.0_X2.0             0             0             0             0 #> Y.0001_X1.0_X2.0             0             0             0             0 #> Y.1001_X1.0_X2.0             0             0             0             0 #> Y.0101_X1.0_X2.0             0             0             0             0 #> Y.1101_X1.0_X2.0             0             0             0             0 #> Y.0011_X1.0_X2.0             0             0             0             0 #> Y.1011_X1.0_X2.0             0             0             0             0 #> Y.0111_X1.0_X2.0             1             0             0             0 #> Y.1111_X1.0_X2.0             0             0             0             0 #> Y.0000_X1.0_X2.1             0             0             0             0 #> Y.1000_X1.0_X2.1             0             0             0             0 #> Y.0100_X1.0_X2.1             0             0             0             0 #> Y.1100_X1.0_X2.1             0             0             0             0 #> Y.0010_X1.0_X2.1             0             0             0             0 #> Y.1010_X1.0_X2.1             0             0             0             0 #> Y.0110_X1.0_X2.1             0             0             0             0 #> Y.1110_X1.0_X2.1             0             0             0             0 #> Y.0001_X1.0_X2.1             0             0             0             0 #> Y.1001_X1.0_X2.1             0             0             0             0 #> Y.0101_X1.0_X2.1             0             0             0             0 #> Y.1101_X1.0_X2.1             0             0             0             0 #> Y.0011_X1.0_X2.1             0             0             0             0 #> Y.1011_X1.0_X2.1             0             0             0             0 #> Y.0111_X1.0_X2.1             0             0             1             0 #> Y.1111_X1.0_X2.1             0             0             0             0 #> Y.0000_X1.1_X2.0             0             0             0             0 #> Y.1000_X1.1_X2.0             0             0             0             0 #> Y.0100_X1.1_X2.0             0             0             0             0 #> Y.1100_X1.1_X2.0             0             0             0             0 #> Y.0010_X1.1_X2.0             0             0             0             0 #> Y.1010_X1.1_X2.0             0             0             0             0 #> Y.0110_X1.1_X2.0             0             0             0             0 #> Y.1110_X1.1_X2.0             0             0             0             0 #> Y.0001_X1.1_X2.0             0             0             0             0 #> Y.1001_X1.1_X2.0             0             0             0             0 #> Y.0101_X1.1_X2.0             0             0             0             0 #> Y.1101_X1.1_X2.0             0             0             0             0 #> Y.0011_X1.1_X2.0             0             0             0             0 #> Y.1011_X1.1_X2.0             0             0             0             0 #> Y.0111_X1.1_X2.0             0             1             0             0 #> Y.1111_X1.1_X2.0             0             0             0             0 #> Y.0000_X1.1_X2.1             0             0             0             0 #> Y.1000_X1.1_X2.1             0             0             0             0 #> Y.0100_X1.1_X2.1             0             0             0             0 #> Y.1100_X1.1_X2.1             0             0             0             0 #> Y.0010_X1.1_X2.1             0             0             0             0 #> Y.1010_X1.1_X2.1             0             0             0             0 #> Y.0110_X1.1_X2.1             0             0             0             0 #> Y.1110_X1.1_X2.1             0             0             0             0 #> Y.0001_X1.1_X2.1             0             0             0             0 #> Y.1001_X1.1_X2.1             0             0             0             0 #> Y.0101_X1.1_X2.1             0             0             0             0 #> Y.1101_X1.1_X2.1             0             0             0             0 #> Y.0011_X1.1_X2.1             0             0             0             0 #> Y.1011_X1.1_X2.1             0             0             0             0 #> Y.0111_X1.1_X2.1             0             0             0             1 #> Y.1111_X1.1_X2.1             0             0             0             0 #>                  X10.X20.Y1111 X11.X20.Y1111 X10.X21.Y1111 X11.X21.Y1111 #> X1.0                         1             0             1             0 #> X1.1                         0             1             0             1 #> X2.0                         1             1             0             0 #> X2.1                         0             0             1             1 #> Y.0000_X1.0_X2.0             0             0             0             0 #> Y.1000_X1.0_X2.0             0             0             0             0 #> Y.0100_X1.0_X2.0             0             0             0             0 #> Y.1100_X1.0_X2.0             0             0             0             0 #> Y.0010_X1.0_X2.0             0             0             0             0 #> Y.1010_X1.0_X2.0             0             0             0             0 #> Y.0110_X1.0_X2.0             0             0             0             0 #> Y.1110_X1.0_X2.0             0             0             0             0 #> Y.0001_X1.0_X2.0             0             0             0             0 #> Y.1001_X1.0_X2.0             0             0             0             0 #> Y.0101_X1.0_X2.0             0             0             0             0 #> Y.1101_X1.0_X2.0             0             0             0             0 #> Y.0011_X1.0_X2.0             0             0             0             0 #> Y.1011_X1.0_X2.0             0             0             0             0 #> Y.0111_X1.0_X2.0             0             0             0             0 #> Y.1111_X1.0_X2.0             1             0             0             0 #> Y.0000_X1.0_X2.1             0             0             0             0 #> Y.1000_X1.0_X2.1             0             0             0             0 #> Y.0100_X1.0_X2.1             0             0             0             0 #> Y.1100_X1.0_X2.1             0             0             0             0 #> Y.0010_X1.0_X2.1             0             0             0             0 #> Y.1010_X1.0_X2.1             0             0             0             0 #> Y.0110_X1.0_X2.1             0             0             0             0 #> Y.1110_X1.0_X2.1             0             0             0             0 #> Y.0001_X1.0_X2.1             0             0             0             0 #> Y.1001_X1.0_X2.1             0             0             0             0 #> Y.0101_X1.0_X2.1             0             0             0             0 #> Y.1101_X1.0_X2.1             0             0             0             0 #> Y.0011_X1.0_X2.1             0             0             0             0 #> Y.1011_X1.0_X2.1             0             0             0             0 #> Y.0111_X1.0_X2.1             0             0             0             0 #> Y.1111_X1.0_X2.1             0             0             1             0 #> Y.0000_X1.1_X2.0             0             0             0             0 #> Y.1000_X1.1_X2.0             0             0             0             0 #> Y.0100_X1.1_X2.0             0             0             0             0 #> Y.1100_X1.1_X2.0             0             0             0             0 #> Y.0010_X1.1_X2.0             0             0             0             0 #> Y.1010_X1.1_X2.0             0             0             0             0 #> Y.0110_X1.1_X2.0             0             0             0             0 #> Y.1110_X1.1_X2.0             0             0             0             0 #> Y.0001_X1.1_X2.0             0             0             0             0 #> Y.1001_X1.1_X2.0             0             0             0             0 #> Y.0101_X1.1_X2.0             0             0             0             0 #> Y.1101_X1.1_X2.0             0             0             0             0 #> Y.0011_X1.1_X2.0             0             0             0             0 #> Y.1011_X1.1_X2.0             0             0             0             0 #> Y.0111_X1.1_X2.0             0             0             0             0 #> Y.1111_X1.1_X2.0             0             1             0             0 #> Y.0000_X1.1_X2.1             0             0             0             0 #> Y.1000_X1.1_X2.1             0             0             0             0 #> Y.0100_X1.1_X2.1             0             0             0             0 #> Y.1100_X1.1_X2.1             0             0             0             0 #> Y.0010_X1.1_X2.1             0             0             0             0 #> Y.1010_X1.1_X2.1             0             0             0             0 #> Y.0110_X1.1_X2.1             0             0             0             0 #> Y.1110_X1.1_X2.1             0             0             0             0 #> Y.0001_X1.1_X2.1             0             0             0             0 #> Y.1001_X1.1_X2.1             0             0             0             0 #> Y.0101_X1.1_X2.1             0             0             0             0 #> Y.1101_X1.1_X2.1             0             0             0             0 #> Y.0011_X1.1_X2.1             0             0             0             0 #> Y.1011_X1.1_X2.1             0             0             0             0 #> Y.0111_X1.1_X2.1             0             0             0             0 #> Y.1111_X1.1_X2.1             0             0             0             1 #> [1] 68 64 inspect(model, \"parameters_df\") #>  #> parameters_df #> Mapping of model parameters to nodal types:  #>  #>   param_names: name of parameter #>   node:        name of endogeneous node associated #>                with the parameter #>   gen:         partial causal ordering of the #>                parameter's node #>   param_set:   parameter groupings forming a simplex #>   given:       if model has confounding gives #>                conditioning nodal type #>   param_value: parameter values #>   priors:      hyperparameters of the prior #>                Dirichlet distribution  #>  #>  #> snippet (use grab() to access full 68 x 8 object):  #>  #>         param_names node gen   param_set nodal_type      given param_value #> 1              X1.0   X1   1          X1          0                 0.5000 #> 2              X1.1   X1   1          X1          1                 0.5000 #> 3              X2.0   X2   2          X2          0                 0.5000 #> 4              X2.1   X2   2          X2          1                 0.5000 #> 5  Y.0000_X1.0_X2.0    Y   3 Y.X1.0.X2.0       0000 X1.0, X2.0      0.0625 #> 6  Y.1000_X1.0_X2.0    Y   3 Y.X1.0.X2.0       1000 X1.0, X2.0      0.0625 #> 7  Y.0100_X1.0_X2.0    Y   3 Y.X1.0.X2.0       0100 X1.0, X2.0      0.0625 #> 8  Y.1100_X1.0_X2.0    Y   3 Y.X1.0.X2.0       1100 X1.0, X2.0      0.0625 #> 9  Y.0010_X1.0_X2.0    Y   3 Y.X1.0.X2.0       0010 X1.0, X2.0      0.0625 #> 10 Y.1010_X1.0_X2.0    Y   3 Y.X1.0.X2.0       1010 X1.0, X2.0      0.0625 #>    priors #> 1       1 #> 2       1 #> 3       1 #> 4       1 #> 5       1 #> 6       1 #> 7       1 #> 8       1 #> 9       1 #> 10      1  # A single node graph is also possible model <- make_model(\"X\")  # Unconnected nodes not allowed if (FALSE) { # \\dontrun{  model <- make_model(\"X <-> Y\") } # }  nodal_types <-   list(     A = c(\"0\",\"1\"),     B = c(\"0\",\"1\"),     C = c(\"0\",\"1\"),     D = c(\"0\",\"1\"),     E = c(\"0\",\"1\"),     Y = c(       \"00000000000000000000000000000000\",       \"01010101010101010101010101010101\",       \"00110011001100110011001100110011\",       \"00001111000011110000111100001111\",       \"00000000111111110000000011111111\",       \"00000000000000001111111111111111\",       \"11111111111111111111111111111111\" ))  make_model(\"A -> Y; B ->Y; C->Y; D->Y; E->Y\",           nodal_types = nodal_types) |>  inspect(\"parameters_df\") #>  #> parameters_df #> Mapping of model parameters to nodal types:  #>  #>   param_names: name of parameter #>   node:        name of endogeneous node associated #>                with the parameter #>   gen:         partial causal ordering of the #>                parameter's node #>   param_set:   parameter groupings forming a simplex #>   given:       if model has confounding gives #>                conditioning nodal type #>   param_value: parameter values #>   priors:      hyperparameters of the prior #>                Dirichlet distribution  #>  #>  #> snippet (use grab() to access full 17 x 8 object):  #>  #>    param_names node gen param_set nodal_type given param_value priors #> 1          A.0    A   1         A          0               0.5      1 #> 2          A.1    A   1         A          1               0.5      1 #> 3          B.0    B   2         B          0               0.5      1 #> 4          B.1    B   2         B          1               0.5      1 #> 5          C.0    C   3         C          0               0.5      1 #> 6          C.1    C   3         C          1               0.5      1 #> 7          D.0    D   4         D          0               0.5      1 #> 8          D.1    D   4         D          1               0.5      1 #> 9          E.0    E   5         E          0               0.5      1 #> 10         E.1    E   5         E          1               0.5      1  nodal_types = list(Y = c(\"01\", \"10\"), Z = c(\"0\", \"1\")) make_model(\"Z -> Y\", nodal_types = nodal_types) |>  inspect(\"parameters_df\") #> Ordering of provided nodal types is being altered to match generation #>  #> parameters_df #> Mapping of model parameters to nodal types:  #>  #>   param_names: name of parameter #>   node:        name of endogeneous node associated #>                with the parameter #>   gen:         partial causal ordering of the #>                parameter's node #>   param_set:   parameter groupings forming a simplex #>   given:       if model has confounding gives #>                conditioning nodal type #>   param_value: parameter values #>   priors:      hyperparameters of the prior #>                Dirichlet distribution  #>  #>   param_names node gen param_set nodal_type given param_value priors #> 1         Z.0    Z   1         Z          0               0.5      1 #> 2         Z.1    Z   1         Z          1               0.5      1 #> 3        Y.01    Y   2         Y         01               0.5      1 #> 4        Y.10    Y   2         Y         10               0.5      1"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_parameters_df.html","id":null,"dir":"Reference","previous_headings":"","what":"function to make a parameters_df from nodal types ‚Äî make_parameters_df","title":"function to make a parameters_df from nodal types ‚Äî make_parameters_df","text":"function make parameters_df nodal types","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_parameters_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"function to make a parameters_df from nodal types ‚Äî make_parameters_df","text":"","code":"make_parameters_df(nodal_types)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_parameters_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"function to make a parameters_df from nodal types ‚Äî make_parameters_df","text":"nodal_types list nodal types","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_parameters_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"function to make a parameters_df from nodal types ‚Äî make_parameters_df","text":"","code":"CausalQueries:::make_parameters_df(list(X = \"1\", Y = c(\"01\", \"10\"))) #>   param_names node gen param_set nodal_type given param_value priors #> 1         X.1    X   1         X          1               1.0      1 #> 2        Y.01    Y   2         Y         01               0.5      1 #> 3        Y.10    Y   2         Y         10               0.5      1"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_par_values.html","id":null,"dir":"Reference","previous_headings":"","what":"make_par_values ‚Äî make_par_values","title":"make_par_values ‚Äî make_par_values","text":"one step function make_priors make_parameters. See make_priors help.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_par_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_par_values ‚Äî make_par_values","text":"","code":"make_par_values(   model,   alter = \"priors\",   x = NA,   alter_at = NA,   node = NA,   label = NA,   nodal_type = NA,   param_set = NA,   given = NA,   statement = NA,   join_by = \"|\",   param_names = NA,   distribution = NA,   normalize = FALSE )"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_par_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_par_values ‚Äî make_par_values","text":"model model created make_model alter character vector one \"priors\" \"param_value\" specifying alter x vector real non negative values substituted \"priors\" \"param_value\" alter_at string specifying filtering operations applied parameters_df, yielding logical vector indicating parameters values altered. (see examples) node string indicating nodes altered label string. Label nodal type indicating nodal types values altered. Equivalent nodal_type. nodal_type string. Label nodal type indicating nodal types values altered param_set string indicating  name set parameters altered given string indicates node parameter altered depends statement causal query determines nodal types values altered join_by string specifying logical operator joining expanded types statement contains wildcards. Can take values '&' (logical ) '|' (logical ). param_names vector strings. name specific parameter form , example, 'X.1', 'Y.01' distribution string indicating common prior distribution (uniform, jeffreys certainty) normalize logical. TRUE normalizes param set probabilities sum 1.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_par_values.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"make_par_values ‚Äî make_par_values","text":"","code":"# the below methods can be applied to either priors or # param_values by specifying the desired option in \\code{alter}  model <- CausalQueries::make_model(\"X -> M -> Y; X <-> Y\")  #altering values using \\code{alter_at} CausalQueries:::make_par_values(model = model,                                 x = c(0.5,0.25),                                 alter_at = paste(                                   \"node == 'Y' &\",                                   \"nodal_type %in% c('00','01') &\",                                   \"given == 'X.0'\")) #>  [1] 1.00 1.00 1.00 1.00 1.00 1.00 0.50 1.00 0.25 1.00 1.00 1.00 1.00 1.00  #altering values using \\code{param_names} CausalQueries:::make_par_values(model = model,                                 x = c(0.5,0.25),                                 param_names = c(\"Y.10_X.0\",\"Y.10_X.1\")) #>  [1] 1.00 1.00 1.00 1.00 1.00 1.00 1.00 0.50 1.00 1.00 1.00 0.25 1.00 1.00  #altering values using \\code{statement} CausalQueries:::make_par_values(model = model,                                 x = c(0.5,0.25),                                 statement = \"Y[M=1] > Y[M=0]\") #> Warning: Possible ambiguity: use additional arguments or check behavior in parameters_df. #>  [1] 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 0.50 1.00 1.00 1.00 0.25 1.00  #altering values using a combination of other arguments CausalQueries:::make_par_values(model = model, x = c(0.5,0.25), node = \"Y\", nodal_type = c(\"00\",\"01\"), given = \"X.0\") #>  [1] 1.00 1.00 1.00 1.00 1.00 1.00 0.50 1.00 0.25 1.00 1.00 1.00 1.00 1.00"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_par_values_stops.html","id":null,"dir":"Reference","previous_headings":"","what":"make_par_values_stops ‚Äî make_par_values_stops","title":"make_par_values_stops ‚Äî make_par_values_stops","text":"helper remove stops reduce complexity make_par_values","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_par_values_stops.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_par_values_stops ‚Äî make_par_values_stops","text":"","code":"make_par_values_stops(   model,   alter = \"priors\",   x = NA,   alter_at = NA,   node = NA,   label = NA,   nodal_type = NA,   param_set = NA,   given = NA,   statement = NA,   join_by = \"|\",   param_names = NA,   distribution = NA,   normalize = FALSE )"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_par_values_stops.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_par_values_stops ‚Äî make_par_values_stops","text":"model model created make_model alter character vector one \"priors\" \"param_value\" specifying alter x vector real non negative values substituted \"priors\" \"param_value\" alter_at string specifying filtering operations applied parameters_df, yielding logical vector indicating parameters values altered. (see examples) node string indicating nodes altered label string. Label nodal type indicating nodal types values altered. Equivalent nodal_type. nodal_type string. Label nodal type indicating nodal types values altered param_set string indicating  name set parameters altered given string indicates node parameter altered depends statement causal query determines nodal types values altered join_by string specifying logical operator joining expanded types statement contains wildcards. Can take values '&' (logical ) '|' (logical ). param_names vector strings. name specific parameter form , example, 'X.1', 'Y.01' distribution string indicating common prior distribution (uniform, jeffreys certainty) normalize logical. TRUE normalizes param set probabilities sum 1.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_prior_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a prior distribution from priors ‚Äî make_prior_distribution","title":"Make a prior distribution from priors ‚Äî make_prior_distribution","text":"Create `n_param`x `n_draws` database possible lambda draws attached model.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_prior_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a prior distribution from priors ‚Äî make_prior_distribution","text":"","code":"make_prior_distribution(model, n_draws = 4000)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_prior_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make a prior distribution from priors ‚Äî make_prior_distribution","text":"model causal_model. model object generated make_model. n_draws scalar. Number draws.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_prior_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make a prior distribution from priors ‚Äî make_prior_distribution","text":"`data.frame` dimension `n_param`x `n_draws` possible   lambda draws","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/make_prior_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make a prior distribution from priors ‚Äî make_prior_distribution","text":"","code":"make_model('X -> Y') |>   CausalQueries:::make_prior_distribution(n_draws = 5) #>          X.0       X.1       Y.00       Y.10        Y.01        Y.11 #> 1 0.01967763 0.9803224 0.07020172 0.46511985 0.104333437 0.360344995 #> 2 0.44274386 0.5572561 0.18938866 0.05739555 0.271800357 0.481415427 #> 3 0.23098125 0.7690187 0.35779159 0.19704767 0.441944067 0.003216664 #> 4 0.32214528 0.6778547 0.62263574 0.33487147 0.004418769 0.038074021 #> 5 0.83050866 0.1694913 0.27464915 0.20451997 0.467203889 0.053626989"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/minimal_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a data frame for case with no data ‚Äî minimal_data","title":"Creates a data frame for case with no data ‚Äî minimal_data","text":"Creates data frame case data","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/minimal_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a data frame for case with no data ‚Äî minimal_data","text":"","code":"minimal_data(model)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/minimal_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a data frame for case with no data ‚Äî minimal_data","text":"model causal_model. model object generated make_model.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/minimal_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a data frame for case with no data ‚Äî minimal_data","text":"data.frame one row NAs columns named according   nodes model.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/minimal_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a data frame for case with no data ‚Äî minimal_data","text":"","code":"# \\donttest{ model <- make_model('X -> K -> Y') CausalQueries:::minimal_data(model) #>    X  K  Y #> 1 NA NA NA # }"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/minimal_event_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a compact data frame for case with no data ‚Äî minimal_event_data","title":"Creates a compact data frame for case with no data ‚Äî minimal_event_data","text":"Creates compact data frame case data","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/minimal_event_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a compact data frame for case with no data ‚Äî minimal_event_data","text":"","code":"minimal_event_data(model)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/minimal_event_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a compact data frame for case with no data ‚Äî minimal_event_data","text":"model causal_model. model object generated make_model.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/minimal_event_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a compact data frame for case with no data ‚Äî minimal_event_data","text":"compact data frame row represents element   exhaustive set events model. count event   set zero.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/minimal_event_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a compact data frame for case with no data ‚Äî minimal_event_data","text":"","code":"# \\donttest{ model <- make_model('X -> K -> Y') CausalQueries:::minimal_event_data(model) #>    event strategy count #> 1 X0K0Y0      XKY     0 #> 2 X1K0Y0      XKY     0 #> 3 X0K1Y0      XKY     0 #> 4 X1K1Y0      XKY     0 #> 5 X0K0Y1      XKY     0 #> 6 X1K0Y1      XKY     0 #> 7 X0K1Y1      XKY     0 #> 8 X1K1Y1      XKY     0 # }"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/parameter_setting.html","id":null,"dir":"Reference","previous_headings":"","what":"Setting parameters ‚Äî parameter_setting","title":"Setting parameters ‚Äî parameter_setting","text":"Functionality altering parameters: vector 'true' parameters; possibly drawn prior posterior. Add true parameter vector model. Parameters can created using arguments passed make_parameters make_priors. Extracts parameters named vector","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/parameter_setting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Setting parameters ‚Äî parameter_setting","text":"","code":"make_parameters(   model,   parameters = NULL,   param_type = NULL,   warning = TRUE,   normalize = TRUE,   ... )  set_parameters(   model,   parameters = NULL,   param_type = NULL,   warning = FALSE,   ... )  get_parameters(model, param_type = NULL)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/parameter_setting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Setting parameters ‚Äî parameter_setting","text":"model causal_model. model object generated make_model. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn parameters dataframe. See inspect(model, \"parameters_df\"). param_type character. String specifying type parameters make \"flat\", \"prior_mean\", \"posterior_mean\", \"prior_draw\", \"posterior_draw\", \"define\". param_type set define use arguments passed make_priors; otherwise flat sets equal probabilities nodal type parameter set; prior_mean, prior_draw, posterior_mean, posterior_draw take parameters means draws prior posterior. warning Logical. Whether warn parameter renormalization. normalize Logical. parameter given subset family residual elements normalized parameters param_set sum 1 provided params unaltered. ... Options passed onto make_priors.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/parameter_setting.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Setting parameters ‚Äî parameter_setting","text":"vector draws prior distribution parameters object class causal_model. essentially returns   list containing elements comprising model   (e.g. 'statement', 'nodal_types' 'DAG') true vector   parameters attached . vector draws prior distribution parameters","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/parameter_setting.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Setting parameters ‚Äî parameter_setting","text":"","code":"# make_parameters examples:  # Simple examples model <- make_model('X -> Y') data  <- make_data(model, n = 2) model <- update_model(model, data) #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 1.9e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.126 seconds (Warm-up) #> Chain 1:                0.137 seconds (Sampling) #> Chain 1:                0.263 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1.5e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.128 seconds (Warm-up) #> Chain 2:                0.125 seconds (Sampling) #> Chain 2:                0.253 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 1.8e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.138 seconds (Warm-up) #> Chain 3:                0.124 seconds (Sampling) #> Chain 3:                0.262 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 1.6e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.132 seconds (Warm-up) #> Chain 4:                0.141 seconds (Sampling) #> Chain 4:                0.273 seconds (Total) #> Chain 4:  make_parameters(model, parameters = c(.25, .75, 1.25,.25, .25, .25)) #>   X.0   X.1  Y.00  Y.10  Y.01  Y.11  #> 0.250 0.750 0.625 0.125 0.125 0.125  make_parameters(model, param_type = 'flat') #> Altering all parameters. #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #> 0.50 0.50 0.25 0.25 0.25 0.25  make_parameters(model, param_type = 'prior_draw') #>         X.0         X.1        Y.00        Y.10        Y.01        Y.11  #> 0.010964204 0.989035796 0.006390548 0.364744398 0.477638130 0.151226924  make_parameters(model, param_type = 'prior_mean') #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #> 0.50 0.50 0.25 0.25 0.25 0.25  make_parameters(model, param_type = 'posterior_draw') #>        X.0        X.1       Y.00       Y.10       Y.01       Y.11  #> 0.95148303 0.04851697 0.18007705 0.11237298 0.30673603 0.40081395  make_parameters(model, param_type = 'posterior_mean') #>       X.0       X.1      Y.00      Y.10      Y.01      Y.11  #> 0.7480843 0.2519157 0.2430079 0.2544886 0.2532707 0.2492328    # \\donttest{  #altering values using \\code{alter_at} make_model(\"X -> Y\") |> make_parameters(parameters = c(0.5,0.25), alter_at = \"node == 'Y' & nodal_type %in% c('00','01')\") #>   X.0   X.1  Y.00  Y.10  Y.01  Y.11  #> 0.500 0.500 0.500 0.125 0.250 0.125   #altering values using \\code{param_names} make_model(\"X -> Y\") |> make_parameters(parameters = c(0.5,0.25), param_names = c(\"Y.10\",\"Y.01\")) #>   X.0   X.1  Y.00  Y.10  Y.01  Y.11  #> 0.500 0.500 0.125 0.500 0.250 0.125   #altering values using \\code{statement} make_model(\"X -> Y\") |> make_parameters(parameters = c(0.5), statement = \"Y[X=1] > Y[X=0]\") #>       X.0       X.1      Y.00      Y.10      Y.01      Y.11  #> 0.5000000 0.5000000 0.1666667 0.1666667 0.5000000 0.1666667   #altering values using a combination of other arguments make_model(\"X -> Y\") |> make_parameters(parameters = c(0.5,0.25), node = \"Y\", nodal_type = c(\"00\",\"01\")) #>   X.0   X.1  Y.00  Y.10  Y.01  Y.11  #> 0.500 0.500 0.500 0.125 0.250 0.125   # Normalize renormalizes values not set so that value set is not renomalized make_parameters(make_model('X -> Y'),                statement = 'Y[X=1]>Y[X=0]', parameters = .5) #>       X.0       X.1      Y.00      Y.10      Y.01      Y.11  #> 0.5000000 0.5000000 0.1666667 0.1666667 0.5000000 0.1666667  make_parameters(make_model('X -> Y'),                statement = 'Y[X=1]>Y[X=0]', parameters = .5,                normalize = FALSE) #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #>  0.5  0.5  0.2  0.2  0.4  0.2     # }  # set_parameters examples:  make_model('X->Y') |>  set_parameters(1:6) |>  inspect(\"parameters\") #>  #> parameters #> Model parameters with associated probabilities:  #>  #>       X.0       X.1      Y.00      Y.10      Y.01      Y.11  #> 0.3333333 0.6666667 0.1666667 0.2222222 0.2777778 0.3333333   # Simple examples model <- make_model('X -> Y') data  <- make_data(model, n = 2) model <- update_model(model, data) #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.2e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.117 seconds (Warm-up) #> Chain 1:                0.116 seconds (Sampling) #> Chain 1:                0.233 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1.6e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.144 seconds (Warm-up) #> Chain 2:                0.121 seconds (Sampling) #> Chain 2:                0.265 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 1.6e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.127 seconds (Warm-up) #> Chain 3:                0.13 seconds (Sampling) #> Chain 3:                0.257 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 1.6e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.134 seconds (Warm-up) #> Chain 4:                0.124 seconds (Sampling) #> Chain 4:                0.258 seconds (Total) #> Chain 4:  set_parameters(model, parameters = c(.25, .75, 1.25,.25, .25, .25)) #>  #> Causal statement:  #> X -> Y #>  #> Number of nodal types by node: #> X Y  #> 2 4  #>  #> Number of causal types: 8 #>  #> Model has been updated and contains a posterior distribution with #> 4 chains, each with iter=2000; warmup=1000; thin=1;   #> Use inspect(model, 'stan_objects') to inspect stan summary #>  set_parameters(model, param_type = 'flat') #> Altering all parameters. #>  #> Causal statement:  #> X -> Y #>  #> Number of nodal types by node: #> X Y  #> 2 4  #>  #> Number of causal types: 8 #>  #> Model has been updated and contains a posterior distribution with #> 4 chains, each with iter=2000; warmup=1000; thin=1;   #> Use inspect(model, 'stan_objects') to inspect stan summary #>  set_parameters(model, param_type = 'prior_draw') #>  #> Causal statement:  #> X -> Y #>  #> Number of nodal types by node: #> X Y  #> 2 4  #>  #> Number of causal types: 8 #>  #> Model has been updated and contains a posterior distribution with #> 4 chains, each with iter=2000; warmup=1000; thin=1;   #> Use inspect(model, 'stan_objects') to inspect stan summary #>  set_parameters(model, param_type = 'prior_mean') #>  #> Causal statement:  #> X -> Y #>  #> Number of nodal types by node: #> X Y  #> 2 4  #>  #> Number of causal types: 8 #>  #> Model has been updated and contains a posterior distribution with #> 4 chains, each with iter=2000; warmup=1000; thin=1;   #> Use inspect(model, 'stan_objects') to inspect stan summary #>  set_parameters(model, param_type = 'posterior_draw') #>  #> Causal statement:  #> X -> Y #>  #> Number of nodal types by node: #> X Y  #> 2 4  #>  #> Number of causal types: 8 #>  #> Model has been updated and contains a posterior distribution with #> 4 chains, each with iter=2000; warmup=1000; thin=1;   #> Use inspect(model, 'stan_objects') to inspect stan summary #>  set_parameters(model, param_type = 'posterior_mean') #>  #> Causal statement:  #> X -> Y #>  #> Number of nodal types by node: #> X Y  #> 2 4  #>  #> Number of causal types: 8 #>  #> Model has been updated and contains a posterior distribution with #> 4 chains, each with iter=2000; warmup=1000; thin=1;   #> Use inspect(model, 'stan_objects') to inspect stan summary #>    # \\donttest{  #altering values using \\code{alter_at} make_model(\"X -> Y\") |> set_parameters(parameters = c(0.5,0.25), alter_at = \"node == 'Y' & nodal_type %in% c('00','01')\") #>  #> Causal statement:  #> X -> Y #>  #> Number of nodal types by node: #> X Y  #> 2 4  #>  #> Number of causal types: 8  #altering values using \\code{param_names} make_model(\"X -> Y\") |> set_parameters(parameters = c(0.5,0.25), param_names = c(\"Y.10\",\"Y.01\")) #>  #> Causal statement:  #> X -> Y #>  #> Number of nodal types by node: #> X Y  #> 2 4  #>  #> Number of causal types: 8  #altering values using \\code{statement} make_model(\"X -> Y\") |> set_parameters(parameters = c(0.5), statement = \"Y[X=1] > Y[X=0]\") #>  #> Causal statement:  #> X -> Y #>  #> Number of nodal types by node: #> X Y  #> 2 4  #>  #> Number of causal types: 8  #altering values using a combination of other arguments make_model(\"X -> Y\") |> set_parameters(parameters = c(0.5,0.25), node = \"Y\", nodal_type = c(\"00\",\"01\")) #>  #> Causal statement:  #> X -> Y #>  #> Number of nodal types by node: #> X Y  #> 2 4  #>  #> Number of causal types: 8     # }"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/parents_to_int.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper to turn parents_list into a list of data_realizations column positions ‚Äî parents_to_int","title":"Helper to turn parents_list into a list of data_realizations column positions ‚Äî parents_to_int","text":"Helper turn parents_list list data_realizations column positions","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/parents_to_int.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper to turn parents_list into a list of data_realizations column positions ‚Äî parents_to_int","text":"","code":"parents_to_int(parents_list, position_set)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/parents_to_int.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper to turn parents_list into a list of data_realizations column positions ‚Äî parents_to_int","text":"parents_list named list character vectors specifying nodes DAG respective parents","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/parents_to_int.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper to turn parents_list into a list of data_realizations column positions ‚Äî parents_to_int","text":"list column positions","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/perm.html","id":null,"dir":"Reference","previous_headings":"","what":"Produces the possible permutations of a set of nodes ‚Äî perm","title":"Produces the possible permutations of a set of nodes ‚Äî perm","text":"Produces possible permutations set nodes","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/perm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produces the possible permutations of a set of nodes ‚Äî perm","text":"","code":"perm(max = rep(1, 2))"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/perm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produces the possible permutations of a set of nodes ‚Äî perm","text":"max vector integers. maximum value integer value starting 0. Defaults 1. number permutation defined max's length","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/perm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produces the possible permutations of a set of nodes ‚Äî perm","text":"matrix permutations","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/perm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Produces the possible permutations of a set of nodes ‚Äî perm","text":"","code":"# \\donttest{ CausalQueries:::perm(3) #>     #> 1 0 #> 2 1 #> 3 2 #> 4 3 # }"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/plot_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots a DAG in ggplot style using a causal model input ‚Äî plot_model","title":"Plots a DAG in ggplot style using a causal model input ‚Äî plot_model","text":"Creates plot DAG using ggplot functionality Sugiyama layout igraph.  Unmeasured confounds  (<->) indicated represented curved dotted lines.  Users can control node sizes colors well coordinates label behavior. modifications can made adding additional ggplot layers.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/plot_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots a DAG in ggplot style using a causal model input ‚Äî plot_model","text":"","code":"plot_model(   model = NULL,   x_coord = NULL,   y_coord = NULL,   labels = NULL,   title = \"\",   textcol = \"white\",   textsize = 3.88,   shape = 16,   nodecol = \"black\",   nodesize = 12,   strength = 0.3 )"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/plot_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots a DAG in ggplot style using a causal model input ‚Äî plot_model","text":"model causal_model object generated make_model x_coord vector x coordinates DAG nodes. left empty, coordinates randomly generated y_coord vector y coordinates DAG nodes. left empty, coordinates randomly generated labels Optional labels nodes title String specifying title graph textcol String specifying color text labels textsize Numeric, size text labels shape Indicates shape node. Defaults circular node. nodecol String indicating color node accepted ggplot's default palette nodesize Size node. strength Degree curvature curved arcs","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/plot_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots a DAG in ggplot style using a causal model input ‚Äî plot_model","text":"ggplot object.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/plot_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots a DAG in ggplot style using a causal model input ‚Äî plot_model","text":"","code":"if (FALSE) { # \\dontrun{ model <- make_model('X -> K -> Y')  # Simple plot model |> plot_model()  # Adding additional layers model |> plot_model() +   ggplot2::coord_flip()  # Adding labels model |>   plot_model(     labels = c(\"A long name for a \\n node\", \"This\", \"That\"),     nodecol = \"white\",     textcol = \"black\")  # Controlling  positions and using math labels model |> plot_model(     x_coord = 0:2,     y_coord = 0:2,     title = \"Mixed text and math: $\\\\alpha^2 + \\\\Gamma$\") } # }  # DAG with unobserved confounding and shapes make_model('Z -> X -> Y; X <-> Y') |>   plot(x_coord = 1:3, y_coord = 1:3, shape = c(15, 16, 16))"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/prep_stan_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare data for 'stan' ‚Äî prep_stan_data","title":"Prepare data for 'stan' ‚Äî prep_stan_data","text":"Create list containing data passed 'stan","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/prep_stan_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare data for 'stan' ‚Äî prep_stan_data","text":"","code":"prep_stan_data(   model,   data,   keep_type_distribution = TRUE,   censored_types = NULL )"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/prep_stan_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare data for 'stan' ‚Äî prep_stan_data","text":"model causal_model. model object generated make_model. data data.frame.  Data nodes can take three values: 0, 1, NA. long form generated make_events","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/prep_stan_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare data for 'stan' ‚Äî prep_stan_data","text":"list containing data passed 'stan'","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/prep_stan_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare data for 'stan' ‚Äî prep_stan_data","text":"","code":"# \\donttest{ model <- make_model('X->Y') data  <-  collapse_data(make_data(model, n = 6), model) CausalQueries:::prep_stan_data(model, data) #> $parmap #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X.0     1    0    1    0 #> X.1     0    1    0    1 #> Y.00    1    1    0    0 #> Y.10    0    1    1    0 #> Y.01    1    0    0    1 #> Y.11    0    0    1    1 #> attr(,\"map\") #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 #>  #> $map #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 #>  #> $n_paths #> [1] 4 #>  #> $n_params #> [1] 6 #>  #> $n_param_sets #> [1] 2 #>  #> $n_param_each #> X Y  #> 2 4  #>  #> $l_starts #> X Y  #> 1 3  #>  #> $l_ends #> X Y  #> 2 6  #>  #> $node_starts #> X Y  #> 1 3  #>  #> $node_ends #> X Y  #> 2 6  #>  #> $n_nodes #> [1] 2 #>  #> $lambdas_prior #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #>    1    1    1    1    1    1  #>  #> $n_data #> [1] 4 #>  #> $n_events #> [1] 4 #>  #> $n_strategies #> [1] 1 #>  #> $strategy_starts #> [1] 1 #>  #> $strategy_ends #> [1] 4 #>  #> $keep_type_distribution #> [1] 1 #>  #> $E #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 #>  #> $Y #> [1] 1 2 1 2 #>  #> $P #>      X0.Y00 X1.Y00 X0.Y10 X1.Y10 X0.Y01 X1.Y01 X0.Y11 X1.Y11 #> X.0       1      0      1      0      1      0      1      0 #> X.1       0      1      0      1      0      1      0      1 #> Y.00      1      1      0      0      0      0      0      0 #> Y.10      0      0      1      1      0      0      0      0 #> Y.01      0      0      0      0      1      1      0      0 #> Y.11      0      0      0      0      0      0      1      1 #>  #> $n_types #> [1] 8 #>   model <- make_model('X->Y') |>   set_confound(list(X = 'Y[X=1]>Y[X=0]')) data  <-  collapse_data(make_data(model, n = 6), model) CausalQueries:::prep_stan_data(model, data) #> $parmap #>      X0Y0 X1Y0 X0Y1 X1Y1 #> Y.00    1    1    0    0 #> Y.10    0    1    1    0 #> Y.01    1    0    0    1 #> Y.11    0    0    1    1 #> attr(,\"map\") #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 #>  #> $map #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 #>  #> $n_paths #> [1] 4 #>  #> $n_params #> [1] 4 #>  #> $n_param_sets #> [1] 1 #>  #> $n_param_each #> Y  #> 4  #>  #> $l_starts #> Y  #> 1  #>  #> $l_ends #> Y  #> 4  #>  #> $node_starts #> Y  #> 1  #>  #> $node_ends #> Y  #> 4  #>  #> $n_nodes #> [1] 1 #>  #> $lambdas_prior #> Y.00 Y.10 Y.01 Y.11  #>    1    1    1    1  #>  #> $n_data #> [1] 4 #>  #> $n_events #> [1] 4 #>  #> $n_strategies #> [1] 1 #>  #> $strategy_starts #> [1] 1 #>  #> $strategy_ends #> [1] 4 #>  #> $keep_type_distribution #> [1] 1 #>  #> $E #>      X0Y0 X1Y0 X0Y1 X1Y1 #> X0Y0    1    0    0    0 #> X1Y0    0    1    0    0 #> X0Y1    0    0    1    0 #> X1Y1    0    0    0    1 #>  #> $Y #> [1] 1 2 3 0 #>  #> $P #>      X0.Y00 X1.Y00 X0.Y10 X1.Y10 X0.Y01 X1.Y01 X0.Y11 X1.Y11 #> Y.00      1      1      0      0      0      0      0      0 #> Y.10      0      0      1      1      0      0      0      0 #> Y.01      0      0      0      0      1      1      0      0 #> Y.11      0      0      0      0      0      0      1      1 #>  #> $n_types #> [1] 8 #>  # }"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/print.causal_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for a causal model ‚Äî print.causal_model","title":"Print a short summary for a causal model ‚Äî print.causal_model","text":"print method class \"causal_model\".","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/print.causal_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for a causal model ‚Äî print.causal_model","text":"","code":"# S3 method for class 'causal_model' print(x, ...)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/print.causal_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for a causal model ‚Äî print.causal_model","text":"x object causal_model class, usually result call make_model update_model. ... arguments passed methods.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/print.causal_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print a short summary for a causal model ‚Äî print.causal_model","text":"information regarding causal model includes statement describing causal relations using dagitty syntax, number nodal types per parent DAG, number causal types.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/print.event_probabilities.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for event probabilities ‚Äî print.event_probabilities","title":"Print a short summary for event probabilities ‚Äî print.event_probabilities","text":"print method class event_probabilities.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/print.event_probabilities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for event probabilities ‚Äî print.event_probabilities","text":"","code":"# S3 method for event_probabilities print(x, ...)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/print.event_probabilities.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for event probabilities ‚Äî print.event_probabilities","text":"x object event_probabilities class, sub-object object causal_model class produced using update_model. ... arguments passed methods.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/print.model_query.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a tightened summary of model queries ‚Äî print.model_query","title":"Print a tightened summary of model queries ‚Äî print.model_query","text":"print method class model_query.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/print.model_query.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a tightened summary of model queries ‚Äî print.model_query","text":"","code":"# S3 method for class 'model_query' print(x, ...)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/print.model_query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a tightened summary of model queries ‚Äî print.model_query","text":"x object model_query class. ... arguments passed methods.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/print.posterior_event_probabilities.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary of posterior_event_probabilities ‚Äî print.posterior_event_probabilities","title":"Print a short summary of posterior_event_probabilities ‚Äî print.posterior_event_probabilities","text":"print method class posterior_event_probabilities.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/print.posterior_event_probabilities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary of posterior_event_probabilities ‚Äî print.posterior_event_probabilities","text":"","code":"# S3 method for posterior_event_probabilities print(x, ...)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/print.posterior_event_probabilities.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary of posterior_event_probabilities ‚Äî print.posterior_event_probabilities","text":"x object posterior_event_probabilities class. ... arguments passed methods.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/print.stan_objects.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for stan_objects ‚Äî print.stan_objects","title":"Print a short summary for stan_objects ‚Äî print.stan_objects","text":"print method class stan_objects.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/print.stan_objects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for stan_objects ‚Äî print.stan_objects","text":"","code":"# S3 method for class 'stan_objects' print(x, ...)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/print.stan_objects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for stan_objects ‚Äî print.stan_objects","text":"x object stan_objects class, list containing data, type_distribution  stan_summary. ... arguments passed methods.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/print.stan_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a short summary for stan fit ‚Äî print.stan_summary","title":"Print a short summary for stan fit ‚Äî print.stan_summary","text":"print method class stan_summary.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/print.stan_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a short summary for stan fit ‚Äî print.stan_summary","text":"","code":"# S3 method for stan_summary print(x, ...)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/print.stan_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a short summary for stan fit ‚Äî print.stan_summary","text":"x object stan_summary class, sub-object object causal_model class produced using update_model. ... arguments passed methods.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/prior_setting.html","id":null,"dir":"Reference","previous_headings":"","what":"Setting priors ‚Äî prior_setting","title":"Setting priors ‚Äî prior_setting","text":"Functionality altering priors: make_priors Generates priors model. set_priors  Adds priors model. Extracts priors named vector","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/prior_setting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Setting priors ‚Äî prior_setting","text":"","code":"make_priors(   model,   alphas = NA,   distribution = NA,   alter_at = NA,   node = NA,   nodal_type = NA,   label = NA,   param_set = NA,   given = NA,   statement = NA,   join_by = \"|\",   param_names = NA )  set_priors(   model,   alphas = NA,   distribution = NA,   alter_at = NA,   node = NA,   nodal_type = NA,   label = NA,   param_set = NA,   given = NA,   statement = NA,   join_by = \"|\",   param_names = NA )  get_priors(model, nodes = NULL)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/prior_setting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Setting priors ‚Äî prior_setting","text":"model model object generated make_model(). alphas Real positive numbers giving hyperparameters Dirichlet distribution distribution string indicating common prior distribution (uniform, jeffreys certainty) alter_at string specifying filtering operations applied parameters_df, yielding logical vector indicating parameters values altered. (see examples) node string indicating nodes altered nodal_type string. Label nodal type indicating nodal types values altered label string. Label nodal type indicating nodal types values altered. Equivalent nodal_type. param_set string indicating  name set parameters altered given string indicates node parameter altered depends statement causal query determines nodal types values altered join_by string specifying logical operator joining expanded types statement contains wildcards. Can take values '&' (logical ) '|' (logical ). param_names vector strings. name specific parameter form , example, 'X.1', 'Y.01' nodes vector nodes","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/prior_setting.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Setting priors ‚Äî prior_setting","text":"vector indicating parameters prior distribution   nodal types (\"hyperparameters\"). object class causal_model. essentially returns   list containing elements comprising model   (e.g. 'statement', 'nodal_types' 'DAG') `priors` attached   . vector indicating hyperparameters prior distribution   nodal types.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/prior_setting.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Setting priors ‚Äî prior_setting","text":"Seven arguments govern parameters altered. default '' can reduced specifying * alter_at String specifying filtering operations applied   parameters_df, yielding logical vector indicating parameters   values altered. \"node == 'X' & nodal_type * node, restricts example parameters associated node   'X' * label nodal_type label particular nodal type,   written either form Y0000 Y.Y0000 * param_set param_set parameter. * given Given parameter set parameter. * statement, restricts example nodal types satisfy   statement 'Y[X=1] > Y[X=0]' * param_set, given, useful setting confound   statements produce several sets parameters Two arguments govern values apply: * alphas one non-negative numbers * distribution indicates one common class: uniform, Jeffreys,   'certain' Forbidden statements include: Setting distribution values time. Setting distribution uniform, Jeffreys,     certainty. Setting negative values. specifying alter_at node,     nodal_type, param_set, given, statement,     param_names specifying param_names node,     nodal_type, param_set, given, statement,     alter_at specifying statement node     nodal_type","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/prior_setting.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Setting priors ‚Äî prior_setting","text":"","code":"# make_priors examples:  # Pass all nodal types model <- make_model(\"Y <- X\") make_priors(model, alphas = .4) #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #>  0.4  0.4  0.4  0.4  0.4  0.4  make_priors(model, distribution = \"jeffreys\") #> Altering all parameters. #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #>  0.5  0.5  0.5  0.5  0.5  0.5   model <- CausalQueries::make_model(\"X -> M -> Y; X <-> Y\")  #altering values using \\code{alter_at} make_priors(model = model, alphas = c(0.5,0.25), alter_at = \"node == 'Y' & nodal_type %in% c('00','01') & given == 'X.0'\") #>      X.0      X.1     M.00     M.10     M.01     M.11 Y.00_X.0 Y.10_X.0  #>     1.00     1.00     1.00     1.00     1.00     1.00     0.50     1.00  #> Y.01_X.0 Y.11_X.0 Y.00_X.1 Y.10_X.1 Y.01_X.1 Y.11_X.1  #>     0.25     1.00     1.00     1.00     1.00     1.00   #altering values using \\code{param_names} make_priors(model = model, alphas = c(0.5,0.25), param_names = c(\"Y.10_X.0\",\"Y.10_X.1\")) #>      X.0      X.1     M.00     M.10     M.01     M.11 Y.00_X.0 Y.10_X.0  #>     1.00     1.00     1.00     1.00     1.00     1.00     1.00     0.50  #> Y.01_X.0 Y.11_X.0 Y.00_X.1 Y.10_X.1 Y.01_X.1 Y.11_X.1  #>     1.00     1.00     1.00     0.25     1.00     1.00   #altering values using \\code{statement} make_priors(model = model, alphas = c(0.5,0.25), statement = \"Y[M=1] > Y[M=0]\") #> Warning: Possible ambiguity: use additional arguments or check behavior in parameters_df. #>      X.0      X.1     M.00     M.10     M.01     M.11 Y.00_X.0 Y.10_X.0  #>     1.00     1.00     1.00     1.00     1.00     1.00     1.00     1.00  #> Y.01_X.0 Y.11_X.0 Y.00_X.1 Y.10_X.1 Y.01_X.1 Y.11_X.1  #>     0.50     1.00     1.00     1.00     0.25     1.00   #altering values using a combination of other arguments make_priors(model = model, alphas = c(0.5,0.25), node = \"Y\", nodal_type = c(\"00\",\"01\"), given = \"X.0\") #>      X.0      X.1     M.00     M.10     M.01     M.11 Y.00_X.0 Y.10_X.0  #>     1.00     1.00     1.00     1.00     1.00     1.00     0.50     1.00  #> Y.01_X.0 Y.11_X.0 Y.00_X.1 Y.10_X.1 Y.01_X.1 Y.11_X.1  #>     0.25     1.00     1.00     1.00     1.00     1.00   # set_priors examples:  # Pass all nodal types model <- make_model(\"Y <- X\") set_priors(model, alphas = .4) #>  #> Causal statement:  #> X -> Y #>  #> Number of nodal types by node: #> X Y  #> 2 4  #>  #> Number of causal types: 8 set_priors(model, distribution = \"jeffreys\") #> Altering all parameters. #>  #> Causal statement:  #> X -> Y #>  #> Number of nodal types by node: #> X Y  #> 2 4  #>  #> Number of causal types: 8  model <- CausalQueries::make_model(\"X -> M -> Y; X <-> Y\")  #altering values using \\code{alter_at} set_priors(model = model, alphas = c(0.5,0.25), alter_at = \"node == 'Y' & nodal_type %in% c('00','01') & given == 'X.0'\") #>  #> Causal statement:  #> M -> Y; X -> M; X <-> Y #>  #> Number of nodal types by node: #> X M Y  #> 2 4 4  #>  #> Number of causal types: 32  #altering values using \\code{param_names} set_priors(model = model, alphas = c(0.5,0.25), param_names = c(\"Y.10_X.0\",\"Y.10_X.1\")) #>  #> Causal statement:  #> M -> Y; X -> M; X <-> Y #>  #> Number of nodal types by node: #> X M Y  #> 2 4 4  #>  #> Number of causal types: 32  #altering values using \\code{statement} set_priors(model = model, alphas = c(0.5,0.25), statement = \"Y[M=1] > Y[M=0]\") #> Warning: Possible ambiguity: use additional arguments or check behavior in parameters_df. #>  #> Causal statement:  #> M -> Y; X -> M; X <-> Y #>  #> Number of nodal types by node: #> X M Y  #> 2 4 4  #>  #> Number of causal types: 32  #altering values using a combination of other arguments set_priors(model = model, alphas = c(0.5,0.25), node = \"Y\", nodal_type = c(\"00\",\"01\"), given = \"X.0\") #>  #> Causal statement:  #> M -> Y; X -> M; X <-> Y #>  #> Number of nodal types by node: #> X M Y  #> 2 4 4  #>  #> Number of causal types: 32"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/queries_to_types.html","id":null,"dir":"Reference","previous_headings":"","what":"helper to get types from queries ‚Äî queries_to_types","title":"helper to get types from queries ‚Äî queries_to_types","text":"helper get types queries","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/queries_to_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"helper to get types from queries ‚Äî queries_to_types","text":"","code":"queries_to_types(jobs, model, query_col, realisations)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/queries_to_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"helper to get types from queries ‚Äî queries_to_types","text":"jobs data frame argument combinations model list models query_col string specifying name column jobs holding queries evaluated realisations list data frame outputs calls realise_outcomes","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/queries_to_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"helper to get types from queries ‚Äî queries_to_types","text":"jobs data frame nested column   map_query_to_nodal_type outputs","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/query_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate query distribution ‚Äî query_distribution","title":"Calculate query distribution ‚Äî query_distribution","text":"Calculated distribution query prior posterior distribution parameters","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/query_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate query distribution ‚Äî query_distribution","text":"","code":"query_distribution(   model,   queries = NULL,   given = NULL,   using = \"parameters\",   parameters = NULL,   n_draws = 4000,   join_by = \"|\",   case_level = FALSE,   query = NULL )"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/query_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate query distribution ‚Äî query_distribution","text":"model causal_model. model object generated make_model. queries vector strings list strings specifying queries potential outcomes \"Y[X=1] - Y[X=0]\". Queries can also indicate conditioning sets placing second queries colon: \"Y[X=1] - Y[X=0] : X == 1 & Y == 1\". Note colon, ':' used rather traditional conditioning marker '|' avoid confusion logical operators. given character vector specifying given conditions query. 'given' quoted expression evaluates logical statement. given allows query conditioned either observed counterfactural distributions. value TRUE interpreted conditioning. given statement can alternatively provided colon query statement. using character. Whether use priors, posteriors parameters parameters vector list vectors real numbers [0,1]. true parameter vector used instead parameters attached model case  using specifies parameters n_draws integer. Number draws.rm join_by character. logical operator joining expanded types query contains wildcard (.). Can take values \"&\" (logical ) \"|\" (logical ). restriction contains wildcard (.) join_by specified, defaults \"|\", otherwise defaults NULL. case_level Logical. TRUE estimates probability query case. query alias queries","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/query_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate query distribution ‚Äî query_distribution","text":"data frame columns contain draws distribution   potential outcomes specified query","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/query_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate query distribution ‚Äî query_distribution","text":"","code":"model <- make_model(\"X -> Y\") |>          set_parameters(c(.5, .5, .1, .2, .3, .4))  # \\donttest{  # simple  queries  query_distribution(model, query = \"(Y[X=1] > Y[X=0])\", using = \"priors\") |>    head() #>   (Y[X=1] > Y[X=0]) #> 1        0.03526002 #> 2        0.41611720 #> 3        0.02047593 #> 4        0.29217581 #> 5        0.31917748 #> 6        0.11378919   # multiple  queries  query_distribution(model,      query = list(PE = \"(Y[X=1] > Y[X=0])\", NE = \"(Y[X=1] < Y[X=0])\"),      using = \"priors\")|>    head() #>            PE          NE #> 1 0.312957263 0.008955461 #> 2 0.003650971 0.879498649 #> 3 0.640273317 0.284740516 #> 4 0.037841815 0.006646958 #> 5 0.077452915 0.466764656 #> 6 0.553717338 0.137227128   # multiple queries and givens, with ':' to identify conditioning distributions  query_distribution(model,    query = list(POC = \"(Y[X=1] > Y[X=0]) : X == 1 & Y == 1\",                 Q = \"(Y[X=1] < Y[X=0]) : (Y[X=1] <= Y[X=0])\"),    using = \"priors\")|>    head() #>          POC         Q #> 1 0.97096826 0.3976348 #> 2 0.56078001 0.1285707 #> 3 0.01965798 0.1921490 #> 4 0.16753670 0.1278787 #> 5 0.13147501 0.6443660 #> 6 0.30626861 0.5511230   # multiple queries and givens, using 'given' argument  query_distribution(model,    query = list(\"(Y[X=1] > Y[X=0])\", \"(Y[X=1] < Y[X=0])\"),    given = list(\"Y==1\", \"(Y[X=1] <= Y[X=0])\"),    using = \"priors\")|>    head() #>   (Y[X=1] > Y[X=0]) : Y==1 (Y[X=1] < Y[X=0]) : (Y[X=1] <= Y[X=0]) #> 1               0.10616708                             0.02339975 #> 2               0.30902547                             0.21086177 #> 3               0.01068651                             0.71508330 #> 4               0.16555480                             0.29437477 #> 5               0.27081796                             0.07719978 #> 6               0.03556959                             0.20782996   # linear queries  query_distribution(model, query = \"(Y[X=1] - Y[X=0])\") #>   (Y[X=1] - Y[X=0]) #> 1               0.1    # Linear query conditional on potential outcomes  query_distribution(model, query = \"(Y[X=1] - Y[X=0]) : Y[X=1]==0\") #>   (Y[X=1] - Y[X=0]) : Y[X=1]==0 #> 1                    -0.6666667   # Use join_by to amend query interpretation  query_distribution(model, query = \"(Y[X=.] == 1)\", join_by = \"&\") #> Generated expanded expression: #> (Y[X=0] == 1 | Y[X=1] == 1) #>   (Y[X=.] == 1) #> 1           0.9   # Probability of causation query  query_distribution(model,     query = \"(Y[X=1] > Y[X=0])\",     given = \"X==1 & Y==1\",     using = \"priors\")  |> head() #>   (Y[X=1] > Y[X=0]) : X==1 & Y==1 #> 1                       0.1416616 #> 2                       0.5731357 #> 3                       0.1078356 #> 4                       0.7793219 #> 5                       0.1340290 #> 6                       0.8277877   # Case level probability of causation query  query_distribution(model,     query = \"(Y[X=1] > Y[X=0])\",     given = \"X==1 & Y==1\",     case_level = TRUE,     using = \"priors\") #>   (Y[X=1] > Y[X=0]) : X==1 & Y==1 #> 1                       0.4918965   # Query posterior  update_model(model, make_data(model, n = 3)) |>  query_distribution(query = \"(Y[X=1] - Y[X=0])\", using = \"posteriors\") |>  head() #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.14 seconds (Warm-up) #> Chain 1:                0.174 seconds (Sampling) #> Chain 1:                0.314 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1.7e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.129 seconds (Warm-up) #> Chain 2:                0.127 seconds (Sampling) #> Chain 2:                0.256 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 1.6e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.129 seconds (Warm-up) #> Chain 3:                0.163 seconds (Sampling) #> Chain 3:                0.292 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 1.6e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.132 seconds (Warm-up) #> Chain 4:                0.134 seconds (Sampling) #> Chain 4:                0.266 seconds (Total) #> Chain 4:  #>   (Y[X=1] - Y[X=0]) #> 1         0.2213036 #> 2        -0.1498878 #> 3        -0.0241682 #> 4         0.2389134 #> 5        -0.3239749 #> 6         0.2436667   # Case level queries provide the inference for a case, which is a scalar  # The case level query *updates* on the given information  # For instance, here we have a model for which we are quite sure that X  # causes Y but we do not know whether it works through two positive effects  # or two negative effects. Thus we do not know if M=0 would suggest an  # effect or no effect   set.seed(1)  model <-    make_model(\"X -> M -> Y\") |>    update_model(data.frame(X = rep(0:1, 8), Y = rep(0:1, 8)), iter = 10000) #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.9e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.29 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 10000 [  0%]  (Warmup) #> Chain 1: Iteration: 1000 / 10000 [ 10%]  (Warmup) #> Chain 1: Iteration: 2000 / 10000 [ 20%]  (Warmup) #> Chain 1: Iteration: 3000 / 10000 [ 30%]  (Warmup) #> Chain 1: Iteration: 4000 / 10000 [ 40%]  (Warmup) #> Chain 1: Iteration: 5000 / 10000 [ 50%]  (Warmup) #> Chain 1: Iteration: 5001 / 10000 [ 50%]  (Sampling) #> Chain 1: Iteration: 6000 / 10000 [ 60%]  (Sampling) #> Chain 1: Iteration: 7000 / 10000 [ 70%]  (Sampling) #> Chain 1: Iteration: 8000 / 10000 [ 80%]  (Sampling) #> Chain 1: Iteration: 9000 / 10000 [ 90%]  (Sampling) #> Chain 1: Iteration: 10000 / 10000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 1.407 seconds (Warm-up) #> Chain 1:                1.582 seconds (Sampling) #> Chain 1:                2.989 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 2.4e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.24 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 10000 [  0%]  (Warmup) #> Chain 2: Iteration: 1000 / 10000 [ 10%]  (Warmup) #> Chain 2: Iteration: 2000 / 10000 [ 20%]  (Warmup) #> Chain 2: Iteration: 3000 / 10000 [ 30%]  (Warmup) #> Chain 2: Iteration: 4000 / 10000 [ 40%]  (Warmup) #> Chain 2: Iteration: 5000 / 10000 [ 50%]  (Warmup) #> Chain 2: Iteration: 5001 / 10000 [ 50%]  (Sampling) #> Chain 2: Iteration: 6000 / 10000 [ 60%]  (Sampling) #> Chain 2: Iteration: 7000 / 10000 [ 70%]  (Sampling) #> Chain 2: Iteration: 8000 / 10000 [ 80%]  (Sampling) #> Chain 2: Iteration: 9000 / 10000 [ 90%]  (Sampling) #> Chain 2: Iteration: 10000 / 10000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 1.389 seconds (Warm-up) #> Chain 2:                1.435 seconds (Sampling) #> Chain 2:                2.824 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 3.1e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.31 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 10000 [  0%]  (Warmup) #> Chain 3: Iteration: 1000 / 10000 [ 10%]  (Warmup) #> Chain 3: Iteration: 2000 / 10000 [ 20%]  (Warmup) #> Chain 3: Iteration: 3000 / 10000 [ 30%]  (Warmup) #> Chain 3: Iteration: 4000 / 10000 [ 40%]  (Warmup) #> Chain 3: Iteration: 5000 / 10000 [ 50%]  (Warmup) #> Chain 3: Iteration: 5001 / 10000 [ 50%]  (Sampling) #> Chain 3: Iteration: 6000 / 10000 [ 60%]  (Sampling) #> Chain 3: Iteration: 7000 / 10000 [ 70%]  (Sampling) #> Chain 3: Iteration: 8000 / 10000 [ 80%]  (Sampling) #> Chain 3: Iteration: 9000 / 10000 [ 90%]  (Sampling) #> Chain 3: Iteration: 10000 / 10000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 1.61 seconds (Warm-up) #> Chain 3:                1.416 seconds (Sampling) #> Chain 3:                3.026 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 2.3e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 10000 [  0%]  (Warmup) #> Chain 4: Iteration: 1000 / 10000 [ 10%]  (Warmup) #> Chain 4: Iteration: 2000 / 10000 [ 20%]  (Warmup) #> Chain 4: Iteration: 3000 / 10000 [ 30%]  (Warmup) #> Chain 4: Iteration: 4000 / 10000 [ 40%]  (Warmup) #> Chain 4: Iteration: 5000 / 10000 [ 50%]  (Warmup) #> Chain 4: Iteration: 5001 / 10000 [ 50%]  (Sampling) #> Chain 4: Iteration: 6000 / 10000 [ 60%]  (Sampling) #> Chain 4: Iteration: 7000 / 10000 [ 70%]  (Sampling) #> Chain 4: Iteration: 8000 / 10000 [ 80%]  (Sampling) #> Chain 4: Iteration: 9000 / 10000 [ 90%]  (Sampling) #> Chain 4: Iteration: 10000 / 10000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 1.432 seconds (Warm-up) #> Chain 4:                2.198 seconds (Sampling) #> Chain 4:                3.63 seconds (Total) #> Chain 4:    Q <- \"Y[X=1] > Y[X=0]\"  G <- \"X==1 & Y==1 & M==1\"  QG <- \"(Y[X=1] > Y[X=0]) & (X==1 & Y==1 & M==1)\"   # In this case these are very different:  query_distribution(model, Q, given = G, using = \"posteriors\")[[1]] |> mean() #> [1] 0.4238768  query_distribution(model, Q, given = G, using = \"posteriors\",    case_level = TRUE) #>   Y[X=1] > Y[X=0] : X==1 & Y==1 & M==1 #> 1                            0.6715179   # These are equivalent:  # 1. Case level query via function  query_distribution(model, Q, given = G,     using = \"posteriors\", case_level = TRUE) #>   Y[X=1] > Y[X=0] : X==1 & Y==1 & M==1 #> 1                            0.6715179   # 2. Case level query by hand using Bayes' rule  query_distribution(      model,      list(QG = QG, G = G),      using = \"posteriors\") |>     dplyr::summarize(mean(QG)/mean(G)) #>   mean(QG)/mean(G) #> 1        0.6715179  # }"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/query_helpers.html","id":null,"dir":"Reference","previous_headings":"","what":"Query helpers ‚Äî query_helpers","title":"Query helpers ‚Äî query_helpers","text":"Various helpers describe queries parts queries natural language. Generate statement Y monotonic (increasing) X Generate statement Y weakly monotonic (increasing) X Generate statement Y monotonic (decreasing) X Generate statement Y weakly monotonic (increasing) X Generate statement X1, X1 interact production Y Generate statement X1, X1 complement production Y Generate statement X1, X1 substitute production Y Generate statement (Y(1) - Y(0)). statement applied model returns element (1,0,-1) set cases. useful purposes querying model, uses require list types, set_restrictions.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/query_helpers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query helpers ‚Äî query_helpers","text":"","code":"increasing(X, Y)  non_decreasing(X, Y)  decreasing(X, Y)  non_increasing(X, Y)  interacts(X1, X2, Y)  complements(X1, X2, Y)  substitutes(X1, X2, Y)  te(X, Y)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/query_helpers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query helpers ‚Äî query_helpers","text":"X character. quoted name input node Y character. quoted name outcome node X1 character. quoted name input node 1. X2 character. quoted name input node 2.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/query_helpers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query helpers ‚Äî query_helpers","text":"character statement class statement character statement class statement character statement class statement character statement class statement character statement class statement character statement class statement character statement class statement character statement class statement","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/query_helpers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query helpers ‚Äî query_helpers","text":"","code":"# \\donttest{ increasing('A', 'B') #> [1] \"(B[A=1] > B[A=0])\" # } # \\donttest{ non_decreasing('A', 'B') #> [1] \"(B[A=1] >= B[A=0])\" # } # \\donttest{ decreasing('A', 'B') #> [1] \"(B[A=1] < B[A=0])\" # } # \\donttest{ non_increasing('A', 'B') #> [1] \"(B[A=1] <= B[A=0])\" # } # \\donttest{ interacts('A', 'B', 'W') #> [1] \"((W[A =1, B = 1]) - (W[A = 0, B = 1])) != ((W[A =1, B = 0]) - (W[A = 0, B = 0]))\" get_query_types(model = make_model('X-> Y <- W'),          query = interacts('X', 'W', 'Y'), map = \"causal_type\") #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  ((Y[X=1,W=1])-(Y[X=0,W=1]))!=((Y[X=1,W=0])-(Y[X=0,W=0]))  #>  #> W0.X0.Y1000  W1.X0.Y1000 #> W0.X1.Y1000  W1.X1.Y1000 #> W0.X0.Y0100  W1.X0.Y0100 #> W0.X1.Y0100  W1.X1.Y0100 #> W0.X0.Y0010  W1.X0.Y0010 #> W0.X1.Y0010  W1.X1.Y0010 #> W0.X0.Y0110  W1.X0.Y0110 #> W0.X1.Y0110  W1.X1.Y0110 #> W0.X0.Y1110  W1.X0.Y1110 #> W0.X1.Y1110  W1.X1.Y1110 #> W0.X0.Y0001  W1.X0.Y0001 #> W0.X1.Y0001  W1.X1.Y0001 #> W0.X0.Y1001  W1.X0.Y1001 #> W0.X1.Y1001  W1.X1.Y1001 #> W0.X0.Y1101  W1.X0.Y1101 #> W0.X1.Y1101  W1.X1.Y1101 #> W0.X0.Y1011  W1.X0.Y1011 #> W0.X1.Y1011  W1.X1.Y1011 #> W0.X0.Y0111  W1.X0.Y0111 #> W0.X1.Y0111  W1.X1.Y0111 #>  #>  #>  Number of causal types that meet condition(s) =  40 #>  Total number of causal types in model =  64 # } # \\donttest{ complements('A', 'B', 'W') #> [1] \"((W[A =1, B = 1]) - (W[A = 0, B = 1])) > ((W[A =1, B = 0]) - (W[A = 0, B = 0]))\" # } # \\donttest{ get_query_types(model = make_model('A -> B <- C'),          query = substitutes('A', 'C', 'B'),map = \"causal_type\") #>  #> Causal types satisfying query's condition(s)   #>  #>  query =  ((B[A=1,C=1])-(B[A=0,C=1]))<((B[A=1,C=0])-(B[A=0,C=0]))  #>  #> A0.C0.B0100  A1.C0.B0100 #> A0.C1.B0100  A1.C1.B0100 #> A0.C0.B0010  A1.C0.B0010 #> A0.C1.B0010  A1.C1.B0010 #> A0.C0.B0110  A1.C0.B0110 #> A0.C1.B0110  A1.C1.B0110 #> A0.C0.B1110  A1.C0.B1110 #> A0.C1.B1110  A1.C1.B1110 #> A0.C0.B0111  A1.C0.B0111 #> A0.C1.B0111  A1.C1.B0111 #>  #>  #>  Number of causal types that meet condition(s) =  20 #>  Total number of causal types in model =  64  query_model(model = make_model('A -> B <- C'),          queries = substitutes('A', 'C', 'B'),          using = 'parameters') #>  #> Causal queries generated by query_model (all at population level) #>  #> |query                                                                             |using      |  mean| #> |:---------------------------------------------------------------------------------|:----------|-----:| #> |((B[A = 1, C = 1]) - (B[A = 0, C = 1])) < ((B[A = 1, C = 0]) - (B[A = 0, C = 0])) |parameters | 0.312| #>  # } # \\donttest{ te('A', 'B') #> [1] \"(B[A=1] - B[A=0])\"  model <- make_model('X->Y') |> set_restrictions(increasing('X', 'Y')) query_model(model, list(ate = te('X', 'Y')),  using = 'parameters') #>  #> Causal queries generated by query_model (all at population level) #>  #> |label |query             |using      |   mean| #> |:-----|:-----------------|:----------|------:| #> |ate   |(Y[X=1] - Y[X=0]) |parameters | -0.333| #>   # set_restrictions  breaks with te because it requires a listing # of causal types, not numeric output. # } if (FALSE) { # \\dontrun{ model <- make_model('X->Y') |> set_restrictions(te('X', 'Y')) } # }"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/query_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate data frame for batches of causal queries ‚Äî query_model","title":"Generate data frame for batches of causal queries ‚Äî query_model","text":"Calculated parameter vector, prior posterior distribution.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/query_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate data frame for batches of causal queries ‚Äî query_model","text":"","code":"query_model(   model,   queries = NULL,   given = NULL,   using = list(\"parameters\"),   parameters = NULL,   stats = NULL,   n_draws = 4000,   expand_grid = NULL,   case_level = FALSE,   query = NULL,   cred = 95,   labels = NULL )"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/query_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate data frame for batches of causal queries ‚Äî query_model","text":"model causal_model. model object generated make_model. queries vector strings list strings specifying queries potential outcomes \"Y[X=1] - Y[X=0]\". Queries can also indicate conditioning sets placing second queries colon: \"Y[X=1] - Y[X=0] : X == 1 & Y == 1\". Note colon, ':' used rather traditional conditioning marker '|' avoid confusion logical operators. given character vector specifying given conditions query. 'given' quoted expression evaluates logical statement. given allows query conditioned either observed counterfactural distributions. value TRUE interpreted conditioning. given statement can alternatively provided colon query statement. using vector list strings. Whether use priors, posteriors parameters. parameters vector real numbers [0,1]. Values parameters specify (optional). default, parameters drawn parameters dataframe. See inspect(model, \"parameters_df\"). stats Functions applied query distribution. NULL, defaults mean, standard deviation, 95% confidence interval. Functions return single numeric value. n_draws integer. Number draws. expand_grid Logical. TRUE combinations provided lists examined. list cycled separately. Defaults FALSE. case_level Logical. TRUE estimates probability query case. query alias queries cred size credible interval ranging 0 100 labels labels queries: provided labels length combinations requests","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/query_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate data frame for batches of causal queries ‚Äî query_model","text":"data frame columns Model, Query, Given Using   defined corresponding input values. columns generated   specified stats.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/query_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate data frame for batches of causal queries ‚Äî query_model","text":"Queries can condition observed counterfactual quantities. Nested \"complex\" counterfactual queries form Y[X=1, M[X=0]] allowed.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/query_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate data frame for batches of causal queries ‚Äî query_model","text":"","code":"model <- make_model(\"X -> Y\") query_model(model, \"Y[X=1] - Y[X = 0]\", using = \"priors\") #>  #> Causal queries generated by query_model (all at population level) #>  #> |query             |using  |   mean|   sd| cred.low| cred.high| #> |:-----------------|:------|------:|----:|--------:|---------:| #> |Y[X=1] - Y[X = 0] |priors | -0.004| 0.32|   -0.653|      0.63| #>  query_model(model, \"Y[X=1] - Y[X = 0] : X==1 & Y==1\", using = \"priors\") #>  #> Causal queries generated by query_model (all at population level) #>  #> |label                           |using  | mean|    sd| cred.low| cred.high| #> |:-------------------------------|:------|----:|-----:|--------:|---------:| #> |Y[X=1] - Y[X = 0] : X==1 & Y==1 |priors | 0.49| 0.288|    0.025|     0.972| #>  query_model(model,   list(\"Y[X=1] - Y[X = 0]\",        \"Y[X=1] - Y[X = 0] : X==1 & Y==1\"),   using = \"priors\") #>  #> Causal queries generated by query_model (all at population level) #>  #> |label                           |query             |given       |using  |  mean|    sd| cred.low| cred.high| #> |:-------------------------------|:-----------------|:-----------|:------|-----:|-----:|--------:|---------:| #> |Y[X=1] - Y[X = 0]               |Y[X=1] - Y[X = 0] |-           |priors | 0.003| 0.318|   -0.641|     0.639| #> |Y[X=1] - Y[X = 0] : X==1 & Y==1 |Y[X=1] - Y[X = 0] |X==1 & Y==1 |priors | 0.495| 0.291|    0.024|     0.976| #>  query_model(model, \"Y[X=1] > Y[X = 0]\", using = \"parameters\") #>  #> Causal queries generated by query_model (all at population level) #>  #> |query             |using      | mean| #> |:-----------------|:----------|----:| #> |Y[X=1] > Y[X = 0] |parameters | 0.25| #>  query_model(model, \"Y[X=1] > Y[X = 0]\", using = c(\"priors\", \"parameters\")) #>  #> Causal queries generated by query_model (all at population level) #>  #> |query             |using      |  mean|    sd| cred.low| cred.high| #> |:-----------------|:----------|-----:|-----:|--------:|---------:| #> |Y[X=1] > Y[X = 0] |priors     | 0.249| 0.193|    0.009|     0.708| #> |Y[X=1] > Y[X = 0] |parameters | 0.250|    NA|    0.250|     0.250| #>  # \\donttest{  # `expand_grid= TRUE` requests the Cartesian product of arguments  models <- list(  M1 = make_model(\"X -> Y\"),  M2 = make_model(\"X -> Y\") |>    set_restrictions(\"Y[X=1] < Y[X=0]\")  )  # No expansion: lists should be equal length query_model(   models,   query = list(ATE = \"Y[X=1] - Y[X=0]\",                Share_positive = \"Y[X=1] > Y[X=0]\"),   given = c(TRUE,  \"Y==1 & X==1\"),   using = c(\"parameters\", \"priors\"),   expand_grid = FALSE) #>  #> Causal queries generated by query_model (all at population level) #>  #> |label          |model |query           |given       |using      |  mean|    sd| cred.low| cred.high| #> |:--------------|:-----|:---------------|:-----------|:----------|-----:|-----:|--------:|---------:| #> |ATE            |M1    |Y[X=1] - Y[X=0] |-           |parameters | 0.000|    NA|    0.000|     0.000| #> |Share_positive |M1    |Y[X=1] > Y[X=0] |Y==1 & X==1 |priors     | 0.501| 0.290|    0.026|     0.974| #> |ATE            |M2    |Y[X=1] - Y[X=0] |-           |parameters | 0.333|    NA|    0.333|     0.333| #> |Share_positive |M2    |Y[X=1] > Y[X=0] |Y==1 & X==1 |priors     | 0.504| 0.291|    0.026|     0.979| #>   # Expansion when query and given arguments coupled query_model(   models,   query = list(ATE = \"Y[X=1] - Y[X=0]\",                Share_positive = \"Y[X=1] > Y[X=0] : Y==1 & X==1\"),   using = c(\"parameters\", \"priors\"),   expand_grid = TRUE) #>  #> Causal queries generated by query_model (all at population level) #>  #> |label          |model |query           |given       |using      |   mean|    sd| cred.low| cred.high| #> |:--------------|:-----|:---------------|:-----------|:----------|------:|-----:|--------:|---------:| #> |ATE            |M1    |Y[X=1] - Y[X=0] |-           |parameters |  0.000|    NA|    0.000|     0.000| #> |ATE            |M2    |Y[X=1] - Y[X=0] |-           |parameters |  0.333|    NA|    0.333|     0.333| #> |ATE            |M1    |Y[X=1] - Y[X=0] |-           |priors     | -0.005| 0.320|   -0.643|     0.657| #> |ATE            |M2    |Y[X=1] - Y[X=0] |-           |priors     |  0.333| 0.236|    0.012|     0.849| #> |Share_positive |M1    |Y[X=1] > Y[X=0] |Y==1 & X==1 |parameters |  0.500|    NA|    0.500|     0.500| #> |Share_positive |M2    |Y[X=1] > Y[X=0] |Y==1 & X==1 |parameters |  0.500|    NA|    0.500|     0.500| #> |Share_positive |M1    |Y[X=1] > Y[X=0] |Y==1 & X==1 |priors     |  0.499| 0.289|    0.027|     0.972| #> |Share_positive |M2    |Y[X=1] > Y[X=0] |Y==1 & X==1 |priors     |  0.501| 0.288|    0.024|     0.974| #>   # Expands over query and given argument when these are not coupled query_model(   models,   query = list(ATE = \"Y[X=1] - Y[X=0]\",                Share_positive = \"Y[X=1] > Y[X=0]\"),   given = c(TRUE,  \"Y==1 & X==1\"),   using = c(\"parameters\", \"priors\"),   expand_grid = TRUE) #>  #> Causal queries generated by query_model (all at population level) #>  #> |label          |model |query           |given       |using      |  mean|    sd| cred.low| cred.high| #> |:--------------|:-----|:---------------|:-----------|:----------|-----:|-----:|--------:|---------:| #> |ATE            |M1    |Y[X=1] - Y[X=0] |-           |parameters | 0.000|    NA|    0.000|     0.000| #> |ATE            |M2    |Y[X=1] - Y[X=0] |-           |parameters | 0.333|    NA|    0.333|     0.333| #> |ATE            |M1    |Y[X=1] - Y[X=0] |-           |priors     | 0.001| 0.319|   -0.640|     0.627| #> |ATE            |M2    |Y[X=1] - Y[X=0] |-           |priors     | 0.335| 0.235|    0.014|     0.831| #> |ATE            |M1    |Y[X=1] - Y[X=0] |Y==1 & X==1 |parameters | 0.500|    NA|    0.500|     0.500| #> |ATE            |M2    |Y[X=1] - Y[X=0] |Y==1 & X==1 |parameters | 0.500|    NA|    0.500|     0.500| #> |ATE            |M1    |Y[X=1] - Y[X=0] |Y==1 & X==1 |priors     | 0.497| 0.288|    0.027|     0.971| #> |ATE            |M2    |Y[X=1] - Y[X=0] |Y==1 & X==1 |priors     | 0.503| 0.287|    0.026|     0.973| #> |Share_positive |M1    |Y[X=1] > Y[X=0] |-           |parameters | 0.250|    NA|    0.250|     0.250| #> |Share_positive |M2    |Y[X=1] > Y[X=0] |-           |parameters | 0.333|    NA|    0.333|     0.333| #> |Share_positive |M1    |Y[X=1] > Y[X=0] |-           |priors     | 0.248| 0.193|    0.009|     0.705| #> |Share_positive |M2    |Y[X=1] > Y[X=0] |-           |priors     | 0.335| 0.235|    0.014|     0.831| #> |Share_positive |M1    |Y[X=1] > Y[X=0] |Y==1 & X==1 |parameters | 0.500|    NA|    0.500|     0.500| #> |Share_positive |M2    |Y[X=1] > Y[X=0] |Y==1 & X==1 |parameters | 0.500|    NA|    0.500|     0.500| #> |Share_positive |M1    |Y[X=1] > Y[X=0] |Y==1 & X==1 |priors     | 0.497| 0.288|    0.027|     0.971| #> |Share_positive |M2    |Y[X=1] > Y[X=0] |Y==1 & X==1 |priors     | 0.503| 0.287|    0.026|     0.973| #>   # An example of a custom statistic: uncertainty of token causation f <- function(x) mean(x)*(1-mean(x))  query_model(   model,   using = list( \"parameters\", \"priors\"),   query = \"Y[X=1] > Y[X=0]\",   stats = c(mean = mean, sd = sd, token_variance = f)) #>  #> Causal queries generated by query_model (all at population level) #>  #> |query           |using      |  mean|    sd| token_variance| #> |:---------------|:----------|-----:|-----:|--------------:| #> |Y[X=1] > Y[X=0] |parameters | 0.250|    NA|          0.188| #> |Y[X=1] > Y[X=0] |priors     | 0.247| 0.194|          0.186| #>  # }"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/query_to_expression.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper to turn query into a data expression ‚Äî query_to_expression","title":"Helper to turn query into a data expression ‚Äî query_to_expression","text":"Helper turn query data expression","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/query_to_expression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper to turn query into a data expression ‚Äî query_to_expression","text":"","code":"query_to_expression(query, node)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/query_to_expression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper to turn query into a data expression ‚Äî query_to_expression","text":"query character string. expression defining nodal types interrogate. expression form \"Y[X=1]\" asks value Y X set 1 node character string. quoted name node.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/query_to_expression.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper to turn query into a data expression ‚Äî query_to_expression","text":"cleaned query expression","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/realise_outcomes.html","id":null,"dir":"Reference","previous_headings":"","what":"Realise outcomes ‚Äî realise_outcomes","title":"Realise outcomes ‚Äî realise_outcomes","text":"Realise outcomes causal types. Calculated sequentially calculating endogenous nodes. operator applied node takes given value descendants generated accordingly.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/realise_outcomes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Realise outcomes ‚Äî realise_outcomes","text":"","code":"realise_outcomes(model, dos = NULL, node = NULL, add_rownames = TRUE)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/realise_outcomes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Realise outcomes ‚Äî realise_outcomes","text":"model causal_model. model object generated make_model. dos named list. actions defining node values, e.g., list(X = 0, M = 1). node character. optional quoted name node whose outcome revealed. specified values parents need specified via dos. add_rownames logical indicating whether add causal types rownames output","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/realise_outcomes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Realise outcomes ‚Äî realise_outcomes","text":"data.frame object revealed data node (columns)   given causal / nodal type (rows).","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/realise_outcomes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Realise outcomes ‚Äî realise_outcomes","text":"node specified outcomes realised possible causal types consistent model. node specified outcomes Y returned conditional different values parents, whether values parents obtain given restrictions model. realise_outcomes starts creating types   (via get_nodal_types). takes types endogenous   reveals outcome based value parents took.   Exogenous nodes outcomes correspond type.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/realise_outcomes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Realise outcomes ‚Äî realise_outcomes","text":"","code":"# \\donttest{ make_model(\"X -> Y\") |>   realise_outcomes() #>      X Y #> 0.00 0 0 #> 1.00 1 0 #> 0.10 0 1 #> 1.10 1 0 #> 0.01 0 0 #> 1.01 1 1 #> 0.11 0 1 #> 1.11 1 1  make_model(\"X -> Y <- W\") |> set_restrictions(labels = list(X = \"1\", Y=\"0010\"),                  keep = TRUE) |>  realise_outcomes() #>          W X Y #> 0.1.0010 0 1 1 #> 1.1.0010 1 1 0  make_model(\"X1->Y; X2->M; M->Y\") |> realise_outcomes(dos = list(X1 = 1, M = 0)) #>             X1 X2 M Y #> 0.0.00.0000  1  0 0 0 #> 1.0.00.0000  1  0 0 0 #> 0.1.00.0000  1  1 0 0 #> 1.1.00.0000  1  1 0 0 #> 0.0.10.0000  1  0 0 0 #> 1.0.10.0000  1  0 0 0 #> 0.1.10.0000  1  1 0 0 #> 1.1.10.0000  1  1 0 0 #> 0.0.01.0000  1  0 0 0 #> 1.0.01.0000  1  0 0 0 #> 0.1.01.0000  1  1 0 0 #> 1.1.01.0000  1  1 0 0 #> 0.0.11.0000  1  0 0 0 #> 1.0.11.0000  1  0 0 0 #> 0.1.11.0000  1  1 0 0 #> 1.1.11.0000  1  1 0 0 #> 0.0.00.1000  1  0 0 0 #> 1.0.00.1000  1  0 0 0 #> 0.1.00.1000  1  1 0 0 #> 1.1.00.1000  1  1 0 0 #> 0.0.10.1000  1  0 0 0 #> 1.0.10.1000  1  0 0 0 #> 0.1.10.1000  1  1 0 0 #> 1.1.10.1000  1  1 0 0 #> 0.0.01.1000  1  0 0 0 #> 1.0.01.1000  1  0 0 0 #> 0.1.01.1000  1  1 0 0 #> 1.1.01.1000  1  1 0 0 #> 0.0.11.1000  1  0 0 0 #> 1.0.11.1000  1  0 0 0 #> 0.1.11.1000  1  1 0 0 #> 1.1.11.1000  1  1 0 0 #> 0.0.00.0100  1  0 0 1 #> 1.0.00.0100  1  0 0 1 #> 0.1.00.0100  1  1 0 1 #> 1.1.00.0100  1  1 0 1 #> 0.0.10.0100  1  0 0 1 #> 1.0.10.0100  1  0 0 1 #> 0.1.10.0100  1  1 0 1 #> 1.1.10.0100  1  1 0 1 #> 0.0.01.0100  1  0 0 1 #> 1.0.01.0100  1  0 0 1 #> 0.1.01.0100  1  1 0 1 #> 1.1.01.0100  1  1 0 1 #> 0.0.11.0100  1  0 0 1 #> 1.0.11.0100  1  0 0 1 #> 0.1.11.0100  1  1 0 1 #> 1.1.11.0100  1  1 0 1 #> 0.0.00.1100  1  0 0 1 #> 1.0.00.1100  1  0 0 1 #> 0.1.00.1100  1  1 0 1 #> 1.1.00.1100  1  1 0 1 #> 0.0.10.1100  1  0 0 1 #> 1.0.10.1100  1  0 0 1 #> 0.1.10.1100  1  1 0 1 #> 1.1.10.1100  1  1 0 1 #> 0.0.01.1100  1  0 0 1 #> 1.0.01.1100  1  0 0 1 #> 0.1.01.1100  1  1 0 1 #> 1.1.01.1100  1  1 0 1 #> 0.0.11.1100  1  0 0 1 #> 1.0.11.1100  1  0 0 1 #> 0.1.11.1100  1  1 0 1 #> 1.1.11.1100  1  1 0 1 #> 0.0.00.0010  1  0 0 0 #> 1.0.00.0010  1  0 0 0 #> 0.1.00.0010  1  1 0 0 #> 1.1.00.0010  1  1 0 0 #> 0.0.10.0010  1  0 0 0 #> 1.0.10.0010  1  0 0 0 #> 0.1.10.0010  1  1 0 0 #> 1.1.10.0010  1  1 0 0 #> 0.0.01.0010  1  0 0 0 #> 1.0.01.0010  1  0 0 0 #> 0.1.01.0010  1  1 0 0 #> 1.1.01.0010  1  1 0 0 #> 0.0.11.0010  1  0 0 0 #> 1.0.11.0010  1  0 0 0 #> 0.1.11.0010  1  1 0 0 #> 1.1.11.0010  1  1 0 0 #> 0.0.00.1010  1  0 0 0 #> 1.0.00.1010  1  0 0 0 #> 0.1.00.1010  1  1 0 0 #> 1.1.00.1010  1  1 0 0 #> 0.0.10.1010  1  0 0 0 #> 1.0.10.1010  1  0 0 0 #> 0.1.10.1010  1  1 0 0 #> 1.1.10.1010  1  1 0 0 #> 0.0.01.1010  1  0 0 0 #> 1.0.01.1010  1  0 0 0 #> 0.1.01.1010  1  1 0 0 #> 1.1.01.1010  1  1 0 0 #> 0.0.11.1010  1  0 0 0 #> 1.0.11.1010  1  0 0 0 #> 0.1.11.1010  1  1 0 0 #> 1.1.11.1010  1  1 0 0 #> 0.0.00.0110  1  0 0 1 #> 1.0.00.0110  1  0 0 1 #> 0.1.00.0110  1  1 0 1 #> 1.1.00.0110  1  1 0 1 #> 0.0.10.0110  1  0 0 1 #> 1.0.10.0110  1  0 0 1 #> 0.1.10.0110  1  1 0 1 #> 1.1.10.0110  1  1 0 1 #> 0.0.01.0110  1  0 0 1 #> 1.0.01.0110  1  0 0 1 #> 0.1.01.0110  1  1 0 1 #> 1.1.01.0110  1  1 0 1 #> 0.0.11.0110  1  0 0 1 #> 1.0.11.0110  1  0 0 1 #> 0.1.11.0110  1  1 0 1 #> 1.1.11.0110  1  1 0 1 #> 0.0.00.1110  1  0 0 1 #> 1.0.00.1110  1  0 0 1 #> 0.1.00.1110  1  1 0 1 #> 1.1.00.1110  1  1 0 1 #> 0.0.10.1110  1  0 0 1 #> 1.0.10.1110  1  0 0 1 #> 0.1.10.1110  1  1 0 1 #> 1.1.10.1110  1  1 0 1 #> 0.0.01.1110  1  0 0 1 #> 1.0.01.1110  1  0 0 1 #> 0.1.01.1110  1  1 0 1 #> 1.1.01.1110  1  1 0 1 #> 0.0.11.1110  1  0 0 1 #> 1.0.11.1110  1  0 0 1 #> 0.1.11.1110  1  1 0 1 #> 1.1.11.1110  1  1 0 1 #> 0.0.00.0001  1  0 0 0 #> 1.0.00.0001  1  0 0 0 #> 0.1.00.0001  1  1 0 0 #> 1.1.00.0001  1  1 0 0 #> 0.0.10.0001  1  0 0 0 #> 1.0.10.0001  1  0 0 0 #> 0.1.10.0001  1  1 0 0 #> 1.1.10.0001  1  1 0 0 #> 0.0.01.0001  1  0 0 0 #> 1.0.01.0001  1  0 0 0 #> 0.1.01.0001  1  1 0 0 #> 1.1.01.0001  1  1 0 0 #> 0.0.11.0001  1  0 0 0 #> 1.0.11.0001  1  0 0 0 #> 0.1.11.0001  1  1 0 0 #> 1.1.11.0001  1  1 0 0 #> 0.0.00.1001  1  0 0 0 #> 1.0.00.1001  1  0 0 0 #> 0.1.00.1001  1  1 0 0 #> 1.1.00.1001  1  1 0 0 #> 0.0.10.1001  1  0 0 0 #> 1.0.10.1001  1  0 0 0 #> 0.1.10.1001  1  1 0 0 #> 1.1.10.1001  1  1 0 0 #> 0.0.01.1001  1  0 0 0 #> 1.0.01.1001  1  0 0 0 #> 0.1.01.1001  1  1 0 0 #> 1.1.01.1001  1  1 0 0 #> 0.0.11.1001  1  0 0 0 #> 1.0.11.1001  1  0 0 0 #> 0.1.11.1001  1  1 0 0 #> 1.1.11.1001  1  1 0 0 #> 0.0.00.0101  1  0 0 1 #> 1.0.00.0101  1  0 0 1 #> 0.1.00.0101  1  1 0 1 #> 1.1.00.0101  1  1 0 1 #> 0.0.10.0101  1  0 0 1 #> 1.0.10.0101  1  0 0 1 #> 0.1.10.0101  1  1 0 1 #> 1.1.10.0101  1  1 0 1 #> 0.0.01.0101  1  0 0 1 #> 1.0.01.0101  1  0 0 1 #> 0.1.01.0101  1  1 0 1 #> 1.1.01.0101  1  1 0 1 #> 0.0.11.0101  1  0 0 1 #> 1.0.11.0101  1  0 0 1 #> 0.1.11.0101  1  1 0 1 #> 1.1.11.0101  1  1 0 1 #> 0.0.00.1101  1  0 0 1 #> 1.0.00.1101  1  0 0 1 #> 0.1.00.1101  1  1 0 1 #> 1.1.00.1101  1  1 0 1 #> 0.0.10.1101  1  0 0 1 #> 1.0.10.1101  1  0 0 1 #> 0.1.10.1101  1  1 0 1 #> 1.1.10.1101  1  1 0 1 #> 0.0.01.1101  1  0 0 1 #> 1.0.01.1101  1  0 0 1 #> 0.1.01.1101  1  1 0 1 #> 1.1.01.1101  1  1 0 1 #> 0.0.11.1101  1  0 0 1 #> 1.0.11.1101  1  0 0 1 #> 0.1.11.1101  1  1 0 1 #> 1.1.11.1101  1  1 0 1 #> 0.0.00.0011  1  0 0 0 #> 1.0.00.0011  1  0 0 0 #> 0.1.00.0011  1  1 0 0 #> 1.1.00.0011  1  1 0 0 #> 0.0.10.0011  1  0 0 0 #> 1.0.10.0011  1  0 0 0 #> 0.1.10.0011  1  1 0 0 #> 1.1.10.0011  1  1 0 0 #> 0.0.01.0011  1  0 0 0 #> 1.0.01.0011  1  0 0 0 #> 0.1.01.0011  1  1 0 0 #> 1.1.01.0011  1  1 0 0 #> 0.0.11.0011  1  0 0 0 #> 1.0.11.0011  1  0 0 0 #> 0.1.11.0011  1  1 0 0 #> 1.1.11.0011  1  1 0 0 #> 0.0.00.1011  1  0 0 0 #> 1.0.00.1011  1  0 0 0 #> 0.1.00.1011  1  1 0 0 #> 1.1.00.1011  1  1 0 0 #> 0.0.10.1011  1  0 0 0 #> 1.0.10.1011  1  0 0 0 #> 0.1.10.1011  1  1 0 0 #> 1.1.10.1011  1  1 0 0 #> 0.0.01.1011  1  0 0 0 #> 1.0.01.1011  1  0 0 0 #> 0.1.01.1011  1  1 0 0 #> 1.1.01.1011  1  1 0 0 #> 0.0.11.1011  1  0 0 0 #> 1.0.11.1011  1  0 0 0 #> 0.1.11.1011  1  1 0 0 #> 1.1.11.1011  1  1 0 0 #> 0.0.00.0111  1  0 0 1 #> 1.0.00.0111  1  0 0 1 #> 0.1.00.0111  1  1 0 1 #> 1.1.00.0111  1  1 0 1 #> 0.0.10.0111  1  0 0 1 #> 1.0.10.0111  1  0 0 1 #> 0.1.10.0111  1  1 0 1 #> 1.1.10.0111  1  1 0 1 #> 0.0.01.0111  1  0 0 1 #> 1.0.01.0111  1  0 0 1 #> 0.1.01.0111  1  1 0 1 #> 1.1.01.0111  1  1 0 1 #> 0.0.11.0111  1  0 0 1 #> 1.0.11.0111  1  0 0 1 #> 0.1.11.0111  1  1 0 1 #> 1.1.11.0111  1  1 0 1 #> 0.0.00.1111  1  0 0 1 #> 1.0.00.1111  1  0 0 1 #> 0.1.00.1111  1  1 0 1 #> 1.1.00.1111  1  1 0 1 #> 0.0.10.1111  1  0 0 1 #> 1.0.10.1111  1  0 0 1 #> 0.1.10.1111  1  1 0 1 #> 1.1.10.1111  1  1 0 1 #> 0.0.01.1111  1  0 0 1 #> 1.0.01.1111  1  0 0 1 #> 0.1.01.1111  1  1 0 1 #> 1.1.01.1111  1  1 0 1 #> 0.0.11.1111  1  0 0 1 #> 1.0.11.1111  1  0 0 1 #> 0.1.11.1111  1  1 0 1 #> 1.1.11.1111  1  1 0 1  # With node specified make_model(\"X->M->Y\") |> realise_outcomes(node = \"Y\") #>      M Y #> 0.00 0 0 #> 1.00 1 0 #> 0.10 0 1 #> 1.10 1 0 #> 0.01 0 0 #> 1.01 1 1 #> 0.11 0 1 #> 1.11 1 1  make_model(\"X->M->Y\") |> realise_outcomes(dos = list(M = 1), node = \"Y\") #>      M Y #> 1.00 1 0 #> 1.10 1 0 #> 1.01 1 1 #> 1.11 1 1 # }"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/reveal_outcomes.html","id":null,"dir":"Reference","previous_headings":"","what":"Reveal outcomes ‚Äî reveal_outcomes","title":"Reveal outcomes ‚Äî reveal_outcomes","text":"`r lifecycle::badge(\"deprecated\")` function deprecated name causes clashes DeclareDesign. Use realise_outcomes instead.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/reveal_outcomes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reveal outcomes ‚Äî reveal_outcomes","text":"","code":"reveal_outcomes(model, dos = NULL, node = NULL)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_ambiguities_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Set ambiguity matrix ‚Äî set_ambiguities_matrix","title":"Set ambiguity matrix ‚Äî set_ambiguities_matrix","text":"Add ambiguities matrix model","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_ambiguities_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set ambiguity matrix ‚Äî set_ambiguities_matrix","text":"","code":"set_ambiguities_matrix(model, A = NULL)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_ambiguities_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set ambiguity matrix ‚Äî set_ambiguities_matrix","text":"model causal_model. model object generated make_model. data.frame. Ambiguities matrix. required may provided avoid repeated computation simulations. inspect(model, \"ambiguities_matrix\")","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_ambiguities_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set ambiguity matrix ‚Äî set_ambiguities_matrix","text":"object type causal_model   ambiguities matrix attached","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_confound.html","id":null,"dir":"Reference","previous_headings":"","what":"Set confound ‚Äî set_confound","title":"Set confound ‚Äî set_confound","text":"Adjust parameter matrix allow confounding.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_confound.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set confound ‚Äî set_confound","text":"","code":"set_confound(model, confound = NULL)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_confound.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set confound ‚Äî set_confound","text":"model causal_model. model object generated make_model. confound list statements indicating pairs nodes whose types jointly distributed (e.g. list(\"<-> B\", \"C <-> D\")).","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_confound.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set confound ‚Äî set_confound","text":"object class causal_model updated parameters_df   parameter matrix.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_confound.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set confound ‚Äî set_confound","text":"Confounding X Y arises nodal types X Y independently distributed. X -> Y graph, instance, 2 nodal types X 4 Y. thus 8 joint nodal types: table 8 interior elements unconstrained joint distribution 7 degrees freedom. confounding assumption means Pr(t^X | t^Y) = Pr(t^X),  Pr(t^X, t^Y) = Pr(t^X)Pr(t^Y). case 3 degrees freedom Y 1 X, totaling 4 rather 7. set_confound lets relax assumption increasing number parameters characterizing joint distribution. Using fact P(,B) = P()P(B|) new parameters introduced capture P(B|=) rather simply P(B). instance two parameters (one degree freedom) govern distribution types X  four parameters (3 degrees freedom) govern  types Y given type X total 1+3+3 = 7 degrees freedom.","code":"|          | t^X                |                    |           | |-----|----|--------------------|--------------------|-----------| |     |    | 0                  | 1                  | Sum       | |-----|----|--------------------|--------------------|-----------| | t^Y | 00 | Pr(t^X=0 & t^Y=00) | Pr(t^X=1 & t^Y=00) | Pr(t^Y=00)| |     | 10 | .                  | .                  | .         | |     | 01 | .                  | .                  | .         | |     | 11 | .                  | .                  | .         | |-----|----|--------------------|--------------------|-----------| |     |Sum | Pr(t^X=0)          | Pr(t^X=1)          | 1         |"},{"path":[]},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_confound.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set confound ‚Äî set_confound","text":"","code":"make_model('X -> Y; X <-> Y') |> inspect(\"parameters\") #>  #> parameters #> Model parameters with associated probabilities:  #>  #>      X.0      X.1 Y.00_X.0 Y.10_X.0 Y.01_X.0 Y.11_X.0 Y.00_X.1 Y.10_X.1  #>     0.50     0.50     0.25     0.25     0.25     0.25     0.25     0.25  #> Y.01_X.1 Y.11_X.1  #>     0.25     0.25   make_model('X -> M -> Y; X <-> Y') |> inspect(\"parameters\") #>  #> parameters #> Model parameters with associated probabilities:  #>  #>      X.0      X.1     M.00     M.10     M.01     M.11 Y.00_X.0 Y.10_X.0  #>     0.50     0.50     0.25     0.25     0.25     0.25     0.25     0.25  #> Y.01_X.0 Y.11_X.0 Y.00_X.1 Y.10_X.1 Y.01_X.1 Y.11_X.1  #>     0.25     0.25     0.25     0.25     0.25     0.25   model <- make_model('X -> M -> Y; X <-> Y; M <-> Y') inspect(model, \"parameters_df\") #>  #> parameters_df #> Mapping of model parameters to nodal types:  #>  #>   param_names: name of parameter #>   node:        name of endogeneous node associated #>                with the parameter #>   gen:         partial causal ordering of the #>                parameter's node #>   param_set:   parameter groupings forming a simplex #>   given:       if model has confounding gives #>                conditioning nodal type #>   param_value: parameter values #>   priors:      hyperparameters of the prior #>                Dirichlet distribution  #>  #>  #> snippet (use grab() to access full 38 x 8 object):  #>  #>      param_names node gen  param_set nodal_type     given param_value priors #> 1            X.0    X   1          X          0                  0.50      1 #> 2            X.1    X   1          X          1                  0.50      1 #> 3           M.00    M   2          M         00                  0.25      1 #> 4           M.10    M   2          M         10                  0.25      1 #> 5           M.01    M   2          M         01                  0.25      1 #> 6           M.11    M   2          M         11                  0.25      1 #> 7  Y.00_M.00_X.0    Y   3 Y.M.00.X.0         00 M.00, X.0        0.25      1 #> 8  Y.10_M.00_X.0    Y   3 Y.M.00.X.0         10 M.00, X.0        0.25      1 #> 9  Y.01_M.00_X.0    Y   3 Y.M.00.X.0         01 M.00, X.0        0.25      1 #> 10 Y.11_M.00_X.0    Y   3 Y.M.00.X.0         11 M.00, X.0        0.25      1  # Example where set_confound is implemented after restrictions make_model(\"A -> B -> C\") |> set_restrictions(increasing(\"A\", \"B\")) |> set_confound(\"B <-> C\") |> inspect(\"parameters\") #>  #> parameters #> Model parameters with associated probabilities:  #>  #>       A.0       A.1      B.00      B.10      B.11 C.00_B.00 C.10_B.00 C.01_B.00  #> 0.5000000 0.5000000 0.3333333 0.3333333 0.3333333 0.2500000 0.2500000 0.2500000  #> C.11_B.00 C.00_B.10 C.10_B.10 C.01_B.10 C.11_B.10 C.00_B.11 C.10_B.11 C.01_B.11  #> 0.2500000 0.2500000 0.2500000 0.2500000 0.2500000 0.2500000 0.2500000 0.2500000  #> C.11_B.11  #> 0.2500000   # Example where two parents are confounded make_model('A -> B <- C; A <-> C') |>   set_parameters(node = \"C\", c(0.05, .95, .95, 0.05)) |>   make_data(n = 50) |>   cor() #> Warning: Possible ambiguity: use additional arguments or check behavior in parameters_df. #>             A           C           B #> A  1.00000000 -0.95431352 -0.06189845 #> C -0.95431352  1.00000000  0.02432316 #> B -0.06189845  0.02432316  1.00000000   # Example with two confounds, added sequentially model <- make_model('A -> B -> C') |>   set_confound(list(\"A <-> B\", \"B <-> C\")) inspect(model, \"statement\") #>  #> Causal statement:  #> A -> B; B -> C; B <-> A; C <-> B # plot(model)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_parameter_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Set parameter matrix ‚Äî set_parameter_matrix","title":"Set parameter matrix ‚Äî set_parameter_matrix","text":"Add parameter matrix model","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_parameter_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set parameter matrix ‚Äî set_parameter_matrix","text":"","code":"set_parameter_matrix(model, P = NULL)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_parameter_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set parameter matrix ‚Äî set_parameter_matrix","text":"model causal_model. model object generated make_model. P data.frame. Parameter matrix. required may provided avoid repeated computation simulations. See inspect(model, \"parameter_matrix\").","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_parameter_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set parameter matrix ‚Äî set_parameter_matrix","text":"object class causal_model. essentially returns   list containing elements comprising model   (e.g. 'statement', 'nodal_types' 'DAG') parameter matrix   attached .","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_parameter_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set parameter matrix ‚Äî set_parameter_matrix","text":"","code":"model <- make_model('X -> Y') P <- diag(8) colnames(P) <- inspect(model, \"causal_types\") |> rownames() #>  #> causal_types (Causal Types) #>  #> Cartesian product of nodal types #>        X  Y #> X0.Y00 0 00 #> X1.Y00 1 00 #> X0.Y10 0 10 #> X1.Y10 1 10 #> X0.Y01 0 01 #> X1.Y01 1 01 #> X0.Y11 0 11 #> X1.Y11 1 11 model <- set_parameter_matrix(model, P = P)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_prior_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Add prior distribution draws ‚Äî set_prior_distribution","title":"Add prior distribution draws ‚Äî set_prior_distribution","text":"Add `n_param x n_draws` database possible parameter draws model.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_prior_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add prior distribution draws ‚Äî set_prior_distribution","text":"","code":"set_prior_distribution(model, n_draws = 4000)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_prior_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add prior distribution draws ‚Äî set_prior_distribution","text":"model causal_model. model object generated make_model. n_draws scalar. Number draws.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_prior_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add prior distribution draws ‚Äî set_prior_distribution","text":"object class causal_model `prior_distribution`   attached .","code":""},{"path":[]},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_prior_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add prior distribution draws ‚Äî set_prior_distribution","text":"","code":"make_model('X -> Y') |>   set_prior_distribution(n_draws = 5) |>   inspect(\"prior_distribution\") #>  #> prior_distribution #> Summary statistics of model parameters prior distributions: #>  #>   Distributions matrix dimensions are  #>   5 rows (draws) by 6 cols (parameters) #>  #>      mean   sd #> X.0  0.35 0.30 #> X.1  0.65 0.30 #> Y.00 0.27 0.30 #> Y.10 0.17 0.07 #> Y.01 0.21 0.14 #> Y.11 0.35 0.21"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_restrictions.html","id":null,"dir":"Reference","previous_headings":"","what":"Restrict a model ‚Äî set_restrictions","title":"Restrict a model ‚Äî set_restrictions","text":"Restrict model's parameter space. reduces number nodal types consequence number unit causal types.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_restrictions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Restrict a model ‚Äî set_restrictions","text":"","code":"set_restrictions(   model,   statement = NULL,   join_by = \"|\",   labels = NULL,   param_names = NULL,   given = NULL,   keep = FALSE )"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_restrictions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Restrict a model ‚Äî set_restrictions","text":"model causal_model. model object generated make_model. statement quoted expressions defining restriction. values parents specified, statements surrounded parentheses, instance (Y[= 1] > Y[=0]) interpreted combinations parents Y set possible levels might take. join_by string. logical operator joining expanded types statement contains wildcard (.). Can take values '&' (logical ) '|' (logical ). restriction contains wildcard (.) join_by specified, defaults '|', otherwise defaults NULL. Note join_by joins within statements, across statements. labels list character vectors specifying nodal types kept removed model. Use get_nodal_types see syntax. Note labels gets overwritten statement statement NULL. param_names character vector names parameters restrict . given character vector list character vectors specifying nodes parameter set restricted depends. restricting statement, given must either NULL length statement. mixing statements restricted given ones , statements without given restrictions given specified one NULL, NA, \"\" \" \". keep Logical. `FALSE`, removes `TRUE` keeps causal types specified statement labels.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_restrictions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Restrict a model ‚Äî set_restrictions","text":"object class model. causal types nodal types   model reduced according stated restriction.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_restrictions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Restrict a model ‚Äî set_restrictions","text":"Restrictions made nodal types, unit causal types. Thus instance model X -> M -> Y, one apply simple restriction Y nondecreasing  X, however one can restrict M nondecreasing X Y nondecreasing M. restriction Y nondecreasing X otherwise require restrictions causal types, nodal types, implies form undeclared confounding (.e. cases M decreasing X, Y decreasing M). Since restrictions nodal types, parents node implicitly fixed.  Thus model make_model(`X -> Y <- W`) request set_restrictions(`(Y[X=1] == 0)`) interpreted set_restrictions(`(Y[X=1, W=0] == 0 | Y[X=1, W=1] == 0)`). Statements implicitly controlled nodes surrounded parentheses, examples. Note prior probabilities redistributed remaining types.","code":""},{"path":[]},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/set_restrictions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Restrict a model ‚Äî set_restrictions","text":"","code":"# 1. Restrict parameter space using statements model <- make_model('X->Y') |>   set_restrictions(statement = c('X[] == 0'))  model <- make_model('X->Y') |>   set_restrictions(non_increasing('X', 'Y'))  model <- make_model('X -> Y <- W') |>   set_restrictions(c(decreasing('X', 'Y'), substitutes('X', 'W', 'Y')))  inspect(model, \"parameters_df\") #>  #> parameters_df #> Mapping of model parameters to nodal types:  #>  #>   param_names: name of parameter #>   node:        name of endogeneous node associated #>                with the parameter #>   gen:         partial causal ordering of the #>                parameter's node #>   param_set:   parameter groupings forming a simplex #>   given:       if model has confounding gives #>                conditioning nodal type #>   param_value: parameter values #>   priors:      hyperparameters of the prior #>                Dirichlet distribution  #>  #>  #> snippet (use grab() to access full 11 x 8 object):  #>  #>    param_names node gen param_set nodal_type given param_value priors #> 1          W.0    W   1         W          0         0.5000000      1 #> 2          W.1    W   1         W          1         0.5000000      1 #> 3          X.0    X   2         X          0         0.5000000      1 #> 4          X.1    X   2         X          1         0.5000000      1 #> 5       Y.0000    Y   3         Y       0000         0.1428571      1 #> 10      Y.1010    Y   3         Y       1010         0.1428571      1 #> 13      Y.0001    Y   3         Y       0001         0.1428571      1 #> 15      Y.0101    Y   3         Y       0101         0.1428571      1 #> 17      Y.0011    Y   3         Y       0011         0.1428571      1 #> 18      Y.1011    Y   3         Y       1011         0.1428571      1  model <- make_model('X-> Y <- W') |>   set_restrictions(statement = decreasing('X', 'Y')) inspect(model, \"parameters_df\") #>  #> parameters_df #> Mapping of model parameters to nodal types:  #>  #>   param_names: name of parameter #>   node:        name of endogeneous node associated #>                with the parameter #>   gen:         partial causal ordering of the #>                parameter's node #>   param_set:   parameter groupings forming a simplex #>   given:       if model has confounding gives #>                conditioning nodal type #>   param_value: parameter values #>   priors:      hyperparameters of the prior #>                Dirichlet distribution  #>  #>  #> snippet (use grab() to access full 13 x 8 object):  #>  #>    param_names node gen param_set nodal_type given param_value priors #> 1          W.0    W   1         W          0         0.5000000      1 #> 2          W.1    W   1         W          1         0.5000000      1 #> 3          X.0    X   2         X          0         0.5000000      1 #> 4          X.1    X   2         X          1         0.5000000      1 #> 5       Y.0000    Y   3         Y       0000         0.1111111      1 #> 9       Y.0010    Y   3         Y       0010         0.1111111      1 #> 10      Y.1010    Y   3         Y       1010         0.1111111      1 #> 13      Y.0001    Y   3         Y       0001         0.1111111      1 #> 15      Y.0101    Y   3         Y       0101         0.1111111      1 #> 17      Y.0011    Y   3         Y       0011         0.1111111      1  model <- make_model('X->Y') |>   set_restrictions(decreasing('X', 'Y')) inspect(model, \"parameters_df\") #>  #> parameters_df #> Mapping of model parameters to nodal types:  #>  #>   param_names: name of parameter #>   node:        name of endogeneous node associated #>                with the parameter #>   gen:         partial causal ordering of the #>                parameter's node #>   param_set:   parameter groupings forming a simplex #>   given:       if model has confounding gives #>                conditioning nodal type #>   param_value: parameter values #>   priors:      hyperparameters of the prior #>                Dirichlet distribution  #>  #>   param_names node gen param_set nodal_type given param_value priors #> 1         X.0    X   1         X          0         0.5000000      1 #> 2         X.1    X   1         X          1         0.5000000      1 #> 3        Y.00    Y   2         Y         00         0.3333333      1 #> 5        Y.01    Y   2         Y         01         0.3333333      1 #> 6        Y.11    Y   2         Y         11         0.3333333      1  model <- make_model('X->Y') |>   set_restrictions(c(increasing('X', 'Y'), decreasing('X', 'Y'))) inspect(model, \"parameters_df\") #>  #> parameters_df #> Mapping of model parameters to nodal types:  #>  #>   param_names: name of parameter #>   node:        name of endogeneous node associated #>                with the parameter #>   gen:         partial causal ordering of the #>                parameter's node #>   param_set:   parameter groupings forming a simplex #>   given:       if model has confounding gives #>                conditioning nodal type #>   param_value: parameter values #>   priors:      hyperparameters of the prior #>                Dirichlet distribution  #>  #>   param_names node gen param_set nodal_type given param_value priors #> 1         X.0    X   1         X          0               0.5      1 #> 2         X.1    X   1         X          1               0.5      1 #> 3        Y.00    Y   2         Y         00               0.5      1 #> 6        Y.11    Y   2         Y         11               0.5      1 # \\donttest{ # Restrict to define a model with monotonicity model <- make_model('X->Y') |> set_restrictions(statement = c('Y[X=1] < Y[X=0]')) inspect(model, \"parameter_matrix\") #>  #> parameter_matrix: #>  #>   rows:   parameters #>   cols:   causal types #>   cells:  whether a parameter probability is used #>           in the calculation of causal type probability #>  #>      X0.Y00 X1.Y00 X0.Y01 X1.Y01 X0.Y11 X1.Y11 #> X.0       1      0      1      0      1      0 #> X.1       0      1      0      1      0      1 #> Y.00      1      1      0      0      0      0 #> Y.01      0      0      1      1      0      0 #> Y.11      0      0      0      0      1      1  # Restrict to a single type in endogenous node model <- make_model('X->Y') |> set_restrictions(statement =  '(Y[X = 1] == 1)', join_by = '&', keep = TRUE) inspect(model, \"parameter_matrix\") #>  #> parameter_matrix: #>  #>   rows:   parameters #>   cols:   causal types #>   cells:  whether a parameter probability is used #>           in the calculation of causal type probability #>  #>      X0.Y01 X1.Y01 X0.Y11 X1.Y11 #> X.0       1      0      1      0 #> X.1       0      1      0      1 #> Y.01      1      1      0      0 #> Y.11      0      0      1      1  #  Use of | and & # Keep node if *for some value of B* Y[A = 1] == 1 model <- make_model('A->Y<-B') |> set_restrictions(statement =  '(Y[A = 1] == 1)', join_by = '|', keep = TRUE) dim(inspect(model ,\"parameter_matrix\")) #>  #> parameter_matrix: #>  #>   rows:   parameters #>   cols:   causal types #>   cells:  whether a parameter probability is used #>           in the calculation of causal type probability #>  #>        A0.B0.Y0100 A1.B0.Y0100 A0.B1.Y0100 A1.B1.Y0100 A0.B0.Y1100 A1.B0.Y1100 #> A.0              1           0           1           0           1           0 #> A.1              0           1           0           1           0           1 #> B.0              1           1           0           0           1           1 #> B.1              0           0           1           1           0           0 #> Y.0100           1           1           1           1           0           0 #> Y.1100           0           0           0           0           1           1 #> Y.0110           0           0           0           0           0           0 #> Y.1110           0           0           0           0           0           0 #> Y.0001           0           0           0           0           0           0 #> Y.1001           0           0           0           0           0           0 #> Y.0101           0           0           0           0           0           0 #> Y.1101           0           0           0           0           0           0 #> Y.0011           0           0           0           0           0           0 #> Y.1011           0           0           0           0           0           0 #> Y.0111           0           0           0           0           0           0 #> Y.1111           0           0           0           0           0           0 #>        A0.B1.Y1100 A1.B1.Y1100 A0.B0.Y0110 A1.B0.Y0110 A0.B1.Y0110 A1.B1.Y0110 #> A.0              1           0           1           0           1           0 #> A.1              0           1           0           1           0           1 #> B.0              0           0           1           1           0           0 #> B.1              1           1           0           0           1           1 #> Y.0100           0           0           0           0           0           0 #> Y.1100           1           1           0           0           0           0 #> Y.0110           0           0           1           1           1           1 #> Y.1110           0           0           0           0           0           0 #> Y.0001           0           0           0           0           0           0 #> Y.1001           0           0           0           0           0           0 #> Y.0101           0           0           0           0           0           0 #> Y.1101           0           0           0           0           0           0 #> Y.0011           0           0           0           0           0           0 #> Y.1011           0           0           0           0           0           0 #> Y.0111           0           0           0           0           0           0 #> Y.1111           0           0           0           0           0           0 #>        A0.B0.Y1110 A1.B0.Y1110 A0.B1.Y1110 A1.B1.Y1110 A0.B0.Y0001 A1.B0.Y0001 #> A.0              1           0           1           0           1           0 #> A.1              0           1           0           1           0           1 #> B.0              1           1           0           0           1           1 #> B.1              0           0           1           1           0           0 #> Y.0100           0           0           0           0           0           0 #> Y.1100           0           0           0           0           0           0 #> Y.0110           0           0           0           0           0           0 #> Y.1110           1           1           1           1           0           0 #> Y.0001           0           0           0           0           1           1 #> Y.1001           0           0           0           0           0           0 #> Y.0101           0           0           0           0           0           0 #> Y.1101           0           0           0           0           0           0 #> Y.0011           0           0           0           0           0           0 #> Y.1011           0           0           0           0           0           0 #> Y.0111           0           0           0           0           0           0 #> Y.1111           0           0           0           0           0           0 #>        A0.B1.Y0001 A1.B1.Y0001 A0.B0.Y1001 A1.B0.Y1001 A0.B1.Y1001 A1.B1.Y1001 #> A.0              1           0           1           0           1           0 #> A.1              0           1           0           1           0           1 #> B.0              0           0           1           1           0           0 #> B.1              1           1           0           0           1           1 #> Y.0100           0           0           0           0           0           0 #> Y.1100           0           0           0           0           0           0 #> Y.0110           0           0           0           0           0           0 #> Y.1110           0           0           0           0           0           0 #> Y.0001           1           1           0           0           0           0 #> Y.1001           0           0           1           1           1           1 #> Y.0101           0           0           0           0           0           0 #> Y.1101           0           0           0           0           0           0 #> Y.0011           0           0           0           0           0           0 #> Y.1011           0           0           0           0           0           0 #> Y.0111           0           0           0           0           0           0 #> Y.1111           0           0           0           0           0           0 #>        A0.B0.Y0101 A1.B0.Y0101 A0.B1.Y0101 A1.B1.Y0101 A0.B0.Y1101 A1.B0.Y1101 #> A.0              1           0           1           0           1           0 #> A.1              0           1           0           1           0           1 #> B.0              1           1           0           0           1           1 #> B.1              0           0           1           1           0           0 #> Y.0100           0           0           0           0           0           0 #> Y.1100           0           0           0           0           0           0 #> Y.0110           0           0           0           0           0           0 #> Y.1110           0           0           0           0           0           0 #> Y.0001           0           0           0           0           0           0 #> Y.1001           0           0           0           0           0           0 #> Y.0101           1           1           1           1           0           0 #> Y.1101           0           0           0           0           1           1 #> Y.0011           0           0           0           0           0           0 #> Y.1011           0           0           0           0           0           0 #> Y.0111           0           0           0           0           0           0 #> Y.1111           0           0           0           0           0           0 #>        A0.B1.Y1101 A1.B1.Y1101 A0.B0.Y0011 A1.B0.Y0011 A0.B1.Y0011 A1.B1.Y0011 #> A.0              1           0           1           0           1           0 #> A.1              0           1           0           1           0           1 #> B.0              0           0           1           1           0           0 #> B.1              1           1           0           0           1           1 #> Y.0100           0           0           0           0           0           0 #> Y.1100           0           0           0           0           0           0 #> Y.0110           0           0           0           0           0           0 #> Y.1110           0           0           0           0           0           0 #> Y.0001           0           0           0           0           0           0 #> Y.1001           0           0           0           0           0           0 #> Y.0101           0           0           0           0           0           0 #> Y.1101           1           1           0           0           0           0 #> Y.0011           0           0           1           1           1           1 #> Y.1011           0           0           0           0           0           0 #> Y.0111           0           0           0           0           0           0 #> Y.1111           0           0           0           0           0           0 #>        A0.B0.Y1011 A1.B0.Y1011 A0.B1.Y1011 A1.B1.Y1011 A0.B0.Y0111 A1.B0.Y0111 #> A.0              1           0           1           0           1           0 #> A.1              0           1           0           1           0           1 #> B.0              1           1           0           0           1           1 #> B.1              0           0           1           1           0           0 #> Y.0100           0           0           0           0           0           0 #> Y.1100           0           0           0           0           0           0 #> Y.0110           0           0           0           0           0           0 #> Y.1110           0           0           0           0           0           0 #> Y.0001           0           0           0           0           0           0 #> Y.1001           0           0           0           0           0           0 #> Y.0101           0           0           0           0           0           0 #> Y.1101           0           0           0           0           0           0 #> Y.0011           0           0           0           0           0           0 #> Y.1011           1           1           1           1           0           0 #> Y.0111           0           0           0           0           1           1 #> Y.1111           0           0           0           0           0           0 #>        A0.B1.Y0111 A1.B1.Y0111 A0.B0.Y1111 A1.B0.Y1111 A0.B1.Y1111 A1.B1.Y1111 #> A.0              1           0           1           0           1           0 #> A.1              0           1           0           1           0           1 #> B.0              0           0           1           1           0           0 #> B.1              1           1           0           0           1           1 #> Y.0100           0           0           0           0           0           0 #> Y.1100           0           0           0           0           0           0 #> Y.0110           0           0           0           0           0           0 #> Y.1110           0           0           0           0           0           0 #> Y.0001           0           0           0           0           0           0 #> Y.1001           0           0           0           0           0           0 #> Y.0101           0           0           0           0           0           0 #> Y.1101           0           0           0           0           0           0 #> Y.0011           0           0           0           0           0           0 #> Y.1011           0           0           0           0           0           0 #> Y.0111           1           1           0           0           0           0 #> Y.1111           0           0           1           1           1           1 #> [1] 16 48   # Keep node if *for all values of B* Y[A = 1] == 1 model <- make_model('A->Y<-B') |> set_restrictions(statement =  '(Y[A = 1] == 1)', join_by = '&', keep = TRUE) dim(inspect(model, \"parameter_matrix\")) #>  #> parameter_matrix: #>  #>   rows:   parameters #>   cols:   causal types #>   cells:  whether a parameter probability is used #>           in the calculation of causal type probability #>  #>        A0.B0.Y0101 A1.B0.Y0101 A0.B1.Y0101 A1.B1.Y0101 A0.B0.Y1101 A1.B0.Y1101 #> A.0              1           0           1           0           1           0 #> A.1              0           1           0           1           0           1 #> B.0              1           1           0           0           1           1 #> B.1              0           0           1           1           0           0 #> Y.0101           1           1           1           1           0           0 #> Y.1101           0           0           0           0           1           1 #> Y.0111           0           0           0           0           0           0 #> Y.1111           0           0           0           0           0           0 #>        A0.B1.Y1101 A1.B1.Y1101 A0.B0.Y0111 A1.B0.Y0111 A0.B1.Y0111 A1.B1.Y0111 #> A.0              1           0           1           0           1           0 #> A.1              0           1           0           1           0           1 #> B.0              0           0           1           1           0           0 #> B.1              1           1           0           0           1           1 #> Y.0101           0           0           0           0           0           0 #> Y.1101           1           1           0           0           0           0 #> Y.0111           0           0           1           1           1           1 #> Y.1111           0           0           0           0           0           0 #>        A0.B0.Y1111 A1.B0.Y1111 A0.B1.Y1111 A1.B1.Y1111 #> A.0              1           0           1           0 #> A.1              0           1           0           1 #> B.0              1           1           0           0 #> B.1              0           0           1           1 #> Y.0101           0           0           0           0 #> Y.1101           0           0           0           0 #> Y.0111           0           0           0           0 #> Y.1111           1           1           1           1 #> [1]  8 16  # Restrict multiple nodes model <- make_model('X->Y<-M; X -> M' ) |> set_restrictions(statement =  c('(Y[X = 1] == 1)', '(M[X = 1] == 1)'),                  join_by = '&', keep = TRUE) inspect(model, \"parameter_matrix\") #>  #> parameter_matrix: #>  #>   rows:   parameters #>   cols:   causal types #>   cells:  whether a parameter probability is used #>           in the calculation of causal type probability #>  #>        X0.M01.Y0101 X1.M01.Y0101 X0.M11.Y0101 X1.M11.Y0101 X0.M01.Y1101 #> X.0               1            0            1            0            1 #> X.1               0            1            0            1            0 #> M.01              1            1            0            0            1 #> M.11              0            0            1            1            0 #> Y.0101            1            1            1            1            0 #> Y.1101            0            0            0            0            1 #> Y.0111            0            0            0            0            0 #> Y.1111            0            0            0            0            0 #>        X1.M01.Y1101 X0.M11.Y1101 X1.M11.Y1101 X0.M01.Y0111 X1.M01.Y0111 #> X.0               0            1            0            1            0 #> X.1               1            0            1            0            1 #> M.01              1            0            0            1            1 #> M.11              0            1            1            0            0 #> Y.0101            0            0            0            0            0 #> Y.1101            1            1            1            0            0 #> Y.0111            0            0            0            1            1 #> Y.1111            0            0            0            0            0 #>        X0.M11.Y0111 X1.M11.Y0111 X0.M01.Y1111 X1.M01.Y1111 X0.M11.Y1111 #> X.0               1            0            1            0            1 #> X.1               0            1            0            1            0 #> M.01              0            0            1            1            0 #> M.11              1            1            0            0            1 #> Y.0101            0            0            0            0            0 #> Y.1101            0            0            0            0            0 #> Y.0111            1            1            0            0            0 #> Y.1111            0            0            1            1            1 #>        X1.M11.Y1111 #> X.0               0 #> X.1               1 #> M.01              0 #> M.11              1 #> Y.0101            0 #> Y.1101            0 #> Y.0111            0 #> Y.1111            1  # Restrict using statements and given: model <- make_model(\"X -> Y -> Z; X <-> Z\") |>  set_restrictions(list(decreasing('X','Y'), decreasing('Y','Z')),                   given = c(NA,'X.0')) inspect(model, \"parameter_matrix\") #>  #> parameter_matrix: #>  #>   rows:   parameters #>   cols:   causal types #>   cells:  whether a parameter probability is used #>           in the calculation of causal type probability #>  #>          X0.Y00.Z00 X1.Y00.Z00 X0.Y01.Z00 X1.Y01.Z00 X0.Y11.Z00 X1.Y11.Z00 #> X.0               1          0          1          0          1          0 #> X.1               0          1          0          1          0          1 #> Y.00              1          1          0          0          0          0 #> Y.01              0          0          1          1          0          0 #> Y.11              0          0          0          0          1          1 #> Z.00_X.0          1          0          1          0          1          0 #> Z.01_X.0          0          0          0          0          0          0 #> Z.11_X.0          0          0          0          0          0          0 #> Z.00_X.1          0          1          0          1          0          1 #> Z.10_X.1          0          0          0          0          0          0 #> Z.01_X.1          0          0          0          0          0          0 #> Z.11_X.1          0          0          0          0          0          0 #>          X1.Y00.Z10 X1.Y01.Z10 X1.Y11.Z10 X0.Y00.Z01 X1.Y00.Z01 X0.Y01.Z01 #> X.0               0          0          0          1          0          1 #> X.1               1          1          1          0          1          0 #> Y.00              1          0          0          1          1          0 #> Y.01              0          1          0          0          0          1 #> Y.11              0          0          1          0          0          0 #> Z.00_X.0          0          0          0          0          0          0 #> Z.01_X.0          0          0          0          1          0          1 #> Z.11_X.0          0          0          0          0          0          0 #> Z.00_X.1          0          0          0          0          0          0 #> Z.10_X.1          1          1          1          0          0          0 #> Z.01_X.1          0          0          0          0          1          0 #> Z.11_X.1          0          0          0          0          0          0 #>          X1.Y01.Z01 X0.Y11.Z01 X1.Y11.Z01 X0.Y00.Z11 X1.Y00.Z11 X0.Y01.Z11 #> X.0               0          1          0          1          0          1 #> X.1               1          0          1          0          1          0 #> Y.00              0          0          0          1          1          0 #> Y.01              1          0          0          0          0          1 #> Y.11              0          1          1          0          0          0 #> Z.00_X.0          0          0          0          0          0          0 #> Z.01_X.0          0          1          0          0          0          0 #> Z.11_X.0          0          0          0          1          0          1 #> Z.00_X.1          0          0          0          0          0          0 #> Z.10_X.1          0          0          0          0          0          0 #> Z.01_X.1          1          0          1          0          0          0 #> Z.11_X.1          0          0          0          0          1          0 #>          X1.Y01.Z11 X0.Y11.Z11 X1.Y11.Z11 #> X.0               0          1          0 #> X.1               1          0          1 #> Y.00              0          0          0 #> Y.01              1          0          0 #> Y.11              0          1          1 #> Z.00_X.0          0          0          0 #> Z.01_X.0          0          0          0 #> Z.11_X.0          0          1          0 #> Z.00_X.1          0          0          0 #> Z.10_X.1          0          0          0 #> Z.01_X.1          0          0          0 #> Z.11_X.1          1          0          1  # Restrictions on levels for endogenous nodes aren't allowed if (FALSE) { # \\dontrun{ model <- make_model('X->Y') |> set_restrictions(statement =  '(Y == 1)') } # }  # 2. Restrict parameter space Using labels: model <- make_model('X->Y') |> set_restrictions(labels = list(X = '0', Y = '00'))  # Restrictions can be  with wildcards model <- make_model('X->Y') |> set_restrictions(labels = list(Y = '?0')) inspect(model, \"parameter_matrix\") #>  #> parameter_matrix: #>  #>   rows:   parameters #>   cols:   causal types #>   cells:  whether a parameter probability is used #>           in the calculation of causal type probability #>  #>      X0.Y01 X1.Y01 X0.Y11 X1.Y11 #> X.0       1      0      1      0 #> X.1       0      1      0      1 #> Y.01      1      1      0      0 #> Y.11      0      0      1      1  # Deterministic model model <- make_model('S -> C -> Y <- R <- X; X -> C -> R') |> set_restrictions(labels = list(C = '1000', R = '0001', Y = '0001'),                  keep = TRUE) inspect(model, \"parameter_matrix\") #>  #> parameter_matrix: #>  #>   rows:   parameters #>   cols:   causal types #>   cells:  whether a parameter probability is used #>           in the calculation of causal type probability #>  #>        S0.X0.C1000.R0001.Y0001 S1.X0.C1000.R0001.Y0001 S0.X1.C1000.R0001.Y0001 #> S.0                          1                       0                       1 #> S.1                          0                       1                       0 #> X.0                          1                       1                       0 #> X.1                          0                       0                       1 #> C.1000                       1                       1                       1 #> R.0001                       1                       1                       1 #> Y.0001                       1                       1                       1 #>        S1.X1.C1000.R0001.Y0001 #> S.0                          0 #> S.1                          1 #> X.0                          0 #> X.1                          1 #> C.1000                       1 #> R.0001                       1 #> Y.0001                       1  # Restrict using labels and given: model <- make_model(\"X -> Y -> Z; X <-> Z\") |>  set_restrictions(labels = list(X = '0', Z = '00'), given = c(NA,'X.0')) inspect(model, \"parameter_matrix\") #>  #> parameter_matrix: #>  #>   rows:   parameters #>   cols:   causal types #>   cells:  whether a parameter probability is used #>           in the calculation of causal type probability #>  #>          X1.Y00.Z00 X1.Y10.Z00 X1.Y01.Z00 X1.Y11.Z00 X1.Y00.Z10 X1.Y10.Z10 #> X.1               1          1          1          1          1          1 #> Y.00              1          0          0          0          1          0 #> Y.10              0          1          0          0          0          1 #> Y.01              0          0          1          0          0          0 #> Y.11              0          0          0          1          0          0 #> Z.00_X.1          1          1          1          1          0          0 #> Z.10_X.1          0          0          0          0          1          1 #> Z.01_X.1          0          0          0          0          0          0 #> Z.11_X.1          0          0          0          0          0          0 #>          X1.Y01.Z10 X1.Y11.Z10 X1.Y00.Z01 X1.Y10.Z01 X1.Y01.Z01 X1.Y11.Z01 #> X.1               1          1          1          1          1          1 #> Y.00              0          0          1          0          0          0 #> Y.10              0          0          0          1          0          0 #> Y.01              1          0          0          0          1          0 #> Y.11              0          1          0          0          0          1 #> Z.00_X.1          0          0          0          0          0          0 #> Z.10_X.1          1          1          0          0          0          0 #> Z.01_X.1          0          0          1          1          1          1 #> Z.11_X.1          0          0          0          0          0          0 #>          X1.Y00.Z11 X1.Y10.Z11 X1.Y01.Z11 X1.Y11.Z11 #> X.1               1          1          1          1 #> Y.00              1          0          0          0 #> Y.10              0          1          0          0 #> Y.01              0          0          1          0 #> Y.11              0          0          0          1 #> Z.00_X.1          0          0          0          0 #> Z.10_X.1          0          0          0          0 #> Z.01_X.1          0          0          0          0 #> Z.11_X.1          1          1          1          1 # }"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/simulate_data.html","id":null,"dir":"Reference","previous_headings":"","what":"simulate_data is an alias for make_data ‚Äî simulate_data","title":"simulate_data is an alias for make_data ‚Äî simulate_data","text":"simulate_data alias make_data","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/simulate_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"simulate_data is an alias for make_data ‚Äî simulate_data","text":"","code":"simulate_data(...)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/simulate_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"simulate_data is an alias for make_data ‚Äî simulate_data","text":"... arguments make_model","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/simulate_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"simulate_data is an alias for make_data ‚Äî simulate_data","text":"data.frame simulated data.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/simulate_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"simulate_data is an alias for make_data ‚Äî simulate_data","text":"","code":"simulate_data(make_model(\"X->Y\")) #> Error in simulate_data(make_model(\"X->Y\")): could not find function \"simulate_data\""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/snippet.html","id":null,"dir":"Reference","previous_headings":"","what":"helper to print snippets of large objects ‚Äî snippet","title":"helper to print snippets of large objects ‚Äî snippet","text":"helper print snippets large objects","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/snippet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"helper to print snippets of large objects ‚Äî snippet","text":"","code":"snippet(df, nc = 10, nr = 10)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/summary.causal_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing causal models ‚Äî summary.causal_model","title":"Summarizing causal models ‚Äî summary.causal_model","text":"summary method class \"causal_model\".","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/summary.causal_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing causal models ‚Äî summary.causal_model","text":"","code":"# S3 method for class 'causal_model' summary(object, include = NULL, ...)  # S3 method for class 'summary.causal_model' print(x, what = NULL, ...)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/summary.causal_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing causal models ‚Äî summary.causal_model","text":"object object causal_model class produced using make_model update_model. include character string specifying additional objects include summary. Defaults NULL. See details full list available values. ... arguments passed methods. x object summary.causal_model class, produced using summary.causal_model. character string specifying objects summaries print. Defaults NULL printing causal statement, specification nodal types summary model restrictions. See details full list available values.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/summary.causal_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarizing causal models ‚Äî summary.causal_model","text":"Returns object class summary.causal_model preserves list structure causal_model class adds following additional objects: \"parents\" list parents nodes model, \"parameters\" vector 'true' parameters, \"parameter_names\" vector names parameters, \"data_types\" list data  types consistent model; options see \"?get_all_data_types\", \"prior_event_probabilities\" vector prior data (event) probabilities given parameter vector; options see \"?get_event_probabilities\", \"prior_hyperparameters\" vector alpha values used parameterize Dirichlet prior distributions; optionally provide node names reduce output \"inspect(prior_hyperparameters, c('M', 'Y'))\"","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/summary.causal_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarizing causal models ‚Äî summary.causal_model","text":"addition default objects included `summary.causal_model` users can request additional objects via `include` argument. Note additional objects can large complex models can increase computing time. `include` argument can vector following additional objects: \"parameter_matrix\" matrix mapping parameters causal types, \"parameter_mapping\" matrix mapping parameters data types, \"causal_types\" data frame listing causal types nodal types produce , \"prior_distribution\" data frame parameter prior distribution, \"ambiguities_matrix\" matrix mapping causal types data types, \"type_prior\" matrix type probabilities using priors. print.summary.causal_model reports causal statement, full specification nodal types summary model restrictions. specifying `` argument users can instead print custom summary set following objects contained `summary.causal_model`: \"statement\" character string giving causal statement, \"nodes\" list containing nodes model, \"parents\" list parents nodes model, \"parents_df\" data frame listing nodes, whether root nodes , number names parents , \"parameters\" vector 'true' parameters, \"parameters_df\" data frame containing parameter information, \"parameter_names\" vector names parameters, \"parameter_mapping\" matrix mapping parameters data types, \"parameter_matrix\" matrix mapping parameters causal types, \"causal_types\" data frame listing causal types nodal types produce , \"nodal_types\" list nodal types model, \"data_types\" list data types consistent model; options see `\"?get_all_data_types\"`, \"prior_hyperparameters\" vector alpha values used parameterize Dirichlet prior distributions; optionally provide node names reduce output `inspect(prior_hyperparameters, c('M', 'Y'))` \"prior_distribution\" data frame parameter prior distribution, \"prior_event_probabilities\" vector data (event) probabilities given single (sepcified) parameter vector; options see `\"?get_event_probabilities\"`, \"ambiguities_matrix\" matrix mapping causal types data types, \"type_prior\" matrix type probabilities using priors, \"type_distribution\" matrix type probabilities using posteriors, \"posterior_distribution\" data frame parameter posterior distribution, \"posterior_event_probabilities\" sample data (event) probabilities posterior, \"data\" data frame data used update model. \"stanfit\" `stanfit` object generated Stan, \"stan_summary\" `stanfit` summary updated parameter names, \"stan_objects\" list Stan outputs includes `stanfit`, `data`, , requested updating model, posterior `event_probabilities` `type_distribution`.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/summary.causal_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarizing causal models ‚Äî summary.causal_model","text":"","code":"# \\donttest{ model <-   make_model(\"X -> Y\")  model |>   update_model(     keep_event_probabilities = TRUE,     keep_fit = TRUE,     data = make_data(model, n = 100)   ) |>   summary() #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.1e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.245 seconds (Warm-up) #> Chain 1:                0.362 seconds (Sampling) #> Chain 1:                0.607 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1.6e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.279 seconds (Warm-up) #> Chain 2:                0.264 seconds (Sampling) #> Chain 2:                0.543 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 1.9e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.263 seconds (Warm-up) #> Chain 3:                0.199 seconds (Sampling) #> Chain 3:                0.462 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 1.6e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.277 seconds (Warm-up) #> Chain 4:                0.322 seconds (Sampling) #> Chain 4:                0.599 seconds (Total) #> Chain 4:  #>  #> Causal statement:  #> X -> Y #>  #> Nodal types:  #> $X #> 0  1 #>  #>   node position display interpretation #> 1    X       NA      X0          X = 0 #> 2    X       NA      X1          X = 1 #>  #> $Y #> 00  10  01  11 #>  #>   node position display interpretation #> 1    Y        1   Y[*]*      Y | X = 0 #> 2    Y        2   Y*[*]      Y | X = 1 #>  #> Number of types by node: #> X Y  #> 2 4  #>  #> Number of causal types:  8 #>  #> Model has been updated and contains a posterior distribution with #> 4 chains, each with iter=2000; warmup=1000; thin=1;   #> Use inspect(model, 'stan_summary') to inspect stan summary #>  #> Note: To pose causal queries of this model use query_model() #>  # }  # \\donttest{ model <-   make_model(\"X -> Y\") |>   update_model(     keep_event_probabilities = TRUE,     keep_fit = TRUE,     data = make_data(model, n = 100)   ) #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.31 seconds (Warm-up) #> Chain 1:                0.255 seconds (Sampling) #> Chain 1:                0.565 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1.8e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.309 seconds (Warm-up) #> Chain 2:                0.334 seconds (Sampling) #> Chain 2:                0.643 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 1.7e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.337 seconds (Warm-up) #> Chain 3:                0.424 seconds (Sampling) #> Chain 3:                0.761 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 2e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.28 seconds (Warm-up) #> Chain 4:                0.284 seconds (Sampling) #> Chain 4:                0.564 seconds (Total) #> Chain 4:   print(summary(model), what = \"type_distribution\") #>  #> type_distribution #> Posterior draws of causal types (transformed parameters): #>  #>   Distributions matrix dimensions are  #>   4000 rows (draws) by 8 cols (causal types) #>  #>        mean   sd #> X0.Y00 0.09 0.06 #> X1.Y00 0.10 0.06 #> X0.Y10 0.09 0.06 #> X1.Y10 0.10 0.06 #> X0.Y01 0.14 0.06 #> X1.Y01 0.16 0.07 #> X0.Y11 0.15 0.06 #> X1.Y11 0.17 0.07 print(summary(model), what = \"posterior_distribution\") #>  #> posterior_distribution #> Summary statistics of model parameters posterior distributions: #>  #>   Distributions matrix dimensions are  #>   4000 rows (draws) by 6 cols (parameters) #>  #>      mean   sd #> X.0  0.47 0.05 #> X.1  0.53 0.05 #> Y.00 0.20 0.12 #> Y.10 0.19 0.12 #> Y.01 0.29 0.13 #> Y.11 0.32 0.13 print(summary(model), what = \"posterior_event_probabilities\") #>  #> posterior_event_probabilities #> Posterior draws of event probabilities (transformed parameters): #>  #>   Distributions matrix dimensions are  #>   4000 rows (draws) by 4 cols (events) #>  #>      mean   sd #> X0Y0 0.23 0.04 #> X1Y0 0.21 0.04 #> X0Y1 0.24 0.04 #> X1Y1 0.32 0.05 print(summary(model), what = \"data_types\") #>  #> data_types (Data types): #> Data frame of all possible data (events) given the model: #>  #>      event  X  Y #> X0Y0  X0Y0  0  0 #> X1Y0  X1Y0  1  0 #> X0Y1  X0Y1  0  1 #> X1Y1  X1Y1  1  1 #> Y0      Y0 NA  0 #> Y1      Y1 NA  1 #> X0      X0  0 NA #> X1      X1  1 NA #> None  None NA NA print(summary(model), what = \"ambiguities_matrix\") #> Warning: Model summary does not contain ambiguities_matrix; to include this object use summary with 'include = 'ambiguities_matrix'' print(summary(model), what = \"prior_hyperparameters\") #>  #> prior_hyperparameters #> Alpha parameter values used for Dirichlet prior distributions: #>  #>  X.0  X.1 Y.00 Y.10 Y.01 Y.11  #>    1    1    1    1    1    1  print(summary(model), what = c(\"statement\", \"nodes\")) #>  #> Causal statement:  #> X -> Y #>  #> Nodes:  #> X, Y print(summary(model), what = \"parameters_df\") #>  #> parameters_df #> Mapping of model parameters to nodal types:  #>  #>   param_names: name of parameter #>   node:        name of endogeneous node associated #>                with the parameter #>   gen:         partial causal ordering of the #>                parameter's node #>   param_set:   parameter groupings forming a simplex #>   given:       if model has confounding gives #>                conditioning nodal type #>   param_value: parameter values #>   priors:      hyperparameters of the prior #>                Dirichlet distribution  #>  #>   param_names node gen param_set nodal_type given param_value priors #> 1         X.0    X   1         X          0              0.50      1 #> 2         X.1    X   1         X          1              0.50      1 #> 3        Y.00    Y   2         Y         00              0.25      1 #> 4        Y.10    Y   2         Y         10              0.25      1 #> 5        Y.01    Y   2         Y         01              0.25      1 #> 6        Y.11    Y   2         Y         11              0.25      1 print(summary(model), what = \"posterior_event_probabilities\") #>  #> posterior_event_probabilities #> Posterior draws of event probabilities (transformed parameters): #>  #>   Distributions matrix dimensions are  #>   4000 rows (draws) by 4 cols (events) #>  #>      mean   sd #> X0Y0 0.23 0.04 #> X1Y0 0.21 0.04 #> X0Y1 0.24 0.04 #> X1Y1 0.32 0.05 print(summary(model), what = \"posterior_distribution\") #>  #> posterior_distribution #> Summary statistics of model parameters posterior distributions: #>  #>   Distributions matrix dimensions are  #>   4000 rows (draws) by 6 cols (parameters) #>  #>      mean   sd #> X.0  0.47 0.05 #> X.1  0.53 0.05 #> Y.00 0.20 0.12 #> Y.10 0.19 0.12 #> Y.01 0.29 0.13 #> Y.11 0.32 0.13 print(summary(model), what = \"data\") #>  #> Data used to update the model: #>  #> data #>   Data frame dimensions are  #>   100 rows by 2 cols #>  #>  #> snippet (use grab() to access full 100 x 2 object):  #>  #>    X Y #> 1  0 0 #> 2  0 0 #> 3  0 0 #> 4  0 0 #> 5  0 0 #> 6  0 0 #> 7  0 0 #> 8  0 0 #> 9  0 0 #> 10 0 0 print(summary(model), what = \"stanfit\") #>  #> stanfit #> Stan model summary: #> Inference for Stan model: simplexes. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>              mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> lambdas[1]   0.47    0.00 0.05   0.37   0.44   0.47   0.50   0.56  1445    1 #> lambdas[2]   0.53    0.00 0.05   0.44   0.50   0.53   0.56   0.63  1445    1 #> lambdas[3]   0.20    0.00 0.12   0.01   0.10   0.19   0.29   0.42   723    1 #> lambdas[4]   0.19    0.00 0.12   0.01   0.10   0.19   0.29   0.41   836    1 #> lambdas[5]   0.29    0.00 0.13   0.04   0.19   0.30   0.40   0.53   920    1 #> lambdas[6]   0.32    0.00 0.13   0.06   0.22   0.32   0.42   0.55  1015    1 #> w[1]         0.23    0.00 0.04   0.16   0.20   0.23   0.26   0.31  2226    1 #> w[2]         0.21    0.00 0.04   0.14   0.18   0.21   0.23   0.29  2466    1 #> w[3]         0.24    0.00 0.04   0.16   0.21   0.24   0.27   0.32  2354    1 #> w[4]         0.32    0.00 0.05   0.24   0.29   0.32   0.35   0.42  2084    1 #> types[1]     0.09    0.00 0.06   0.01   0.05   0.09   0.13   0.20   738    1 #> types[2]     0.10    0.00 0.06   0.01   0.05   0.10   0.15   0.23   745    1 #> types[3]     0.09    0.00 0.06   0.00   0.05   0.09   0.13   0.20   840    1 #> types[4]     0.10    0.00 0.06   0.00   0.05   0.10   0.15   0.22   860    1 #> types[5]     0.14    0.00 0.06   0.02   0.09   0.14   0.18   0.26   924    1 #> types[6]     0.16    0.00 0.07   0.02   0.10   0.16   0.21   0.29   961    1 #> types[7]     0.15    0.00 0.06   0.03   0.10   0.15   0.19   0.27  1041    1 #> types[8]     0.17    0.00 0.07   0.03   0.11   0.17   0.22   0.30  1030    1 #> lp__       -14.42    0.05 1.58 -18.40 -15.22 -14.05 -13.26 -12.41   865    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Nov 27 14:46:27 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). print(summary(model), what = \"type_distribution\") #>  #> type_distribution #> Posterior draws of causal types (transformed parameters): #>  #>   Distributions matrix dimensions are  #>   4000 rows (draws) by 8 cols (causal types) #>  #>        mean   sd #> X0.Y00 0.09 0.06 #> X1.Y00 0.10 0.06 #> X0.Y10 0.09 0.06 #> X1.Y10 0.10 0.06 #> X0.Y01 0.14 0.06 #> X1.Y01 0.16 0.07 #> X0.Y11 0.15 0.06 #> X1.Y11 0.17 0.07 # }"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/summary.model_query.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing model queries ‚Äî summary.model_query","title":"Summarizing model queries ‚Äî summary.model_query","text":"summary method class \"model_query\".","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/summary.model_query.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing model queries ‚Äî summary.model_query","text":"","code":"# S3 method for class 'model_query' summary(object, ...)  # S3 method for class 'summary.model_query' print(x, ...)"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/summary.model_query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing model queries ‚Äî summary.model_query","text":"object object model_query class produced using query_model ... arguments passed methods. x object model_query class produced using query_model","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/summary.model_query.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarizing model queries ‚Äî summary.model_query","text":"Returns object class summary.model_query","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/summary.model_query.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarizing model queries ‚Äî summary.model_query","text":"","code":"# \\donttest{ model <-   make_model(\"X -> Y\") |>   query_model(\"Y[X=1] > Y[X=1]\")  |>   summary() #> Call:  #> query_model(model = make_model(\"X -> Y\"), queries = \"Y[X=1] > Y[X=1]\")  #>  #> Queries evaluated on:  #> Wed Nov 27 14:46:28 2024 #>  #> Causal queries generated by query_model (all at population level) #>  #> |query           |using      | mean| #> |:---------------|:----------|----:| #> |Y[X=1] > Y[X=1] |parameters |    0| #>  # }"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/update_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit causal model using 'stan' ‚Äî update_model","title":"Fit causal model using 'stan' ‚Äî update_model","text":"Takes model data returns model object data attached posterior model","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/update_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit causal model using 'stan' ‚Äî update_model","text":"","code":"update_model(   model,   data = NULL,   data_type = NULL,   keep_type_distribution = TRUE,   keep_event_probabilities = FALSE,   keep_fit = FALSE,   censored_types = NULL,   ... )"},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/update_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit causal model using 'stan' ‚Äî update_model","text":"model causal_model. model object generated make_model. data data.frame.  Data nodes can take three values: 0, 1, NA. long form generated make_events data_type Either 'long' (made make_data) 'compact' (made collapse_data). Compact data must entries member strategy family produce valid simplex. long form data provided missingness, missing data assumed missing random. keep_type_distribution Logical. Whether keep (transformed) distribution causal types.  Defaults `TRUE` keep_event_probabilities Logical. Whether keep (transformed) distribution event probabilities. Defaults `FALSE` keep_fit Logical. Whether keep stanfit object produced sampling inspection. See ?stanfit details. Defaults `FALSE`. Note  stanfit object internal names parameters (lambda), event probabilities (w), type distribution (types) censored_types vector data types selected data, e.g. c(\"X0Y0\") ... Options passed onto sampling call. details see ?rstan::sampling","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/update_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit causal model using 'stan' ‚Äî update_model","text":"object class causal_model. returned model   list containing elements comprising model   (e.g. 'statement', 'nodal_types' 'DAG')   posterior_distribution returned stan   attached .","code":""},{"path":[]},{"path":"https://integrated-inferences.github.io/CausalQueries/reference/update_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit causal model using 'stan' ‚Äî update_model","text":"","code":"model <- make_model('X->Y')  data_long   <- make_data(model, n = 4)  data_short  <- collapse_data(data_long, model)  model <-  update_model(model, data_long) #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.2e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.143 seconds (Warm-up) #> Chain 1:                0.142 seconds (Sampling) #> Chain 1:                0.285 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1.6e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.142 seconds (Warm-up) #> Chain 2:                0.119 seconds (Sampling) #> Chain 2:                0.261 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 1.5e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.131 seconds (Warm-up) #> Chain 3:                0.136 seconds (Sampling) #> Chain 3:                0.267 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 1.8e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.144 seconds (Warm-up) #> Chain 4:                0.128 seconds (Sampling) #> Chain 4:                0.272 seconds (Total) #> Chain 4:   model <-  update_model(model, data_short) #> Warning: count column should be integer valued; value has been forced to integer #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.1e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.139 seconds (Warm-up) #> Chain 1:                0.174 seconds (Sampling) #> Chain 1:                0.313 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1.6e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.139 seconds (Warm-up) #> Chain 2:                0.138 seconds (Sampling) #> Chain 2:                0.277 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 2.3e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.138 seconds (Warm-up) #> Chain 3:                0.122 seconds (Sampling) #> Chain 3:                0.26 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 2e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.138 seconds (Warm-up) #> Chain 4:                0.166 seconds (Sampling) #> Chain 4:                0.304 seconds (Total) #> Chain 4:      # It is possible to implement updating without data, in which    # case the posterior is a stan object that reflects the prior     update_model(model) #> No data provided #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 3.6e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.36 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.133 seconds (Warm-up) #> Chain 1:                0.143 seconds (Sampling) #> Chain 1:                0.276 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 2e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.129 seconds (Warm-up) #> Chain 2:                0.136 seconds (Sampling) #> Chain 2:                0.265 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 2.4e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.24 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.128 seconds (Warm-up) #> Chain 3:                0.124 seconds (Sampling) #> Chain 3:                0.252 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'simplexes' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 3.1e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.31 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.128 seconds (Warm-up) #> Chain 4:                0.113 seconds (Sampling) #> Chain 4:                0.241 seconds (Total) #> Chain 4:  #>  #> Causal statement:  #> X -> Y #>  #> Number of nodal types by node: #> X Y  #> 2 4  #>  #> Number of causal types: 8 #>  #> Model has been updated and contains a posterior distribution with #> 4 chains, each with iter=2000; warmup=1000; thin=1;   #> Use inspect(model, 'stan_objects') to inspect stan summary #>    if (FALSE) { # \\dontrun{     # Censored data types illustrations    # Here we update less than we might because we are aware of filtered data     data <- data.frame(X=rep(0:1, 10), Y=rep(0:1,10))    uncensored <-      make_model(\"X->Y\") |>      update_model(data) |>      query_model(te(\"X\", \"Y\"), using = \"posteriors\")     censored <-      make_model(\"X->Y\") |>      update_model(        data,        censored_types = c(\"X1Y0\")) |>      query_model(te(\"X\", \"Y\"), using = \"posteriors\")      # Censored data: We learn nothing because the data    # we see is the only data we could ever see    make_model(\"X->Y\") |>      update_model(        data,        censored_types = c(\"X1Y0\", \"X0Y0\", \"X0Y1\")) |>      query_model(te(\"X\", \"Y\"), using = \"posteriors\")  } # }"},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"causalqueries-121","dir":"Changelog","previous_headings":"","what":"CausalQueries 1.2.1","title":"CausalQueries 1.2.1","text":"CRAN release: 2024-11-05 minor release introducing changes meant focus S3 methods utility functions around two core classes: causal_model model_query. aim improve user experience CausalQueries focusing user facing functionality clearly around workflow making, updating, querying inspecting causal models. respect causal_model objects release introduces expressive concise S3 summary print methods causal_model class internal objects. Updates grab() inspect() functions streamline access objects contained within causal_model, facilitating advanced use-cases deeper review. release introduces model_query class along S3 summary, print plot methods seamless querying workflow. Finally, release removes dependency dagitty, restoring compatibility CausalQueries systems V8 JavaScript WASM supported.","code":""},{"path":[]},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"id_1-improved-causal_model-summaries-1-2-1","dir":"Changelog","previous_headings":"New Functionality","what":"1. Improved causal_model summaries","title":"CausalQueries 1.2.1","text":"summary() method objects class causal_model now supports include argument allowing users specify additional objects internal causal_model object like summaries appended main output summary(). Summaries additionally made informative readable. Please see ?summary.causal_model extensive documentation new functionality.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"id_2-streamlined-causal_model-object-access-1-2-1","dir":"Changelog","previous_headings":"New Functionality","what":"2. Streamlined causal_model object access","title":"CausalQueries 1.2.1","text":"Internal objects causal_model instance can now returned quietly via grab() eliminating need interact causal_model instance directly.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"id_3-new-querying-utility-functionality-1-2-1","dir":"Changelog","previous_headings":"New Functionality","what":"3. New querying utility functionality","title":"CausalQueries 1.2.1","text":"newly introduced model_query class comes print, summary plot method. plot() generates coefficient plot credible intervals evaluated queries.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"causalqueries-111","dir":"Changelog","previous_headings":"","what":"CausalQueries 1.1.1","title":"CausalQueries 1.1.1","text":"CRAN release: 2024-04-26 patch release fixing bug print.model_query() S3 method occurred querying models using paramters.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"causalqueries-110","dir":"Changelog","previous_headings":"","what":"CausalQueries 1.1.0","title":"CausalQueries 1.1.0","text":"CRAN release: 2024-04-10","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"non-backwards-compatible-changes-1-1-0","dir":"Changelog","previous_headings":"","what":"Non Backwards Compatible Changes","title":"CausalQueries 1.1.0","text":"Accessing causal-model objects via get_ methods e.g.¬†get_nodal_types(), get_parameters longer supported. Objects may now accessed via unified syntax inspect() function (see New Functionality). following functions longer exported: get_causal_types() get_nodal_types() get_all_data_types() get_event_probabilities() get_ambiguities_matrix() get_parameters() get_parameter_names() get_parmap() get_parameter_matrix() get_priors() get_param_dist() get_type_prob_multiple()","code":""},{"path":[]},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"id_1-unified-object-access-syntax-via-inspect-1-1-0","dir":"Changelog","previous_headings":"New Functionality","what":"1. unified object access syntax via inspect()","title":"CausalQueries 1.1.0","text":"causal-model objects can now accessed via inspect() like : See documentation exhaustive list accessible objects. causal-model objects now additionally come dedicated print methods returning short informative summaries given object.","code":"inspect(model, \"parameters_df\")"},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"id_2-model-diagnostics-1-1-0","dir":"Changelog","previous_headings":"New Functionality","what":"2. model diagnostics","title":"CausalQueries 1.1.0","text":"summary parameter values convergence information produced update_model() Stan model can now accessed via: Advanced model diagnostics raw Stan output via external packages possible saving stan_fit object updating. facilitated via keep_fit option update_model():","code":"inspect(model, \"stan_summary\") model <- make_model(\"X -> Y\") |>   update_model(data, keep_fit = TRUE)  model |> inspect(\"stanfit\")"},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"causalqueries-102","dir":"Changelog","previous_headings":"","what":"CausalQueries 1.0.2","title":"CausalQueries 1.0.2","text":"CRAN release: 2024-01-15","code":""},{"path":[]},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"id_1-passing-nodal_types-to-make_model-now-implements-correct-error-handling-1-0-2","dir":"Changelog","previous_headings":"Bug Fixes","what":"1. passing nodal_types to make_model() now implements correct error handling","title":"CausalQueries 1.0.2","text":"Previously make_model(\"X -> Y\" , nodal_types = list(Y = c(\"0\", \"1\"))) permissible leading setting nodal_types: led undefined behavior unhelpful downstream error messages. passing nodal_types make_model() users now forced specify set nodal_types node.","code":"$X NULL  $Y [1] \"0\" \"1\""},{"path":[]},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"id_3-node-naming-checks-are-operational-in-make_model-1-0-2","dir":"Changelog","previous_headings":"Bug Fixes","what":"3. node naming checks are operational in make_model()","title":"CausalQueries 1.0.2","text":"Previously hyphenated names throw error corrupted silently conversion model definition strings dagitty objects. Checks correct variable naming now reinstated.","code":"make_model(\"institutions -> political-inequality\")  Statement: [1] \"institutions -> political-inequality\"  DAG:         parent  children 1 institutions political"},{"path":[]},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"id_1-type-safety-1-0-2","dir":"Changelog","previous_headings":"Improvements","what":"1. type safety","title":"CausalQueries 1.0.2","text":"Calls sapply() ben replaced vapply() wherever possible enforce type safety.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"id_2-range-based-looping-1-0-2","dir":"Changelog","previous_headings":"Improvements","what":"2. range based looping","title":"CausalQueries 1.0.2","text":"Looping via index replaced range based looping wherever possible guard 0 length exceptions.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"id_3-goodpracticegp-1-0-2","dir":"Changelog","previous_headings":"Improvements","what":"3. goodpractice::gp()","title":"CausalQueries 1.0.2","text":"goodpractice code improvements implemented.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"causalqueries-100","dir":"Changelog","previous_headings":"","what":"CausalQueries 1.0.0","title":"CausalQueries 1.0.0","text":"CRAN release: 2023-10-13","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"non-backwards-compatible-changes-1-0-0","dir":"Changelog","previous_headings":"","what":"Non Backwards Compatible Changes","title":"CausalQueries 1.0.0","text":"query_distribution() now supports use multiple queries one function call thus returns DataFrame distribution draws instead single numeric vector.","code":""},{"path":[]},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"querying-1-0-0","dir":"Changelog","previous_headings":"New Functionality","what":"Querying","title":"CausalQueries 1.0.0","text":"query_distribution(): now supports specification multiple queries givens evaluated single model one function call. query_model(): now supports specification multiple models evaluate set queries one function call. eliminates need redundant function calls querying models substantially improves computation time computationally expensive function calls produce data structures required querying now reduced minimum via redundancy elimination caching.","code":"model <- make_model(\"X -> Y\")   query_distribution(model,    query = list(\"(Y[X=1] > Y[X=0])\", \"(Y[X=1] < Y[X=0])\"),    given = list(\"Y==1\", \"(Y[X=1] <= Y[X=0])\"),    using = \"priors\")|>  head() models <- list(   M1 = make_model(\"X -> Y\"),   M2 = make_model(\"X -> Y\") |> set_restrictions(\"Y[X=1] < Y[X=0]\")   )   query_model(   models,   query = list(ATE = \"Y[X=1] - Y[X=0]\", Share_positive = \"Y[X=1] > Y[X=0]\"),   given = c(TRUE,  \"Y==1 & X==1\"),   using = c(\"parameters\", \"priors\"),   expand_grid = FALSE)   query_model(   models,   query = list(ATE = \"Y[X=1] - Y[X=0]\", Share_positive = \"Y[X=1] > Y[X=0]\"),   given = c(TRUE,  \"Y==1 & X==1\"),   using = c(\"parameters\", \"priors\"),   expand_grid = TRUE)"},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"realising-outcomes-and-interpreting-nodal-causal-types-1-0-0","dir":"Changelog","previous_headings":"New Functionality","what":"Realising Outcomes and Interpreting Nodal-/Causal-Types","title":"CausalQueries 1.0.0","text":"realise_outcomes(): specifying node option now produces DataFrame detailing specified node responds parents presence absence operations. produces reduced form usual realise_outcomes() output detailing causal-types; aids interpretation nodal- causal-types. update resolves previous bugs errors relating specification nodes multiple parents node option.","code":"model <- make_model(\"X1 -> M -> Y -> Z; X2 -> Y\") |>   realise_outcomes(dos = list(M = 1), node = \"Y\")"},{"path":[]},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"id_1-setting-parameters-and-priors-1-0-0","dir":"Changelog","previous_headings":"Bug Fixes","what":"1. Setting Parameters and Priors","title":"CausalQueries 1.0.0","text":"Previously set_parameters() set_priors() default applying changes order parameters appeared parameters_df DataFrame; regardless order changes specified aforementioned functions. Calling: results following parameters_df. Now changes parameters values get applied order specified function call; resulting following parameters_df example: Additionally implemented helpful warnings instructions identifying parameters updated specified. particularly useful setting priors parameters models confounding changes may inadvertently applied across param_sets.","code":"model <- make_model(\"X -> Y\")  set_priors(model, alphas = c(3,4), nodal_type = c(\"10\",00)) param_names node    gen param_set nodal_type given param_value priors   <chr>       <chr> <int> <chr>     <chr>      <chr>       <dbl>  <dbl> 1 X.0         X         1 X         0          \"\"           0.5       1 2 X.1         X         1 X         1          \"\"           0.5       1 3 Y.00        Y         2 Y         00         \"\"           0.25      3 4 Y.10        Y         2 Y         10         \"\"           0.25      4 5 Y.01        Y         2 Y         01         \"\"           0.25      1 6 Y.11        Y         2 Y         11         \"\"           0.25      1 param_names node    gen param_set nodal_type given param_value priors   <chr>       <chr> <int> <chr>     <chr>      <chr>       <dbl>  <dbl> 1 X.0         X         1 X         0          \"\"           0.5       1 2 X.1         X         1 X         1          \"\"           0.5       1 3 Y.00        Y         2 Y         00         \"\"           0.25      4 4 Y.10        Y         2 Y         10         \"\"           0.25      3 5 Y.01        Y         2 Y         01         \"\"           0.25      1 6 Y.11        Y         2 Y         11         \"\"           0.25      1"},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"id_2-updating-with-censored-types-1-0-0","dir":"Changelog","previous_headings":"Bug Fixes","what":"2. Updating with Censored Types","title":"CausalQueries 1.0.0","text":"Previously updating models censored types fail 0s w vector induced censoring evaluate -Inf Stan MCMC algorithm began sampling posterior multinational distribution. resolved issue pruning w vector multinomial run. preserves true w vector (event probabilities without censoring) still updating censored data-","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"id_3-setting-restrictions-with-wild-cards-1-0-0","dir":"Changelog","previous_headings":"Bug Fixes","what":"3. Setting Restrictions with Wild Cards","title":"CausalQueries 1.0.0","text":"Previously wildcards set_restrictions() erroneously interpreted valid nodal types, leading errors undefined behavior. Proper unpacking mapping wildcards existing nodal types restored.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"id_4-checks-for-misspecified-queries-1-0-0","dir":"Changelog","previous_headings":"Bug Fixes","what":"4. Checks for Misspecified Queries","title":"CausalQueries 1.0.0","text":"Previously misspecifications queries like Y[X==1]=1 lead undefined behavior mapping queries nodal causal types. now correct misspecified queries internally warn misspecification. example; running: now produces","code":"model <- CausalQueries::make_model(\"X -> Y\") get_query_types(model, \"Y[X=1]=1\") Causal types satisfying query's condition(s)   query =  Y[X=1]==1  X0.Y01  X1.Y01 X0.Y11  X1.Y11    Number of causal types that meet condition(s) =  4  Total number of causal types in model =  8 Warning message: In check_query(query) :   statements to the effect that the realization of a node should equal some value should be specified with `==` not `=`.   The query has been changed accordingly: Y[X=1]==1"},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"id_5-allowing-overwriting-of-a-parameter-matrix-1-0-0","dir":"Changelog","previous_headings":"Bug Fixes","what":"5. Allowing overwriting of a Parameter Matrix","title":"CausalQueries 1.0.0","text":"Previously parameter matrix P attached causal_model object overwritten. Overwrites now possible.","code":""},{"path":[]},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"id_1-fast-realise_outcomes-1-0-0","dir":"Changelog","previous_headings":"Improvements","what":"1. Fast realise_outcomes()","title":"CausalQueries 1.0.0","text":"achieved ~100 fold speed gain realise_outcomes() functionality. Nodal types given node generated Cartesian product parent realizations. Consider meaning nodal types node YY 3 parents [X1,X2,X3][X1,X2,X3]: row DataFrame corresponds digit Y's nodal types. first digit nodal type YY (see first row ), corresponds realization YY X1=0,X2=0,X3=0X1 = 0, X2 = 0, X3 = 0. fourth digit nodal type YY (see fourth row ), corresponds realization YY X1=1,X2=1,X3=0X1 = 1, X2 = 1, X3 = 0. Finding position realization value YY nodal type given parent realizations equivalent finding row number Cartesian product DataFrame. definition Cartesian product, number consecutive 0 1 elements given column 2columnindex2^{columnindex}, indexing columns 0. Given set parent realizations RR indexed 0, corresponding row number DataFrame indexed 0 can thus computed via: row=(‚àë=0|R|‚àí1(2i√óRi))row = (\\sum_{= 0}^{|R| - 1} (2^{} \\times R_i)). implement fast C++ version computing powers 2 via bit shifting.","code":""},{"path":"https://integrated-inferences.github.io/CausalQueries/news/index.html","id":"id_2-stan-update-1-0-0","dir":"Changelog","previous_headings":"Improvements","what":"2. Stan update","title":"CausalQueries 1.0.0","text":"updated new array syntax introduced Stan v2.33.0","code":""}]
