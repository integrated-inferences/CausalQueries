% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/process_tracing_strategies.R
\name{expected_learning}
\alias{expected_learning}
\title{Expected learning}
\usage{
expected_learning(model, query, strategy = NULL, given = NULL,
  parameters = NULL)
}
\arguments{
\item{model}{A  model}

\item{query}{A query as a character string, for example 'Y[X=1]>Y[X=0]'}

\item{strategy}{A set of variables to be sought}

\item{given}{A conditioning set as a character string that evaluates to a logical, for example 'Y==1'}

\item{parameters}{a parameter vector}
}
\description{
Expected reduction in variance from one step data collection strategy
}
\examples{
# Reduction in variance given monotonic X -> M1 -> M2 -> Y model
library(dplyr)
model <- make_model("X -> M1 -> M2 -> Y") \%>\%
  set_restrictions(node_restrict = list(M1 = "10", M2 = "10", Y = "10")) \%>\%
  set_priors() \%>\%
  set_parameters(type = 'flat')
el <- expected_learning(model, query = "Y[X=1]>Y[X=0]",
                  strategy = c("X", "M2"), given = "Y==1")
attr(el, "results_table")
el2 <- expected_learning(model, query = "Y[X=1]>Y[X=0]",
                  strategy = c("M1"), given = "Y==1 & X==1 & M2==1")
attr(el2, "results_table")

# No strategy
expected_learning(model, query = "Y[X=1]>Y[X=0]")

# No givens
expected_learning(model, query = "Y[X=1]>Y[X=0]", strategy = c("M1"))
expected_learning(model, query = "Y[X=1]>Y[X=0]", strategy = c("M1"), given = "Y==1")


library(dplyr)
 model <-  make_model("S -> C -> Y <- R <- X; X -> C -> R") \%>\%
 set_restrictions(node_restrict = list(C = "C1110", R = "R0001", Y = "Y0001"), action = "keep")
expected_learning(model, query = list(COE = "(Y[S=0] > Y[S=1])"), strategy = "C", given = "Y==1 & S==0")
expected_learning(model, query = list(COE = "(Y[X=1] > Y[X=0])"), strategy = "S", given = "X==0 & Y==0")
}
